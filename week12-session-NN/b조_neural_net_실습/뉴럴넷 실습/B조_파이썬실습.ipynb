{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B조 파이썬 실습 : 역전파~ 신경망 관련 학습 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- 순전파forward propagation : 계산을 왼쪽에서 오른쪽으로 진행\n",
    "\n",
    "\n",
    "- 역전파backward propagation : 계산을 반대 방향으로 진행. 미분을 효율적으로 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buy_apple문제\n",
    "#### 슈퍼에서 1개 100원인 사과를 2개 사고 소비세가 10%일 때, 지불 금액은?\n",
    "\n",
    "100 * 2 * 1.1 = 220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src ='./계산함수그림.png'  > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 사과 가격이 오를 때 최종 가격에 미치는 영향(=사과 가격에 대한 지불 금액의 미분)을 구하고 싶다.\n",
    "따라서 사과 값 : x, 지불 금액 : L일 때, ∂L/∂x를 구하는 것.\n",
    "\n",
    "계산 그래프의 역전파를 이용해서 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 곱셈 계층 구현\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "# 순전파(forward)\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "print(price) # 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 220\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dTax: 200\n"
     ]
    }
   ],
   "source": [
    "# 역전파(backward): 호출순서가 forward() 때와 반대. backward()가 받는 인수는 '순전파의 출력에 대한 미분'임을 주의!\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print('price:', int(price)) # 220\n",
    "print('dApple:', dapple) # 2.2\n",
    "print('dApple_num:', int(dapple_num)) # 110\n",
    "print('dTax:', dtax) # 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 덧셈 계층 구현\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer= MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n"
     ]
    }
   ],
   "source": [
    "# 순전파(forward)\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num) #(1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num) #(2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price) #(3)\n",
    "price = mul_tax_layer.forward(all_price, tax) #(4)\n",
    "\n",
    "print(price) # 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dOrange: 3.3000000000000003\n",
      "dOrange_num: 165\n",
      "dTax: 650\n"
     ]
    }
   ],
   "source": [
    "# 역전파(backward) - 미분\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice) #(4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) #(3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price) #(2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price) #(1)\n",
    "\n",
    "print('price:', int(price)) # 715\n",
    "print('dApple:', dapple) # 2.2\n",
    "print('dApple_num:', int(dapple_num)) # 110\n",
    "print('dOrange:', dorange) # 3.3\n",
    "print('dOrange_num:', int(dorange_num)) # 165\n",
    "print('dTax:', dtax) # 650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 학습 순서\n",
    "\n",
    "**전제**\n",
    "신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 '학습'이라 한다. 신경망 학습은 다음과 같이 4단계로 수행한다.\n",
    "\n",
    "**1단계 - 미니배치**\n",
    "훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실함수 값을 줄이는 것이 목표이다.\n",
    "\n",
    "**2단계 - 기울기 산출**\n",
    "미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다.\n",
    "\n",
    "**3단계 - 매개변수 갱신**\n",
    "가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.\n",
    "\n",
    "**4단계 - 반복**\n",
    "1~3단계를 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 수치 미분과 오차역전파법은 2단계에서 사용\n",
    "- 수치 미분은 구현은 쉽지만 계산이 오래걸림\n",
    "- 오차역전파법을 통해 기울기를 효율적이고 빠르게 구할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient_check(오차역전파법으로 구한 기울기 검증하기)\n",
    "\n",
    "앞에서 설명했듯이, 기울기를 구하는데에는 두 가지 방법이 있다.\n",
    "1. 수치 미분 : 느리다. 구현이 쉽다.\n",
    "2. 해석적으로 수식을 풀기(오차 역전파법) : 빠르지만 실수가 있을 수 있다.\n",
    "\n",
    "두 기울기 결과를 비교해서 오차역전파법을 제대로 구현했는지 검증한다. 이 작업을 기울기 확인(gradient check)라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2:1.201261257133268e-10\n",
      "b1:7.507472102685309e-13\n",
      "W1:2.283005110575095e-13\n",
      "W2:8.148377105433175e-13\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 차이의 절댓값을 구한 후, 그 절댓값들의 평균(절대 오차의 평균)을 구한다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key + ':' + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 확인해 보면, 수치 미분과 오차역전파법으로 구한 기울기의 차이가 매우 작다. 이는 오차역전파가 실수 없이 구현되었을 확률이 높다는 것을 의미한다.\n",
    "컴퓨터가 할 수 있는 계산의 정밀도가 유한하기 때문에 수치 미분과 오차역전파법의 결과 오차는 0이 될 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라메터\n",
    "iters_num = 10000 # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에포당 반복 수 (1에포: 학습 횟수)\n",
    "iter_per_epoch = max(train_size / batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "train set accuracy: 0.10583333333333333  test accuracy: 0.105\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9036  test accuracy: 0.9053\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.92305  test accuracy: 0.9235\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9351666666666667  test accuracy: 0.9358\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9399666666666666  test accuracy: 0.9389\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9501833333333334  test accuracy: 0.948\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9546666666666667  test accuracy: 0.9521\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9589  test accuracy: 0.9557\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9603166666666667  test accuracy: 0.9569\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9657166666666667  test accuracy: 0.9603\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9693  test accuracy: 0.9632\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.96975  test accuracy: 0.962\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9715666666666667  test accuracy: 0.9649\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.97455  test accuracy: 0.9661\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9758166666666667  test accuracy: 0.9656\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9784333333333334  test accuracy: 0.9674\n",
      "-------------------------------------------\n",
      "train set accuracy: 0.9770333333333333  test accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 오차역전파법으로 기울기를 구한다.\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에포당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print('-------------------------------------------')\n",
    "        print('train set accuracy: %s  test accuracy: %s'%(train_acc, test_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치정규화\n",
    "> 각 층이 활성화 값을 적당히 퍼트리는 것을 강제하도록 하는 것을 배치 정규화Batch Normalization\n",
    "이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋을 사용하여 학습진도 차이를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.optimizer import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "x_train = x_train[:1000] \n",
    "t_train = t_train[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayerNetExtend\n",
    ">완전 연결 다층 신경망(확장판)\n",
    "  가중치 감소, 드롭아웃, 배치 정규화 구현\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    weight_decay_lambda : 가중치 감소(L2 법칙)의 세기\n",
    "    use_dropout : 드롭아웃 사용 여부\n",
    "    dropout_ration : 드롭아웃 비율\n",
    "    use_batchNorm : 배치 정규화 사용 여부\n",
    "> 대부분의 초깃값 표준편차에서 학습 진도가 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __train(weight_init_std):\n",
    "    bn_network = MultiLayerNetExtend(\n",
    "            input_size=784,\n",
    "            hidden_size_list=[100, 100, 100, 100, 100],\n",
    "            output_size=10,\n",
    "            weight_init_std=weight_init_std,\n",
    "            use_batchnorm=True,\n",
    "    )\n",
    "    network = MultiLayerNetExtend(\n",
    "            input_size=784,\n",
    "            hidden_size_list=[100, 100, 100, 100, 100],\n",
    "            output_size=10,\n",
    "            weight_init_std=weight_init_std,\n",
    "    )\n",
    "    optimizer = SGD(lr=learning_rate)\n",
    "    \n",
    "    train_acc_list = []\n",
    "    bn_train_acc_list = []\n",
    "    \n",
    "    iter_per_epoch = max(train_size / batch_size, 1)\n",
    "    epoch_cnt = 0\n",
    "    \n",
    "    for i in range(1000000000):\n",
    "        batch_mask = np.random.choice(train_size, batch_size)\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = t_train[batch_mask]\n",
    "        \n",
    "        for _network in (bn_network, network):\n",
    "            grads = _network.gradient(x_batch, t_batch)\n",
    "            optimizer.update(_network.params, grads)\n",
    "            \n",
    "        if i % iter_per_epoch == 0:\n",
    "            train_acc = network.accuracy(x_train, t_train)\n",
    "            bn_train_acc = bn_network.accuracy(x_train, t_train)\n",
    "            train_acc_list.append(train_acc)\n",
    "            bn_train_acc_list.append(bn_train_acc)\n",
    "            \n",
    "            print('epoch:' + str(epoch_cnt) + ' | ' + str(train_acc) + ' - ' + str(bn_train_acc))\n",
    "            \n",
    "            epoch_cnt += 1\n",
    "            if epoch_cnt >= max_epochs:\n",
    "                break\n",
    "                \n",
    "    return train_acc_list, bn_train_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========1/16==========\n",
      "epoch:0 | 0.087 - 0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmi\\Desktop\\뉴럴넷 실습\\common\\functions.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
      "C:\\Users\\jimmi\\Desktop\\뉴럴넷 실습\\common\\functions.py:34: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = x - np.max(x, axis=0)\n",
      "C:\\Users\\jimmi\\Desktop\\뉴럴넷 실습\\common\\layers.py:12: RuntimeWarning: invalid value encountered in less_equal\n",
      "  self.mask = (x <= 0)\n",
      "C:\\Users\\jimmi\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 | 0.097 - 0.128\n",
      "epoch:2 | 0.097 - 0.116\n",
      "epoch:3 | 0.097 - 0.128\n",
      "epoch:4 | 0.097 - 0.146\n",
      "epoch:5 | 0.097 - 0.169\n",
      "epoch:6 | 0.097 - 0.193\n",
      "epoch:7 | 0.097 - 0.216\n",
      "epoch:8 | 0.097 - 0.243\n",
      "epoch:9 | 0.097 - 0.253\n",
      "epoch:10 | 0.097 - 0.28\n",
      "epoch:11 | 0.097 - 0.29\n",
      "epoch:12 | 0.097 - 0.32\n",
      "epoch:13 | 0.097 - 0.341\n",
      "epoch:14 | 0.097 - 0.347\n",
      "epoch:15 | 0.097 - 0.357\n",
      "epoch:16 | 0.097 - 0.377\n",
      "epoch:17 | 0.097 - 0.385\n",
      "epoch:18 | 0.097 - 0.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.097 - 0.416\n",
      "==========2/16==========\n",
      "epoch:0 | 0.083 - 0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmi\\Desktop\\뉴럴넷 실습\\common\\multi_layer_net_extend.py:104: RuntimeWarning: overflow encountered in square\n",
      "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
      "C:\\Users\\jimmi\\Desktop\\뉴럴넷 실습\\common\\multi_layer_net_extend.py:104: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 | 0.097 - 0.111\n",
      "epoch:2 | 0.097 - 0.14\n",
      "epoch:3 | 0.097 - 0.164\n",
      "epoch:4 | 0.097 - 0.188\n",
      "epoch:5 | 0.097 - 0.208\n",
      "epoch:6 | 0.097 - 0.24\n",
      "epoch:7 | 0.097 - 0.255\n",
      "epoch:8 | 0.097 - 0.279\n",
      "epoch:9 | 0.097 - 0.3\n",
      "epoch:10 | 0.097 - 0.318\n",
      "epoch:11 | 0.097 - 0.333\n",
      "epoch:12 | 0.097 - 0.357\n",
      "epoch:13 | 0.097 - 0.372\n",
      "epoch:14 | 0.097 - 0.393\n",
      "epoch:15 | 0.097 - 0.402\n",
      "epoch:16 | 0.097 - 0.419\n",
      "epoch:17 | 0.097 - 0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 | 0.097 - 0.466\n",
      "epoch:19 | 0.097 - 0.475\n",
      "==========3/16==========\n",
      "epoch:0 | 0.125 - 0.08\n",
      "epoch:1 | 0.315 - 0.118\n",
      "epoch:2 | 0.424 - 0.164\n",
      "epoch:3 | 0.524 - 0.218\n",
      "epoch:4 | 0.606 - 0.266\n",
      "epoch:5 | 0.673 - 0.315\n",
      "epoch:6 | 0.685 - 0.353\n",
      "epoch:7 | 0.744 - 0.38\n",
      "epoch:8 | 0.791 - 0.429\n",
      "epoch:9 | 0.824 - 0.458\n",
      "epoch:10 | 0.854 - 0.489\n",
      "epoch:11 | 0.875 - 0.525\n",
      "epoch:12 | 0.897 - 0.552\n",
      "epoch:13 | 0.912 - 0.587\n",
      "epoch:14 | 0.927 - 0.597\n",
      "epoch:15 | 0.937 - 0.622\n",
      "epoch:16 | 0.94 - 0.635\n",
      "epoch:17 | 0.955 - 0.647\n",
      "epoch:18 | 0.961 - 0.672\n",
      "epoch:19 | 0.965 - 0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========4/16==========\n",
      "epoch:0 | 0.069 - 0.066\n",
      "epoch:1 | 0.184 - 0.091\n",
      "epoch:2 | 0.308 - 0.152\n",
      "epoch:3 | 0.407 - 0.243\n",
      "epoch:4 | 0.524 - 0.322\n",
      "epoch:5 | 0.579 - 0.411\n",
      "epoch:6 | 0.632 - 0.48\n",
      "epoch:7 | 0.664 - 0.528\n",
      "epoch:8 | 0.706 - 0.577\n",
      "epoch:9 | 0.73 - 0.613\n",
      "epoch:10 | 0.75 - 0.642\n",
      "epoch:11 | 0.77 - 0.667\n",
      "epoch:12 | 0.792 - 0.691\n",
      "epoch:13 | 0.803 - 0.715\n",
      "epoch:14 | 0.82 - 0.732\n",
      "epoch:15 | 0.818 - 0.752\n",
      "epoch:16 | 0.833 - 0.758\n",
      "epoch:17 | 0.851 - 0.775\n",
      "epoch:18 | 0.848 - 0.794\n",
      "epoch:19 | 0.862 - 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========5/16==========\n",
      "epoch:0 | 0.117 - 0.119\n",
      "epoch:1 | 0.119 - 0.173\n",
      "epoch:2 | 0.122 - 0.273\n",
      "epoch:3 | 0.13 - 0.379\n",
      "epoch:4 | 0.138 - 0.474\n",
      "epoch:5 | 0.143 - 0.546\n",
      "epoch:6 | 0.154 - 0.605\n",
      "epoch:7 | 0.17 - 0.651\n",
      "epoch:8 | 0.165 - 0.684\n",
      "epoch:9 | 0.186 - 0.723\n",
      "epoch:10 | 0.195 - 0.754\n",
      "epoch:11 | 0.2 - 0.785\n",
      "epoch:12 | 0.208 - 0.796\n",
      "epoch:13 | 0.223 - 0.814\n",
      "epoch:14 | 0.223 - 0.821\n",
      "epoch:15 | 0.22 - 0.834\n",
      "epoch:16 | 0.231 - 0.847\n",
      "epoch:17 | 0.247 - 0.853\n",
      "epoch:18 | 0.257 - 0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.266 - 0.877\n",
      "==========6/16==========\n",
      "epoch:0 | 0.086 - 0.108\n",
      "epoch:1 | 0.134 - 0.195\n",
      "epoch:2 | 0.13 - 0.414\n",
      "epoch:3 | 0.116 - 0.571\n",
      "epoch:4 | 0.116 - 0.65\n",
      "epoch:5 | 0.117 - 0.703\n",
      "epoch:6 | 0.116 - 0.726\n",
      "epoch:7 | 0.117 - 0.751\n",
      "epoch:8 | 0.151 - 0.784\n",
      "epoch:9 | 0.117 - 0.801\n",
      "epoch:10 | 0.117 - 0.824\n",
      "epoch:11 | 0.117 - 0.848\n",
      "epoch:12 | 0.117 - 0.859\n",
      "epoch:13 | 0.118 - 0.875\n",
      "epoch:14 | 0.117 - 0.891\n",
      "epoch:15 | 0.117 - 0.904\n",
      "epoch:16 | 0.117 - 0.917\n",
      "epoch:17 | 0.117 - 0.924\n",
      "epoch:18 | 0.117 - 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.117 - 0.944\n",
      "==========7/16==========\n",
      "epoch:0 | 0.116 - 0.101\n",
      "epoch:1 | 0.117 - 0.393\n",
      "epoch:2 | 0.117 - 0.618\n",
      "epoch:3 | 0.117 - 0.704\n",
      "epoch:4 | 0.117 - 0.738\n",
      "epoch:5 | 0.116 - 0.785\n",
      "epoch:6 | 0.116 - 0.817\n",
      "epoch:7 | 0.116 - 0.852\n",
      "epoch:8 | 0.17 - 0.888\n",
      "epoch:9 | 0.117 - 0.904\n",
      "epoch:10 | 0.117 - 0.926\n",
      "epoch:11 | 0.117 - 0.939\n",
      "epoch:12 | 0.117 - 0.959\n",
      "epoch:13 | 0.117 - 0.969\n",
      "epoch:14 | 0.117 - 0.98\n",
      "epoch:15 | 0.117 - 0.978\n",
      "epoch:16 | 0.117 - 0.981\n",
      "epoch:17 | 0.117 - 0.983\n",
      "epoch:18 | 0.117 - 0.986\n",
      "epoch:19 | 0.117 - 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========8/16==========\n",
      "epoch:0 | 0.067 - 0.113\n",
      "epoch:1 | 0.116 - 0.499\n",
      "epoch:2 | 0.116 - 0.716\n",
      "epoch:3 | 0.116 - 0.777\n",
      "epoch:4 | 0.116 - 0.826\n",
      "epoch:5 | 0.116 - 0.87\n",
      "epoch:6 | 0.116 - 0.922\n",
      "epoch:7 | 0.116 - 0.948\n",
      "epoch:8 | 0.116 - 0.965\n",
      "epoch:9 | 0.116 - 0.981\n",
      "epoch:10 | 0.117 - 0.979\n",
      "epoch:11 | 0.117 - 0.988\n",
      "epoch:12 | 0.117 - 0.988\n",
      "epoch:13 | 0.117 - 0.99\n",
      "epoch:14 | 0.117 - 0.993\n",
      "epoch:15 | 0.117 - 0.996\n",
      "epoch:16 | 0.117 - 0.997\n",
      "epoch:17 | 0.117 - 0.997\n",
      "epoch:18 | 0.117 - 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.117 - 0.999\n",
      "==========9/16==========\n",
      "epoch:0 | 0.087 - 0.087\n",
      "epoch:1 | 0.116 - 0.429\n",
      "epoch:2 | 0.116 - 0.753\n",
      "epoch:3 | 0.116 - 0.791\n",
      "epoch:4 | 0.116 - 0.863\n",
      "epoch:5 | 0.116 - 0.905\n",
      "epoch:6 | 0.116 - 0.943\n",
      "epoch:7 | 0.116 - 0.973\n",
      "epoch:8 | 0.116 - 0.987\n",
      "epoch:9 | 0.117 - 0.993\n",
      "epoch:10 | 0.117 - 0.995\n",
      "epoch:11 | 0.117 - 0.999\n",
      "epoch:12 | 0.117 - 0.999\n",
      "epoch:13 | 0.117 - 0.999\n",
      "epoch:14 | 0.117 - 0.999\n",
      "epoch:15 | 0.117 - 0.999\n",
      "epoch:16 | 0.117 - 1.0\n",
      "epoch:17 | 0.117 - 1.0\n",
      "epoch:18 | 0.117 - 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.117 - 1.0\n",
      "==========10/16==========\n",
      "epoch:0 | 0.1 - 0.146\n",
      "epoch:1 | 0.117 - 0.523\n",
      "epoch:2 | 0.117 - 0.766\n",
      "epoch:3 | 0.117 - 0.829\n",
      "epoch:4 | 0.117 - 0.834\n",
      "epoch:5 | 0.117 - 0.85\n",
      "epoch:6 | 0.117 - 0.942\n",
      "epoch:7 | 0.117 - 0.973\n",
      "epoch:8 | 0.117 - 0.956\n",
      "epoch:9 | 0.117 - 0.982\n",
      "epoch:10 | 0.117 - 0.99\n",
      "epoch:11 | 0.117 - 0.991\n",
      "epoch:12 | 0.117 - 0.996\n",
      "epoch:13 | 0.117 - 0.998\n",
      "epoch:14 | 0.117 - 0.997\n",
      "epoch:15 | 0.117 - 0.998\n",
      "epoch:16 | 0.117 - 0.999\n",
      "epoch:17 | 0.117 - 0.999\n",
      "epoch:18 | 0.117 - 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.117 - 0.999\n",
      "==========11/16==========\n",
      "epoch:0 | 0.099 - 0.099\n",
      "epoch:1 | 0.117 - 0.622\n",
      "epoch:2 | 0.117 - 0.487\n",
      "epoch:3 | 0.117 - 0.735\n",
      "epoch:4 | 0.116 - 0.75\n",
      "epoch:5 | 0.116 - 0.744\n",
      "epoch:6 | 0.116 - 0.736\n",
      "epoch:7 | 0.117 - 0.83\n",
      "epoch:8 | 0.117 - 0.867\n",
      "epoch:9 | 0.117 - 0.86\n",
      "epoch:10 | 0.117 - 0.873\n",
      "epoch:11 | 0.117 - 0.89\n",
      "epoch:12 | 0.117 - 0.892\n",
      "epoch:13 | 0.117 - 0.972\n",
      "epoch:14 | 0.117 - 0.983\n",
      "epoch:15 | 0.117 - 0.973\n",
      "epoch:16 | 0.117 - 0.987\n",
      "epoch:17 | 0.117 - 0.987\n",
      "epoch:18 | 0.117 - 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.117 - 0.991\n",
      "==========12/16==========\n",
      "epoch:0 | 0.094 - 0.111\n",
      "epoch:1 | 0.117 - 0.566\n",
      "epoch:2 | 0.117 - 0.681\n",
      "epoch:3 | 0.117 - 0.734\n",
      "epoch:4 | 0.117 - 0.762\n",
      "epoch:5 | 0.117 - 0.764\n",
      "epoch:6 | 0.117 - 0.778\n",
      "epoch:7 | 0.117 - 0.725\n",
      "epoch:8 | 0.117 - 0.786\n",
      "epoch:9 | 0.117 - 0.83\n",
      "epoch:10 | 0.116 - 0.882\n",
      "epoch:11 | 0.116 - 0.869\n",
      "epoch:12 | 0.116 - 0.88\n",
      "epoch:13 | 0.116 - 0.89\n",
      "epoch:14 | 0.116 - 0.943\n",
      "epoch:15 | 0.116 - 0.986\n",
      "epoch:16 | 0.117 - 0.984\n",
      "epoch:17 | 0.117 - 0.989\n",
      "epoch:18 | 0.117 - 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.117 - 0.991\n",
      "==========13/16==========\n",
      "epoch:0 | 0.099 - 0.099\n",
      "epoch:1 | 0.117 - 0.481\n",
      "epoch:2 | 0.117 - 0.478\n",
      "epoch:3 | 0.117 - 0.56\n",
      "epoch:4 | 0.117 - 0.647\n",
      "epoch:5 | 0.117 - 0.641\n",
      "epoch:6 | 0.117 - 0.674\n",
      "epoch:7 | 0.116 - 0.604\n",
      "epoch:8 | 0.116 - 0.642\n",
      "epoch:9 | 0.117 - 0.647\n",
      "epoch:10 | 0.117 - 0.715\n",
      "epoch:11 | 0.117 - 0.706\n",
      "epoch:12 | 0.117 - 0.726\n",
      "epoch:13 | 0.117 - 0.706\n",
      "epoch:14 | 0.117 - 0.715\n",
      "epoch:15 | 0.117 - 0.692\n",
      "epoch:16 | 0.117 - 0.7\n",
      "epoch:17 | 0.117 - 0.711\n",
      "epoch:18 | 0.117 - 0.786\n",
      "epoch:19 | 0.117 - 0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========14/16==========\n",
      "epoch:0 | 0.117 - 0.14\n",
      "epoch:1 | 0.117 - 0.433\n",
      "epoch:2 | 0.117 - 0.411\n",
      "epoch:3 | 0.117 - 0.453\n",
      "epoch:4 | 0.117 - 0.466\n",
      "epoch:5 | 0.117 - 0.531\n",
      "epoch:6 | 0.117 - 0.381\n",
      "epoch:7 | 0.116 - 0.566\n",
      "epoch:8 | 0.116 - 0.595\n",
      "epoch:9 | 0.116 - 0.587\n",
      "epoch:10 | 0.117 - 0.531\n",
      "epoch:11 | 0.116 - 0.594\n",
      "epoch:12 | 0.117 - 0.59\n",
      "epoch:13 | 0.117 - 0.572\n",
      "epoch:14 | 0.116 - 0.604\n",
      "epoch:15 | 0.117 - 0.605\n",
      "epoch:16 | 0.117 - 0.646\n",
      "epoch:17 | 0.117 - 0.646\n",
      "epoch:18 | 0.117 - 0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.117 - 0.703\n",
      "==========15/16==========\n",
      "epoch:0 | 0.116 - 0.09\n",
      "epoch:1 | 0.117 - 0.361\n",
      "epoch:2 | 0.117 - 0.259\n",
      "epoch:3 | 0.117 - 0.477\n",
      "epoch:4 | 0.117 - 0.489\n",
      "epoch:5 | 0.117 - 0.502\n",
      "epoch:6 | 0.117 - 0.51\n",
      "epoch:7 | 0.117 - 0.509\n",
      "epoch:8 | 0.116 - 0.521\n",
      "epoch:9 | 0.116 - 0.52\n",
      "epoch:10 | 0.117 - 0.525\n",
      "epoch:11 | 0.117 - 0.527\n",
      "epoch:12 | 0.117 - 0.525\n",
      "epoch:13 | 0.117 - 0.527\n",
      "epoch:14 | 0.117 - 0.524\n",
      "epoch:15 | 0.117 - 0.527\n",
      "epoch:16 | 0.117 - 0.61\n",
      "epoch:17 | 0.117 - 0.622\n",
      "epoch:18 | 0.117 - 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 | 0.117 - 0.614\n",
      "==========16/16==========\n",
      "epoch:0 | 0.117 - 0.117\n",
      "epoch:1 | 0.116 - 0.297\n",
      "epoch:2 | 0.116 - 0.378\n",
      "epoch:3 | 0.116 - 0.352\n",
      "epoch:4 | 0.116 - 0.396\n",
      "epoch:5 | 0.116 - 0.416\n",
      "epoch:6 | 0.116 - 0.42\n",
      "epoch:7 | 0.116 - 0.418\n",
      "epoch:8 | 0.116 - 0.431\n",
      "epoch:9 | 0.116 - 0.415\n",
      "epoch:10 | 0.116 - 0.515\n",
      "epoch:11 | 0.116 - 0.501\n",
      "epoch:12 | 0.116 - 0.525\n",
      "epoch:13 | 0.116 - 0.511\n",
      "epoch:14 | 0.116 - 0.527\n",
      "epoch:15 | 0.116 - 0.521\n",
      "epoch:16 | 0.116 - 0.526\n",
      "epoch:17 | 0.116 - 0.524\n",
      "epoch:18 | 0.116 - 0.529\n",
      "epoch:19 | 0.116 - 0.53\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA38AAANsCAYAAADr9RG6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd81dX9x/HXSQgjIQRICCOMAGGEJbIFQVBU0KqldWsFF3VrW9va1t1lbWt/rjrqnihOVFyoCAqy996QAAlJyE7IOr8/zhe9XBMSQm5uxvv5eHwfyb3f9fnee8699/P9nu85xlqLiIiIiIiINGwhwQ5AREREREREAk/Jn4iIiIiISCOg5E9ERERERKQRUPInIiIiIiLSCCj5ExERERERaQSU/ImIiIiIiDQCSv5EREREREQaASV/DZQx5g/GmNl+z22p4LmLy1n/z8aYNcaYEmPMvZXsyxhj/mGMSfemB40xpkYOROq1GiiH8caYr4wx+caYjcaYiUfZ1wvGmCJjTK7PFFrOcvcYY6zvtowxFxpjFnj7mVvOOk8bYzYZY8qMMdPKmd/DGPOhMSbHGJNmjHnQZ16iMeZLY0yWMWarMWaK3/FZv5jv8pn/L++1yfGO/wq//YYaY/5ijNnrLbPCGNPamzfNGFPqt+3x5cR+ihfDX6p6TD7L9DLGFBpjXvF7vp0x5jVjTKYx5qAx5lWfeQ8aY/YYY7KNMbuMMX/ymTfWL95cL7af++9bflDL9ayyMnmOMWat994tMMb085k31RizzHvvk7yy0MQvjtlemdlvjHnMb36F5d0vhi+9ctOknHk/Ku9VqSvGmFuNMTuMMXnGmA3GmN7lbPt5b9sJfs9f7K2TZ4zZZowZ6z0/yhjzuTEmwxhzwBgz0xjT0We9e40xxX5x9fDm9TbGvO+tl2GM+dQY08dvn5uM+9xJNca8aIxp5TPfv56VGmMe9T+mxqyW61Vl30HWKz+H369nfOY1M8Y8aYxJ8crCB8aYuHK2UdHn9c1e2c42xiw1xpzsM6+1V3ZSvelev3W/8spgtjFmlTHmPJ95HY0xs7z6ao0x8X7rxnllOMP7PLjOZ95Ry7ffdsqt7xXV2SrEVe3fA5XVO5/lyn0vao21VlMDnIAxQBYQ6j3uAOwE9vs9Z4FO5aw/FZgMvA/cW8m+fglsAjoDccB64Lpgvwaagj/VQDlcCDwEtAB+DmQC7SrY1wvAXyqJpyewBtgLTPR5fiJwIXA3MLec9W4ETgOWAtP85jUFtgG/BiKA5sAgb14TYLM3LxQ4FcgDenvz471jb1JBvPcBfXEn6kYCB4HRPvP/AnwJdAMMMABo7s2bBnxTyesRBqwEvvN97Y52TH7rfwbMB17xe36+975Fefs40WdeHyDC+z8OWAf8rIL4xgM5h5fXVCfqWYVlEugFZAMne2X/D8DWw+UbuB4Y65WvOGAZcIfPtmfj6nFzL941wC1VKe8+y1wGzCuvXh2lvB+1rgDXAKuBft5+ewJt/ZY52We/CT7Pnw7sAkZ5r1kcEOfNmwxcALQCwoHngE981r3Xv275zBsBXA209Y7rz8BGn/ldgBjv/5bAq8AjFWwrAsgFxgW7LNelqZbrVWXfQUeUK795vwNWAe29uvMy8E45y/3o8xpXh/OAoV7Zvh444HN8zwMzvfIZj/teuNJn/UH8UL9H4j6vO3qP2wM3ACd58cf7xfMV8H9e+T0ByAAmVKV8+2yj3PrOUepsFeI6nt8DVap35b0XtVq2g125NAXojXVfrvnAUO/xhV4l/trvua2VbOcVKk/+FgDTfR5fDXwX7NdAU/Cn4ymHQG/gEBDp89x8KjixQNWSv4+Bs3Bf4BPLmX9NeR/2PvO/KefDfjowv4LlB+B+VBmf5z4D/uz9H+//pVVJ/LOA33j/t/G23bOCZadRefJ3B/Cg/2t3tGPyWeZi4E38fqACZ3ivb2gVjicO9wP/dxXMfx54PtjluK5PtVnPKimTNwEf+cwLAQqA0ypY99fABz6PNwBn+Tz+J/CU9/9Ry7u3TBTuZMuo8urVUcp7hXXFO4Y9FR2Dt0wTYAXuh7B/8rcAuLqKr+UQIMfn8RF1q5J123r7ji5nXkvgJWB2BetOBbbj8zmlKTj1igq+g/zLld+8J4AHfR6fDWzyW6aiz+uLgMU+jyO8fR1O4NKA4T7z/0jF33cjgEJghN/zTfBLsrwyafFJhoGngZcr2PaPyndF9b0qdbaiuKryXvjM/9HvAb/55da7it6L2pzU7LOBstYWAYuAcd5T43AfPN/4PTcPwLjmXXdUc3f9cWedDlvlPSeN3HGWw/7Admttjs8mKytbN3hNRJYZv6aCxpgLgCJr7ewK1q2uUcBOY8zHxjWPnGuMGXh4t+Usf/iKha9dXrOX540xMeXtxBjTAhiOu1IGMBAoAc43roncZmPMjX6rnejFtNkYc5c5sgldN+Aq4P5jPCa8Ziz3A7+pYN1NwIvGNQNfYow5xe9Y7jDG5AJJuB8br5VzvOHA+cCL5b0e8oMg1DO87fiXScORZf7wY//yftg4n3UBHgYuNsaEe83WJgOfePOqUt7/hvshvL+cWI9W3qHiutLZmwYY11x5hzHmPmOM7++nXwHzrLWr/fYZCgwD2hnX5DvJuKasLar4egCc432mrTPGXF/BeofX3W+tTffZ/8nGmCzc1Zif466ylGcq8JL1fpmKE6x6dRTzvLL/jl9TxWeBMcaYTt7n5mW4E514cR3t8/pjINQYM9Irr1fhro771iH/On1EffaOuxD3Ws3FXRGrjPH7W+62ffyofFNxfa9KnQ2Yo9W7St6LWqPkr2H7mh8+oMbiPrTm+z33NYC19ifW2gequZ+WuKYRh2UBLY3RfX8CVL8c+pcrvMeRFeznEVyzs1jgLuAFY8wYAGNMS9wXxW3HezDl6Iw7k/cI0An4CHjfGNMU2AikAr81xoQZY84ATsE1oQHvrCquGdtQ3LG9SvmexP14+NRnv1G4M8zdcYnSvcaY073583BfpLG4L6BLgN/6bO8R4C5rbe4xHhO4JjjPWmv3VLDuGbgmPR2Af3vrfp/Ueu9xJO5Kx8v8+H3GizkNr2xIpWqrnvnyL5OfA6cYY8Z7ZeWPuKsn4f4rGmOuxCVG//I7hv64pqNJuB+R73nzjlrejTHDcM30Krpv7Wjl/Wh1pbP39wxcAjrBm3+1t98uuFsf7i5nu+1xTdbOx73+g4ETgTv9FzTGDPK24VtH3wQSgXbAtcDdxphLylm3M/A47krq96y131hro7xj+Cfuirz/ul1xn0k6yVK+YNSr8pyCaynSF3fbwoc+Jyg2A7uBZFzdSeTIkxxH+7zOAd7GJbSHgHtwLbkOnwj4BLjDGBNp3L2sV+FXn621P/GO6yzgU2ttWWUH4yXF3wJ3GWOaG2OG4OpeeZ8VPyrfldT3o9bZQKuk3h3tvag1Sv4atnnAycaYNrhL61twTVBGe88N8JY5Xrm4exYOawXk6iyieKpbDv3LFd7jnHKWxVq73Fqbbq0t8a7uvQr8zJt9H645yY7jP5wfKcA1GfvYO1P8LyAaSLTWFgM/xTXD2Y872/cm7oct1tpca+1SL+YUXLO5M/xvEDfG/BP3Ol3oU68KvL/3W2sLvKsOM3BfwFhrt1trd1hry6y1a3A/Bs73tncOrjnSG8d6TMaYwbh7Iv5zlHV3WmuftdYWW2tn4JrgjPFdyDorvOXvK2c7uhpxbGqlnh1WXpm01m7EvW+PAfuAGNw94El+6/4UeACYbK1N854LwSWR7+CuBsfgmnr+w1utwvLurftf4FZrbUk5sR61vB+trvjs90Frbaa1difwFF49w53Vv99aW94JjMPrPmqt3ecd60M+6x6OLwF3BeZWa+18n7jWW2v3WmtLrbULcFdGz/dbtx2uKfl/rbWvV3B8ybgf8TPKmX0Frq4H4rOxIajVelURa+08a22RtTYTuBV3AiTRm/0E7l6/aFzdeQfvyl8VPq+vwSV0/XEnai7HJZadvPm34MrxFlwfEK/jV5+9+IqttR8DZxpjzq3iYV3mHcce7xhe9d92eeW7svpO5XW2VvjXuyq8F7VGyV/DthB3pnQ67gwL1tps3Fmj6cDeGvrAX4e7WfewE/hx0xVpvKpbDtcBPYwxvmdKj6VsWX5oUnIacIvXZGY/7qbsN40xvz/WgynHam9f5Qdh7Wpr7SnW2mhr7ZlAD2DxUWLGJ26MMffhmr+d4b1uvvv1Xacy/q/HMJ/X4yLgNmPM+1U4pvG4M9C7vXVvB35ujFlehXXL0wR3M/73vKsp43H3S0jV1Fo9O0qZxFr7lrV2gLU2GncVoRuwxGfdScD/gHO8ROuwtrh6+Zi19pDXvOt5fvjBdrTy3gp3FfENr0we3l+ScT1rVlbe/fnWlU1AUQX7xdv2P322DbDQGHOptfYg7sdshfXBa446B3cf8MsVLVdOXHjJx2fALGvtXytZ90f1zHMFuup3NMH6/qqMb1k4AXjBWpthrT2Euxo2wmttMZ6jf16fgLvvdrN38uMT3Imb0d6xZlhrL7PWdrDW9sflDRV9f0HF5ezHB2DtLu9qaTtr7Uhc8vr9to9Sviur75XV2drk+3qM5+jvRe2xQbjRUFPtTbgzVCkc2WPao95zrx5lvTDcmaTXcD2sNaeCDhyA63A36sfhmoitQ719avKZjqMcfoe76tQcmMLRe0s7H9fUJgTX3CMHGO/Ni8Y1QTw87cH1stfSmx/q7eM63Fnc5kCYz7abes99i2t+1RwI8eb1wXUKMNHbzq9wPaI19eYP8pYPx33Y7wCaefNGeuuHeDG+AXzls98/4M64dqzgmOfhzmg2w50FTsW7yR3347y9939fYC1wj/c40u/1eAN3NrJtZcfkHYfvuv8C3jr8vuB+xB/EXQEK9d6XDNyVnBBcE7k2uB8uI3A/NG7xO64/4u6hCnrZrU9TLdWzysrkUO99b+eVq9d85p0KpFNBr5K4TkfuwP1gag286xt3ReXdK0u+ZXI47odfnFdmKyvvFdYV77mXgA+97XTGNee+2psX67dti7vvtYU3/37cj9NYr9zP54cOn+K8evXbCl6P8/zqSjIw1ZvXCvdD+bEK1r0M6Oqt2w3XNPEdv2VG43p6jCxvG5pqtV5V+B2Euyo32FumJe5q8yaf+c/jmm4e7l35j0CyN6+yz+upuGajPbyycjrus7+vN78n7rsp1KsnaUB/n7oyGdebaRjuqmERMMTnuJrzQycyffDpnRdXhyP54Ypjmk9cFZZvKqnvldXZKsR1PL8HKqx3lb0XtVqmg12pNAX4DYa/e4XbtzJe6D33S5/nPgb+6PP4BW8Z32maN28srlnn4WUNrge1DG96EPUapslnOo5yGI+7gbwA92XnOzzDZcA6n8fzcfdUZOPuQ7r4KPHs9NvWtHLK+ws+8+eWM3+8z/yf4bq0z/aW7e8z75+4ZCjXOz7fngAvwSWDebgk6CWgg898i7sPI9dn8n194nDNSnJxP5x9X8t/4X6c5Hnz7sfnC8zv9XgBv55Sj3ZMfsvdy4+HehiL68UzF3ff1ljv+RAv3gxv3mbcDxXjt/4RX9Sa6lQ9q6xMfoM78ZKBS9QifOZ9heu0xXfdj33mD/biOIj7ITgTiK1Kefd7HeI5+hAqR5T3yuoK7ofoDO+49uDuzSv3O44f9/YZhmuilolr+v0IPwzHco+3vO/r4fvd+jouWc716oRv8jHVWzfPb/2u3vy/4q465nl/n8avJ1Dv/Sm3d0VNtV6vplHBdxDupMkm771Mxd0H28tn3Whck8lUr5x9g1+Pmz7L3suRvX0ar7zv9sr3BuAXfse5F5cQrgTO9JmXiOvkJcfb7xJgSjn14YjJZ95tuGEl8ryYh1W1fPvtI54fD/Vw1DpbSVwVvhfe/LnlzB9f1XpX0XtRm5PxAhAREREREZEGTPf8iYiIiIiINAIBS/6MMc8ZY1KNMWsrmG+MMY94Y9+s9rp5FRERERERkQAI5JW/F4BJR5k/GTcmVy9cj0lPBDAWERERERGRRi1gyZ+1dh7uhu+KnIc3hpO19jugtTGmY6DiERERERERacyaBHHfcbgeeA5L8p7b57+gMWY67uogERERQ/v27VsrAYrUlmXLlqVZa9sFO47DYmJibHx8fLDDEKlRda2egeqaNEx1ra6pnklDVN16Fszkz5TzXLldj1prn8Z1l8qwYcPs0qVLAxmXSK0zxuwKdgy+4uPjUT2Thqau1TNQXZOGqa7VNdUzaYiqW8+C2dtnEtDF53Fn3FgiIiIiIiIiUsOCmfzNAq7wev0cBWRZa3/U5FNERERERESOX8CafRpjXgfGAzHGmCTgHiAMwFr7JDAbOAvYCuQDVwYqFhERERERkcYuYMmftfaSSuZb4MZA7V9EREREakhZGRRmQpNm0DQi2NGISDUFs8MXEREREQmmQzmQuQey9kDmbug8HDoNhozt8P7NkJ8GeWlQkAG2DKY8DSdcFOyoRaSalPyJiIiINGSlJbBnEexbBe37QY/xkJMC/x0JBQePXHbivS75C23mkr3oBOg6CsJjICIGOp1Y+/GLSI1R8iciIiLS0FgL69+HTR/Dlk9/SPJGTHfJX3g09P8ZtO4CUV2gdTeI6gwR3rBhUXFw1cfBil5EAkTJn4iIiEhDkJUMBzZAwkQwBub+HXJToPck6DMZuo1xSR9AaBP4yUPBjVdEap2SPxEREZG6qrTE3X+XnwaFWVCYDQN+7pK3DR/Als/c8xk7YP9qaBoJv9sOTZrCZW9BZEe3rIgISv5ERERE6oayMkjfCm26uV41F/8PPr8bivOPXC5hIkREQ8p62PwZNG8FLdu7+/X6nAWhYW651l1q+whEpI5T8iciIiISDEV5sO0r2PMdJK9wHbIU5cDVn0OXEdCuLwyZCh1PgMgO0Dzqhwlg/O/dJCJSRUr+RERERGpL9j7AQqtOkLwM3rjM9azZYSCccLHrabNNd7ds97FuEhGpIUr+RERERALFWkhZ53rd3DQb9i6Hk26CM/8KXU+CqR9Al1HuHj0RkQBT8iciIiJSk6x1vW1aC0+Ncx2xAMQNg1PvgsRz3ePQMOg+Lnhxikijo+RPRERE5HgVZMLWOe7q3sFdcO0XLgEcdCEMv8YNtxDZPthRikgjp+RPREREpLq2zIEFj8Cub6GsxA2S3nsSFBdCWHMYfXOwIxQR+Z6SPxEREZGqshZ2fA2x/aFlOyg46AZSH32zG2YhbiiEhAY7ShGRcin5ExEREalMSRGsfQsWPg4pa+HUO2Hcb2Hg+TDogmBHJyJSJUr+RERERCpiLXz7f/Ddk5C7H9olwrmPwUAv4TMmuPGJiBwDJX8iIiIi/nJSXActxkDSUohNhJ8+Dj1PU8InIvWWkj8RERERgLIy2P4VLHrK9dx50xKI7gnnP69x+ESkQVDyJyIiIo1bUR6seBUWPw3pWyAiFsbdDs2j3HwlfiLSQCj5ExERkcap5BA0aQbFBfDZndBhAEx5Gvr/1D0vIlJbSg7BrgWu1cGI6dCmW0B2o+RPREREGpfd38H8f0NhNlz9KUTEwE2LoU18sCMTkcakMBvWvOnGC90xD4rzILQpdB2l5E9ERETkuOSlwWd3warXXNPO4VdDWakbl0+Jn4hUV2kxbP0CVr0OO7+BHqfA+c+5eR/c5loXNI/yplbQ6USIP9mt99Ht0LorDL4EEk6H7mOhaUTAQlXyJyIiIg1f8nJ4eYq7v+/kX7t7+gL4A0tEGolvH4ZvH4H8NAiPhl5nQscTfpifvhUO7oLCLDiUDVjodYZL/iKi4bbVENWl1noRVvInIiIiDVdxAYS1gNh+0OcsOPk2aNcn2FGJSH2VvRfWvOXuywtr7p6LHwMnXAIJEyE07Mjlp334w/9lZVCU45p2Hta6a+Bj9qHkT0RERBqewiz48q+w5VO4fiE0DYcpTwQ7KhGpjzL3wOZPYMMH7t48LHQcBD3Gw5hbq76dkJAfehEOEiV/IiIi0nBYC2vfhk//CLmpMPwasKXBjkpE6hNroSgXmkVC6kb470j3fHQCnPI7GHSRGwO0HlLyJyIiIg1DYTa8fTVs+cx1qHDJDIgbEuyoRCTYkpZC8jI3hEtYuGsK3qKta64JkJUMWEjdAJtmw6ZPoNdEOPdR10x88j+h5wSI6RXUw6gJSv5ERESkYWja0v2d9IC7HyckNLjxiEhwWAsZ23+4Ojfvn67Zpq+Y3nDTEvf/21fD7oXu/7AISDjN9bwJriOWkdNrJ+5aENDkzxgzCXgYCAWesdY+4De/K/Ai0Npb5g5r7exAxiQiIiINSE4KfH4XTLwPWnWES9+stV7zRKSOSd/mOmNZ+xakbYbb1kLrLjD5H3DOw2DLoCgfivOP/JwYeztkJ0GrOIgf+0NHLg1QwJI/Y0wo8DhwOpAELDHGzLLWrvdZ7E7gTWvtE8aYfsBsID5QMYmIiEgDcfjevtm3ux49+50Hrc5W4ifSGO1bDbNugn2rAAPdxsDI637oXKWycTx7TQx0hFWWU1jM1tRcWrUIo2e7ljW+/UBe+RsBbLXWbgcwxswAzgN8kz8LtPL+jwL2BjAeERERaQhyD8BHv3I978UNg58+Ae16BzsqEQm0nBRIWgx7vGnQBa5Tp8gOEBIGZ/wV+k+BqLhgR1qpg3lFbEnNZUtqDltTc9mamsuWlFz2ZxcCcOWYeO45p3+N7zeQyV8csMfncRIw0m+Ze4HPjDE3AxFAuWm3MWY6MB2ga9faHQtDRERE6pi5f4PNn7qmnqNv1r19Ig1daQk8PgIytrnHoU2h4+Af7vNtGQvXfhG8+KqgtMzyzdY03ly6h0Xb00nLLfp+XnjTUBJiWzK6ZzQJ7VvSKzaS/p1aHWVr1RfI5K+8dhfW7/ElwAvW2n8bY04CXjbGDLDWlh2xkrVPA08DDBs2zH8bIiIi0hgcHrD91Ltchy6xicGOSEQCIfcALH0WDu5y43OGNoG+Z0HLDtBlBHQ8wfXcWQ/sychn5rIk3l6WRHJmAa3Dw5iY2J6+HSLpGduSXrEt6RTVgpCQ2mmyHsjkLwno4vO4Mz9u1nk1MAnAWrvQGNMciAFSAxiXiIiI1CfWwtwHYONHcOVHEN7WTSLSsBzYDAsfg1UzoPQQ9J4MpcUQGgZn/CXY0VVZYXEpn61P4c0le/h2WxoAJyfEcMfkvpzRvz3NmgSvtUIgk78lQC9jTHcgGbgYuNRvmd3AacALxphEoDlwIIAxiYiISH1irevNc8GjMPjyH5p5iUjDsuYtN+RCk+Yw+FIYdUO9upfXWsvqpCzeXZHMeyuTycwvJq51C245tRcXDOtM5zbhwQ4RCGDyZ60tMcbcBHyKG8bhOWvtOmPM/cBSa+0s4DfA/4wxv8I1CZ1mrVWzThEREYGyMteb59JnYfi1MPlBCAkJdlQiUhOK8mHdu66zloTToOepMOFPMOwqiIgJdnRVtjklh1kr9/LB6r3sSs+naWgIp/dvz0XDujAmIYbQWmrOWVUBHefPG7Nvtt9zd/v8vx4YE8gYREREpJ6a+zeX+I251XXuomEcROq/A5th6XOw6jUozIKBF7jkL7wtnPK7YEdXJbvT8/lg9V4+WLWXjftzCDEwumcMN4zvyaT+HYkKDwt2iBUKaPInIiIiUm1Dp0F4tBuvS4mfSP334a9c4hcSBv3OhWFXQ7fRwY6qQtZasgqKSTpYQNLBAnak5fHpuv2s3JMJwNBubbjv3P5MHtiB2Mj6MTC8kj8RERGpO4oL3Y/Dkb+EqM4w6vpgRyQi1XVwJyx/2V29b94K4k+G1l3d/bst2wU7uu9Za1m0I4OVezJJPlhA0sF8kjMLSD5YQF5R6RHL9uvYijsm9+UngzrWmfv4joWSPxEREakbivJgxmWw/SvoMAC6jwt2RCJyrEpLYMtn7iTO1jnuqn2XkdD7DBjw82BHd4TM/CLeWpbEa4t2sz0tD4CoFmHEtW5Bt+gIRveMoXObFnRu04K41uF0btOCNhFNgxz18VHyJyIiIsFXWgyvXwI758NPn1DiJ1If5WfAk2MhO8mNyTfutzB0qruKX0dYa1m+O5NXF+3io9X7OFRSxpCurfn3BSdwev/2tGped+/XqwlK/kRERCS4rHW9eu742iV+g/1HhhKROqmszNXbtM2uqXZ4W3cvX7fR0HuSG5+vjsg9VMJ7K5J5ddFuNuzLJqJpKBcM68ylI7rRr1OrYIdXa5T8iYiISHAd3AGr34STf6XET6Q+OJQLy15wvfFmbIfITjD0SmjSFCb9PdjRfa+ktIxvt6Uza+VePlm7j7yiUhI7tuKvUwZw3uA4WjZrfKlQ4ztiERERqVva9oDrvoE23YMdiYhUZsvn8M50KMiALqNg/B8g8VyX+NUBZWWWpbsOMmtVMrPX7Ccjr4jIZk04a2BHLh3ZlcFdWmMace/BSv5EREQkOA5sht0L3T1B0T2DHY2IVCQ/Aw5lQ5t4iOkFXUfB2N9A52HBjgxw9/GtTc5m1qpkPly9j31ZhTQPC+G0xPace0InTundjuZhocEOs05Q8iciIiK1Lz8DXr8IDuW4e4RatAl2RCLiLy8NFj4Gi59xCd/lb7kE8JLXgx0ZAIdKSnl7WTLPzN/O9rQ8wkINp/Ruxx2T+zIxsT0RjbBZZ2X0ioiIiEjtKi2GmVMhKwmmfqjET6SuyU2Fbx92wzUUF0D/KTDu9mBH9b3C4lLeWLKHJ7/exr6sQk7oHMUDPxvIpAEdaB1eN5qf1lVK/kRERKT2WAsf/w52zIMpT0HXkcGOSET8ffdfNw28wDXvbNcn2BEBkF9UwmuLdvPUvO0cyDnE8Pg2/OPngxjbK6ZR38d3LJT8iYiISO3Zu9xdTRhzG5xwcbCjERFfRfnQNBwm3AmDL4eYhGBHBLhhGl5auJNn5+8gPa+Ik3pE88jFJzKqR1slfcdIyZ+IiIjUnrihMG02dD0p2JGIyGHWwoJHYckzcM0caBlbJxK/rIJiXlywk+e+3UFmfjHjerfjllMTGBbfNtih1VtK/kRERCSwsvfCtq9cRxHxY9wk9Ya1li2puczdlMrXmw/w8MUnEtOyWbDDkpoLLGXLAAAgAElEQVRSWgyzfwvLnod+50GzyGBHxMG8Ip77dgcvfLuTnEMlTEyM5aZTezG4S+tgh1bvKfkTERGRmrfxI9g0G3Z+6wZxBzeO3w3fQVjz4MYmlco9VMK3W9OYu+kA8zYfIDmzAIA+7SPZn1Wo5K+hKMyCN6fC9q/g5F/BqXdDSEjQwknLPcT/5m/nlYW7yCsqZfKADtx0agL9O0UFLaaGRsmfiIiIHJ+yMlgz043Z95P/gDEu+dv4EXQbAyOuhW6jocMgCNFYW3XV9gO5fL4+hbmbDrB0VwbFpZaWzZowJiGam05N4JTe7ejUukWww5Sa9NldsHM+nPsYDPlF0MJIyS7kqa+389riXRwqKeMngzpx04QE+nQI/lXIhkbJn4iIiByfBY/AnHsgIhbG3wGRHWDSA+4HZRCvIkjVbE7J4eE5W/hozT4A+naI5KqTuzO+dyxDu7WhaRO9hw2Ote4kzcR7YdBFQWuKvS+rgCfmbmPGkj2UllnOG9yJGyck0LNdy6DE0xgo+RMREZHqS1oKX/7Z3St0wYvuByVA81bBjUsqte1ALg/P2cIHq/cS0bQJt5yawMUjuurqXkNmLSx/EdbPcgO1h7cNSuKXkl3If7/ayuuL92Cx/HxIZ24Yn0DX6PBaj6WxUfInIiIi1VOQCW9dCZGd4JxHfkj8pE7bmZbHI19u4b0VyTQPC+W6U3oyfWwP2kRocOwGLWM7zLrFNfPsPg6K8qBJ7d67eSDnEE9+vY1XvttFaZnlgmGduXFCAp3bKOmrLUr+REREpHoKDkLzKDj7IWihXvjquj0Z+Tz65RbeXp5MWKjhmrE9mD6uhzpvaejKSuG7J+DLv0BoGJzzMAyZWqsnazLyinjq6228uHAnxaWWn50Yx82n9tKVviBQ8iciIiLV07Y7TJ+n+/rqqLIyy6aUHBZtT+e77RnM2ZBCSIjhipO6cf34nsRGqtfVRqG02A3j0OMUd6ImKq7Wdp2ZX8T/5m/nhW93kl9cyk8Hx3HLab3oHhNRazHIkZT8iYiIyLFJ3QjfPQ5n/h2aqWOGuqKktIz1+7JZvCOD77ZnsGRnBlkFxQDEtW7B5aO6cd0pPekQpaSvwSspgsVPw9Bpro5e9SmER9fa1b6ikjJeWLCDR7/YSm5RCWcP7MhtE3uREKveO4NNyZ+IiIhUXXGBu88v7wBM+JOSvyAqK7Os35fNgm1pfLs1nWW7DpJ7qASA+OhwJvXvwIjubRnZo63uqWpMkpfDrJshZa3r0GXwpRARU2u7n7f5APd+sI7tB/I4tW8sv5vUh74d1AFUXaHkT0RERKru0z9C6nq4/G03pIPUqt3p+XyzNY1vt6WxYGsaB/Pdlb2e7SI4b3AnRvaIZmT3trRvpat7jdKmj+GNyyE8Bi5+HfqeVWu73pORz58/XM9n61OIjw7n+WnDmdA3ttb2L1Wj5E9ERESqZv37sPQ5GH0LJEwMdjSNQklpGXM2pPD15gN8szWNPRkFAHRo1ZxT+7ZnTEI0YxJilOwJ7FoAM6dBh4Hwi3ehRZta2W1hcSlPzN3Gk19vIzTE8LtJfbj65O40axJaK/uXY6PkT0RERCpXWgyf3QlxQ+HUu4IdTYNXWmb5YNVeHv5iCzvS8ohs3oSTekRzzck9GJMQQ892ERgNrSG+IjtC91Pgp0/USuJnreXTdfv584cbSM4s4NwTOvGHs/rSMUrjRNZlAU3+jDGTgIeBUOAZa+0D5SxzIXAvYIFV1tpLAxmTiIiIVENoGEz7yA0S3UTjwQVKWZnlozX7+L85m9l2II++HSJ58vKhTEyMpUmoelWVcuSmumaebbvDZW/Wyi73ZxXyu7dXM2/zAfp2iGTG9FGM6hFdK/uW41Ol5M8Y8zbwHPCxtbasiuuEAo8DpwNJwBJjzCxr7XqfZXoBfwDGWGsPGmPUMFhERKSu2b0IuoyA1l2DHUmDVVZm+Wz9fv7z+RY2peTQK7Yl/71sCJP6dyAkRFf4pAJZyfDcmZB4Lkz6W63s8suNKfzmzVUUFpdx7zn9uHxUN52YqEeqeuXvCeBK4BFjzEzgBWvtxkrWGQFstdZuBzDGzADOA9b7LHMt8Li19iCAtTb1WIIXERGRANu/Bp6fBGf+DUZdH+xoGhxrLV9sSOWhzzezfl82PWIiePjiwfxkUCdClfTJ0eSlw8tToCATBl0Y8N0dKinlwU828ew3O0js2IrHLj2Rnu3U2299U6Xkz1o7B5hjjIkCLgE+N8bsAf4HvGKtLS5ntThgj8/jJGCk3zK9AYwx3+Kaht5rrf3Ef0PGmOnAdICuXXXWUUREpFZYC7N/C81bw6CLgh1Ng5BfVMK6vdmsTspiTVImK/Zksis9n27R4Tx04Qmce0InXUWRyh3KgVfPh8xdrufdToMDursdaXnc/Ppy1iZnM210PHdM7kvzMHXoUh9V+Z4/Y0w0cDnwC2AF8CpwMjAVGF/eKuU8Z8vZfy9v/c7AfGPMAGtt5hErWfs08DTAsGHD/LchIiIigbD6Ddi9EM591I0XJsektMyyOimTNclZrE7KYnVSJltTcynzfsl0aNWcgZ2juHFCAlNOjCNMSZ9UhbUw80rYtwoufhXiTw7o7t5dkcSd764lrEkIT/9iKGf01xAv9VlV7/l7B+gLvAycY63d5816wxiztILVkoAuPo87A3vLWeY778rhDmPMJlwyuKSK8YuIiEggFGbBZ3dB3DAYfHmwo6l3dqblceuMFaxKygIgpmVTBnVuzeQBHRnUOYqBcVHEangGqQ5j4KQbXVPPPpMDtpu8QyXc/f463l6exIj4tvzfxYPp1Fo9edZ3Vb3y95i19svyZlhrh1WwzhKglzGmO5AMXAz49+T5Hq4Z6QvGmBhcM9DtVYxJREREAuXgLghrAWf9E0J0RaqqrLXMXJbEvbPW0STE8MDPBjKudzs6RjXX0AxyfKyFpKXQZTj0nBDQXW3Yl82Nry5nR3oet5zWi1tOTVBz5AaiqslfojFm+eHmmMaYNsAl1tr/VrSCtbbEGHMT8Cnufr7nrLXrjDH3A0uttbO8eWcYY9YDpcBvrbXpx3NAIiIiUgM6DoKbl0OohgSuqsz8Iv707lo+WrOPUT3a8tCFulIiNeirv8K8f8LVn7vedwNk5Z5MfvHsIsKbhvLaNaM4qaeGcGhIqvqJfq219vHDD7xhGa4FKkz+vOVmA7P9nrvb538L/NqbREREJNishRUvw8ALIUzNEqtq4bZ0fv3mSg7kHOL3k/oyfVwP9dYpNWfJsy7xG3IFdB4esN2s3JPJL55ZRJuIprw+fRRxOnnR4FQ1+QsxxhgvWTs8hp9GeBUREWloVr8Js26G0KZwwsXBjqbOKyop46HPN/PUvG10j47g3RvGMLBzVLDDkoZkw4cw+3bodSac/R93z18A+CZ+M6aP0lXrBqqqyd+nwJvGmCdxPXZeB/xoSAYRERGpxwqz4LM7IW6ou/InR7X9QC63zljJmuQsLh7ehbvP6Ud4UzWTlRqUuRvevho6nQgXPB+wZtgrdh/kimcXK/FrBKpagn4P/BK4HjeEw2fAM4EKSkRERIJg7gOQdwAufUOdvBxFflEJ/5u3gye/3kazsBCevHwIkwZ0DHZY0hC17gpn/cv16tk0IiC7OJz4tW3ZlNevVeLX0FV1kPcy4AlvEhERkYYmZR0segqGToO4IcGOpk4qKS3jrWVJPPT5ZlJzDjGpfwfuPbc/HaJ0b6TUsOx9kJcKHU+AIb8I2G6W7z7IVCV+jUpVx/nrBfwd6Ad8/wlnre0RoLhERESkNpkQSDgNTru78mUbGWstX21K5YGPN7I5JZchXVvzxOVDGNpNA99LABRmwavnQ14a3LoqYB0vLfeu+EW3dE09O0Yp8WsMqtrs83ngHuA/wATgSlzzTxEREWkIYhPhspnBjqLOWZOUxd9mb2Dh9nTio8N54rIhTBrQQWP2SWCUHIIZl8GBjXDpmwFP/GJaul49lfg1HlVN/lpYa7/wevzcBdxrjJmPSwhFRESkvirMduOHjb0dWrYLdjR1RtLBfP716SbeW7mXthFNue/c/lw6sithGuhaAqWsDN67HnbOhylPuSvxAbBs10GmPqfEr7GqavJXaIwJAbZ4A7cnA7GBC0tERERqxfx/uXv9Bl2o5A/XxHPmsiTueX8dZdZyw/ieXDe+J62ahwU7NGnoFj8Fa9+GifcGbJiVxTsyuPL5xbSLbKbEr5GqavJ3GxAO3AL8Gdf0c2qgghIREZFakJcGi/8HA893wzs0cjmFxdz53lreX7mXUT3a8u8LB2uQa6k9Q6dB2x7Q64yAbH7BtjSufmEpnVo357VrR9G+lToqaowqTf68Ad0vtNb+FsjF3e8nIiIi9d3Cx6G4AMb9NtiRBN3qpExufn0FezLy+c3pvblhQgKhIbqvT2pRWAvofWZANj1v8wGufWkp3aLDefWaUbSLbBaQ/UjdV2nyZ60tNcYM9e73s7URlIiIiARYfgYsfhr6T4F2fYIdTdCUlVme+3YH//hkI+1aNuONX57E8Hj14im17L0bIP5kGHxpjW/6q42p/PKVZfRs15JXrh5BdEslfo1ZVZt9rgDeN8bMBPIOP2mtfScgUYmIiEhglRZD/5/CqBuDHUnQpOce4jczVzF30wHO6NeeB88fROvwpsEOSxqblPWw8lWI6V3jm/5s3X5ufG05fTpE8srVI1W+pcrJX1sgHTjV5zkLKPkTERGpjyLbw3mPBzuKoFmwNY3b3lhJZkEx95/Xn1+M6qbhGyQ4ljwDoc3gxJodzP3jNfu4+fUV9I+L4qWrRhDVQp0WSRWTP2ut7vMTERFpKNa+A226NcpOXgqKSvm/Lzbz9LztdI+J4IUrR9CvU6tghyWNVWEWrJrhOl2KiK6xzc5atZdfvbGSwV1a8/yVw9VbrXyvSsmfMeZ53JW+I1hrr6rxiERERCRwCrPhw19B15Pg0hnBjqZWzd9ygD+9u5bdGflcPLwLd5/Tj/CmVW0EJRIAq2ZAcR4Mv6bGNvnO8iRun7mKYfFteW7acFo2UxmXH1S1NHzo839zYAqwt+bDEREROTaHSkrZkpJLVkExYxJigh1O3bfkf1CYCaf8LtiR1Jr03EP85aMNvLsimR4xEbx+7ShO6llzV1lEqi2mN4yYDnFDamRzC7al8ZuZqzipRzTPTB2mkxvyI1Vt9vm272NjzOvAnIBEJCIiUoHUnEI27Mthw77s76dtB/IoLbPEtW7Bt3ecWvlGGrNDubDgMUg4vcZ+bNZl1lreWpbEX2dvIO9QCbecmsANExJoHhYa7NBEnJ4T3FQDMvOL+PUbq+geHcH/rlDiJ+WrbqnoBXStyUBERET8FZWU8eHqvby3ci/r92aRllv0/byOUc1J7NiK0/u1J7FjKxI76r6tSi19DgoyGsVVvx1pefzxnTUs3J7OsG5t+PvPBtKrfWSwwxL5weqZbniHVh2Pe1PWWv747hrScg/x7g1jiFBTT6lAVe/5y+HIe/72A78PSEQiItLoZeUX8+riXby4YCcp2YfoERPBhD6x3yd5iR0j1WV5dYSEQr/zoMuIYEcSMEUlZTw9bxuPfLmVZk1C+OuUAVwyvCshGrBd6pLM3fDudBhzG0y857g3N3NZErPX7Of3k/oysHNUDQQoDVVVm33qVJmIiATcrvQ8nvtmB28uTaKguJSxvWL4x88HcUrvduqGvyacdKObGqi5m1K5/4P1bE/L4+yBHbnnnH7Etmoe7LBEfmzpc+7vsOPvO3FnWh73zlrHqB5tmT6ux3FvTxq2ql75mwJ8aa3N8h63BsZba98LZHAiItLwWWtZtusgz8zfwafr99MkxHDuCXFcM7a7mnLWlOJC2PYl9JkMDTCJ3p2ez/0frmfOhhS6x0Tw/JXDmdAnNthhiZSvuBCWvwR9zoLWXY5vU6Vl3PrGSsJCQ3jowsGE6gq3VKKqDYLvsda+e/iBtTbTGHMPoORPRESqxVrLvC1pPDxnM8t3ZxLVIowbxvdk6knxulpT01a8DLNvh6s+ha6jgh1NjSkoKuW/c7fy1LztNAkx/H5SX646OZ5mTdShi9Rh696F/PQaGd7h4TlbWLUnk8cvHUKn1i1qIDhp6Kqa/IUcx7oiIiLfs9ayYFs6D32+mWW7DhLXugX3n9ef84d2Vu90gVByCL75jxvXr8vIYEdTI6y1fLx2P3/5cD17swo5b3An/jA5kQ5ROmkg9UD6VmiXCD3GH9dmFm1P5/G5W7lgaGfOHnT8ncZI41DVb9mlxpiHgMdxHb/cDCwLWFQiItIgLdqezr8/38ziHRl0jGrOX6cM4IKhXWjapLxzjFIjVr4K2clw7qMNosnn5pQc7p21jgXb0unbIZL/XDSYkT00Zp/UI6fd5XrcPY76mFVQzK/fXEXXtuHcc27/GgxOGrqqJn83A3cBb3iPPwPuDEhEIiLS4CzblcFDn2/m263pxEY2475z+3PR8C4aby3QSoth/n8gbhj0rP9jIH61MZVfvryM5mEh3H9efy4d0ZUmoTpxIPVIXjpEREOTZtXehLWWO99by/7sQt6+fjQtNayDHIOq9vaZB9wR4FhERKQBKSuzLN6ZwX/nbmPe5gPEtGzKnWcncvmobkr6akvGDjAc91WGuuDLjSlc9/JyendoyQtXjiCmZfV/PIsERV46/Kc/nH4fjPxltTfz7opkPli1l9vP6M3gLq1rMEBpDKra2+fnwAXW2kzvcRtghrX2zEAGJ1IfWWtJOljA8t0HWbE7k+W7D3L+0M5ccVJ8sEMTCThrLWuSs/hg1V4+XL2PfVmFtAkP447JfbnipG66p6+2tesNN69w4/vVY4cTvz4dInnl6pFEhYcFOySRY7fiZSgpgO7jqr2J3en53P3+OobHt+H68Qk1GJw0FlX9Fo45nPgBWGsPGmMq7UPZGDMJeBgIBZ6x1j5QwXLnAzOB4dbapVWMSaROKCwuZd3eLJbtOsjyXS7ZS805BECLsFBO6BKlwailwduamsOslXv5YPU+dqTlERZqOKV3O+6Y3JeJie2JULOk2peVDOHREFa/O0H5YkMK17+ixE/qubJSWPIsxI+F2MRqbcJay+0zV2EM/OciDesg1VPVb+MyY0xXa+1uAGNMPK7jlwoZY0JxHcScDiQBS4wxs6y16/2WiwRuARYdW+giwVNSWsaXG1N5ddFuFm5Lp6i0DIAubVtwUs9ohnZrw5CubejbIVL3o0iDlF9Uwsb9OXy3PZ1ZK/eycX8OIQZO6hnNdaf04Mz+HXTSI9hm3QR5afDLefW2yefhxK9vx0hevkqJn9RjGz6ArN1wxp+rvYlP1u5n8c4M/jZlIJ3bhNdgcNKYVDX5+xPwjTHma+/xOGB6JeuMALZaa7cDGGNmAOcB6/2W+zPwIHB7FWMRCZr9WYXMWLKbGYv3sD+7kPatmjF1dDeGdmvLkG6tiY2s32fYRfxZa0nOLGDDvhw27Mv+ftqVkY/1TgEO6dqae8/px1mDOqoO1BX717pB3U+7u14nfte9sozEjq14+eqRRLVQ4if12Hf/hegESDynWqsXlZTxj0820rt9Sy4afnwDw0vjVtUOXz4xxgzDJXwrgfeBgkpWiwP2+DxOAo4YYMgYcyLQxVr7oTGmwuTPGDPd2zddu3atSsgiNaaszPLN1jReXbSLORtSKS2zjOvdjvvO689pfWN1ZU8anEMlpcxes4+ZS5NYk5xFTmHJ9/O6RYeT2KEVU07sTGLHSAZ2jqJjlAYWrnMWPg5h4TD0ymBHUi1z1qdw/avL6NexFS8p8ZOG4OLXITup2vffvrZoFzvT83l+2nA195TjUtUOX64BbgU645K/UcBC4Gj9RpdXMr9vKmqMCQH+A0yrbP/W2qeBpwGGDRt21OamIjUh91AJW1NzWbgtndcX72Z3Rj5tI5py7dgeXDKiC92iI4IdokiNS80u5JVFu3lt0S7ScovoERPBuSd0IrFjKxI7tqJvh0jdu1cfZO+DNTNh2FUQ3jbY0RwzJX7SoBxuIhER7aZqyCoo5uEvtjC6ZzTj+7SrweCkMarqt/itwHDgO2vtBGNMX+C+StZJAnyvS3cG9vo8jgQGAHONa5LSAZhljDlXnb5IbcnML2Jrai5bUnPZkpLL1gO5bE3JYW9W4ffLjOjelt+c0ZtJAzrQrEn97jFPxJ+1luW7M3lxwU5mr9lHqbWc2ieWaWPiOTkhBlNPmww2auveBVsKo64PdiTHxFrLh6v38es3V9KvUxQvXTVCiZ/Ufxs/gvn/gotehai4am3iibnbyCwo5o9nJeozWY5bVZO/QmttoTEGY0wza+1GY0yfStZZAvQyxnQHkoGLgUsPz7TWZgExhx8bY+YCtyvxk0BLzixgxuLdvLM8meTMH1ovNw8LISG2JSN7RJMQ25KE2Jb069iKLm11U7U0PIdKSvlw1T5eXLiT1UlZRDZrwtTR8VxxUjdd2a7vRl0PPcZD2+7BjqTK1iRl8bfZG1i4PZ3BXVrzohI/aQisha//AUW50LJ9tTaRnFnAc9/uYMrgOAbERdVwgNIYVTX5SzLGtAbeAz43xhzkyKt4P2KtLTHG3AR8ihvq4Tlr7TpjzP3AUmvtrOMJXORYlJZZvt6cyqvf7earTalYYEKfWKaO7kav2EgSYlsS17oFIWpHLw1YdmExX286wOfrU/hqUyo5hSUkxLbkzz8dwM9OjFOTzoagrAxCQqB9v2BHUiV7MvL512ebeH/lXtpGNOX+8/pzyYiuhOleamkINn0M+1fDef+F0Op9vv77000A/ObMyq65iFRNVTt8meL9e68x5isgCvikCuvNBmb7PXd3BcuOr0osIsciNaeQmUuTeG3RbpIzC2gX2YwbJyRw0fAu6iZZGoU9Gfl8sSGFORtS+W57OiVlluiIpkzq34HzBscxJiFazYgairJSeHIsDJ0GIyvrkDu4svKLeXzuVl74difGwI0TenLdKT2JbK6rfdJAWAtfPwBt4mHQRdXaxNrkLN5Zkcz143sS11oda0nNOObTENbarytfSiR4UrMLWbknk/dX7uXTdfspKbOMSYjmT2cncnq/9jqjLA3ejrQ83lmexOfrU9i4PweAhNiWXDO2B6f3i2VwlzbqLa4h2vABpK6DyA7BjqRCh0pKeXnhLh79civZhcX8fEhnfnNGb/UYKw3P1jmwbxWc+1i1rvpZa/nb7A20jWjK9eN7BiBAaazUxkfqtfTcQ6xJzmJ1kpvWJGeSkn0IgKgWYUwbHc+lI7vSo13LIEcqEnibU3J47MutfLjatcofFt+WO89O5LTE9nSP0X18DZq1sOBRaNMd+p4d7GjK9c2WNP7w7mr2ZBQwtlcMf5icSL9OrYIdlkhgdB/nEr8TLq7W6nM3HWDBtnTuPacfrXRFXGqQkj+p8wqLS0nOLCD5YAFJBwtIzsxn+4E8Vidlfd9hizHQIyaC0T1jGBgXxaDOUQyIi6J5mHrnlIZv3d4sHvtyKx+v3U9401CuHduDq8d214DrjcmeRZC8FM76V7XHEQuUsjLL419t5aE5m+nZriUvXTWCcb3VXb00cE2awZBfVGvVktIy/jZ7A91jIrh0ZLcaDkwaOyV/Uqds2p/D+yuT2ZWeT1JmAckH80nLLTpimdAQQ5c2LTixa2umju7GoM6t6d+ple4VkUZndVImj3yxlTkbUohs1oSbJiRw1cndaRvRNNihSW1b8Ci0aAODL6182VqUmV/Er95YyVebDjDlxDj+OmUA4U3100MaMGth5lRIPBcGnl+tTcxclsSW1FyevHwITZvoVhWpWfoElqArLbPM2ZDCC9/uZOH2dMJCDZ3bhNO5TQsSE9sT17oFndu2IK51OHFtWtA+shlNdN+eNFJuXL6DPPLFVr7efICoFmH8amJvpo2JV9f4jdmEP0LGdmhad5r3rknK4vpXl5GSXciffzqAy0d2VedC0vBt+wLWvw89JlRr9bxDJTz0+WaGdWvDmf3r7v27Un8p+ZOgycwv4o0le3hp4S6SMwvoFNWc30/qy8XDu9BGVy5EvldSWsaSnQeZsyGFORtS2JWeT9uIpvz2zD5ccVI3XfUWaN/fTXWAtZY3luzh7lnriIloyszrRjO4S+tghyUSeNbC3H9AVBcYfFm1NvG/+ds5kHOIJy8fqpMlEhBK/qTWbdyfzYsLdvLuimQKi8sY2b0td/0kkYmJ7XVFT8STU1jMvM1pzNmQwpcbU8kqKKZpaAijE6KZPq4HU06MU/M5gfwM+OQPcMrvIDr4PQIWFpdy13trmbksibG9Ynj44hPVDFkaj21fQtJiOPshaHLs5T41u5Cnvt7O2QM7MrRbmwAEKKLkT2rRlpQc7v9wPfO3pNGsSQhTToxj6uh4EjuqtzcRgIN5RXy0Zh+frtvPd9vTKS61tAkPY2Jie07vF8vYXu00ELscaemzsHoGnHxbsCNhV3oe172ynA37srnltF7celovDSkijYe18PU/oFUcnHh5tTbx4KebKCkr43eTNKC7BI5+RUjA5ReV8MgXW3lm/nYimjVR004RH4dKSvlq4wHeWZ7EV5tSKS61dI+J4Mox3Tm9X3uGdNWYfFKBslJY9DQkTITYxKCGsmxXBtOeX0KIMTw/bTgT+sYGNR6RoDj511Ba5Hr6PEbfbU/nrWVJ3DC+J92i6869u9LwKPmTgPps3X7u+2A9yZkFnD+0M3+Y3Jfolsf+oSjSkFhrWbEnk3eWJ/Hh6n1k5hfTLrIZU0+KZ8qQOPp3igp2iFIf7FsJealwwiVBDWPZrgymPreEdpHNeOmqEXRpGx7UeESCwhjoM6laqx4qKeVP766hS9sW3HxqrxoOTORISv4kIPZk5HPfB+uYsyGVPu0jefOXJzGie9tghyUSVMmZBbyzLIl3ViSzIy2PZk1COLN/B342JI6TE2J0z6scmyuwDV0AACAASURBVB3z3N/u44IWwrJdGVzx7GJiWzVnxvRRtG+lsSWlEUrdAGvfhlE3QPix/9b5f/buO76O4lz4+G/Um9WtYsmWbMtN7gVXigEbbEoIlxK6TQ+E5JKQlxASArkJN6TcVHpvpoYeejNuuBv3JqtYktV719E58/4xK7w6Oio2OpIsPd+Pz8d7dnb3zK52dvfZmZ197KtMDpXU8ey1JxEc0L/e0ykGHgn+RI9qbnHxxOpM/vXFQXyU4u5zxnPtgpH4y0WtGKS01mzIKufZtdl8sqcQl4a5o6K5ZeFolk5KkJ46xfELCIOxSyGsb5pYbs4uZ9nTG4kPD+JlCfzEYLb5adjynAn+jlFWaR0PfpnBuVMSWThOmksL75PgT3xnDqeLg0W1bM+r5MnV5u7V0kkJ3HNeOsMig/s6e0L0iYZmJ+98k8+z67LZV1hDZIg/N506mivnjJBmcaJnzL7RfPqABH5CWJrrYfurkP69Y67101pzz9u7CPT14d7z0r2UQSHakuBPHBOnS3OopJYdeVXszKtkR34Ve45U09TiAiAlJoRnrj2J0+XulRik8irqeWF9Dq9szKWqwcGExHD+eNFkLpiWRJC/NOcRPaS53nQq4dP7+9Sm7HKWS+AnhLHnHWiqgpnLj3nWd7cfYU1GKf9zwUTipByJXiLBn+iS1poPdhby3NfZ7Mqvor7ZCUBogC8TkyK4em4KU4ZHMiUpghHRIfhIz4RiENqSU8Hjqw7x6Z4ilFKcPTGe5fNHclJqlLyoV/S8df+EjY/DT3eDf++1sLAHfq/cNFcuWIXY+hzEpEHKgmOararewe/+s4epyRFcOSfFS5kToj0J/kSnNmWXc//7e/kmt5LRQ0O5dNZwpiRHMCU5gpGxYdIFvRj01meW8a8vDrI2o4yoEH9+eNporpqbIk2ehXdlrYLIEb0e+C17eiMJEUG8cqMEfkLQ0myeuU2/wPT2eQz++PE+KuodPHfdbLmWEr1Kgj/h0aGSWv744T4+2VNEfHggf7p4ChfNSJYDlBCY2vA1GaX86/MMNmaXExsWyK/OmcCVc0cQEiCHVeFlzXWQuxHmHXvnEsdLAj8hPPALgEufP+bZtuRU8NKGw9xw8kh5tY/odXKVItooqWniH58f4OWNuQT7+/Lzs8Zy/cmjpOthITBB35f7i/nn5xl8k1tJQngQ952fzmWzR8jzfKL3HF4PLkevveLh60NlXP/cJgn8hLBzNEJVLsQe23v5HE4Xv3prJ8Migvjp4rFeypwQHZPgTwBQ39zCU6uzePSrQzS2uLhi9gj+e9EYYuWF7ELQ6HDy5b5iHlqZwa78apIig/n99ydxyaxkAv0k6BO9LGsV+PjBiHle/6k1B0u54flNDI8KYcWNc4gbIoGfEADsfQ/evAFu+AKSZ3Z7tqfWZLGvsIbHr55JaKBchoveJ3vdIFVc3ciOvCp2WD12bjtcSVWDg7MnxnPnkvGMHhrW11kUok+V1zXzxb5iPttTxKqDJdQ3O0mJCeFPF03hwhlJ8u5K0XfGnwcRyRAQ6tWfWbm/mJte2MKo2FBevGGO3AwUwm7rcxCVCsOmd3uW3PJ6/v7ZARanx3PWxATv5U2ITkjwNwjUNDrYnFPBzrwq84qG/EqKqpsA8FEwNn4IZ6XHc+lJwzkp9djeUSPEQJJZUstne4v4bE8xm3PKcWmIDw/kwulJLEqP55S0WPwk6BN9bfhJ5uNFn+0p4tYVWxkTH8aL188hKjTAq78nxAmlNAOyV8OZvwGf7p0TtNbc++5ufJTit9+b6OUMCtExCf4GsEaHk+e/zubBLzKobmxBKRg9NIwFo2OZbPXYmZ4YIc/ziUGtucXFE6szeWNrHpkldQCkJ4Zz2xljWDwhnklJ4fKqBtF/lOyHuhIYPhd8vXMK/2hXAbe9tI2Jw8J5/ro5RIT4e+V3hDhhbX0OlC9Mu7Lbs3yxr5gv9hXz63MnSG/Qok9J8DcAuVya93Yc4U8f7Se/soGF44Zy0ymjmJwcwZAgOYkL0eqb3Eru/Pd2DhTVMn90DMvmpXLmhDiSo0L6OmtCeLb5adjyHNyVgzdO4e9tP8Ltr37D1OQInr1uNuFyzhCiLZcLdr8F45bCkO413XS6NA98uI9RsaEsm5/q3fwJ0QUJ/gaYdYdK+cMH+9iZX8XEYeH86eIpLEiL7etsCdGvNDQ7+eun+3lqTRZxQ4J4evkszhgf39fZEqJrWatgxFzw6/nn797alscdr21nZkoUz1w7mzDpjEKI9nx84IerobGq27O8sTWPg8W1PHLlDHleXPQ5ObIPEAeKanjgw318sa+YpMhg/vaDqVwwNQkfeS+fEG2szyzjF2/sIKesnivmjOCupeOldkOcGGqLoXgPTL6kxxf9+uZc7nxjB3NHxvDU8lnyvkohOhMcZT7d0Ohw8rdPDzB1eCRLJkknL6LvydH9BHeksoF/fn6Q1zbnEhrox11Lx7N8fqq8c0wINzWNDh74cB8rNhwmJSaEl26cw/zRUisuTiDZq83/I0/r0cW+tjmXO/+9g1PGxPL41bPkOXAhOlKRDf++Hs79Pxg2rVuzPLcum4KqRv72g2ny/LjoF7wa/CmllgD/AHyBJ7XWD7il/wy4AWgBSoDrtNY53szTQJFRXMOjX2Xy9rZ8lIJl81P58RljiJYe2YRo58t9xdz91k6Kqhu54eSR3HHWOLnAFSee7LUQGAGJU3tskR/vLuSuN0zg98Q1s+TGoRCd2foCHNkKoUO7NXlVvYOHvszg9HFDmTsqxsuZE6J7vBb8KaV8gYeAxUAesEkp9a7Weo9tsm3ALK11vVLqFuBPwA+8laeBYOvhCh5deYhP9hQR5O/DVXNTuOGUkdJBhRBuHE4Xn+8tZsWGHFYfLGVsfBgPXzmf6SO611RHiH5nyQMw5+Ye6+VzQ2YZP355G1OSI3ns6pkS+AnRGWcLbHsR0hZDRFK3Znn4qwxqmlq4c8l4L2dOiO7zZs3fbCBDa50JoJR6BbgA+Db401p/aZt+PXCVF/NzwtJa89WBEh5ZeYgNWeVEBPvzkzPHsGxeCjHy0l0h2jhS2cArm3J5ddNhiqqbGBYRxC+WjOe6k1MJ9JOLW3EC8wuAoeN6ZFF7C6q54fnNDI8K5pnlJ8kzfkJ05eDHUFsIM//WrcmPVDbwzNpsLpyexITEcC9nToju8+bRPgnItX3PA+Z0Mv31wIeeEpRSNwE3AYwYMaKn8tfvOV2a93cW8MjKQ+wtqCYhPIhfnzuBy2ePIFR6YRPiWy6XZtXBEl5cf5gv9hWhgYVjh3L/91M4fXwcvtLxkTjRHfjY9PR5+q8g4Lu19Mgtr+eapzcSGuDH8/ICdyG6Z8uzMCQRxpzVrcn/9ukBAO44q2du2AjRU7wZQXi62tIeJ1TqKmAW4PEpdq3148DjALNmzfK4jIHE4XTxzjdHePjLDDJL6xg9NJQ/XzyFC6YlEeAnXQQL0aqqwcGKDTm8vPEwueUNxIYFcMvC0Vx20giGR0tTaDGA7HoTMj6Ds37/nRZTWtvENU9vpLnFxes/nEeSvGxaiO6Z8D0Yf163ml3vL6zhja15XH/ySCljot/xZvCXBwy3fU8GjrhPpJRaBPwKOE1r3eTF/PR7zS0u3tiax8MrM8gtbyA9MZxHrpzB2RMT5JUNQthU1DXz1JosnluXTU1TC/NGxfCLJeM5Kz1BbpCIgUdrU+s38lT4Dr0F1ja1cO0zmyioamDFDXMYGz+kBzMpxAA34+puT/rnj/cRGujHrQvTvJghIY6PN4O/TcAYpdRIIB+4DLjCPoFSajrwGLBEa13sxbz0a40OJ69tzuXRlYc4UtXI1OQI7j1vImdOiJNugYWwKalp4snVmbywPocGh5OlkxK47fQxpA+T5ynEAFZ2CGqOmODvODW1OPnhC1vYU1DNE9fMZGZKdA9mUIgBzOmArc+Z92sGRXQ5+cascj7bW8ydS8ZJk2rRL3kt+NNatyilbgM+xrzq4Wmt9W6l1P8Am7XW7wJ/BsKA160g57DW+nveylN/09DsZMWGHB5flUlxTROzUqL4w0VTOHVMrAR9QtgUVTfy6FeHeHnjYZpbXJw/dRi3nZ7GGKm5EINB1krz/3EGfy6X5o7XtrMmo5S/XDKVM8bH91zehBjo9rwD798BESNgbOfP+2mteeDDvSSEB3Ht/JG9lEEhjo1Xew3RWn8AfOA27je24UXe/P3+qqrewfNfZ/PMumzK65qZNyqGv182jXmjYiToE8Imv7KBR1ce4tXNuThdmgunJ3HrwtGMGhrW11kTovc4GiFhCkSPOuZZtdb89r3d/GdHAb9cOp6LZyZ7IYNCDGAbHzdlL63rS9aPdxex9XAlf7xosrxLVvRb0mVkLyqsauSpNZm8tOEwdc1Ozhgfxy0LR3NSqjS/EcLucFk9D6/M4I2teQBcPDOZW05LY0SMdOIiBqH5t5nPMdJac//7e3nu6xxuOHkkN5167MGjEIPakW2Qu8G8Y9On8+fJW5wu/vTxPtLiwrhohtxkEf2XBH+94FBJLY9/lcmb2/JwaTh/SiI3nzZa3vsihJtDJbU89GUG73xzBF8fxeWzR3DzaaOltzQxeLlcXV50euJ0ae5+cyevbs5l2bwU7j5ngrQsEeJYbXgc/ENh2hVdTvr6ljwyS+p4/OqZ+PlKx2Oi/5Lgz4u251byyMpDfLynkABfHy6fPYIbTxklXdAL4WZ/YQ0PfpnBf3YcIdDPh+XzU7n51FHEhQf1ddaE6FsbHoFNT8LNqyCwe8+4Nre4+Omr3/D+zgJ+ckYaP108VgI/IY6VywW1RTDt8i47eimubuT/PjnAzJQoFqfLM7Wif5Pgr4dV1jfz3o4C3tyax7bDlYQH+fGjhWksX5BKbFhgX2dPiH5lV34VD36RwUe7CwkN8OXmU0dzwykjpawI0SprFSifbgd+Dc1OfvjiFr46UMKvzpnAjdLUU4jj4+MDV78JzpZOJ2tqMWWurqmF339/ktxoEf2eBH89oLnFxcr9xby5NZ8v9hXT7HQxLn4Ivz53ApfNHkFYoGxmIezyKur53w/28sHOQoYE+fGTM9K4dsFI6RZbCDtnC2SvhSmXdGvyqgYH1z+7iS2HK3jgvyZz2ewRXs6gEAOU0wH15TAkvsuXut/37h62Hq7koStmyOM84oQgUclx0lqzI6+KN7fm8e72I1TUO4gNC+DqeSn814wk0hPD5e6PEG4aHU4e+yqTR77KQKG4fdEYrl0wkohg/77OmhD9z5Ft0FzTrVc8lNY2cc1TGzlYXMODl8/g3CmJvZBBIQaove/BmzfBDZ/BsGkdTrZiQw4vbzzMrQtHS5kTJ4wBG/w5XZrimkbyKxrIr2wgr8J88isbCPTzYXZqNLNHRjNxWHi3H8wtq21iY1Y5G7LKWXWwhMySOgL9fFicHs9FM5I5ZUysPOQrhAdaaz7ZU8Tv/rOHvIoGzp2SyK/OmcAw6chFiI5lfWX+Tz2l08mOVDZw1ZMbOFLVwBPXzGLhuLheyJwQA9iGxyB8GCRM7nCSTdnl3PfubhaOG8odZ43rxcwJ8d0MqODv871FPLk6i/zKBgqqGnA4dZv06NAAkiKDqWl08OmeIgDCAv2YmRLF7JHRzB0VzeSkSAL8TABXVN3IhqxyNmSWsSGrnIziWgCC/H2YlRLNzaeOYunkRMKDpNZCiI4cKqnlvnd3s/pgKePih/DSjXOYPzq2r7MlRP+XNBNO+TmEdlxeMktqufqpjVQ3OHjh+jny6iAhvquC7ZC7Hs66H3w8v6uvoKqBW17cSnJUCP+4bDq+PtLSS5w4BlTw1+LSNLU4mTY8knOnJJIUGUxSVDDDo4IZFhlMSMDR1W0N7DZmlbEhs5w/f7wfMIHdlORIiqsbyS6rB0yAOCs1iotmJDN7ZDSTkyK+DRCFEJ7VNrXwr88P8vTaLIL8fbn3/HSunpsiteNCdNfo082nA+sySvnxy9vQwMs3zWVSUuc9EgohumHD4+AfAtOv8pjc6HDywxe20Ohw8spNc+SxBXHCGVDB39kTEzh7YkK3po0PD+J7U4fxvanDANOkc1O2adK5NaeCtLghXDU3hTkjY5iQOEQuWIXohrqmFjZmlbMmo5R3tx+hpKaJS2clc+eS8dKDpxA9xOXSPLrqEH/5eD+jhobx2NUzGT00rK+zJcSJr6kWdr8JU34AwZHtkrXW/OqtXWzPq+Lxq2eSFte9XniF6E8GVPD3XcSEBbJkUiJLJskDu0J0l8PpYntuJWsySlmbUcq2w5W0uDQBfj7MHRXDE9eMZdrw9idQIcTxqWpwcMdr2/lsbxHnTUnkjxdNIVR6lBaiZwSGwa3rO2zu+ey6bN7Ymsfti8ZwVjcrG4TobwbXGUNrKNxpXtppFxYHiVPN8KEvwOVsmz4kERImmeGDnwFtnyUkYjjEjTfzHfqi/e9GjYTYNGhpPvoAv13MaIgeBc31kLO2ffrQcRA5AhqrIXdD+/T4iebB5PpyyN/SPj1hiumuuK7U9B7nbtgMCI2BmkKzfdwln2TugFXlQ/Ge9ukj5pp3UFXkQOmB9umpJ4N/MJQdgvLM9umjFoKvP5QehIrs9umjzzTv2yneC1V5bdOUgrRFZrhwp1kHOx+/o82mjnwDdSVt0/2CYKTVmULeFmgob5seEAYp88zw4Q3QVN02PSgShp9khnPWQXNd2/SQaPPczgBS0+jgtc15rMsoZX1mGXXNTpSCyUkR3HjqKE5Oi2VmHAQVb4fGTXDQmtE/BFIXmOHcTdBY2XbBgUPMvgRweD001bRND46C5FlmOHsNOBrapofGwrDpZjjzK3A2t00Pi4fEKWY443PQrrbp4UkQn26OExmftV/xyBQYOtZ0v5/5Zfv06FGmLDsaIXt1+/TYMRCVau4sH/66ffrQ8RA5HBqrIHdj+/T4SRCe2HE5T5wGYUOhttg8s+IuaabZH6sLoGhX+/Ths82LjCtzoWRf+/SU+RAQCuVZUJbRPj31FPAP6qScn266TC/ZD5WH26ePWWz+L9oD1flt05QPpJ1phgt2tD+G+wbAqNPaL3OA2X2kiltXbCW/ooH7zk9n2fxU6VVaiJ4WleJx9LpDpfz+/b0sTo/nJ2eM6eVMCdFzBm7w53Kai4wj2wBt2m4rBSsugVq3ACH9Arj0eTP8+nJz8WU37Sr4/kNm+KVLQbsFh3N+CEv/aN4Ls+Li9nk55edw5j0mcPCUfua9cMrPzAWNp/Rz/gKzb4TKHM/p338Upl1u1tdT+g9ehAnnm+DHU/rVb5sA6fDXZv3dXf+ZCXAOfQHv3tY+/db1EDcB9n8AH93VPv32Xeaidteb8OXv26f/Ittc2G97Edb+vX36PWWAD2x60nzsfAPhnmIzvO5B2PFK2/SQGLjTuhBd9WfY95+26ZEpcPsOM/z5b9sH5/GT4BYrIP/4bsjf3DZ9+Fy4/mMz/J+ftr9oHn2meUnsAKKU4g8f7GV4dAgXzkji5LRY5o6MIrI+x9yoAHjufPNyaruYNPixFbR8dm/7Gx2J0+Bma/t/8P+gcEfb9NRTYLn193v3J1B+qG362KVwhfX3f/PG9gHCpIvh4qfM8KtXg8MtUJ+5HM7/hxn2VE7m3QZn3w+Oes/pC38JC++ChgrP6WfdD/Nvg5oCz+nn/R1mXWuCJ0/pFz0Fky82gZun9MtfhXFLIG8zvHJ5+/Tl75sbMdlr4M0b2qff9JXp0jzjU7Mvu7tti7mJtfc9+PSe9ul37Af/BNjxKnz1x/bpv8wH3zDY8hysf6h9+n3WcXfDo7D1ubZpAUPgbuvGz9q/w6432qaHJcDP97df5gDy+uZcfv32LqJCAnj15rnMTJGOXYToUXvfg63Pw/cfadfJUm55PT9asZWRsaH89dKp+EgHL+IEprTWXU/Vj8yaNUtv3ry54wm+fgj2vGsuHB2mwxbiJ8Mta8xw9lpzl9h+tzQ4ytyxB8jf2r5GICQGokea4TwPvx061NwpcrngyNb26UMSICLZBIee7siHJ5k7+o5Gz3fkI0eY2snmOlP75S4q1RyommpMAOguepS5499Q6fmOfewYc8e/vtzzHfuh40ytTG2JCUDdxaVDQAjUFEFVbvv0hMngFwjVR8zHXeI0UyNQmdv+gh1MjYVSplawrtQtUUGyVbNWnmnWwc7H92htUGlG+9om34CjtUEl+9vXNvkHm5pVMNvevWYvINQEvgCFu6ClsW16YLipLeqCUmqL1npWlxP2kq7KWUlNE0N9as0NgYxPTU1aQ7kJtIOjTM2ds9nU9rXyCzzabXbxPmiubbtQ/xBT8wZQtLt9zV5AmKlhB1PL29LUNj0owuzLYG50uFraprcp51tMDZ9daKwpS1p7rlkLizNl0dkCBd+0Tx+SCBFJpobfPXAFcwwYkmDWq2h3+/TIFFNz11TrueYtaqSpoW+s9lzDHjParGNDhQkg3cWOhaBwqCuDiqz26XETzP5cW+y5Zi5+oikPNYXta+DBtDDwCzAtBGoK2qcPm27KY+Vh8xvuWmt1y7OgvqxtmvKBpBlmuOyQWUc7H79O38X17WL6WTmDrstao8PJb9/bzcsbc5k/OoZ/Xj5dnp8V/V5/K2tdXjsCPHMuVB2Gn3zzbbPPqgYHT63J4uk1WSgF7/xoAaPk+VrRTxxvORt4wd+Hd5navmHTj35i0kyzQSH6qRPuRLnjdVO7hjY3R0afaZrfTjjPBBBC9EP9rZxB52Utt7yeW1dsZWd+FT86fTQ/WzxOupQXJ4T+Vta6PKcV7oJHF8Di38GCn1DT6ODZtdk8sTqT6sYWlk5K4I6zxkoHL6JfOd5yNvCafS59oK9zIMTAlzzLNHFMW2xqXDp4OF4IcXy01tz+6jdkl9Xx5DWzWJQe39dZEmLg2vgY+AVTN/FynluZweOrMqmsd7BoQjw/XTyGicPkNSpi4Bh4wZ8QwvuiR5rgTwjhFUop/njRZPx9fUiJkdp0Ibymvhy943X2xS3lqn99Q1ldM6ePG8pPF49lSrL0Vi0GHgn+hOhhDoeDvLw8Ghsb26UFBQWRnJyMv7+8FFaI72IwlDNpYib6g4Fe1r7KKGeX60LezppGelo4ty8ay8yUqL7OlhhkerOcSfAnRA/Ly8tjyJAhpKa27YZda01ZWRl5eXmMHDmyD3MoxIlPypkQvWOgl7WhsXGsSVjG/YvHMnuk9KIr+kZvljPpBUWIHtbY2EhMTEy7928ppYiJifF4V0cIcWyknAnROwZ6WUsfFs7LN82VwE/0qd4sZxL8CeEFHb14WV7ILETPkXImRO+QsiaE9/VWOZPgTwghhBBCCCEGAQn+hBBCCCGEEGIQkOBPCC/QWh/TeCHEsZNyJkTvkLImhPf1VjmT4E+IHhYUFERZWVm7wtraY1NQUFAf5UyIgUPKmRC9Q8qaEN7Xm+VMXvUgRA9LTk4mLy+PkpKSdmmt72oRQnw3Us6E6B1S1oTwvt4sZ14N/pRSS4B/AL7Ak1rrB9zSA4HngZlAGfADrXW2N/MkhLf5+/uf0O88EuJEIOVMiN4hZU0I7+vNcua1Zp9KKV/gIWApkA5crpRKd5vseqBCa50G/A34o7fyI4QQQgghhBCDmTef+ZsNZGitM7XWzcArwAVu01wAPGcN/xs4U8lLY4QQQgghhBCix3kz+EsCcm3f86xxHqfRWrcAVUCMF/MkhBBCCCGEEIOSN5/581SD595XaXemQSl1E3CT9bVWKbX/O+ZNiP4mpa8zYLdly5ZSpVROX+dDiB7Wr8oZSFkTA1a/KmtSzsQAdVzlzJvBXx4w3PY9GTjSwTR5Sik/IAIod1+Q1vpx4HEv5VMI4UZrPbSv8yDEYCBlTQjvk3ImxFHebPa5CRijlBqplAoALgPedZvmXWCZNXwx8IWWN4YKIYQQQgghRI/zWs2f1rpFKXUb8DHmVQ9Pa613K6X+B9istX4XeAp4QSmVganxu8xb+RFCCCGEEEKIwUxJRZsQQgghhBBCDHzebPYphBBCCCGEEKKfkOBPCCGEEEIIIQYBCf6EEEIIIYQQYhCQ4E8IIYQQQgghBgEJ/oQQQgghhBBiEJDgTwghhBBCCCEGAQn+hBBCCCGEEGIQkOBPCCGEEEIIIQYBCf6EEEIIIYQQYhCQ4E8IIYQQQgghBgEJ/oQQQgghhBBiEJDgTwghhBBCCCEGAQn+hBBCCCGEEGIQkOBPCCGEEEIIIQYBCf6EEEIIIYQQYhCQ4E8IIYQQQgghBoFBEfwppX6plPrAbdzBDsZd5mH+VKXUl0qpeqXUPqXUok5+K1Ap9bRSqlopVaiU+plb+qVKqb1KqRql1B6l1PdtacuVUk6lVK3ts9BKG+E2vlYppZVSd9jmH6qUekkpVamUqlBKrbClJSml3lFKlSul8pRSP3TLl1ZK1dmW/aTbOj2qlCqy5n9PKZVkS5+glPpCKVWllMpQSl3YE+tspc9XSm205t2hlDrZbdlXKKVyrLy/rZSKdvu7fWBti0Kl1INKKT9b+vlKqV3Wb65TSqV38Df9wto+ftb3OKXUy0qpI9Y6r1VKzfE070DXn8qWbbp7rb/XIrfxi5RSW619JVcpdamHeZdZ895gG3e6lccqpVS2h3mylVINtv33E1uaUkr9XimVb82/Uik10ZYerZR6VSlVan1WKKXCbenTlFKrrXnzlFK/saWlK6U2W/t3hVLqM/s+rJS6XSmVaW2vI0qpv9n3f2ua/1ZKZVnbZK9Saqw1PlEp9a41n1ZKpbrN9xfrb1pj/d2usaWdojwfqy6y0h91S2tSStXY5u/weGLtL9pt/nvc/yYDTX8pZ0qpuUqpT5U5D5QopV5XSiXa0u9TSjnc/j6jbOmPK6X2K6VcSqnlbr87SSn1sVUOdAfr0Nnx/Axlyne1td/f5DZ/h+dH2zTR1nqtsY3rqpydro7z+GClk73HGwAAIABJREFU/9Ranypruwfa0jo8/ymlFlrb0b6tl9nS3cugUyn1L1v6DVb5qlVKfaSUGuYh7wHW/pLnnjZQ9aOyFqCU+re1/2hluy6y0js9vne231m/+zdrvgql1MNKKX9b+otKqQJr2QdU2/Nhl8dg1cG5VikVq8z1UplVDr9WSi04hnxFK6Xespabo5S6wu13f6zM+azaKrP28vKhW56blVI7bemdnWs7XWfVyfnQSu/s+rrTY6bXaK0H/AdYAFQBvtb3BCAbKHQbp4FhHub/GvgrEAxcBFQCQzv4rT8Aq4EoYIL1G0ustCSgGVgKKOBcoB6Is9KXA2u6uU4jASeQahu32spnBOAPTLelfQn83Ro/FSgHTrelayCtg9+6E9gOxANBwAvAm1aaH3AA+BngC5wB1AFjv+s6A9FAKXCJteyrgAogykqfCNQApwJhwEvAK7b5PwCetfKcAOwEfmKljQGqgZOtdfglkAH4ueXhSmCVtX38rHGjrPVNtPJ1k5XPsL7e1wdr2bJNM9r6Ox8BFtnGpwPF1n7oB8QAo93mjQL2AbuAG2zjZwNXW3/nbA/5yrb/llvapVZeRln7yh+Arbb0h4FPgHBMuf0M+KstfQ9wvzXvaKAA+J6VFgmkYsqVL/ATYIfbtoi0laUvgJ/Z0m8AdljbRlnTR1tp8cCtwDzrb5fqtl6/BcZjbiDOwZTL+R1sg4WYchraQfqzwNPWcFfHk1RsZXGwfOgn5cwqP5dY+2sI8DTwkW3e+4AXO1mPHwFnApuB5W5p44DrgQsA7WHezo7n/tb2udnal08CaoGptvk7PD/apnkCc7xfYxvXVTn7LseHs4EizLksClgJPGArs52d/xYCed3cf0Kt7XGq9f00zPFwIhAAPAJ85WG+X1nbo1u/MxA+/aisBQC3Y65RCoCFbvN2dXzvbL+71/rdaGAosB74rS19IhBoDY+38jXT+p5KJ8dgOjnXYsruOMx5QwHfx1yL+nUzXy8Dr2Ku9062/k4TrbQ5mHPFTGvZtwAlrX8zD/lcCfzG9r2zc21X69zp+ZDOr6/vo5Njptf2874uaL2ykqYQ1dt23kuBZ4Cv3MZleJh3LNAEDLGNWw38sIPfygfOsn3/HVZAYu0UxW7TlwDzrOHldD/4uxf40vb9LExhb7ejWwVFYzsAAY8DL9i+d7ZzPgL8yfb9XGC/NTwJc1JRtvRPgN9913UGzgN2u407AFxvDf8v8JItbTQm0Bxifd8LnGNL/zPwmDV8G/C+Lc0HaADOtI2LsH5vbmcF35q2unVfGkyf/lK2bOM+BM7B7cSHuTHwuy7W5VFMwLMSW/BnS1/EsV/c/QJ4zfZ9ItDolt9bbd9/BHxs+14PpNu+vw780sPv+Fnz1neQjxhMYPmwbX/Pte/vHcznh4fgz8N07wJ3dJD2DPBMB2mhmMDwNOt7V8eT1K7K4kD89LdyZkubAdTYvt9HNy5kgDW4BX+2tDQ8B3+dHc/jrf0ixJa+CbjcGu7w/Gibfh7mwv1aOj4ndVjOjvP48BLwv7bvZwKF1nBX57+FdD/4WwZktpYr4C/AQ7b0Ydb2G20bN9La5ku7+zsD4dMfyxqQh1vw55be5vjejf1uM3CJ7fsVQG4H047DBEKXWt9T6TwQ6vJca03nA5xvLSuuq3xhzhXNWDcCrXEvcPRmyQ+Ajba0UGvZiR5+OxVTeTLSNq7Dc21X6+xh+W3Oh/TD4G9QNPvUWjcDGzA1RFj/r8acgOzjVgEopf6jlLrLGj8RyNRa1xxdItut8W0opaIwB9HtHUy7GdirlPqeUspXmeaPTZi7762mK9Ps5YBS6h7l1kzL5hrgOdv3ucB+4DmrSn2TUuq01qy5/d86PMltmauspgdvqrbNvJ4CFiilhimlQjC1YR96WKanZX+XdVYelm9f9kRs21prfQjr4GCN+gdwmVIqRJlmqkuBjzpYdut3+zb5X0zgW+hhHY/OqNQ0zAkjo7PpBqJ+VLZQSl0CNGutP6C9udY0O63mLC+qtk2EZwOzMAHg8VihTHOxT5RSU23jXwHSlFJjreYryzi6DwI8BJynlIqy1vEijpYtMLX11yil/JVS4zAXqJ/Zf1gpVQk0Av/C7LP2tCuUUtWYGoSpwGNWUrL1mWQ1y8lSSv1WKXXM5wSlVDCmpmW3h7QQ4GLaHqvsLsLcDFrVOounn6D9sSrHaprzjFIq9ljzfKLpT+XMzam0/7ufr0yz0N1KqVu6sXrd1eHxXGtdhKkVuNY6z8wDUjDbBzo/P6KU8sWUxdswF2rtdFbOuqGj40Obc5g1HK+UiqHr8x9AnDKPY2Qp01wutIPfXwY8r62rTQ/Lbh22L/tfwN2Ym6KDRj8ua+10cnxv1dF+5+nvn6yUirAt+2GlVD2mNUwBpubdrqNjcKfnWittB6YsvQs8qbUu7ka+xgJOrfUBW7p9e30I+Cql5ljl+TrgGzxfv10DrNZaZ9nGdXmu7WSd7evW0fmwo+tr8N4xs2O9HW321QcTXb9lDW/HNPtb4jZumYf5rgbWu427H3jWw7TDMSeOINu4xdjuBmKatdQCLZg7Defa0kZh7rb5AJMx1dCe7vKfYi0jzDbuceu3r8c0abkM09wg1kpfgzmYB2Hu1pZj1d5Z6adiAphI4EFM07fWqvhwzIlVW/nextHmYf6YO4p3WsNnYQKwj7/rOmPuZlUCl1vLXga4OHq393Pc7qhh7qQttIYnAFus39WYJkOtdz7HY5oILLTW+x5r2a2/PQtz4PCjk7s+1rbZ6envNFg+9IOyhandPoh1J4/2NX/N1rix1rRvACusNF/MTYrW2uiVHFvN3wJME58QTPPhQo42xwnAXLS2lp0s2t5tHIY5wbisz6dAgC19PuamQus+/Fv337emC8XUWp7bQfoYzF3lBNtyNfA+R5u1HQBudJuvy5o/TGD3UWvZ8vA3zvKUZqV/Dtxn+97p8cT6282y8hUP/BvbsWYgf/pDOXObdgrmPHKKbVy6tU/7WvtYAVbtm9u8x1Pz1+Hx3Eo/H9OEssX63GhL6+r8+FPgEWt4OR3X/HVYzji+48MhbE3Xrbxpqzx2df5LsLa3D+Ycuqo1ze33R9C+luNMTMAwxcrbY9ayW2tKL8Rqzssx1DAOlE8/LGtd1fy1Ob53Y7/7PbAW07QyARPstqslw5Tjk4FfA/7WuE6PwXRyrnVbdpC1by+zjeswX5jr3kK3ZdwIrLSGFeZmhQNT/kuBkzrYXhm0b3be4bm2q3V2W0678yGdX19365jZ4/t4Xxey3vpgnh0pwbStPmKNC8ecLKJwOzja5rsQ2OM27l/AvzxMG4WtCtsadxGw0xpeBJRZO5EP5u5AATCtgzxfBmzxMP5J4Dm3cf8AstzG7QQusIZTgP9Y22CDtQ6fd/C7vpjAaLL1fQXwFqYddiAmUNpgm34KpklEGfAx8CLwVE+sM+bZhE2Yi4yXMU3A7rHS3gHudJu/BtPm2wc4jHlmIRBzIn2Hts1XL7YKYZm1/XZhDt4+wEaONkVLxUPwhzmwfgU80df7t5Qt/o+27fezaRv8VQH32r7PBCqs4R9jPXNmfV/JMQR/HqbbB5xvDd8PrMPUsvlhLiyzsJqnYU50D2MuKsMwNY+vWWnRmObE11jzJmOegbi1g9/1sfbluA7SL+Pos7rTre15mi39DqyLG9u4ToM/TNO7LUB4B+mf0XHAOhxzoh3lNr7D44mHZbQ+e+Px9wfSpz+UM9u4NMyNtqu7yPNdwBsexh9T8EcXx3PMzbx6zDN0PpimagexgjQ6OT9iLryyOHpDczmdPH7RUTnj+I4P27Ga01nfY6ztH2N97/D852G5c4EyD+N/jefn+X5kbaNiTHBQhbnADrXGj7GmW8jgC/76TVmzxnca/FnTfHt878Z+F4wJQvIxN9t+iQnaOno+7lGs52s9pLU5BtPJubaD+fdiPZvbWb4w56x6t3nvAN6zhm/EBG9jrTK6xPp7DXOb52TaV54c67nW43mHLs6H1jRtrq89pHs8Zvb0Z1A0+7R8jXmG6ybMBRda62pMZww3YQp4lof5dgOjlFJDbOOm4qGJk9a6AhPYTO1g2mnAKq31Zq21S2u9CROIddQblMat2YdVpXwJ7ZtR7aCD5ipW3nK01udprYdqredgTjIbO5re7benYu5clWutmzAHs9mt1d5a6x1a69O01jFa67MxtXmty/5O66y1/kprfZLWOhoTmI2zLXs3tm1t9ZAUiKnBiMZcXD6otW7SWpdh2u2fY1v2v7XWk7TWMZhnKFMwJ9pwTLD6qlKq0BoHkKeUOsX6rUDgbcxB6uZOtuNg0B/K1pnAT6xmFYWYv/1rSqlfWOmdlY8zgQtt884H/k8p9WDnq90h97LzqtY6T2vdorV+FnPST7elP6a1rtNa12JOsq376ChMM5fnrXnzMM1Iv92H3fhg7vImdZDuh3kuFkwTuGY6OWZ0RSn1W0zTu7Osv7d7+nDMhePzHSziGmCd1jrTPrKL44m71vx7ai460PSHcoZSKgUT1P9Oa/1CF3ludw47Tl0dzydhWrJ8bJ1n9mNqtZda6Z2V/9mYmoU9Vvn/B+b8Vmg1H3PXVTnrin2btDmHWcNF1vp1df7rbLl27o+IYC37Ia31GK11HKZ2xg9zA3QM5obnamt7vAkkWtsj9RjW80TWL8raMbIf3z35dv/QWjdorW/TWidprUdhbmZs0Vo7j2PZ7sfgTq9FPfDHHOO7ytcBwE8pNcY2r317TcUEggesY8BHmO073+33lmGC5FrbuGM917Y773R1PvQwf0fHxZ46ZnaRAy9Hl/3pg7kDX4TtDgYmkCnCQ7W0bZr1mAekgzB3djrrvekBzF3rKMzdyAKO9t50GqYqepr1fTpm5z7L+r4UiLeGx2MOxPe6Lf8KIAe3ZlSYk2MFZsf2xdRqlXO0WcsEYAim6vkqKx9DrbSJmCDNF1P78HfMxWFrNf8zmJNDay9pdwP5tt+eYm2bEODnmLuogT2xztb0/piA7O/AWlvaRMzdmta7lS/StrfPTMxdFD9Mdftb9r8z5o6UL6aJwatYncdgCl6C7XMSpkAmWdvPH3gPE/wNqo4n+nHZinH7m+VibpKEWenXWfvlKGs/fQ2rwyNr37DPuw7T22SEle5j5W8ppuwFYTXNxDSpWmDtF0HA/8PcMW69c38vppYj3lrO1Zi7fq3Nb760tlOw9Xm4dR+39vlKTJn3sfL2NXC/lb7YKh++1rT/xFycBFnpN3D0Qfp0zEnS3pPo85jWAEMwdzr3YXUmYaUHcfSh+XG0bZ70S0ztQLuH6W3T3I258dNR+n7gOg/jOzuezOFob3ExmHL7ZV/v/4OonCVhmir+vw7mvcCaT2GCqnzaNutqLSdrMXfqgwAfK01Z39OtfS6o9e9upXd4PMdcmNZiamxae67NwGr6SSfnR8wNQ3v5/2/MDcrWJtJdlbPvcnxYgmmOl25tty+wOrCw0js7/y20lq8wgfGXuHWshLnwrcPWAYmtbE+y5h2Bae3wv1aan9v2+C9rfRPopMOcgfahj8ualR5oLScP0wQ+iKOPrnR4fO/GfpeEqfFWmBrjXI5ek8VhahHDrH3+bGsfam1F1ukxmM7PtXMxNW8BmPPdLzCttYZ1lS8r/RVMDXgoR3tlbe3tcxkmQBxlzb8Y0xpgvG3+YOvvcYbb36Grc21X69zh+ZCur687PWZ6bf/u6wLWy4X5D5iTygzbuEutcTfbxn0I3G37noo5ODZYfzR7c7IrsfXIhSmsT2OCkiJsXe9a6bdhTko1mJOZvUegv1jz1Flp/9O6g9im+ZgOelLCBEE7MSfBzbR9FuN2TOGvw1yMzrKlnWGtVx2mCcjbWE0+rPQYTNPPYquArAFm29L/jDmx1lrbLq2n1hlT0Kusz6u0b2pzBaY5UB2mGVC0LW2a9XerwASgr9O2icUaK0/lmGceOuqKPpW2r3o4zfpeb61z6+cUT/MPhk9/KFtu+cnGraczTHfMJdbnBawu0z3Mu5K2r3pYaK2H/bPSSpuIudNZh7mp8Tlty1YQpiOJAivfW2l7ch+JuZFQZu2HH9G27J2BqXmuwlwkPsHRJqOXYAK2WmudPgCm2OZ9hqNlKxtTTu0BXDjmZFqDOcn+hrbPKbivs3ZLa3Lb/+92245tgkm3tHl4uCi10jo8nmCeEcmy5i3ABLAJnn5jIH7o43KGuZmh3f7utbb0l619udb6+//ELf8rPexXC215dE/Lts3b1fH8UszNwxrMxfIfsQJLK73D86NbHpfT9lUPXZWzhR7y3a3jgzXNz6ztXI0ps4Fu29Pj+c+aLx9zHsrFBCbuQd5j2Hr1to2PtOWrELNfddTkbyGDrNlnfyhrVnq2h30r1Urr8Pje1X6HeQYt29p39gNX2tKGYgLSSitfO2n7/GyXx2A6ONdirp22c/S66yus1490lS8rPRpzfVqHue67wpamMNePh63l78WtWbqV93aVJ1ZaZ+faTteZTs6HdH193ekx01uf1jsIQgghhBBCCCEGsMH0zJ8QQgghhBBCDFpeC/6UUk8rpYqVUrs6SFdKqX8qpTKUUjuUUjO8lRchhBBCCCGEGOy8WfP3LOZh5o4sxfQqNQbTe9IjXsyLEEIIIYQQQgxqXgv+tNarMA90duQC4HltrAcilVKJ3sqPEEIIIYQQQgxmfn3420mYHqpa5VnjCtwnVErdhKkdJDQ0dOb48eN7JYNC9JYtW7aUaq2H9nU+WsXGxurU1NS+zoYQPaq/lTOQsiYGpv5W1qScDS4urXG6NE4XuLTr22GnNd7l0t8Ot35a53Fp0Gisf30qNiyQxIigDtOPt5z1ZfDn6SWGHrez1vpx4HGAWbNm6c2bN3szX0L0OqVUTl/nwS41NRUpZ2Kg6W/lDKSsif6hucVFTaOD6sYWnK6uL3mTo4IJ8vftML2/lTUpZ/1PXVML+wpr2FtQTVF1Y6fTag0Op4v6ZicNDicNtv/rHU4am53UO1qoaTSfzvZhHyDIz4fwIH/Cg/0YEuRPeJAf4cHm/yB/XwJ8ffDzVfj5+ODvq/D39cHP1wz7+ih8VOfvYfdREOTvS7C/LyEBfgQH+BDs70dwgBkXHOCLv69CdfE+d18fRYBfx400j7ec9WXwl4d5MWmrZMyLRIUQQgghBoVGh5NGh5Mgf18C/XxQXVxYgnlHc6PDRXWjg5pGB1UNLdQ0Omh0mIvi+mZzYdzYOmz9Rm2Tk+oGB9WNDqobHNQ0tlDd6KDR4TqmPL/zowVMHR55vKssBgCXS7PrSBUNzU6CA3wJCfAlqDXY8fclyN/sy1pr8ioa2FtQ/W2wt7egmpzyelrfNqeU5xohuwA/n2+DqSB/H/Ob/n5EBPuTGB5EcIAvQ4L8CA/yN/8H+7sNm0BviBXgDWZ9Gfy9C9ymlHoFmANUaa3bNfkUQgghhBgIWi+Etx6uYNvhSrbkVLC3oJoWq6bCR/FtzcDRWgI/Av18aHS0Bm4m0HM4u9cozc9Hfbus0MCjF8LDIoI9Xhj7+XbdHcSI6JDvtB3EianF6WJjdjkf7Srko12FFNc0dTp9sL8vSkF9sxMwQV5KdAgTEsP5rxnJTEgMZ0LiEJIig7t100P0DK8Ff0qpl4GFQKxSKg+4F/AH0Fo/CnwAnANkAPXAtd7KixBCCCFEb2t0ONl9pIqtOSbQ23q44tsL5mB/X6YNj+Tm00YRGxZ4tDmbvSmbrdYuOjSA1JjQTmo1/L5tWna0FsYX/24Ec0J0xOF0se5QGR/tKuDj3UWU1zUT5O/D6ePiWDIpwey7bfbZFhocLhqaW2hwOGlxaUYPDWNCYjjjE4YQGtiX9U4CvBj8aa0v7yJdAz/y1u8LIYQQQvSW5hYX+wtr2JFfyc68KnbkVXGgqObbWr0R0SHMHx3DzJQopo+IYnzCkG7VsgnR25pbXKzJKOH9HYV8uqeQ6sYWQgN8OXNCPEsnJXDauKGEBEgQd6KSv5wQQgghxDGqanDwye5CvsmtZGd+FfsKamh2mmfnIkP8mZIcyRnj45icHMGMEVEMHRLYxzkWomNOl2ZDZhnv7TjCh7sKqax3EB7kx6L0eM6ZlMjJY2IH/bNyA4UEf0IIIYQQ3bQjr5IV6w/z7vYjNDicDAn0Y3JyBNeenMqUpEimJEeQHCXPMIn+T2vNttxK3v3mCO/vLKCkpomQAF/OSo/n/KnDOGXM0E57mxQnJgn+hBBCCCE6Ud/cwnvbj/Di+sPszK8i2N+X708fxuWzRzBpWAQ+PhLoiRPHkcoGXlifw3vbj5BX0UCAnw+njxvK96Ymccb4OIIDpIZvIJPgTwghRL/ncLqoqGumrK6Zcuv/o9+bKK9rJizQjz9dPLWvsyoGkANFNaxYn8ObW/OpaWphXPwQfnfBRC6YnkR4kH9fZ0+IY1Je18zDX2bw/PocnC7NgrRYbl80lrMmxsv+PIhI8CeEEKJfKqxq5KNdBXy4q5BN2eV4em+vUhAZ7E90aABpcWG9n0kxoDS3uNh2uIK1h8pYdaCEb3IrCfD14dwpiVw5ZwQzU6KkOac44dQ2tfDU6iyeWJ1JfXMLF81I5r8XjSE5Sl7ZMRhJ8CeEEKLfyKuo56NdhXyws4CthysBGBsfxk2njiYpKpiY0ACiQgKICQsgOjSAyGB/6TFRHDeXS7OvsIa1GaWsPVTKhsxyGhxOfBRMTo7kl0vHc8ms4USHBvR1VoU4Zk0tTlasP8xDX2ZQVtfMkokJ/PzssaTFDenrrIk+JMGfEEKIPuNwusgqreOzvUV8tKuQHXlVAKQnhvPzs8ayZFKi1OiJHuV0aT7dU8h/dhTw9aEyyuqaARg9NJRLZiWzIC2WuaNiiAiWZnDixOR0ad7cmsffPztIfmUDC9Ji+H9nj2fa8Mi+zproByT4E0II4VXNLS5yK+rJKasjq9T8n11WT3ZpHfmVDTit9pxTh5ualiWTEkiJCe3jXIuBpq6phdc25/L02ixyyxuIDQvk1LFDWZAWy4K0GBIjgvs6i0J8Z0cqG7j2mU3sL6phSnIEf7xoCiePie3rbIl+RII/IYQQPaq2qYWNWWWsOVjGukOlHCiqafO83pBAP1JjQ5mSHMEF04aREhPKvNExJEXKxbfoeQVVDTy3LoeXNuRQ3djCzJQofnXOBBanJ+ArvXSKAaSkpomrntxASW0Tj1w5gyWTEuQZVdGOBH9CCCG+E4fTxTe5law5WMq6Q6VsO1xJi0sT6OfDSanRLE6PJzUmlNTYEFJjQokODZALEuF1u/KreGpNFu9tP4JLa5ZOSuT6U0YyY0RUX2dNiB5XVe/g6qc2UFDVyIs3zGZmSnRfZ0n0UxL8CSGEOCZaa/YX1bA2o4y1GaVsyCyjrtmJUjAlKYKbTh3FyWmxzEiJIshf3hclek9VvYNP9xbxxpY8vs4sIzTAl6vnpXDdgpEMj5aeDcXAVNvUwrJnNpJZUsfTy0+SwE90SoI/IYQQXcqvbGDtQdMj4tqMMkprmwAYGRvKf80wnWTMGxVDRIh0kiF6V1ltE5/sKeLDXYWsyyilxaVJigzml0vHc9nsEdJxixjQGh1ObnxuMzvzq3jkyhnyfJ/okgR/Qggh2qlramH1wRLWZJhgL6u0DoDYsEBOTouxOsmIZZg8pyf6QHF1Ix/vLuSDnYVsyCrDpSElJoTrTxnJ0kmJTE2OkKbFYsBzOF38aMVW1meV8ddLp3LWxIS+zpI4AUjwJ4QQAoDqRgdf7C3mw10FrNxfQlOLi7BAP+aMjObquSmcPCaWMXFhclEt+kxWaR2/fnsn6w6VoTWkxYXxo9PTWDIpgfTEcNk3xaDhdGl+9tp2Pt9XzO+/P4kLpyf3dZbECUKCPyF6gdZaLkpEv1RZ38wne8w79tYcLKXZ6SI+PJDLZ4/g7IkJzEqNwl9eoi76gTe35nHP27vw9/Ph9jPHcs7kBMbEy8uqxeCjteZXb+3kve1H+OXS8Vw1N6WvsyROIBL8CeEl2aV1fLirkI92FXDxrOFcLQdn0U+U1DTxyZ5CPtpVyLpDZTitZ6SumZfC0skJTB8ehY90gS/6ibqmFu55Zxdvbs1n9sho/nHZNHknnxi0tNbc//5eXtmUy4/PSOPm00b3dZbECUaCPyF60MGiGj7cVciHuwrZW1ANwNTkCKKkEwzRxwqrGvloVwEf7ipkU3Y5Lg2pMSHcdOoolk5KYHKSPCMl+p9d+VX8+OVt5JTVcfuiMfz4jDHybj4xaGmt+dunB3hyTRbL56fys8Vj+zpL4gQkwZ8Q34HWmj0F1XxkBXwZxbUAzEqJ4tfnTmDJpASSo6R7cdE38irq+WhXIR/sLGDr4UoAxsSFcdsZY1g6KYHxCUMk4BP9ktaaZ9Zm88CH+4gODeClG+cyd1RMX2dLiD7jdGnue3c3L6zP4dJZyfzmvHQ5fovjIsGfEN2gtaaouomDxTVkFNdysLiWjKJaDhbXUFHvwEfBnJExXDMvhbMnJhAfHtTXWRaDUEVdM9tyK9iaU8mqgyXsyKsCID0xnDsWj2Xp5ATS4uQZKdG/ldc1c+e/t/PZ3mLOHB/Hny+ZSnRoQF9nS4g+0+hwcvsr3/DR7kJuPm0Uvzh7vDTNF8dNgj8hLC1OF0U1TeRXNJBXUU9+RQOHy+vJKDGBXk1Ty7fTRgT7MyYujCWTEpiaHMni9HhiwgL7MPdisHG5NAeLa9mSU8HWw+aTWWJex+Dro5icFMFdS8ezdFICKTGhfZxbIbpnfWYZt7/yDeV1zdx7fjrL56dK7YYY1KrqHdz4/GY25ZTzm/PSue7kkX2dJXGCk+BPDDrNLS62Ha5gfWY5OWV15FU2kF/RQGF1I06XbjPt0CGBpA0N48IZSYyJC2N0XBhj4oYQGxYgFySi17lcmk/3FrFiw2G25VR8e0MiKsSfmSlRXDQjmRkjopj3vBBBAAAgAElEQVQ6PIKQADm8ixOHw+ni758d4OGVh0iNCeXNZfOZlBTR19kSok8dqWxg+TMbyS6t51+XT+e8KcP6OktiAJCrAzHguVyafYU1rM0oZU1GKRuzymlwOFEKEsKDSI4K5qTUKJKigkmOCiEpMpikqGCSIoMJ8vft6+wLgdOl+XBXAQ9+kcG+whqSo4I5f9owZo6IYkZKFKkxIXIzQpywskrruP2VbWzPq+LSWcnce/5EQgPl8kQMbvsLa1j29Ebqmlp49rqTmD86tq+zJAYIObqKASm3vP7bYO/rQ2WU1TUDMHpoKJfOSmZ+WixzR8UQESy9cIr+q8Xp4r0dR3jwiwwOldQxemgof/vBVM6fMgw/efeeOMFprXl9cx73vbcbf18fHr5yBudMTuzrbAnR5zZklnHj85sJ8vfl1ZvnkT4svK+zJAYQCf7EgFBR18y6Q2WsyShl3aFScsrqAYgbEshpY4eyIC2WBWmxJERIRyyi/3M4Xby1NZ+HVmaQU1bPuPghPHjFdJZOSpRu7sWAUFnfzN1v7eSDnYXMGxXDX38wVd7dJwTw0a4CfvLKNyRHBfP8dbOlx3DR4yT4EyekhmYnm7LLWXuolLUZpew+Uo3WEBbox9xRMVw7P5UFabGkxYVJczhxwmh0OPn3ljweWXmI/MoGJg4L59GrZnJWerz07CYGjK8PlfGz176hpKaJu5aO58ZTRslNDSGAlzce5u63djJ9eCRPLTuJKOnlVniBBH+i39JaU1zTRFZpHTlldWSV1lv/15FZUkez04W/r2LGiCh+tmgsC8bEMiUpQprDiRNOdaODFesP89SaLEprm5g2PJLffX8ip4+Lk5sXYsBobnHx108P8NiqQ4yMCeWtWxcwOVk6dREC4MX1Ofz67V2cPm4oD185k+AA6XNAeIdXgz+l1BLgH4Av8KTW+gG39BHAc0CkNc1dWusPvJkn0X81Opx8sqeIj3cXcqi4lpyyehoczm/T/XwUI6JDSI0N5bSxQ5mfFstJqVHSq6E4YRXXNPL0mmxWrM+hpqmFU8bEcstp05g3OkaCPjGg7Mir5M5/72BfYQ2Xzx7BPedNkGO3EJbWwO+M8XE8ctUMAv0k8BPe47Ujr1LKF3gIWAzkAZuUUu9qrffYJvs18JrW+hGlVDrwAZDqrTyJ/sfl0mzKLufNrfl8sLOAmqYW4sMDmTgsgvmjY0mNDSE1JpTUmFCGRQZJrZ4YELJL63h8dSb/3pJHi9PF0smJ3HLaaOnaXgw4jQ4nf/vsAE+symTokECevGYWi9Lj+zpbQvQbL6zP4Z63d3Hm+DgelsBP9AJv3nabDWRorTMBlFKvABcA9uBPA61dGEUAR7yYH9GPZJXW8dbWPN7clk9eRQOhAb4snZzIf01PYu6oGHm+SQw4Wmu2Hq7kmbVZfLCzAD8fHy6amcxNp45iZKy8hF0MPBuzyvnFGzvIKq3j8tnDuWvpBOlhWQibF77O5p53drNoQhwPXSmBn+gd3gz+koBc2/c8YI7bNPcBnyilfgyEAou8mB/Rhxz/n737Do+juP84/h51V8m9Se69N2y6Kcb0DqEGCB1+kBAICSkQAiQhJARCIAEHAgQIhIABQwCb3sHYMjbuXcVFlq1T77r5/TErfJZO9tnS+XSnz+t59PjuZvfue+ub3f3uzM7U+Vm5tZivN/l4Y+kWFmcXEmfgsKHd+cmsEcwa00tdgCTmWGtZubWE15du4fUlW8j1VdAxOYGrjhzMFYcNomdnjT4rsae0qpY/vLWKZ77MIqNrO/595XQOHao5ykQCKfGTSAnn2Xawphvb4PkFwFPW2vuNMYcAzxhjxlpr/bu9kTFXA1cD9O/fPyzBSsvaUVpFZpaPzOxCMrN9LM0tpLLG/beO6NWJX5w0ktMn9qOXTn4lBm3cUcbrS7Ywd8kW1m0vJT7OcPjQ7tw0czjHj+lFpxS1fkhs+mhNPr+Y8y1biiq4/LBB/OT44bqwJ9LAv77YxB1K/CRCwrlHzgUyAp6n07hb5xXACQDW2i+MMSlAd2B74ELW2tnAbICpU6c2TCCllfhkbT6vZG5mUbbvu3n2EuMNo/umcsG0/kzu34XJA7rQL01zOUnsKa6s4T8Lcpi7ZAvfbi4CYNqgrtx9xlhOGtubbh2TIxyhSPhUVNdx+2vLeGlRLkN7duTl6w5lcv8ukQ5LpNUJTPz+dtEUkhI0loEcWOFM/r4GhhljBgGbgfOBCxsskw0cCzxljBkFpAD5YYxJwiC/pIq731jB3CVb6NYhiakDu3DhtP5MGdCFsf1SSUnUFS2JbR+vyednLy9la1El49NT+dXJozh5fB9NWi1tQmlVLZc/9TULNxVw4zFDueGYoWrJEAliV+LXi79dNFmJn0RE2JI/a22tMeYGYB5uGod/WmuXG2PuAhZaa+cCtwD/MMb8GNcl9DJrrVr2ooS1lhcX5vC7N1dRUV3Hj2cO59qjBuugL21GaVUtv/3fSp5fkM2QHh2Yc71aO6RtKSqv4ZInF7B8cxF/OX8Sp07oG+mQRFql177ZrMRPWoWwdsT35ux7s8FrdwQ8XgEcFs4YJDzW55fyiznf8tXGAqYN6srvzhzH0J4dIx2WyAHz2bod/PSlpWwpquCaIwfz4+OGq5Vb2pQdpVV8/4kFrN9eyt8vnsJxmsJBJKhlm4v42ctLOWhgFyV+EnG6C1v2SVVtHY9+uIFHPlhHu6R4/nD2OM6dkqGpGaTNKKuq5V5vJMNB3Tvw0rWHMGVA10iHJXJA5RVXcuE/vmRzYQVPXDaVI4b1iHRIIq3SztIqrnlmEV3aJ+keP2kVlPxJyL7eVMDP53zLuu2lnDahL7efMpoenTSIhbQdX27Yya0vLSHX50YyvPX4EbRLUmuftC05BeVc9PhXFJRV86/LpzNtkC5+iARTU+fnhn8vJr+0ipeuPUTnTNIqKPmTvSqqqOHet1bx/IJs0ru046kfHMRRI3pGOiyRA8ZXVs2D767h6S+y6N+1PS9cdTDTB3eLdFgiB9yG/FIufvwrSqtqefbK6UzMSIt0SCKt1u/eXMkXG3Zy/7kTGJ+uuiKtg5I/aZK1lv99u5XfvL6CgrJqrjpiED8+TnM2SdtRVFHDE59s4J+fbaKsupZLDhnAbSeOVB2QNmn1thIuevwrrLW8cPUhjO7bOdIhibRaLy3K5cnPNnH5YYM4e0p6pMMR+Y7OYCSoXF85d7y2nPdXbWdcv1SevOwgxvZLjXRYIgdESWUNT362iX98soGSylpOGtebm2YOZ3ivTpEOTSQivs0t4pJ/fkVSQhzPXXkwQ3uqLog0ZUlOIb945VsOHdKNX5w0MtLhiOxGyZ/sprbOz1Ofb+L++WswBm4/ZTSXHjKAhHjdoCyxr6yqlqc+d0lfYXkNs0b34qaZw9XCIW2WtZZnv8zit2+upFuHZP591XQGdOsQ6bBEWq3tJZVc88wienZK5uELJ+v8SVodJX/ynWWbi7htzlKWbS7mmJE9ufuMsfRL0yTVEvsqqut45stNPPrRBgrKqjlmZE9+PHM449LV2i1tV15xJbe+tJSP1+Rz5PAe/Omc8fTsnBLpsERarepaP9c/m0lhRTVzrjuMrh2SIh2SSCNK/oTqWj9/mr+axz/ZQNcOyTxy4WROGtcbYzR9g8S2ovIanvlyE09+tomdZdUcObwHP545jEmaqF3auNeXbOFXry6jutbP3WeM5eLp/XVMENmL37y+nIVZPv56wST1GJFWS8lfG5dXXMn1z2WyKMvHBdMyuO2EUaS2T4x0WCJhlVdcyROfbuS5L7Moq67j6BE9+L+jhzJ1oIasl7atqLyG219bxtwlW5iQkcYD35vA4B4dIx2WSKv3/IJsnvsqm2tnDOHUCX0jHY5Ik5T8tWELNxVw3XOZlFbW8vCFkzhlvHZWEts25Jcy++MNzMncTK3fz6kT+nLNkUN0hVYE+HTtDn7y3yXsKK3i5uOGc/1RQ3S/kkgIaur83PPGCg4f2p1bjx8R6XBE9kjJXxtkreXZr7K56/Xl9E1rx7NXTGdEb43cJrFraW4hj360nreWbSMpPo7zDsrgqiMG079b+0iHJhJxlTV13PvWKp76fBNDenRg9iWHak4ykX2wYksxZdV1XDCtP/Fx6h4trZuSvzamsqaO219dxn8X5XL0iB48eN4kdfOUmGWt5XdvruQfn2ykU0oC1x81hMsOHUSPTsmRDk2k1bj1paW8vmQLlx06kNtOHElKYnykQxKJKouyfABMHqCLJtL6KflrQ7YUVnDts4tYmlvED48Zyk0zhxOnK1QSw/76/jr+8clGLpzen5+fOJJOKbrQIRLo600FvL5kCz88dhg3Hzc80uGIRKVF2T76pbWjT6pGSJfWT8lfG/HF+p3c8O9Mqmr9zP7+FGaN6R3pkETC6unPN/Hnd9Zw9uR07jl9rC50iDTg91vuen0FfVJTuG7GkEiHIxK1MrN8TBmgUaIlOij5i3F1fsvjn2zgvnmrGditPY99fypDe2rkNoltr32zmV/PXc7MUb34w9njlPiJBPFyZi7fbi7iwfMm0i5JXT1F9seWwgq2FlUq+ZOooeQvhm3cUcat/13CwiwfJ47tzX3njFe3N4l5H6zazi0vLmH6oK48fOEkjVYoEkRZVS33zVvNxIw0TtOw9CL7LTPb3e+n5E+ihZK/GOT3W57+YhN/eHsVSfFxPHDeBM6Y2E8T9ErM+3pTAdc+u4iRfTrx+KVTNXCFSBP+/uF68kuqeOz7U9QyLtIMi7J8pCTGMaqPpgyS6KDkL8Zk7yznJy8tYcHGAo4e0YN7zx5Pr84pkQ5LJOxWbCnm8qe+pl+Xdjz9g2lq5RZpQq6vnNmfbOCMiX2Z3F+tFSLNkZnlY0J6GonqZSJRQslfjPD7Lc99lcXv31pFvDH88ZzxnDMlXa190iZs2lHGJf9cQMfkBJ65YjrdOmoqB5Gm/P6tVcQZ+OkJIyMdikhUq6iuY/mWYq4+cnCkQxEJmZK/GJBTUM7PXl7K5+t3cuTwHtx71jj6pmm4YWkbthVVcvETX+G3lmeuOJh++u2LNOnrTQX8b+lWfnTsMB0nRJppaW4htX6r+/0kqij5i3JvL9vKLS8uwRjDvWeN47yDMtTaJ21GcWUN33/iK3xl1Tx/9cEayVZkDwKndrhWUzuINNsib7CXSeo+LVFEyV8Ue/HrHG6bs5QJGWn89YJJpHdpH+mQRA6o+95exfr8Up69Yjrj09MiHY5IqzZn8WZN7SDSgjKzfAzu0YGuHZIiHYpIyJT8RanHP9nAPf9byRHDuvPY96fQPkn/ldK2LM728dxX2Vx6yEAOHdo90uGItGplVbXc9/YqTe0g0kKstSzK8jFzVK9IhyKyT5QxRBlrLQ+8s4aH3l/HSeN688B5E0lO0BVcaVtq6/z84pVl9OyUzC2zhkc6HJFW7+8frmd7SRWPamoHkRaxcUcZvvIa3e8nUUfJXxTx+y13vbGCpz7fxPempvP7s8YTr4O4tEFPfraJlVuLefTiyZrSQWQvNLWDSMtblKXJ3SU6KfmLErV1fn768lLmZG7misMH8auTR2lgF2mTcn3l/PmdNRw7sifHj+kd6XBEWr17NbWDSIvLzPbROSWBIT000JhEFyV/UaCypo4fPr+Y+SvyuPm44dx4zFAlftImWWu5c+5yAH5z+hjVA5G9WLa5iDc0tYNIi1uU5WPygC7qRi1RJy6cb26MOcEYs9oYs84Yc1sTy3zPGLPCGLPcGPPvcMYTjcqqarni6a+ZvyKPO08dzQ+PHaYTXmmz5i3P492V27lp5jCNbisSgk/X7QDg0kMHRjYQkRhSVFHDmrxSpqgbtUShkFr+jDEvA/8E3rLW+kNcJx54BDgOyAW+NsbMtdauCFhmGPBz4DBrrc8Y03Nfv0AsK62q5ftPfMWSnELuP3cCZ09Jj3RIIhFTWlXLnXOXM7J3Jy4/fFCkwxGJCouzfQzqrqHoRVrS4mzd7yfRK9SWv78DFwJrjTH3GmNCuXFgGrDOWrvBWlsNvACc3mCZq4BHrLU+AGvt9hDjiXl1fsuPnl/M0twi/nbRZCV+0ub9ef4a8koq+e2Z40iMD2unBZGYYK0lM7uQSRmaA1OkJWVm+YgzMEF1S6JQSGdQ1tp3rbUXAZOBTcA7xpjPjTE/MMY0NdRePyAn4Hmu91qg4cBwY8xnxpgvjTEnBHsjY8zVxpiFxpiF+fn5oYQc9e57exXvrdrOr08dzQlj+0Q6HJGIWra5iKc+38iF0/rrSqtIiLYUVZJfUsWk/jpBFWlJi7J9jOrTmQ7JGjpDok/Il8+NMd2Ay4ArgcXAX3DJ4DtNrRLkNdvgeQIwDDgKuAB43BjT6ChlrZ1trZ1qrZ3ao0ePUEOOWv9dmMNjH2/g4oP7c8khAyMdjkhE1fktv3jlW7p2SNZohSL7oL5r2sQMXTARaSm1dX6+yS7UtCkStUK9528OMBJ4BjjVWrvVK/qPMWZhE6vlAhkBz9OBLUGW+dJaWwNsNMasxiWDX4cYf8xZuKmAX76yjMOGduPXp46JdDgiEffsl1kszS3iL+dPJLWd5vQTCdXi7EKSE+IY2adTpEMRiRmr80ooq65TLxSJWqG2/D1srR1trf19QOIHgLV2ahPrfA0MM8YMMsYkAecDcxss8ypwNIAxpjuuG+iGkKOPMTkF5VzzzCL6pqXwyIWTdV+TtHl5xZX8cd5qjhjWndMm9I10OCJR5ZucQsanp+pYItKCMjW5u0S5UI8IowK7Yxpjuhhjrt/TCtbaWuAGYB6wEnjRWrvcGHOXMeY0b7F5wE5jzArgA+BWa+3Off4WMaC0qpar/rWQ6jo/j196EGntNTKbyF1vrKC6zs/dp4/VFCci+6C61s+3m4uYpK5pIi0qM7uQHp2SSe+ieTMlOoV6p+pV1tpH6p940zJcBfxtTytZa98E3mzw2h0Bjy1ws/fXZvn9lpte+Ia120t58rKDGNqzY6RDEom47SWVvPntVq6dMYSB3TtEOhyRqLJyazHVtX6N9CnSwhZl+ZjSv4suSErUCrXlL84E/Mq9OfzUNNVC7pu3mndX5nH7yaM4cnjsD2gjEor3Vm7HWjh9orp7iuyr+sFe1PIn0nK2l1SSXVCuLp8S1UJt+ZsHvGiMeRQ3Yue1wNthi6oNeXlRLo9+tJ4Lp/fn0kMHRjockVZj/vJt9O/anhG9NFiFyL5anFNIn9QUeqemRDoUkZiRmVUIwGQlfxLFQk3+fgZcA1yHm8JhPvB4uIJqKxZlFfDzOd9yyOBu/Oa0MepCIOIprarls3U7ueSQAaoXIvthcXYhE9XlU6RFZWb7SIqPY2y/zpEORWS/hZT8WWv9wN+9P2kBvrJqrns2kz5pKfztIo3sKRLoo9X5VNf5mTWmd6RDEYk6O0qryC4o5+KD+0c6FJGYsijLx7j0VJIT4iMdish+CynjMMYMM8a8ZIxZYYzZUP8X7uBi2R1zl+Mrr+ZvF02mSwfdPikSaN7ybXTtkKT7KkT2wzfZrmua7vcTaTlVtXV8m1uk45JEvVCbm57EtfrV4ubl+xduwnfZD28s3cLrS7bwo2OHMaZvaqTDEWlVqmv9fLBqOzNH9SQ+Tl0+RfbV4hwfCXGGsTq+iLSYZZuLqa7zM1kXVSTKhZr8tbPWvgcYa22WtfZO4JjwhRW7thdX8qtXlzEhI41rZwyJdDgirc6XG3ZSUlXLrNHq8imyP77JKWRUn860S1LXNJGWUj+5++QBupdWoluoyV+lMSYOWGuMucEYcybQM4xxxSRrLT+f8y0V1XXcf+4EEnSfn0gj81dso11iPIcP6x7pUESiTp3fsiSniEn9dYIq0pIWZfno37U9PTtpBF2JbqFmHzcB7YEfAlOAi4FLwxVUrPrvwlzeW7Wdn50wUhO5iwTh91veWZHHjOE9SElUq4XIvlq3vZTSqlolfyItyFrLomyf7veTmLDX0T69Cd2/Z629FSgFfhD2qGJQTkE5d72xgoMHd+UyzecnEtTSzUXkFVcxa0yvSIciEpW+m9w9QyepIi0l11dBfkmV5veTmLDXlj9rbR0wxWiyrf3m91t++tJSrLX88ZwJxGkQC5Gg5i/fRnyc4ZiR6lUusj8WZxfSpX0iA7q1j3QoIjFjkXe/3xQN9iIxINRJ3hcDrxlj/guU1b9orZ0TlqhizNNfbOKLDTu596xxZHTVAVmkKfNX5HHw4K6ktdf0JyL7Y3GOj4kZaeh6rUjLycz20SEpnhG9O0U6FJFmCzX56wrsZPcRPi2g5G8v1ueXcu9bqzhmZE/OOygj0uGItFrr80tZt72U7x88INKhiESl4soa1m4v5ZTxfSMdikhMWbe9lGG9Omn6IYkJISV/1lrd57cfauv83PLiElIS47n3rHG6EiuyB/OX5wFw3Gjd7yeyP5bmFGEtGuxFpIXl+iqYkKF6JbEhpOTPGPMkrqVvN9bay1s8ohjy2Mcb+CankIcumETPzhoaWGRP5q/Yxrh+qfRNaxfpUESi0uJsH8agk1SRFlTnt2wprOCU8X0iHYpIiwi12+cbAY9TgDOBLS0fTuxYsaWYB99dw8nj+3DaBHXBEdmT7cWVLM4u5Jbjhkc6FJGo9U1OIUN7dKRzSmKkQxGJGVuLKqj1W43ZIDEj1G6fLwc+N8Y8D7wblohigLWWO19fTmq7RO45fWykwxFp9d5Z6bp8zhrTO8KRiEQnay2LcwqZOUoj5Yq0pFxfBQDpXdQrRWJDqJO8NzQM6N+SgcSST9ftYMHGAm48ZhhdOmjUQpG9mb88jwHd2jO8V8dIhyISlbILyikoq2ai5vcTaVE5BeUAZHRRy5/EhlDv+Sth93v+tgE/C0tEUc5ay5/mraZfWjvOn6bRPUX2pqSyhs/X7+CyQwdqUCSR/bQ4uxDQYC8iLS3XV4Ex0CdNYzdIbAi126cmNgnRuyu3syS3iD+cPY7khPhIhyPS6n24Op+aOqsunyLNsDjbR/ukeIb30uFapCXl+Mrp3TlF53QSM0Lq9mmMOdMYkxrwPM0Yc0b4wopOfr/l/vmrGditPWdNTo90OCJRYf6KPLp1SGJyf3VXE9lfi3MKmZCepnnIRFpYrq9C9/tJTAn1nr9fW2uL6p9YawuBX4cnpOj1v2+3smpbCT8+bjiJ8ft7O6VI21FVW8cHq7Yzc1QvnbSK7KfKmjpWbClWl0+RMMgtKNf9fhJTQs1Qgi0X6jQRbUJtnZ8H3l3D8F4dOWW8pnYQCcUX63dSWlXLrDGa2F1kfy3bXESt3zJJreciLaq61s/W4krSNc2DxJBQk7+Fxpg/G2OGGGMGG2MeABaFM7Bo8+o3W9iQX8bNxw1XC4ZIiOavyKN9UjyHDe0e6VBEolb9YC8TNbm7SIvaWlSBtZrmQWJLqMnfjUA18B/gRaAC+L9wBRVtqmv9PPjuGsb268zxGrRCJCR+v+WdFXkcNaIHKYm6kV5kf32TU0hG13b06JQc6VBEYkpOgZvjT90+JZaEOtpnGXBbmGOJWi8uzCHXV8HdZ4zVUPUiIfomt5D8kipmjdYFE5HmWJztY8rArpEOQyTm5PrcHH9q+ZNYEupon+8YY9ICnncxxswLYb0TjDGrjTHrjDFNJo/GmHOMMdYYMzW0sFuPypo6/vr+WqYO6MJRw3tEOhyRqDF/eR4JcYajR/SMdCgiUWtbUSVbiiqZpC6fIi0ux1dOfJyhT6rm+JPYEWq3z+7eCJ8AWGt9wB7P2Iwx8cAjwInAaOACY8zoIMt1An4IfBVq0K3Js19mkVdcxS2zRqjVT2QffLlhJxMz0khtnxjpUESi1jc5PkCTu4uEQ66vgj6pKSRoBHeJIaH+mv3GmP71T4wxAwG7l3WmAeustRustdXAC8DpQZa7G7gPqAwxllajrKqWv3+4nsOGduOQId0iHY5I1KisqWP5liKmDNTohCLNsTi7kKT4OEb37RzpUERiTo6meZAYFGry90vgU2PMM8aYZ4CPgJ/vZZ1+QE7A81zvte8YYyYBGdbaN/b0RsaYq40xC40xC/Pz80MMOfye+nwTO8uquWXWiEiHIhJVlm0uoqbOamJ3kWZanF3ImH6dSU7QoEkiLS3HV0FGV93vJ7ElpOTPWvs2MBVYjRvx8xbciJ97EqwP5HethcaYOOAB77329vmzrbVTrbVTe/RoHffVFVXU8NhH6zl2ZE+dwIrso0VZrqua6o7I/qvzW5ZuLtQUDyJhUFlTR35JFelq+ZMYE9Jon8aYK4EfAenAN8DBwBfAMXtYLRfICHieDmwJeN4JGAt86N0r1xuYa4w5zVq7MNQvEClPfLKB4spabp41PNKhiESdzGwf/bu219D0Is2QtbOMyho/o/uoy6dIS8v1edM8qOVPYkyo3T5/BBwEZFlrjwYmAXvrf/k1MMwYM8gYkwScD8ytL7TWFllru1trB1prBwJfAlGR+BWUVfPEpxs5eVwfxvRNjXQ4IlHFWktmdiGTNUCFSLOsySsFYHivThGORCT27JrmQS1/EltCTf4qrbWVAMaYZGvtKmCPN7pZa2uBG4B5wErgRWvtcmPMXcaY05oTdKQ99dlGymvquGnmsEiHIhJ1cn0V5JdUMWWAunyKNMfavBIAhvbsGOFIRGJPjk8TvEtsCqnbJ5DrzfP3KvCOMcbH7l04g7LWvgm82eC1O5pY9qgQY4mosqpanv4ii+NG9WKYrraK7LPM7Pqh6ZX8iTTHmu2lpHdpR4fkUA/lIhKqXF85SfFx9NTtCRJjQjpiWGvP9B7eaYz5AEgF3g5bVK3Yf77OoaiihmuPGhLpUESi0qIsH+2T4hnZWxdPRJpjbV6JunyKhEluQQX9urQjLk5zOEts2efLhdbaj8IRSDSoqfPzxKcbmTawq0YpFNlPmdk+JqSnadJckWaoqfOzPr+UGSNaxwjYIhnxnWAAACAASURBVLEmx1dOehcN9iKxR2df++D1JVvYXFjBtUcNjnQoIlGpvLqWlVtLdL+fSDNl7Syjps4yvKda/kTCIddXocFeJCYp+QuRtZbHPtrAiF6dOHpEz0iHIxKVluQUUee3TB6gkT5FmkMjfYqET1lVLQVl1ZrmQWKSkr8Qfbg6n9V5JVx95GC8eQlFZB99N9hLhlr+RJpjTV4JxmikT5FwqJ/jTy1/EouU/IXo0Y/W0zc1hdMm9o10KCJRKzPLx+AeHejSISnSoYhEtbV5pWR0aU+7pPhIhyISc3IK3Bx/GbrnT2KQkr8QLM728dXGAi4/fBCJGqRCZL9Ya1mcU6jBkkRawBqN9CkSNvUTvGd0VcufxB5lMiF49KP1pLZL5IJp/SMdikjU2rSznIKyag32ItJM1bV+Nu4oY3gvdfkUCYccXwXtEuPppl4qEoOU/O3F+vxS5q/I45JDBmgiXZFmWJTl7vdTy59I82zaWUat36rlTyRMcgrcNA8a40FikZK/vfjHxxtIio/j0kMHRjoUkaiWme2jU3ICwzRAhUizrMkrAWCYWv5EwsJN86D7/SQ2Kfnbg+3FlczJ3My5U9Pp3jE50uGIRLXMLB8T+6cRF6crqSLNsSavlDgDQ3oo+RMJhxxfue73k5il5G8P/vnZJmr9fq46QpO6izRHSWUNq/NK1OVTpAWszSthQLcOpCRqpE+RllZUUUNJZa1a/iRmKflrQkllDc99mcWJ4/owoFuHSIcjEtWW5BRhLRrsRaQFrMkrUfdpkTDZNc2DWv4kNin5a8K/v8qmpKqWa48cEulQRKLeoiwfxsDE/mmRDkUkqlXV1rFpZ7kGexEJk/oJ3tXtU2KVkr8gqmrreOLTjRw2tBvj0lMjHY5I1MvM9jGsZ0c6pyRGOhSRqLZxRxl1fqvBXkTCpH6OP3X7lFil5C+I1xZvYXtJFdfOUKufSHP5/ZbMbJ+6fIq0gDV5pQBq+RMJk5yCcjolJ5DaThcrJTYp+WvA77c89vF6xvTtzOFDu0c6HJGotz6/lJLKWiZpsBeRZluzrYT4OMPgHroXXSQccn0V9NMcfxLDlPw18NaybazPL+O6o4ao4kvzVBbDyjfcXxtWP7m7Wv5Emm9NXgkDurUnOUEjfYqEg6Z5kFiXEOkAWhO/3/LX99cytGdHThzbJ9LhSLSoLoftKyHvW9i2DIbOhBEnQPFm+M9F0HscjDol0lFGTGa2j7T2iQzurpYKkeZau72UEeryKRIW1lpyfRUcpp5fEsOU/AWYvyKPVdtKePC8icRrImoJprocKougcx/3ePZRsGMNYF15UifoMgA4AboNgyvehV6jIxhw5GVmFzK5fxe1pIs0U2VNHVk7yzh1vC5OioRDQVk15dV1muZBYpqSP4+1rtVvUPcOnKIDq9TbnAlbMmHzYtiyGPJXwoiT4PznIKk9ZBwEY86E3mOh11hIGwBxXm/q+ARX3oYVllezbnspZ0zsG+lQRKLe+vxS/BaGqeVPJCw0zYO0BUr+PO+v2s7yLcX86dwJJMTrVsg2q67GdeHsM949f+Mm2LoE2neDvpNh5Mkw4NBdy5/+SGTijBKLcwoBmKzBXkSaba1G+hQJqxxN8yBtgJI/XKvfQ++tJaNrO05XC0XbU1sF6z+AlXNh1f+gthJuXQ/JHeHM2ZDUAVLTQd0W91lmlo84AxMyNLm7SHOtySshIc4wSPfPioRFToFr+VPyJ7FMyR/w0Zp8luQWce9Z40hUq1/bYK1L5pa/CnNvhKpiSE6FESfC6NMgPskt13NkZOOMcpnZPkb27kyHZO1qRJprTV4pg7p3IClBxymRcMj1lZPWPpFOKZrjT2JXmz8jq2/165fWjrMmp0c6HAmHulrIWwa5X0POAshdAMfdBaNPh+7D3b+jT4dBMyAhKdLRxow6v+Wb7ELVK5EWsnZ7CWP7pkY6DJGYleOr0GAvEvPafPL3+fqdZGYXcvcZY3U1NZKqSmD9+7D6Ldj0KaQfBOc+6coemwHFW3ZffthxcMbf3OOXr3QteSmp3l9n6DMRhhwNxVvhr5OhxvXjp2NvyJjm7uEDNxLn6Q8fmO/YxqzeVkJZdR2TB6jLp0hzVVTXkV1QzpmT+kU6FJGYlesr11QqEvPafPL3l/fW0rtzCt+bqtaJiHnzVlj0FNRVQ7suMPhoyJi+q3zIMVDh232dvpN2PS7KhdI8NwVDZRH4a2HKZS7569QbDroS+kxwSV9qhu7dO0Ays93/mQZ7EWm+9fmlWKvBXkTCxe93c/zNHNUr0qGIhFVYkz9jzAnAX4B44HFr7b0Nym8GrgRqgXzgcmttVjhjCvTlhp0s2FjAnaeOJjkh/kB9bNtVVQr5q2Dde7DhQ7jkVUhIhq5DYNrV7n67jIPdFAmBZv56z+97+du7HlsLNRVg69xzY2DW3S36NSQ0mVk+undMor+GzBZptjV5JQAM79UxwpGIxKYdpVVU1/rJ0GAvEuPClvwZY+KBR4DjgFzga2PMXGvtioDFFgNTrbXlxpjrgPuA88IVU0MPvbeW7h2TOX9a/wP1kW1DhQ/yV0OPEa4lb+Ub8NbPoDjXW8C4bp2leZDWHw6+tuU+2xg3/55EXGa2j0ma3F2kRazJKyUx3jCgm0b6FAmHXdM86BxCYls4W/6mAeustRsAjDEvAKcD3yV/1toPApb/Erg4jPHsZuGmAj5fv5NfnTyKlES1+oXEWjcqZsk2KNnqWuzSMiB/Dbx/t0vmfJvcvwDn/9vNi9epj5sbr8cI95cxHTr2jOhXkfDaWVrFpp3lurAi0kLW5pUwuHtHjUgtEib10zxkdFXLn8S2cCZ//YCcgOe5wPQmlgW4AngrWIEx5mrgaoD+/VvmZPKh99fRrUMSF07XyWlQFYXu3rkO3aEwG168xCV5NWW7ljnpTzDtKsC6lr5OvWHocbuSvPSD3HLpUyD9HxH5GhIZn6/fCeh+P5GWsjqvhImaL1MkbHK9lr9+aWr5k9gWzuQvWF8vG3RBYy4GpgIzgpVba2cDswGmTp0a9D32xeJsHx+vyee2E0fSPqnNj3njpkJY9y5sXgjblrlpEYpy4NAbYdY90KGHG0Vz8iWQ2s+15HXqDd1HuPV7jIAbFkT2O0irUVPn58F31zCoewcm9dfJqkhzlVXVkuur4HtTMyIdikjMyimooHvHZNolqTeYxLZwZj65QOCRKh3Y0nAhY8xM4JfADGttVRjj+c5f319HWvtELj54wIH4uNarrtYNruKvhdeud/fqdRvmRsWcermb9w4gsR1c8lpkY5Wo8e+vslmfX8Y/LpmqLmoiLWDd9lJAg72IhFNuYTnpGuxF2oBwJn9fA8OMMYOAzcD5wIWBCxhjJgGPASdYa7eHMZbvLNtcxPurtvOTWcPpmNxGW/22fAMLZkPuQrj+C0hMgcvnQWq6S/RE9lNReQ0PvruGQwZ3Y+Yo3dcp0hLqR/ocpmkeRMImp6CCCepaLW1A2C7LW2trgRuAecBK4EVr7XJjzF3GmNO8xf4IdAT+a4z5xhgzN1zxAFTW1HHn3OV0TkngkkMHhvOjDozaKijN3/V87buwdQmUbge/f/dl62pg2Rx44niYPQOWvwoDD4dq7x6+7sOU+Emz/fX9tRRW1PCrU0ZplE+RFrJ2eylJ8XEM0LQp7ti2+Fk3v6tIC6nzW7YUVmiaB2kTwtr0Za19E3izwWt3BDyeGc7PD1Tnt9z0wjcszPLxl/Mn0jkl8UB9dMuqLnf3562cC2vmudE0z3zUvf7c2buWi0uAjr3dfXsHX+vm1nvpB9BlIBz/O5h4EbTTFS5pOZt2lPH0F5s4d0o6Y/qmRjockZixJq+EwT06kNDWu1FbC/N+Dl89Cl0GuR4rnTQhtzTftuJKav1W0zxIm9Am+j1aa/nVq8t4e/k27jhlNKdP7BfpkPbPWz+DzH9BTTm06wqjT4dx57qy+CS48j03BUPJNije4v7t3NeVDzsOLnoZhhwNcbqZWVre799aSWJ8HD+ZNSLSoYjElLV5pUwZoJFz2boEvnoMxpwJa+bDs2fBZW+4+WRFmiGnwI30qWkepC1oE8nfA++s4fkF2Vx/1BAuP3xQpMPZu5pK2PoN5CyAbUvhzMdcwta+O0y4AEafBgMOd4O11ItPgPSpTb9nXDwMO2ANrdLGfLlhJ/OW5/GTWcPp2Tkl0uFEhrVQWaQWdWlRpVW1bC6s4IJpGumTvhPhineg3xTY+CG8/QuoKlXyJ82W63Nz/KnlT9qCmE/+nv58Ew+9v47zpmZw6/GttEXCWjDGdef84Pfu6qa/xpV1Gejm2es6CGbcGtEwRYLx+y33/G8FfVNTuPKIwZEOJzKKt8Br/wcbPoIjfwJH3grxUdq1XFqVtRrsBVa96erTsOMgw5s/dsgxcO2n3ojVfrB1qnOy33IKyjEG+qa10YuX0qbEdPL3xtIt3Pn6cmaO6sVvzxwbmQEorHVTKcQnQtkOWP2m645ZshWKt7qWvdMf8bpjJrrum4dcDxnT3STpHTViorRucxZvZtnmYv5y/kRSEttgl+JlL8MbN0NdtTshXTPPJX8iLWBtnpvmYURbTf6yPnf3q/eZCENnugul9eIT3DH21evcBdOz/qHbGmS/5Poq6NUpheQE/X4k9sVs8vfZuh38+D/fMHVAFx6+cNKBuVG+shiW/gfyV0P+KvBtconeiffCQVdCaR7MvdEt276bG5AlYzokewf1wTPcn0iUKK+u5Y/zVjEhI41Tx/fdvbBsp5tGJKlDZII7ECqL4M1bodtQOGs2dBviuqHFJ0J5Aax4FSZfBnFtfKAO2W9r8kpITogjoy2O9LltGfz7fEjNgPP/vXviV88Y6DkK3v01pKTByfcHX05kD3J85brfT9qMmEz+vs0t4up/LWRw9448fslBLdcaYS0Ub/aSOy/B27EGhp8Ah98EWHjzJ5DcGboPhwGHQqc+0Hu8W7/bMLjpW+jYCxKSWyYmkQh67KMN5BVX8beLJhMX551wWQvzfwVfPAyDjoRLX3evv3AR1FRAh+7u4kf7bq5uDJ8VuS+wv3IWuPuOUlLhB29B1yG77sFN9ibiXvwsvHM7rHgNTv8bpEbpQFMSUWu2lzK0Z0fi49pYQuPLgmfPdhePvv8KdOjW9LKH3wQVPvjsQWjfFY751YGLU2LCZl8F0wd1jXQYIgdEzCV/G3eUcdmTC0hrn8S/rphGavv9uAfAXweFWbuSvPZdYfIlruyR6VDtuuHQriv0GAkpnd3zlFS4eRV06h38ymNCEqT1378vJtLKbC2q4LGP13Py+D5MGeAdNK2Ft34KC2bDhAth1Km7VohPcvfG7VzrWsWqS92UI8NnufW+eNjNPdl7QuttKasudy0MC2bDyX+Gg66AHk3cS3zoja5Vf94v4e+HuOXHnXNg45WotzavhIMH7yHxiVVLnofaSrj8bUgLYbCbmXe6BPDjP7pj8yHXhztCiRE1dX62FlWQrjn+pI2IqeRve3ElP3x8HgNtIQ+dMpxeBQthWzmYuF0jXS6b4xK6yiL3V1XsWiJO/Ysrf+oUyPoMbMAk6cNmueTPGHd/Xofu0H0EdOzROIjOfcL/RUVagT/OW43fwm0njHQv+P3wv5th0ZNwyA0w657dL4Kc++Tub1BT4U7uAAo2uNZCgA493L099X/7MnqmtVBX4+7/qat2rfBx8a4rZnWZ644Zl+AS0fjE4PcHWesuAPlrICHFfYfKYshbBnN/6JLX6dfBxAv3HIsxMPUHrvXzlWvh5Stc8nvYD739T3HjdTr3dTFVFEJVSePy1HT3vuUF7vs0VH+SXF7g9m11td628AaQ6uP1Qti61HVJN8bbDomQ1B76TnLlRblQW+W2lfES8fhEd2ELoCTPbd9A8Um75lwr2bbrM+slpOzaZxZvcds4UGI7t28FKNq8+z4YXAtQe+8iQ2FO4+8eWB4jiitr2FpUybBeXmuyv85tV2Nc75H63ijW7r5ickc3Aqbf78obSunsLlbW1br7zxuVp7pl6mrc/2W9uHj3W0nu5Lp0139uOLpZzviZG926y4DQljcGTnnAbaPeY91rxVvdPfeB9vo7bL+rlbEot/G23dvvcG/bPrmT26f569znN9TUtq/XLs29R221u5WkofZdXYw1lVCWH6S8m6vrNRVuHIKGOvRw/7fVZW4/0lDHnjHXc2lLYQV+C+ltsWt1uFSVuuN7Xc2uOrjXY0TyrnEugtXdvR0jQq271rryhsK136zXrov7jNoqKN3euLxh3Q085rawmEr+3lq2jesrZnOi+QJeCijo1AduWeUeL3ke1s53J4Upqe7fwB3ZqFPdfXhdBrhWve7Ddz/5HHPGAfkuIq3Z0txC5mRu5rqjhuy6F8n63Q7r8Jvh2Dv2fkKY2M79gbtX7ifrYP17sPYdWPO2q6vnPevq5PJXXeLV0GVvuIRm0VNu0BXb4ETuxkz33gv/6bpgNnTzKnfB5pP74eP7AxIl76Dxiy1uZ/zB7+Crv0PnfnDJazD4qNA3Vrchrmvol4/smpfz6yfgvd80XvbW9e7g9vlDLqaGfpnnTsw+vBcWPLZ7WVwC3LHTPZ7/K/jmud3LU9Lgtiz3+OP7YOXru5enZsCPl7nHc2+E9e/vXt5jFPzfl+7xfy6G3AW7l6cfBFe+6x4/cyZsX7F7+eCj4ZJX3eMnjoei7N3LR53q/r8BHj0cKhqceE64EM78u3v818mNk8+DroKT/0QsWZtXwqLka+jycSV8WMt3v8upV8Apf3YnRw+MabzioT+EWXdDdQk8OLZx+dG/hBk/dclDsPLjfweH/J+7KPPItMblp/4FplwGmzPh8WPAxO+6iGDi4IxH3P/npk/h+SAXSc59EoYe6wZHevmq3cuSO8Ilc6H70NATv3px8e6z6z19Cuxct/syw46Hi150j2cfDaUNTtLGng3n/NM9DuzpU2/ypXDaQ+5xsG13yA1w/G/dfLzBymf8DI7+hdtXBis/7m53gciXBQ9PaVx+ygMw9XLYvhxmH9W4/KzHYfy5sHkhPHVy4/ILXoARJ7qRiZ8/r3H5pa+7C1ar33IXrBq66gPoN7nx61Fs1zQPTbT81dW6C5vLX3W/jWEz3XHqpSDb58L/wIBDYPkrMPdHjcvrj1mLn3VTlTR09QfumPHVY/D+bxuX3/C1S6A+uR8+/Uvj8ptXuDr03l2w4PHG5T/39rtv/Qy+eX73sqQOcMtK9/i1/4MVDY4RHXvCjQvd4/9eBuveB7xBDetqoOtguME7Ljx3DmR/sfv6fSbCNR955ee6AQ8DDTzCbR+Ap05y+59Aw0+EC19wj2cfBWUNEqhx58LZ3nd+eBrUNLhAOuUHcOqD7vGe6m51afDyo34OR93mPjdY+azfwqE3QMFGeOSgxuX1+8285fCPoxuXn/2E6x2UuwCePtXdFnPtJ42XawExlfxdeuhA8lNvA1vgrgAktXf/JgeMkva9Z5q+4g8w/ZoDE6xIlLLWcs8bK+neMYnrjxriDoxVxe6q1blPu7q1Py0BHXvAhPPdn7/OnVj2HOXKugwI3tJWfwW+1zh3309corv3rn7k3Pr5v4YcDUn3B7SEVbvH9fuGXuNcK91urYIJ7g9g7FnQZ4I7adqfefziE+CwgBOBYbPcFfaG6gfHGXUqdAkyJ2l9POPOhd7jdi8L3OaTLoYBhwW0dCZCQsCJzbG/hsNu8lo5ve0RF9BF/vAfw/jzd0+wUlJ3PT7ilsatCvVXZMGd3FYU7l7eKaBXxHG/adxyGdi178Q/uKujgboGTCNyyoONr/o21f02iq3JK+WruqO5aEp/Uju22/X77jPRLRCXAKc+tKt1tl6v0e7fhHZw2sON37jPBPdvu7Tg5f28pKNjr93LrdfymHGwe96pN8y4bddFk/or+fW3N3TsHbzedvbuf01ND15elOOSv+Y65vbGLeiB994e/1vXAhaoy8Bdj0/6U+PWh+7Ddj0Otu161m/75ODl9fU2uXMT295LrDr2CF6eMd39m9o/eHm693/XbWjw8l7eSWuvMcHLuw/fFUew8rR9TMijwHcTvAeb46+uFl65Bpa95Pa79b+fzv2C/3brW666DNzzMavbsODlyd5tRD1GBi9P9Kai6D0+eHn9dCd9J++5d0rGNKDBcTohadfjAYdDUoMRhgPPpQfNcPUb3DE/PhE6BIxOP/0aGHOWdzxOcJ8V2DPjqNsatyx37LXr8bG/3nPdPeH3e667J9/fjLqb0sR+0+s5k5K6l/1mz+Dl/b39ZtqAPa/ffbgrD2NPFmMbNou2clOnTrULFy6MdBgiLcoYs8haOzXScdTbUz3LKSjntIc/5dbjR3Lh1D7uwJi3wl2xTNQ9E9J6tbZ6Bnuua795fTkvLMhh+W+O3zWgkkgUaG11bU/1rM5vySuupFfnlN0HVgpM/Gbe6S6KibQi+1vPYqrlT0TCL6Nrez689Wg6xNfBS5fDyrlw3F1K/ERa2No8N9KnEj+R8ImPM/RNC3L8yv7CzeM6804lfhJTlPyJyD5LTfTDf38Aq9+EE+6Fg6+LdEgiMef3Z42jqKJm7wuKSMsbdARc9/mubtQiMaKVjqcuIq3a/F+5xO+kPynxEwmTjK7tGdsvde8LikjLqKuFV66Ddd7gVUr8JAap5U9E9t0Rt7iBBzRvnYiIxIK6WphzFSyf4wbEGToz0hGJhIWSPxHZd516K/ETEZHYUFcLc650UzQcd7cbsl8kRin5E2lhNTU15ObmUllZ2agsJSWF9PR0EhMTg6wpIqFSPRM5MGK+rtXVujkNV7wKs+6BQ2+MdETSBh3IeqbkT6SF5ebm0qlTJwYOHIgJmHvNWsvOnTvJzc1l0KAgc7iJSMhUz0QOjJivayYOUjor8ZOIOpD1TAO+iLSwyspKunXrtlvlBTDG0K1bt6BXdURk36ieiRwYMV/X4uLg1IeU+ElEHch6puRPJAwaVt69vS4i+071TOTAiPm6FivfQ6LagapnSv5ERERERETaACV/IiIiIiIibYCSP5EwsNbu0+sisu9Uz0QODNU1kfA7UPVMyZ9IC0tJSWHnzp2NKmv9iE0pKSkRikwkdqieiRwYqmsi4Xcg65mmehBpYenp6eTm5pKfn9+orH6uFhFpHtUzkQNDdU0k/A5kPVPyJ9LCEhMTo3vOI5EooHomcmCoromE34GsZ2Ht9mmMOcEYs9oYs84Yc1uQ8mRjzH+88q+MMQPDGY+IiIiIiEhbFbbkzxgTDzwCnAiMBi4wxoxusNgVgM9aOxR4APhDuOIRERERERFpy8LZ8jcNWGet3WCtrQZeAE5vsMzpwNPe45eAY03MzBgqIiIiIiLSeoTznr9+QE7A81xgelPLWGtrjTFFQDdgR+BCxpirgau9p6XGmNVhiVgkcgZEOoBAixYt2mGMyYp0HCItrFXVM1Bdk5jVquqa6pnEqP2qZ+FM/oK14DWcqCKUZbDWzgZmt0RQIrJ31toekY5BpC1QXRMJP9UzkV3C2e0zF8gIeJ4ObGlqGWNMApAKFIQxJhERERERkTYpnMnf18AwY8wgY0wScD4wt8Eyc4FLvcfnAO/blp7GXkRERERERMLX7dO7h+8GYB4QD/zTWrvcGHMXsNBaOxd4AnjGGLMO1+J3frjiERERERERacuMGtpERERERERiX1gneRcREREREZHWQcmfiIiIiIhIG6DkT0REREREpA1Q8iciIiIiItIGKPkTERERERFpA5T8iYiIiIiItAFK/kRERERERNoAJX8iIiIiIiJtgJI/ERERERGRNkDJn4iIiIiISBug5E9ERERERKQNUPInIiIiIiLSBij5ExERERERaQOU/ImIiIiIiLQBSv5ERERERETaACV/IiIiIiIibUDMJn/GmJ8bY95s8NraJl47P8j6A40xHxhjyo0xq4wxM/fwWcnGmH8aY4qNMduMMTc3KD/We49y7z0HBJQtN8aUBvzVGmNe98q6G2M+M8bsNMYUGmO+MMYcFrDuZcaYugbrH9Xgs39kjNlojCkzxqw0xgwPEv+TxhhrjBka8H2eMMZkGWNKjDGLjTEnBix/sDHmHWNMgTEm3xjzX2NMn4DyO40xNQ3iGhzkcy/1PvfKIGVJ3jbLbfC69b5L/fs+HlCWZox52hiz3fu7M8j77vP28F67wRiz0BhTZYx5quE6Acv92lu3yd9LLImienafMSbHWzfLGPPLBuueaoxZ5v2mPjfGjA4oM8aYe4wxm40xRcaYD40xYwLKv+etU26M+TBI3BONMYu88kXGmIkBZW81qCfVxphvA8rvNsZ8a9x+4c4G7/uLButWGGP8xpjue9te3na3Dda/PaD8KS+WwPJ4r2y0Vxd83t+7gdsr4D2aqsN72taPNvjMKmNMSUD5s8aYrd53WmOC7DtiRRTVrT95MZR4y1zSYN3ZxpjV3m/zsgZlez2GecvN8H6v9zQR//teeULAax8Yd3wqNsYsMcac3sS6jfb33uvnG3eMKDPGrDfGHBFQdqUxZp0X79vGmL4BZcYY8wfjjts7jdv3mIDyPe0PbjLGbPBi3mKMeaDBd2pyf+CV32jc8a3Yq6OHB5Qle/Urz7hj9+vGmH5B3mOYMabSGPNswGtHe59b6H2nV4KtG42iqJ7t7TjTZD3zygcbY97w6ukOY8x9AWUfev/n9XVwdUCZMcb80hiT7cX9gjGmc6hxBSy3P+d7e6orR3vbqMgYsynIezbn2NnPGPOaV09yjTHXNlj/GGNMprc9Nhhjrm4QV5N1xexhf2n2cs7foqy1MfkHHAYUAfHe897AJmBbg9cs0DfI+l8AfwbaAWcDhUCPJj7r98AnQBdglPcZJ3hl3b04zgVSgD8CXzbxPgbYAFziPU8BRuCSdAOcARQACV75ZcCne9gGVwJLgdHe+kOArg2WORz42NsOQ73XOgB3yVfCowAAIABJREFUAgO9zz4FKAEGeuUnet+nM9Ae+CfwdsB73gk8u5f/ny7AKmAZcGWQ8l96ceU2eP27OIOs8yTwXy+mgcB64AfN3R7e62d52//vwFNNfP4Q4FtgCzAz0nVA9WxXPfPqUQfvcT9gOXCW93wYUOz93ycAPwfWsauefc/7Px0MxHtxZAa890xvmTuADxvEnARkAT8GkoEfes+TmviOHwJ3BDy/1KtvrwF37uX/4k7g/RC310Dv/yShifd6CrinibI0b33jbY8fAkuDLNeoDu9tWzcRxz8Dno8Bkr3HI73vNCXS9aCN163feP8XccB0wAccGlD+f8CxwELgsgafexl7OIZ5yyQC3wBfBvtNAhexa5+dEPD6eHbV4em4Y1ifBus2tb8/DldPD/a+Vz+gn1c2A9ju/RaTcMeEjwLWvQZYDaR7660ArvXK9rg/wB1D0rzHXYH3gZsD3rvJ/YH3HcuAKbi6eR2QH/Bb+SmwBOjl/T8+A8wJsj3ne7+FZwNe61X/G/Pivg+YG+k60sbqWZPHmRDqWRLufOhm3PldCjA+oPxDgpyHBfzmVgEZQEfvt/d0qHF5y+zz+V4IdWUa8H3gamBTE3Hv77HzA+BB3L5nAu68+2ivLNH7f7oGV88OAkqBCaHUFfawv2Qv5/wt+ruPdMUL15/3wynHOzHwfpxPAh81eG1dkHWHA1VAp4DXPsHbgQdZfjMwK+D53cAL3uOrgc8DyjoAFcDIIO8zw/sRdQhSFgecitsB9fReu4wmDpze8jnAsXvYRgnAYtxBssmkylt2KXB2E2WTgZKA53ey9+TvUeB6gux0gEHASq/i7kvytwM4KOD5L4BPWnJ7APfQdPL3FnAS7sDRVpK/aKxn/XBJ+k+95zcA/wsoj/PWPdZ7/jPgxYDyMUBlkPe9ksbJ3ywvbhPwWjbeAb/BsgOBOmBQkLJn2cMBDHegWA9cGuL2Gsh+Jn8NlkvAnXSUN3g9aB3e27Zu8B4dcCfsM5r47BHAVuB7ka4H4fiLxrrllc8Fbgny+qfsX/J3G+4EqtFvEkgF1uCStD39nqcBlcC0Br/doPt74HPgiibe60/AIwHP+3rrDwlY9+qA8ivwTuLZt/1BN+Bd4G9ByhrtD4DzgAUN/p8sXsKLS1LvCyg/GVjd4D3OB15kD8dw3Ant74EVka4jLfEXbfWMIMeZBuXB6tnVeOdCTazzIU0nfy8BtwY8P9SrS+1DjYv9ON8Lta7gks9Ne/hu+3TsxCW4loAEHpgNPOM97uWVtw8o/xq4IMh777Wu0PT+stE5f0v+xWy3T2ttNfAVcKT30pG4Svlpg9c+BvCaw2/zXh8DbLDWlux6R5Z4r+/GGNMFt/Nf0sSyYwLLrLVluB9ao/fCXal4yVsm8DOW4irbXOBxa+32gOJJXhP+GmPM7WZXF5F072+scd3dNhpjfmOMCfw//zHwsbV2aZBYAj+/F24nt7yJRY4MUnaq12S+3BhzXYP3mwZMxe0QgvkrLnGraKL8Y6/LxBxjzMCG4TZ4PNZ73GLbIxhjzLlAtbX2zb0uHEOiqZ4ZY24zxpQCubgD67/ri2j8uwn87bwADDXGDDfGJOLq6dvBt0gjY3CtYjbgtaXBviNwCe4AvTHE9w50BO6g9DKEtL3qZXndWp6s7/IS4HqvDi8yxpzd8AONMYW4/dJfgd81KG6qDu9tWwc6G9dy8XGDz/2bMaYcdyV5KxCTdS6a6lbAe7XDXQlv6lgRTFPHMIzr9nY5cFcT6/4Ol9RsC1bobZNK3Hb8ENcqUi/o/t647s1TgR7Gde3MNcY87H03CP4bhl2/4d22F4235R73B8aYC40xxbiLmROAx5r47g29BcQbY6Z73+FyXItp/bZ5AjjMGNPXGNMe12L6VsDndsZt51uCvbkxpr9X5yuAn+AS8qgXjfVsPxwMbDLuNoMdxnXzHNdgmd97ZZ+Z3bteB/u9J+N6cexVM8739uXY2Ry7HTvZ9V2Dnktaa/OA54EfGGPijTGHAANwvxe3cIh1pan95V7O+VtEzCZ/no/YVXmPwFXoTxq89hGAtfYUa+293usdcc26gYqATkE+o2NAebBlQ3ovb2d8Du7q5m6steNxXSwvJOAHhtsZjQV64k6ULgBu9crSvX9nAeOAo73yK7zPy8A1W98R5DsFxpUIPIdr5l8VpHy89x63Brz8Iq5LQw/gKuAOY8wF3vLxwN+AG621/iDvdybu6u0rTYQ0A9dqMRLXFe+NgJOFt4HbjDGdjLt/43JcF9AW2x7BGGM64k5CbtrXdWNEVNQz73M74VqqnwlY/h1ghjHmKGNMEu5AlMSu385W7/usxu3Mz8WdOIZiX77jJQSp/yGqv3BUGvC59Z8V7HN34A46A3DdxDrh6nm9h3AH957A7cBTDe89sNam4VpebsC1oAB7rcN729YNv9O/Ghz8sdZe78V7BDAHd+U9VkVF3QrwKO4Edl7wr9PIno5h4H6Htwf8rr9jjJmK67L316be3Fp7ihfnScC8+mPOXvb3vXBdu87Bbd+JwCTgV175m8D3jDHjvZO3O/BaArzyhturCOhojDFByurLA/dT/7bWdsZdcH0UyGvq+zVQgjuB/RRXJ36Na4Gsrz9rcC0nm3Fdr0exe1J9N/CEtTYn2Jtba7O9Ot8dty0anQ9EsWirZ/sqHdeq+xAuAf0f8Jq3DwbXu2UwrlfMbOB1Y8wQr+wt4Erj7m1M9ZaF4Pvs3TTzfC+c2yPQbsdOL5H/DLjdGJNijJmM2zcFft/ncfW+Cvc7+WVgvdmHuhJ0f7mHc/4WE+vJ38fA4d4Vlx7W2rW4LhmHeq+NpcFVZU8pbsMH6ozbuQZbtr482LKhvtdZuL69HwX7ItbaSmvt87jkZoL32gZr7UZrrd9a+y1uR36Ot0r9VZT7rLWF1tpNuCuIJ3mvPwjcZa1tWLm+47WKPQNU407wGpYPxe0YfmSt/SQg1hXW2i3W2jpr7ef/z959x0de1fsff52Z9J5N2ZJsryxb2MIuRYqgIiogRZAmIohexXIt12tX1Gu/evWnKIqAdERQQLoISGfZZXtPsimbMmmTOpNk5vz++E5205PN5pvJTt7PxyOPzMyZcqac7/f7+Z5zPgf4vx71+hTO2ZxXB3i+VJwzJJ8ZrE7W2hettR3W2kbgczhDBo6LFH828r734ozzvhenl2dMPo8hfBdnSMBoemxiwTHTzqxjE87v4buR23bh7AD+H06gl4szT6f7t/NtnEBpJs6Y/O8Cz0VO2AxnRPUyTmKGaThDbI5I5AD0Q8AdfV63+7X6va61tsVau8Fa2xU5k3kj8J7I2X+stRuttXWR8sdxAsOL+r525Oz074A/G2Pyh2vDI/isu9/TTJwTPX8e5HlC1tqXcA5q/mOg+8SIY6ZtGWN+GqnPpX0D9sEMtQ8zxpyHM5zu/r6Pi+ybfouz7+ka5jU6rbVPAOcYY86P3DzU9r57X/Fra22ltbYWZ07X+yLP90+cbcJfceYgleB8Ft2/4b6fVwbQEvlMRvy9RL7r7ZH3ORLX45zw7J6LeBXOydHuZDQ342y/cnBGPjxEpOfPOIk03gX8YrgXsdbW42xr/t6zl/YYd8y0s1Fqxxle/USkp/NnOL+D4wCsta9ba5uttUFr7R04wU/3sdGfcI6lnsf5Pf4rcnuvbfYgjuZ4z83Po7sOA+07wekVn4szVehmnP1feeQxS4D7cU7WJuC0t/8yxry/7/MP1VaG214OdMw/lmI9+HsV58z0DTg/Zqy1TTg9RjcABwc5YN8OzDPG9DzDsJIBhrJYaxtwDmJWDnLf7T3LIj/4+QM814BnuQcQj3OGZiCWw13Vu3GCtsGe72zgp8YZPtk9LORVY8wVkXoanGEiU3Hm+nX2fHBkOM6zwPestXcOU+ee9TobuLDH654C/NwY8/9wehrmAP+OlD0ETI/cd85wz22trbfWXmmtnWatPR7n9/3GWHwewzgb+GyPx84EHjDGfGWYx8WKY6mddYuLlHc//4PW2mXW2hycA7vZOOP4u1/nfmtteSQYuh1nAnu/DJeDvMcVkfbUbcUA9boGJ/lCvx6OEeg+cfR8j/cz3OfVV3e7MEOUD1bmwTkrWsAI2vAwn3W3j+DMfyka5DW79foeY9Ax0baMMd/FmbPznkj9RqvvvmJtj+3qZcDnjTF/xzkIXAvcHynr/v2Umx5ZOfvo+VsZdHsf+TzKGXxfgbX2N9bahdbafJwgMA4nmQX0+bzo/1mOZHswUJ2HsxJ41Fq7JxJMP4nzvZ7So/z2yH4yiNNjus44w73PxGm3pZHP40vAxcaYjUPUK5/+B+fHqmOinR2FLQzxex5Az+OqsLX229baOdbawkh9KiJ/wzma470jbSuj0W/fCWCtPWCdHt48a+16nEC5+1hyGc5c2acin81unJ7UcxlYv7ZyhNvLoY75R8+O8STCifaHc/amGvhsj9t+Hbnt7iEe9xrO2ZEk4EKGzuD0I5weu2yc4YiVHM7glIfTVX1x5Ll+TJ9snzhnr7uITBjvcftJONnIEnAySX0F56xHdyahc4GpkctLcHY+3+7x+D8Dj+F0kxfidD1fFynLx+lp6P6zkddLjpT/LvIZpA3wfgtwxqJ/eZDP44LIZ2FwJtpXcHgybVaf130FJwNVJk4j6Vl2Ec7GdxpOVsHjcYbgeHGGBPwSJ6iLjzz3fJxG6o18NrXA8WP0ecRFvr8f4vSGJnE4k1xOn8eW4ZxN6vfZxeofE7id4QQnn+jzm6zsU9c1kd9NHs5ZvXt6lH0bZ+jF1MhzXY2TVa87K5838pqfxDk7nNTjN9mdsexzOPMkbqRPtk+ctt0InDXAe46PPN89OMmGkohkoOtxn6dxejGO5PNaz+GsYjmR9/yvHo+9BKeNeXCGSjcDZ0bK3o0zDM6Ls0P7FU47TWKYNjzcZ93j9XcDH+tzWz7O0KW0yOPPiXwPF0T79z9Z21ak/Ks4oy2mD/LcCZHHvYwzDSAJ8ETKBt2H4Wyne/6W7sfpmZqC0457lp2Is80uiLzekshzJ+O0oatwTv6t7vFbGmp7fxNOQJkf+Uz+jXOik0j9l0XqMAvnwPF/erzfT+IksCjAGWK3nf7ZPgfcHuD03nUndFsaeez/jmR7gHMCaQ/OgaLBaadtRBKG4CQx+SvOvjYeZ8h1RaQspc/n8TOcUQh5kfKLOLy9yMOZ2rFxoO/7WP1j4rezQfczI2hniyO/hXdFnuc/cY7hEnCOyc7h8Pb7Spzt6uLIY6fgHFuZyG9yG70TGg21/zua473h2oon8lrnRm5Povd+9Wj2ncfhbH+6e9Bre7SF+Ti9kmdxOGv8PuDjI2krDLG9ZJhj/jH9vUe7wY1Dg/4hzoZ9dY/bLo3c9oketz0BfK3H9Tk4G/V2nAORd/UouxLY3uN6Ik7XeBPOhuILferwLpxAoz3ynHP6lH+VATIx4Qx72hz58ruHhJ7eo/xnkddrxVki4iZ6bwwycJJVNOMEJN+iR+akPq9lObzUw+zI9UDkR979d2Wk/NuR8p5lLT2e616gLnL7LnpsTAd43ecZPMvUmfTO/nRW5LtoxUm1/TdgYZ/v9SDORu5t4Jw+zzeqzyNy/TuR23r+fWeQx5YwSbJ9HgvtDGcj/GSkDbXgHCB9red3jxPcdbez39Mj4y7OTuM3ODvqJmAjPTKO4WQs7PvbuL1H+SrgrUi9NgKr+tT7cpydV7/fIs4cwL7P/dEe5QU4J44Gykw76OcVec3iSFuqxDkxMq1H+b9xDkSacLZBH+5R9qHI59yCk5DlcXqkDR+qDQ/3WUfKT47UK73P7Xk428DGSL22EtnhxvIfE7htRcosztyXnvuDnvV4foDf8JmRsiH3YQO0hcGWH5lDj2yfOAdvr0d+Z404gdyFQ3zGfbf38TjDLRtxEqb8CkiKlGXh9KS0Rsp+SI+DSpwDwp9Eft/1kcs9tzWDbg9wArTuz6MEJ91/0ki2B5HXvQlnXl8zTgB6dY/H5uAMX6uJvK+X6JH9tM/n8R16L/XwGQ5vL6pw9qOzo902Jlk7++gA3/3tI2lnkfKLcIKUpsh9j4/cnofTPrrbymvAu3s8blHkfbXh7Kf61nnIevW57/OM8HhvBG3lzAFe9/mRtJVI+VD7zs/j7NtacdrJ2j7ll+IEwd3DvX/M4UB7yLbCENtLhjnmH8s/E3lBERERERERiWGxPudPREREREREcDH4M8b8yRhTY4zZNki5Mcb8yjjr6GyJpFMVERERERERF7jZ83c78N4hys/FyfazECeb0s0u1kVERERERGRScy34s9a+iDNhcTAXEFnawFr7GpBljJnuVn1EREREREQms2gu0FmAk3GxW3nktsq+dzTG3IDTO0hqauqaJUuWjEsFY1XYWjq6wnSEwnR2Wed/KEwobLHWKXf+IpfDdsgFYgwQ5/Xg9Ri8vZZkiT5jIn+Y/pfHsR7pSXGkJ8UPWv7WW2/VWmvzxrFKQ8rNzbVz5syJdjUmJactgsVpj+C0Rezh28IWusJhOkOWrlDkf+R6eIRJvDyRtnr4dY6MAYw53JaMMZH/Thvj0O2R6+Mg3muYOSVl0PKJ1s5AbU2OLR1dYdo6ushITsAzRLOeaG1N7UyiwQLWRlZW6HO55z798H96XU+I85Ac7x30+UfbzqIZ/A202RjwEMRaewtwC8DatWvthg0b3KxXzAiFLW+XNfDCbh87KpupaGynoqGNpkBXr/ulxnkoyEomIzme5HgPKQlxJMd7SU7wkhzvJSXBS1K8l9REL9kpCeSkJTAlNZEpKQlMSUsgNcGLmWBB37HGGHMg2nXoac6cOaiduScUtpTWt7G3upm9NS3sr2lhb00L+2paaO8Mjfh5UuM8TMtIYmpGIvkZSUxNdy5PzUgiO9Vpm0mRNpyc4CUlPo6kBA8JXk+/NhsOW7rCls5QmK6QpTPs/Pd6DPFeQ7zXQ5zXEO/x4BnqqG8Cm2jtDNTW5OiV1bfx/O4atlb4nRNFQ0hPimNOTiqzc1KYm5tKQVYycd6BB4EFOkNsKffz1oEGNpY2sKm0gaaWDgBuvuEk1s/LGfR1JlpbUzuTkdhY2sCWskZSEuJISvCSEjkWPrQfjXcuN7Z3UN0UpLopQE1T4NDl6uYgNU0B6lo66AiFj7o+H3nHXL75gaWDlo+2nUUz+CsHZva4XoizRpscBV9zkBf2+Hh+dw3/3luLv70Tj4EF+WkUZqdw4pxsCrKSKchOpiArmcLsFHLTEhS8ibisobWD3724nxd2+yiqbaWj6/COYXpmEgvy0/jwupksyE8jKznBCbS8hjiPE3QleD3EeT3EeQyJcR7y0hPJTI4fs7br8RgSPIaEOCWBFnFTOGzZ72thY2kDbx1o4O2yRuI8HlYUZrK8MJMVBVksnpY+aFsMdIZ4o7ie53f7eH5PDUW+VgBy0xJIjBu8lwCgsa2D1o7DJ5jiPE5v+eycFObkpFKYnUx5QzsbSxvYcbCJrkg0OTc3lTMW5bN6dharZ2WzaGr6GH0aIhPDPa+X8o2/bR32BMpAslLimZaRRH5GEovy08hJSyQxzuPswyP77Xiv5/BJ1Mi+/dD/OA/xnsh9IydZ4+MMU1ITxv6NEt3g7xHgRmPMfcB6wG+t7TfkU4YWDls2ljYc2glsq2gCIC89kXcvncqZi/M4bUEemSmDDzkUkeG1BLtIifceca9Xa7CLW18q5g8vFtHS0cVpC/M4Y1EeC/LTDv0NNSRYRI5tzYFO3i5rZOOBxsM9aJEROFkp8ayelU1X2PLk9irue9OZDZPg9bBkejrLCzJZUZjJgvx0tlX4eX53Da8W1RHoDJMQ5+GkeTlctX42Zy7OY25u6rAng6y1+FqCHKhro7i2lQN1rZTUOpffLK6ntSNEcryXlTMzueH0eayZnc2qWdmuHYSKRFs4bPnZ07v57fP7OWNRHj+6eDmhsCXQGaK9wxnm3N4ZItAZoq0jRKAzTGZy/KFRNnnpiSQNMTRzInIt+DPG3AucCeQaY8qBbwPxANba3wGPA+8D9gFtwLVu1SVWbavw842/bePtska8HsPqWVl8+ZzFnLEoj6XTM47ZoVkiE0lLsIufP72bO14pYVpGEuetnMF5K2dw/IyMIQ+0gl0h7nm9lN/8ax+1LR28Z+lUvnTOYp0xF5lEbnu5mO89toOwdea/LspP5/0rZrB6VhZrZmf3CtistZQ3tLOl3M+Wika2lvt55O2D3P166aHnm52TwmVrZ3Lm4nxOmpdDcsKRHXQaY8hPTyI/PYkT50zpVWatpb61g8zk+EGHgorEkmBXiP96cAt/f/sgl6+byfcuWDYpfvuuBX/W2suHKbfAp916/VjWFOjkf5/ew59fLWFKagI/umg55y6fTmayeg9ExtKzO6r51t+3UdkU4OLVhdS3dnDrS8X8/sUi5uWmHgoEF+SnHXpMKGx5eFMFv3hmDxWN7Zw0bwq3fGQJq2dlR/GdiMh4K61r40dP7OLk+Tl84vT5nDAri4whevmNcYZgzpySwvtXOMnPw2HLgfo2dlc1s3haOnNzU12rrzGGnLRE155fZCLxt3Xyibs28FpRPV8+ZzGfOnP+pJkCFc1hn3KErLU8svkg3//HTmpbgly1fjZfOmexgj6RMVbTFOA7j27n8a1VLJ6azq+vWM2a2U7w1tDawRPbqnh080F+9dxe/u+fe1k6PYPzVs6gIDuZX/9zL3trWlhekMkPL1rOaQtzJ80ORUQc1lq+9cg24jyGn3/oBKZlJo3qeTwew9zcVFeDPpHJpryhjWtve5OSulZ+edkJfHBVQbSrNK4U/B0j9vta+Nbft/HyvjpWFGZy6zVrWVGYFe1qicSUcNhyzxul/PiJXQRDYb58zmI+ftq8XokXslMTuGL9LK5YP4vqpgCPbank0c0H+fGTuwCYl5vKb69czbnLpinoE5mkntxWxfO7fXzzA0tHHfiJyNjbVuHn2tvfJNAZ4o6PreOU+bnRrtK4U/A3wQU6Q/zmX/v4/QtFJMZ7+N4Hl3HFull4NZ9PZEztqW7mqw9t5a0DDZwyP4cfXLh82LPtUzOSuO4dc7nuHXMprWujqLaFdyzInRRzBkRkYC3BLr776A6WTs/gmpNnR7s6IhLxr901fPrujWSnJHD39esn7Rx8BX8T2NtljXz23k2U1rdx0aoCvvq+48hL13h8kbF260vF/OiJnaQmxvGzD63k4tUFR9xrNysnhVk5gy8wLiKTwy+e2UN1c4DfXrVaJ4JEJoi/v13BFx7YzJJp6fzpoycyNWPy9sgr+JuArLXc9XopNz26nakZSdz78ZM4ef7gi6mKyOjt97XwP4/v5PSFufzsQyuV8EBERm3HwSZuf6WEy9fNUpInkQni2R3VfOGBzaybM4U/XLOWtMTJHf5M7nc/AbV1dPH1h7fx8KYK3rk4j19cdgJZKVpfR8QtP396N4lxHn5yiQI/ERm9cNjyjb9tJSs5nq+csyTa1RER4PWiOj59z0aWzchQ4BehT2ACKfK18B93bWRPTTNffPciPv3OBVqrT8RFm8saeXxrFZ89e6GGVIvIUbl/QxkbSxv5+YdWkpmiLNwi0batws/1d2xg5pQUbrt2nQK/CH0KE8ST2yr50l+2EO81/Plj6zhtYV60qyQS837y1C6mpCbw8dPmRrsqInIMq2sJ8qMndrF+7hQuWj250saLTERFvhau+dMbZCTHc+d165iSqlF03RT8RVlXKMxPntrNLS8WsXJmFr+9cjUFWcnRrpZIzPv3Xh8v76vjmx9YSvoQCy+LiAznh0/sojXYxfc/uExLvIhE2cHGdq6+9Q0A7rxuHdMzdVzdk4K/KKppCnDjvZt4o7iej5w8m6+//zgS47zRrpZIzAuHLT95cjcFWclcddKsaFdHRI5hrxfV8eBb5XzqzPksnKSp40UmivrWDq6+9XWa2ju594aTmJeXFu0qTTgK/qJkW4Wf6+54k6b2Ln552Ql8cJWGiYiMl8e3VbK1ws/PP7RSJ1xEZNQ6usJ842/bKMxO5jNnLYx2dUQmtZZgFx+97Q3KG9r588fWsawgM9pVmpAU/EXB09ur+Nx9bzMlNYGHPnUKx03PiHaVRCaNzlCYnz21m8VT03XSRUSOyq0vFbO3poVbr1lLcoJOJIlES6AzxA1/3sD2g038/qo1rJ+nJdIGo+BvHFlrufWlYn7w+E5WFGTyh2vWkp8+eReZFImGBzaUUVLXxh8/shavsumKyACaA508t6uGKn+Ato4Qgc4Q7Z0h2jqc/4EO5/LG0gbes3QqZx83NdpVFpmU2jtC7Kj0c/Pz+3llfx2/uGwl71qq9jgUBX/jpCsU5juPbueu10p57/HT+MVlJ+gsocg4a+8I8X/P7mXt7GzOPi4/2tURkQkk0BniuV01PLr5IM/tqiHYFT5UlhjnITnBS0q8l6QELykJXpLjvbzruKl88wNLo1hrkckj2BViV2UzWyr8bClrZGuFnz3VzYQtGAPfOW8pF64qjHY1JzwFf+OgOdDJjfds4oU9Pj5x+jy+8t4lWr9PJAr+9HIxNc1BfnPlamXkExE6Q2Fe2lvLo5sP8vSOalqCXeSmJXL5ulmct3I6S6ZlkBTv1SgBkVF4eFM5P/jHLublpnLqglzesTCHFYVZxHs9wz7WWktxbSsbSxvZWNrAlvJGdlc10xmyAExJTWBFYSbvWTqV5YVZrCzMJD9Do+lGQsGfyyoa27nu9jfZW9PCDy9azuXrlFlQJBoa2zr43Qv7OXtJPifOmRLt6ohIlLR1dPFGcT1Pba/miW2VNLZ1kpkczwdWTOe8lTM4aV6Ogj2Ro/Tktiq++MBmls7IoL0zxC//uYdfPAupCV5OmpfDqQtyOXVBLoumpmGMoa2ji81lfjaWNrDxQAObyhqpb+0AID0xjhUzM7n+tHmsKMhkeWHThtEaAAAgAElEQVQmBVnJOok7Sgr+XLSlvJHr7thAoCPEHdeu4x0Lc6NdJZFJ6+bn99MS7OLL710c7aqIyChZa3mjuB6AObmp5KcnDnsA2BUKs7ncz8v7anl5Xy0bSxvoDFlSEry8e+lUzlsxg9MX5ZEQN3xvhIgM78U9Pj577yZOmJnFndetJzUxjsa2Dl7dX8dLkXb4z101AOSlJ5KXlsju6mZCYadXb35eKmcvyWf17GxWz8pmYX6aRsyNIQV/Lnlhj49P3LmBnNRE7v7UehZp7R+RqKn0t3P7KyVceEIBS6Ypu67Isag12MXXHt7K398+eOi25Hgvs3NSmJubyuycVObmpjA7J5X0pDjeLK7npX11vF5UR3OwC2Pg+BkZfOwdc3nHglxOnDOFpHjNvRcZS2+W1HPDnRuYn5/GbR9dR2qiE2pkpSRw7vLpnLt8OgDlDW28sq+Of++rpbGtg08dN5/Vs7JZNSuLrJSEaL6FmKfgzwW+5iCfv28Tc3JSufO69eSlJ0a7SiKT2i+f2Yu18J/vXhTtqojIKOyqauJTd2+kpLaVL7x7ESfMzKKkrpWS2jZK6lrZXd3MszurD80H6jY7J4XzTpjBOxbkcvK8HLJTdVAp4pZtFX4+dtubzMhK5s7r1pGZEj/ofQuzU7j0xBQuPXHmONZQQMHfmLPW8tWHttLaEeLXl69S4CcSZW+XNfKXt8q45pQ5zJySEu3qiMgRsNbylw3lfPPv28hIjufu60/i5PnO+l2nk9frvl2hMJX+AMW1rTS0dbB6VrbavMg42VvdzNW3vk5Gcjx3Xbee3DQd/05UCv7G2F83VvDszmq+/r7jWKihniJRsbe6mSe2VfH41kp2VTWTkRTHp9+5INrVEpEj0NbRxTf+to2HNlZw6oIcfnnZ0CdU47weZk5JUcAnMs5K69q46tbXifN6uPv69czISo52lWQICv7GUEVjO999ZDvr5kzhY++YG+3qiEwa1lp2VDbxZCTg2+9rxRhYMyubb7z/OD6wYobOQoocQ/ZUN/Opuzey39fCf75rETeetUAZOEUmoCp/gCtvfY1gV5j7bziZObmp0a6SDEPB3xgJhy1feXALIWv52YdWaicl4oJQ2FLXEqS6KUh1U4Dq5gDFvlae3lFNaX0bHgPr5+ZwzSlzOOf4aUzVmj8ix5wH3yrnm3/bRmqil7uuW8+pC5QpW2QiqmsJctWtr1Pf0sE9Hz+JxdM04u1YoOBvjNz1+gFe2lfLDy5cxqwcDTkROVrWWv7472JeL66npjlAdVMAX3OQcO98DsR5DKcsyOU/zpzPe5ZOJUc9fCLHrB89sYvfvbCfk+ZN4VcfXqVFm0UmqNqWINf86Q3K6tu442PrWDkzK9pVkhFS8DcGimtb+Z/Hd3LGojyu0CLuImPijldK+MHjO5mXl0phdgqLp6YzNSOJqZlJTE1PdC5nJJGblkCcV+tziRzr9tU0c8uL+7lkTSE/vniFRtCITFCldW185E+vU+kP8Pur13DSvJxoV0mOgIK/oxQKW774wNskeD38+OIVwy42KyLD21BSz/f/sZN3HZfPLVev1eKuIpPA/z6zh+R4L19733EK/EQmqK3lfq69/Q26wpZ7Pr6eNbOnRLtKcoRcPV1ujHmvMWa3MWafMea/ByifZYz5lzFmkzFmizHmfW7Wxw23vFjExtJGbrpgGdMyNTxF5GjVNAf49D0bKchO5ueXnqDAT2QS2Fru5/GtVVx/2jymaC0+kQnp33t9fPiWV0mM8/LgJ09R4HeMci34M8Z4gd8A5wJLgcuNMUv73O0bwAPW2lXAh4HfulUfN+yqauIXz+zh3GXTuOCEGdGujsgxrysU5jP3bMLf3snNV64hM3nwBWJFJHb87OndZKXEc/1pypQtMhE9vKmca297k5lTUnjoU6ewID8t2lWSUXKz528dsM9aW2St7QDuAy7ocx8LZEQuZwIHXazPmOroCvOF+zeTkRzH9z+4TMM9RcbAT57azevF9fzwouUsnZEx/ANE5Jj3RnE9L+zx8R9nzCc9SSd8RCYSay23vLif/7x/MyfOmcIDnzxZmbSPcW7O+SsAynpcLwfW97nPd4CnjTGfAVKBdw30RMaYG4AbAGbNmhgJVX793F52VDZxy9VrlF1QZAw8vrWSW14s4uqTZnPhqsJoV0dExoG1lp8+tYv89EQ+cvKcaFdHRHoIhy3f/8dO/vRyMR9YMZ2fX7qSxDhvtKslR8nNnr+BusL6JGnncuB2a20h8D7gTmNMvzpZa2+x1q611q7Ny8tzoapH5tHNB/nt8/u5eHUh7zl+WrSrI3LM21fTwpf/splVs7L45gf6jg4XkVj1wh4fb5Y08JmzF5KcoINKkYki2BXis/dt4k8vF/OxU+fyqw+vUuAXI9zs+SsHZva4Xkj/YZ3XAe8FsNa+aoxJAnKBGhfrNWodXWF++MRObnu5hDWzs/n2+TpIFTlarcEuPnnXWyTFe/ntlatJiNOyDSKTgbWWnz29m5lTkrls7czhHyAi4yIUtnzqro38c1cNX3vfEj5+2jxNb4ohbh5lvQksNMbMNcYk4CR0eaTPfUqBswGMMccBSYDPxTqNWpU/wOV/eI3bXi7h2lPncN8NJ5GhuQkiR8Vay3/9dQtFvhZ+ffkqpmcmR7tKIjJOntxWxbaKJj5/9iKd9BEZA4HOEP/aXcPPn95NeUPbqJ/n50/v5p+7arjpguO54fT5CvxijGs9f9baLmPMjcBTgBf4k7V2uzHmJmCDtfYR4IvAH4wx/4kzJPSj1tq+Q0Oj7pX9tXz23k20dYT49eWrOG+lMnuKjIVbXyrmH1sq+e9zl3DKgtxoV0dExkko7PT6LchP44OrCqJdHZFjVnFtK8/vruH53T5eK6oj2BUGnClKD3zyZPLTjyw5y2NbnKlNl6+bpXm4McrVRd6ttY8Dj/e57Vs9Lu8ATnWzDkfDWsvvXijip0/tYm5uKvfdcBIL8tOjXS2RmPBmST0/fGIX5xw/lU+cPi/a1RGRcfTwpgr2+1r53VWrtaC7yAhYawl2hWkNdrGl3O8EfHt8HKhzevjm5qZy+bpZnLk4j4Q4D9fdvoFr/vQm991w0oiXTdpZ2cSX/7KFtbOz+e75x7v5diSKXA3+jmX+9k6+9JfNPLOjmg+smM6PLl5BWqI+LpGx8rvn95OXlsjPPrRSQ0pEJpFgV4hfPLOH5QWZnKOkaSKAk1fiz6+W8OzOato7QrR1hGjvDNHe/b8zRM+xcUnxHk6Zn8t175jLGYvymJ2T2uv5fnf1Gq6/402uu/1N7rxu/bAJlRpaO7jhzg1kJMfx26s0/z6WKZoZwM7KJj5511tUNLTzrQ8s5dpT5+jgVGQMWWvZUuHn9IV5WtdLZJK5/80yKhrb+eFFy7VvlUnPWsuzO2v4wT92UFLXxvEzMshNS2RGlpfkeC/JCc7/lAQvSZHL8/LSWD93Cknxgwd0ZyzK4xeXncBn7t3Ep+5+i1s+spZ478ABXVcozGfu3US1PziqoaJybFHw10dXKMwVf3iNhDgP991wEmvnTIl2lURiTnVTEF9zkOUFWshdZCILhS1vlzXw3K4aukKWguxkCrKSKcxOoSA7+YhHxLR3hPj1c/tYN3cKpy3UPF+Z3HZWNvH9f+zg5X11LMhP47ZrT+Sdi/PH7Pk/sGIGTe1dfO3hrXzxgc388rIT8AwwzPpHT+zipX21/OSSFZwwM2vMXl8mJgV/fZQ3tNPQ1slPLlmhwE/EJVvKGwFYXqidjMhE09bRxb/31vLsjmqe21VDXWsHcR6Dxxg6QuFe981MjqcgK5mC7GQKs5OZn5fGwvw0FuSnkZOW2O+573i1BF9zkN9euVq9fjJp1bYE+fnTe7j/zVIykuP57vnHc8X6WYP2zB2NK9bPorG9g588uZvM5HhuuuD4Xm3v4U3l/PGlYj56yhwu1ZIrk4KCvz6KalsAmJ+XOsw9RWS0tlX48XoMS6er509kIqhpCvDszhqe3VnNS/tq6egKk54UxzsX5/PupVM5Y3EeaQlx1LYEKW9sp6KhnfKGdioa26hoaKektpWX9tbS3hk69JxTUhNYkH84GJyTm8rNz+/nnYvzOFEnV2USCnaFuP3lEv7fc/to7wxxzSlz+NzZC8lKSXD1df/jjPk0tnVyy4tFZKfE84X3LAZga7mf//7rVtbPncLX33+cq3WQiUPBXx9FvlYA5uamRbkmIrFrS4Wfhflpw05AFxH33ftGKV99aCsAhdnJXLl+Fu8+bionzp3SryciPyOJ/IwkVs/K7vc84bClsinA3upm9tW0HPp7dPNBmgJdh+73xciBp8hksq+mhevueJMDdW2ctSSfr73vOBbkj8+xpjGGr567hMa2Dn713D6yUhI4/4QZfOLODeSmJfLbK1e70usoE5OCvz6KalvJSolnSqq7Z2FEJitrLVvL/Zy1ZOzmNYjI6P397Qrm56XymytXs3hq+qiHY3o8xhkCmpXMmT3mLVlr8bUE2VfTgsGwrCBzrKouckyoaGzn6ltfpzNkueNj6zhjUd6418EYw/9cuJym9i5uemwHd752gPq2Dh785CkDDtGW2KUwv48iXwvzcjXkU8QtB/0B6lo7WFGoA0CRaAuHLdsrmjh5fg5LpmW4Mg/PGEN+ehKnzM/l5Pk5Y/78IhNZbUuQq//4Oi3BLv4cpcCvW5zXw/9dfgKnLsihuLaVH1+8QidjJiH1/PVR5Gvl9Cg2TJFYt7XcDyjZi8hEUFrfRnOwi2UzdAAoMtaaA5189LY3OOhv567r1rN0RvTnuSfGebn1mhPZV9OiwG+SUs9fD82BTmqag8xTshcR12ytaCTOY1gyLT3aVRGZ9LZWOCdjdBAoMrYCnSGuv2MDuyqbufmqNRMqg3xSvFdtfhJTz18PxbVOshcN+xRxz5ZyP4umpg+5OK2IjI9tFX4SvB4WTdXJGJGx0hkKc+M9G3mjpJ5fXnbCmK7dJ3K01PPXw6HgL0+ZPkXcYK1la4Vf8/1EJohtB/0snpZOQpwOB0TGQjhs+cqDW3h2Zw03XbCMC04oiHaVRHrR1r6H/b5WPAZm56REuyoiMam8oZ3Gtk6WK/gTiTprLdsqmjT8S2SMWGv53j928NCmCr747kVcfdLsaFdJpB8Ffz0U+VoozE4hMU7D0UTc0D2/aLkONkWirqy+HX97p9qjyBj59XP7uO3lEj526lxuPGtBtKsjMiAFfz0U+VqV7EXERVvK/cR7DYuV7EUk6rYd1MkYkbFy56sl/O8ze7h4dSHfeP9xriybIjIWFPxFhMOW4tpW5irZi4hrtlX4WTItQ73rIhPA1grnZMyiaZrnLnI0apoD3PTYDs5aks+PL16Ox6PATyYuBX8R1c0B2jtDSvYi4hJrLVvKGzXfT2SC2FbhZN7VyRiRo3PP66V0hizf/MBS4rw6tJaJTb/QiCKfk+lzvnr+RFxRWt9GU6BLQ8xEJoDuzLtqjyJHp6MrzN2vl/LOxXkaPSbHBAV/EUW+FkDLPIi4ZUu55heJTBQVjU7m3ePVHkWOyhPbKvE1B7nmlDnRrorIiCj4i9jvayUlwcvUjMRoV0UkJm2r8JMQp8WkRSaCbcq8KzImbn+lhLm5qZy+MC/aVREZEQV/EUWRZC/KziTiji3lfo7TYtIiE8LWCj9xHsMSZd4VGbXNZY1sKm3kmpNnK8mLHDN0FBZRXNuiIZ8iLgmHLdsq/Er2IjJBbKtoYuHUdJLilexFZLTueKWE1AQvF68pjHZVREZMwR8Q6AxR3tDOPE3UFXFFSV0rzcEuVhRkRbsqIpOetc7JmGUzMqJdFZFjlq85yGNbKrlkTSHpSfHRro7IiCn4Aw7UtWEtWuBdxCVbu+cXqedPJOoq/QHqWjvUHkWOwr1vlNIRCvMRJXqRY4yCPw5n+pyvYZ8irtha7icxzsPCfLUxkWjrPhmzTMleREalMxTmrtcOcPqiPB07yjFHwR9OsheAORr2KeKKLRV+ls7I0OK3ImPIWstVf3ydx7dWHtHjtlf48Rg4bpqGfYqMxhPbqqhpDnKtev3kGKQjMZwF3qdmJJKWGBftqojEnHDYsr3Czwr1MoiMKX97Jy/tq+X3L+w/osdtrfCzMD+d5AQlexEZjTteKWFOTgpnLNLyDnLscTX4M8a81xiz2xizzxjz34Pc51JjzA5jzHZjzD1u1mcwRbUtzMtVt72IG4pqW2ntCLG8UMleRMaSrzkIwOZyP/sj0xeGY61la0WThnyKjNLWcj9vHWjg6pPnaHkHOSaNKPgzxvzVGPN+Y8yIg0VjjBf4DXAusBS43BiztM99FgJfBU611h4PfH7ENR8j1lqKfK1K9iLikq0VjYAWkxYZa93BH8DDGytG9JjqpiC1LUGWF2jIp8ho3P5KCSkJXj60Vss7yLFppMHczcAVwF5jzI+MMUtG8Jh1wD5rbZG1tgO4D7igz30+DvzGWtsAYK2tGWF9xkx9awf+9k6t8Sfiki3lfpLjvczXCRaRMeVrcYK/WVNSeHhTBeGwHfYx25TsRWTU6lqCPLrlIBevLiRDyzvIMWpEwZ+19llr7ZXAaqAEeMYY84ox5lpjzGC//gKgrMf18shtPS0CFhljXjbGvGaMee9AT2SMucEYs8EYs8Hn842kyiPWnexFa/yJuGNruZ/jlexFZMx19/xdf9pcKhrbeaOkftjHbI0ke1mqNf5Ejth9b5bR0RXmmlNmR7sqIqN2JMM4c4CPAtcDm4D/wwkGnxnsIQPc1ve0ZBywEDgTuBz4ozGm38Qga+0t1tq11tq1eXljO7m22BcJ/tQrITLmQmHL9oOaXyTiBl9zkIQ4D5esKSQ1wTuioZ/bKvzMz0sjJUEJzkSORGcozJ2vHuC0hbksyE+PdnVERm2kc/4eAv4NpADnWWvPt9beb639DDDYeMlyYGaP64XAwQHu83drbae1thjYjRMMjpv9tS0keD0UZqeM58uKTAr7fS20d4ZYocWkRcZcTXOQvLREUhLieO+y6Ty+tZJAZ2jIx2w76NfJGJFReHp7NVVNAa45eU60qyJyVEba8/f/rLVLrbU/tNb2WlDIWrt2kMe8CSw0xsw1xiQAHwYe6XOfvwHvBDDG5OIMAy0ace3HQJGvldk5KXiVsUlkzG0pd+YXKfgTGXu+5iB56YkAXLS6gOZgF8/urB70/jXNAaqbggr+REbhjldKmDklmXcuyY92VUSOykiDv+N6Dsc0xmQbYz411AOstV3AjcBTwE7gAWvtdmPMTcaY8yN3ewqoM8bsAP4FfNlaW3fE7+IoFPlaNORTxCVbyxtJTfAyV0upiIy5nsHfSfNymJaRNOTQz+5kL8q8K3Jkth/080ZJPdecPEedBXLMG2nw93FrbWP3lUh2zo8P9yBr7ePW2kXW2vnW2h9EbvuWtfaRyGVrrf1CpFdxubX2vtG8idHqCoUprW/TgamIS7ZW+Dl+RqZ2liIu8LUcDv68HsMFq2bwwh4fdS3BAe+/tbwJo2QvIkfs/jfLSI738qE1M4e/s8gEN9Lgz2OMOXT0FlnDL8GdKo2fsoZ2OkNWPX8iLugKhdl+sInlGvIpMuY6Q2HqWzvIjwR/ABetKqQrbHl0c9/p9Y5tB/3MzU0lLVHJXkSOxL6aFo6fkUFmipZ3kGPfSIO/p4AHjDFnG2POAu4FnnSvWuOjuLYFQOuPibhgb00Lwa6w5vuJuKCupQPgUM8fwOJp6SydnsHDmwYe+rmtwq8hnyKjUOUPMDUzKdrVEBkTIw3+vgI8B/wH8Gngn8B/uVWp8VLUvcyDhn2KjLmtml8k4pruNf7y0hJ73X7R6gI2l/vZ72vpdXttS5BKf0DtUeQIWWup9AeYnqHgT2LDSBd5D1trb7bWXmKtvdha+3tr7dD5pI8B+32tZKfEk516zI9gFZlwtpb7SUuMY06OetZFxpqvJQD07vkDOP+EGXgM/RK/dCd7OX6Ggj+RI9EU6KK9M8Q09fxJjBjpOn8LjTEPGmN2GGOKuv/crpzbnEyf6vUTccOWCj/LCjLwKNmLyJg71PPXJ/jLT0/itIV5PLypgnDYHrr9UPBXoGQvIkeiyu+caFHwJ7FipMM+bwNuBrpw1uX7M3CnW5UaL0W1rczNVa+EyFjrDIXZWdnEisKs4e8sIkesO/jL7TPsE5yhnxWN7bxRUn/otq0VTrKXjCQlrBA5EpX+dgCmK/iTGDHS4C/ZWvtPwFhrD1hrvwOc5V613Ncc6MTXHFSmTxEX7KlupqMrrMWkRVziaw6SkRRHUry3X9l7lk4jNcHba+jntoomtUeRUahucnr+pmrOn8SIkQZ/AWOMB9hrjLnRGHMhkO9ivVxXXKtkLyJu2VnZDMDxWk9MxBU91/jrKznBy3uXTefxrZUEOkPUt3ZQ0djOMrVHkSNW6Q9gjDOkWiQWjDT4+zyQAnwWWANcBVzjVqXGQ3emTy3zIDL2SuvbMAZmZqdEuyoiMcnXPHjwB87Qz+ZgF8/urD4030+ZPkWOXJU/QG5aIglxIz1kFpnYhl3pNbKg+6XW2i8DLcC1rtdqHBT5WvAYmJWjg1ORsVZW38aMzGTtLEVc4msOsnyIObUnzcthWkYSD2+sYPXsbACOV/AncsSqmgJM05BPiSHDBn/W2pAxZo0xxlhr7XD3P1bsr22lMDuFxLj+8yVE5OiU1bdRmJ0c7WqIxCxfc7DfGn89eT2GD64q4I//LqI52MWsKSlkJivZi8iRqvIHmDlFHQUSO0Z6Wn4T8HdjzNXGmIu6/9ysmNuKfa1K9iLikrKGNu0sRVzSGuyitSM05LBPcIZ+doUtbxTXa8inyChV+tXzJ7Fl2J6/iClAHb0zfFrgoTGv0TgIhy3Fta2cNC8n2lURiTmBzhDVTUFmKfgTcUVty8Br/PW1aGo6x8/IYPtBZfoUGY32jhD+9k6t8ScxZUTBn7U2Jub5datqCtDeGVLPn4gLyhucNZFmTtGwTxE3DLbA+0AuXFXA9oNN6vkTGYWqyDIPWuNPYsmIgj9jzG04PX29WGs/NuY1GgfdmT4V/ImMvbKGNgD1/Im45FDwN8Scv25Xrp9NSkIcJ8/XSBeRI1Xld4I/DfuUWDLSYZ+P9bicBFwIHBz76oyPotoWQGv8ibihrN4J/rTMg4g7fCMc9gnOmn9XrJ/ldpVEYlJVkzOSRcM+JZaMdNjnX3teN8bcCzzrSo3GQZGvldQEL1Mzht9xisiRKatvIzHOM6IDUxE5cr7mIB4DU1ITol0VkZhW2d3zp+BPYshoF+FaCByzpxKLaluZm5eKMSbaVRGJOWX17cyckqL2JeISX3OQnLREvB61MRE3VfsDZCTFkZIw0oFyIhPfSOf8NdN7zl8V8BVXajQOinwtrJ6VHe1qiMSk0vo2ZmqNPxHX1Ayzxp+IjI1Kf4DpmdqfSWwZ6bDPdLcrMl4CnSEqGtu5ZE1htKsiEnOstZTVt7F2jk6uiLjF1xzUsGqRcVDVFGCqhnxKjBnRsE9jzIXGmMwe17OMMR90r1ruKalrxVqYm6tMnyJjzd/eSXOwS5k+RVyk4E9kfFT5A0xXpk+JMSOd8/dta62/+4q1thH4tjtVcldxZJmH+XnK9Cky1srqncxohcr0KeKKcNhS26LgT8RtnaEwvpagkr1IzBlp8DfQ/Y7J2a9FtU7wp54/kbHXvcafFngXcUdjeyddYas5fyIuq2kOYq0yfUrsGWnwt8EY87/GmPnGmHnGmF8Ab7lZMbfs97UwLSOJ1MRjMnYVmdBKu9f407BPEVccWuBdPX8irqrSMg8So0Ya/H0G6ADuBx4A2oFPu1UpNxXXtqrXT8QlZfVtZKXEk5EUH+2qiMSk7uAvX8GfiKu6g7/pCv4kxow022cr8N8u12VcHKhr45zjp0W7GiIxqayhnZma7yfiGl+Lc0Cqnj8Rd1U1RXr+lPBFYsxIs30+Y4zJ6nE92xjz1Age915jzG5jzD5jzKDBozHmEmOMNcasHVm1R8ff3kl9awdzcnRwKuKGsvo2ZfoUcZGGfYqMjyp/O0nxHjKTNZJFYstIh33mRjJ8AmCtbQDyh3qAMcYL/AY4F1gKXG6MWTrA/dKBzwKvj7TSo1USSfYyR8M+RcZcOGypaGinUMleRFzjaw6SFO8hTfPWRVzVvcC7MSbaVREZUyMN/sLGmFndV4wxcwA7zGPWAfustUXW2g7gPuCCAe73PeAnQGCEdRm1kjpl+hRxS3VzgI5QWD1/Ii7qXuNPB6Qi7qpuCjA1Qz3sEntGGvx9HXjJGHOnMeZO4AXgq8M8pgAo63G9PHLbIcaYVcBMa+1jQz2RMeYGY8wGY8wGn883wir3V1zbijHo4FTEBaV1kUyfmvMn4hpfS1DLPIiMg+6eP5FYM6Lgz1r7JLAW2I2T8fOLOBk/hzLQaclDvYXGGA/wi8hzDff6t1hr11pr1+bl5Y2kygM6UNfG9IwkkuK9o34OERlYWYOzSdAyDyLu6e75ExH3hMM20vOnZC8Se0Y0acAYcz3wOaAQeBs4CXgVOGuIh5UDM3tcLwQO9rieDiwDno8MX5kGPGKMOd9au2Gkb+BIFNe2ar6fiEtK69swBgqydKZUxC2+5iDr5k6JdjVEYlp9WwedIatlHiQmjXTY5+eAE4ED1tp3AquA4cZfvgksNMbMNcYkAB8GHukutNb6rbW51to51to5wGuAa4EfOHP+FPyJuKO83ulZT4gb6WZFRI5ER1eYhrZO8tJ0QCriJi3wLrFspEdpAWttAMAYk2it3QUsHuoB1tou4EbgKWAn8IC1drsx5iZjzPlHU+nRaGzroLGtk7k5Cv5E3FDW0EahhnyKuKauVcs8iIyHSr/W+JPYNdJc0eWRdf7+BjxjjGmg9xDOAVlrHwce73Pbtwa575kjrMuolESSUajnT8QdpfVtnLZw9HNyRSaETRAAACAASURBVGRoWuNPZHx0L/CuYZ8Si0YU/FlrL4xc/I4x5l9AJvCka7VywaE1/rTAu8iYC3SGqG4KKtOniIsU/ImMjyp/O3EeQ44y60oMOuJVYq21L7hREbd1L/OgTIQiY6+isTvTp5K9iLhFwZ/I+Kj0B8hPT8Tr0XqaEnsmTWaGkrpWZmQma5kHEReU1jvDqrWGpoh7uoO/3LSEKNdEJLZVNwWU7EVi1iQK/tqYq/l+Iq4ojwR/6lkXcY+vJUhmcjyJcTqJKeKmSr+CP4ldkyf4q21ltub7ibiirKGdhDgPeZofIeIaLfAu4j5rLVX+ANMyNI1BYtOkCP4aWjvwt3eq50/EJaV1bczMTsaj+REirvE1B3WCRcRlzcEu2jpCyvQpMWtSBH/Fdd2ZPhX8ibihrKFNQz5FXFajnj8R13Uv8D5VwZ/EqEkR/B3oDv7U8yfiirL6NiV7EXGRtVbDPkXGQXfwp54/iVWTIvgrrm3DY5SGXsQN/rZOmgJdWuNPxEWtHSHaO0MK/kRc1h38TctQ8CexaVIEfyW1rczISlaGNBEXlDV0Z/rUyRURtxxa409z/kRcVdk97FPBn8SoyRH81bUq2YuIS0q1zIOI67TAu8j4qGoKkJuWQELcpDhElkko5n/Z1lqKa1uV7EXEJWUK/kRcp+BPZHxU+du1xp/EtJgP/hraOmkOdGmNPxGXlDW0kZkcT0ZSfLSrIhKzfM3OUDQFfyLuqvQHNN9PYlrMB3/FtU6mTw37FHFHaX27Mn2KuMzXEsTrMUxJSYh2VURiWnVTQD1/EtNiPvgrqdUyDyJuKq9vU7IXEZf5moPkpiXg8ZhoV0UkZgU6QzS0darnT2Ja7Ad/da3OMg9KQy8y5sJhS3lDu9qXiMu0xp+I+6qbIss8ZOqEpsSuSRD8tVGYnaKsTSIuqG4O0BEKK9mLiMt8LUEt8yDiskot8C6TQMxHRCW1rUr2IuKSsvp2QJk+Rdymnj8R91VpjT+ZBGI6+LPWUlKrNf5E3HJomYdsDZERcUs4bKlt6VDwJ+KyqkPDPhX8SeyK6eCvrrWD5mCX1vgTcUlpfRvGQIGCPxHXNLR1EApbDfsUcVmVP0B6UhxpiXHRroqIa2I6+DtQp2UeRNxU1tDGtIwkEuO80a6KSMzytXQv8K7eCBE3VfrblelTYl5MB3/Ftc6QNM35E3FHeX275vuJuMzX3B38qedPxE1VTUEN+ZSYF9PBX0ltK16P0cGpiEtK69u0zIOIyxT8iYyPKvX8ySQQ08FfcV0rhdnJxHtj+m2KREWgM0R1c0ALvIu4TMGfiPu6QmF8zUEt8yAxL6ajogN1rUr2IuKSisZ2rIVZ6lkXcZWvOUhyvJfUBM2tFXGLryVI2GqBd4l9MRv8Ocs8tDFH8/1EXHFomQcFfyKu8rU4a/wZY6JdFZGY1b3A+7RM9bBLbHM1+DPGvNcYs9sYs88Y898DlH/BGLPDGLPFGPNPY8zssXrt2pYOWoJdzFGmTxFXlDVEFnjXnD8RV2mBdxH3dS/wPi1DPX8S21wL/owxXuA3wLnAUuByY8zSPnfbBKy11q4AHgR+MlavXxJZ5kHBn4g7yurbSIjzkK+DUhFX+ZqDWuNPxGXdwZ/m/Emsc7Pnbx2wz1pbZK3tAO4DLuh5B2vtv6y1bZGrrwGFY/XiJbWRNf4050/EFWX1bRRmJ+PxaCiaiJu6h32KiHuqmgIkxHnISomPdlVEXOVm8FcAlPW4Xh65bTDXAU+M1YuX1DnLPBRkq/texA1lDVrmQcRtwa4QjW2dCv5EXFblDzA9M0lzayXmuRn8DdR67IB3NOYqYC3w00HKbzDGbDDGbPD5fCN68ZLaNmZqmQcR15TWtSnTp4jLals6AC3zIOK2Kn+AqVrjTyYBNyOjcmBmj+uFwMG+dzLGvAv4OnC+tTY40BNZa2+x1q611q7Ny8sb0YsX17Zqvp+IS/ztnTQFurTGn4jLDq3xpzl/Iq6qbGrXfD+ZFNwM/t4EFhpj5hpjEoAPA4/0vIMxZhXwe5zAr2asXthaqzX+RFx0aJkHDfsUcZUWeBdxn7WWan+QaQr+ZBJwLfiz1nYBNwJPATuBB6y1240xNxljzo/c7adAGvAXY8zbxphHBnm6I+JrCdLaEWKuev5EXKE1/kTGh4I/EffVt3bQEQozTcM+ZRKIc/PJrbWPA4/3ue1bPS6/y43XLal1Dkxna4F3EVeUNSj4ExkP3cFfTlpClGsiErsqtcyDTCIxmQ3l0DIP6vkTcUVpfRuZyfFkJisltoibfC0BslLiSYzzRrsqIjGruimywHum5rFL7IvJ4K+4rpU4j6EgS41YxA1l9e1K9iIyDrTAu4j7unv+NOxTJoOYDP4O1LUya0oKcVrmQcQVWuNPZHz4moPkZyj4E3FTlT+A12M0t1YmhZiMjopr2zTfT8Ql4bClvL5da/yJjANfi3r+RNxW1RQgPz0Rr0cLvEvsi7ng79AyD5rvJ+KKhrYOEuM9FCr4E3GVtdYZ9qneCBFXaYF3mUxczfYZDTXNQdq0zIOIa3LSEtn6nXMIhW20qyIS01qCXQQ6wwr+RFxW1RRgYX5atKshMi5iruevO9OnFngXcZeGx4i4S2v8iYwP9fzJZBJ7wV+dgj8RETn2HQr+0nRQKuKW5kAnLcEurfEnk0bMDfssrm0j3muYkTVII26rh9q9h69nzYKM6dDRBlVb+99/ylxIy4dgM1Tv6F+eswBScyDgh5pd/cvzFkFydv/X7Za/BJIyobUW6vb3L596PCSmQXM1NJT0L5++AuKToekgNJb1L5+xCuISnMc2HIBwJ4Qif+FOWPpB8Hih9DWo6fv+DKy91rlY8hLU7uld7E2AVVc5l/f/CxqKe5fHp8LKy5zLe56GpvLe5UmZsOxi5/Kuf0BLde/ylFxYer5zefvfoL2+d3n6dFh8rnN564MQbOpdnjkLFr7Lufz2vdDV3rt8ynyYd4ZzeeOfIdzVuzxvCcw+BcJh2Hg7/UxdDjNPhK4gvH13//IZq5y/yahuPxx4ufdnmjULFnR/H/dAV6D3Y3p+H2/dATbUu3ysvo9gC2x9oH954TqYtgzaG2D7w/3LZ7/Dac8tNbDrsf7l886EKfOctrjnyf7lC94NWTOdtrj/uf7li98H6dOgdh+UvNi//LgLnG1NzU4ofbV/+bKLnTZVuQUqNvQvX3m5s62oeAsqN/cvX/UR8MZB6etQs71PYY9tQfG/oa7PtqzXtuC5/tuqo90WpObBcec5l4fbFsQQX8swPX/BFtj3jPOb7WY8sOajzuXiF6FuX+/HeBNh1ZXO5X3/hMYD3Q8EbzwkZhze7pa/BYEG8MQ7Zcbr/Iamr3DKq7ZBR2vv509Mc/Zb4PzOOvu086RMZ78HUPS88x567pcyCw9vBzbdDaFg78fnLIS5pzmX37odbLh3ef5SmHUShEOw8Y7+n9m0lVC4BjrbYfO9/csL1sD0lRBogm0P9i+feRJMXers03f8rX/5nNMgd6Gzz979j/7l88+C7DngL4e9T/cvX/ge5zOoL4aif/UvX/IB55jEtwcOvNS/fOkHIWUKVG+Hstf7ly//ECSmw8G34eDG/uUrr4D4JCjfAFVb+pevvsY5Zoghh9f4GyL4O7jJ+evWq52NYpuYkAYrLnUu73kKmip6lydlwbKLnMs7H4PWmt7lvbaJD/feBgCkz4DF73Uub/kLdDT3Lj/q/fFxMPtksNY5fvLGR7YTcc57z1kAeYsh1BXZH/UZKZRZCJkFzvZhoP1R9mxnfzjosfk8SMsb/ti8vRF8u/uXD3psbp1tytRlkJQBjaVOWwl1OMczoU7n/9ILIu1sB5S91v/5l13iPL5ys7PP7at7f1z+FlQN8P5dbmcxF/yV1LYyc6BlHkJd8OYf4F8/hKD/8O3n/A+c/Gnwl8Gf3tP/Cc/7Fay5xgl8Biq/5E/OQcvBt+HP5/cvv+IBWHSOc7B23xX9yz/6OMw51dkJP3xD//JPvOjsiHY9Cv/4Yv/yz2yEnPmw9S/wzLf6l39pr7Oj2HQXvPjT/uVfOxcSUpwDqtdv7l1mPIcP+DbfB5vu7F2emHF447bxjv4HzOkzDh/wvXGLc5DSU+6iwwd8r/y6/wHtjNWHD0L+/bP+G4C5px8+4Hvu+/2Dz8XvOxz8PfNNaPX1Ll9+6eGN2+P/1T84XPsxJ9jAwmP/ST+nfDYSbAQGLn/n1ydX8BdscQ78rIU/X+C0qZ4Wv//wzubpb0Jbbe/yFZcd/j6e+K/+O6O11w39fZz6Oef76Gwf+vsINA5cfs4PneCvuXrg8vN/7ewwGksHLr/kNmeHVLtn4PIrH3SCv6ptA5fnLXF2dhUbBi4vWOvszEpegse/1L983pnOgfX+f8Kz3+lfvuQ8Z2ez+4mBtwUrL3d23NsfHnpbsOU+Z3vSU2Lm4W3BW3f0PyjOKOixLfg97Hu2d3nu4qG3BQVrDh/ovPgzqB5iWxBDBhz2GQ6DMc7f09+At27r/SBP/OGD0rfvhc339C5Pzj4c/L11G+x8tHd51qzD293nbnICtJ7yl8KnIt/PY5+H8jd7lxeug+sj2/qHPgG+nb3L558FV0f2FX+/sf924rjzDm8Hnvqa0157OuHKw8HfP77kBI49rftEJPjrGrgdveMLTvDX0TZw+dnfcva57fUDl5/7Uyf4azo4cPkHb3aCv4aSgcsvvdMJ/ny7Bi6/6iHnwLhy88Dl/5+9+w6Po7j/OP4e1VO1umxLtuUi994BA8Y0Q+iEHiCVNCD5kRBIQighBVIgQEiABEIIpocASTA9gG3AYBtww0XucpNVrF7v5vfHruzz6SSdjE/183qee3S3s2XutLO735nZ2ezxzjm98MPg6YNmOxelWxbBKze0TB9xkhP8FbwBb93eMn3sOU7wt+4/sPjulumTv9Trgr92n/H39p3w9q8OnRYRdbCcffoUfBJwTPT4HxMfhbUvHpqenHsw+Fv6oHPc9pc5+mDw9969LQP5nOkBx8TVh6YPm3sw+Hvrdr9KHtfoM/zOxzdBTcmh6RMv9rs+ur5lJcyMrzvBn7cB/n0tLRzzfTj5NqdS/pFTW6bPuwmOu94JaoNdW8+/E2Z/y8l3sPSz73d+36J1wdMveBTGnetUcPzj3Jbpl/3TuT7cuhieubxl+ldfdY4jWxbBi99pmZ47wylnWxfDwutbpg+f5wR/BW/Amz9vmT7mbOd8vO4/sPiulumTLwtrOTPW9qxBG6ZPn26XLQtSq+2a/4d3yUmJ4+Evzzg0oake/jTbOejO+pZTcME5SKcMdi5cg9WSZY52aifqyp2asEDZ4yEp26k98K8VajZgEiRkQNW+4LVoOVOdk3HF7iAtbzg7mCfZqSUMVnsx+CgneCvb1rKGFyBvDkTFOiei8kKnRiYi6mAtTUa+s4PVVUBjTcvlk/o7f2v3t7wYxzjfHZxap6aAg4OJcE5S4Pw+3oZD0yOinN8GoLqk5Uk8Itq52AWnZTSwZS4yxil84Py+gTVTh6QXtawhjop1fnuAyj20EB3nHMCtbdkSARAd7/xvfL6WtXIAMQnOSTYExpjl1trpIc3cCdorZwdUFzsX+qufd/a//1vrBBBbF0NifycYbNbu/8MDcSnO+3D+P3zelhUB4KTFJDg1e4EnQnAqO2LioamhZcsTOHmLjnPKQWAtLDg1udEep6Yz8IIWIC7NaaVvqGnZig0Qn+6U24Zqp7azRXqG89vXV0FDVcv0hEynrNdXtmytAUjMdgKKunIngA7UU44Fbehu5QzaLmu/eWUdD727mQ2/OI2I4vVOS9WqZ+Gix51zx74Nzr6cPvzQBQ/nf2V9zr4PTq07OOuvLTvYMmd9TovF4FlOeuEyZ3/x5+kHue5PvH1py30xPu1gpdie1c46/VsNYpIO/q8r9wIB1yhhP04kOsctb1PLCioI/3EiLtU5NzXWtvxtoROOE1kQEdH6NUHzcaId3a2stVXOnlm2gx89t5J3rz+Bwenxzjnis5eg/0SnbO36xGlFH3eu89s26ynHxMO6PupAOavYebBFzNvofJeETOfauakBti5quXzaMKdnXWMtbHuvZXp71+ZZYyB5oPPbB2tZa/fafLLz+1UVtWxYiIh00uNSnOUrdgZcO0c5368Hl7NeFfxZaxl786tcMnMwN5851ukGufhuOOV252Bdtc8pTCH8oCKdqSedKAHnou7d3zjdfa3XabmZ8EWnFT1G99tK99Tdyhm0XdZ+8vQHZGx4muuyVsDuT5xul/knw9wb+1avAulxultZa6ucVdc3sb20hvy0aKJWPw1L7oHSzU7vnlOCtI6KdBOHW856VbfPvRX11DZ6GZ4a6XRrevf3gIVx5zjdghIzuzqLIr1DU63TvfGYa52+7dnjVKkicoTtq2rkp76ngHyYf4dT1nQeEzmiEmKjGLP9SVhwF1TtcVp9LnzM6Rop0gv1quBvy74qToxYznkf3ABVO2DMWXDqL52mYxE5cvKOg++tVMAnEkbfmz+RDeVvM2XsqK7OikjvVrzRGYjovAdh6PE6t0mv1quCv20l1VwV9V+ioj1w+Qsw/ISuzpJI7xTR654SI9LtjM/pBzn9ujobIr3f/Duce7RE+oBetadPy0vjw+PuY/rxkyE6pquzIyIiIiLdnQI/6UN61d6en51EfvbMrs6GiIiIiIhIt9Orgj+R7qCxsZHCwkLq6gKHfgaPx0Nubi7R0dFBlhSRUKmciXQOlTWR8OvMcqbgT+QIKywsJCkpiby8PIzfTePWWkpKSigsLGTo0KFdmEORnk/lTKRzqKyJhF9nljON2iByhNXV1ZGenn5I4QUwxpCenh60VkdEOkblTKRzqKyJhF9nljMFfyJhEFh425suIh2ncibSOVTWRMKvs8qZgj8REREREZE+QMGfiIiIiIhIH6DgTyQMrLUdmi4iHadyJtI5VNZEwq+zypmCP5EjzOPxUFJS0qKwNo/Y5PF4uihnIr2HyplI51BZEwm/zixnetSDyBGWm5tLYWEh+/bta5HW/KwWEfl8VM5EOofKmkj4dWY5U/AncoRFR0frmUciYaZyJtI5VNZEwq8zy1lYu30aY+YbY9YbYwqMMTcGSY81xjztpi81xuSFMz8iIiIiIiJ9VdiCP2NMJHA/cBowFrjEGDM2YLavAWXW2hHA3cCd4cqPiIiIiIhIXxbOlr+ZQIG1drO1tgF4Cjg7YJ6zgb+7758DTjR6YqiIiIiIiMgRF857/nKAHX6fC4FZrc1jrW0yxpQD6UCx/0zGmKuAq9yPVcaY9WHJsUjXGdLVGfC3fPnyYmPMtq7Oh8gR1q3KGaisSa/Vrcqaypn0UodVzsIZ/AVrwQt8UEUo82CtfQh46EhkSkTaZ63N7Oo8iPQFKmsi4adyJnJQOLt9FgKD/D7nArtam8cYEwX0A0rDmCcREREREZE+KZzB30dAvjFmqDEmBrgYeClgnpeAK933XwTeskf6MfYiIiIiIiISvm6f7j18VwOvApHAI9baNcaYnwPLrLUvAQ8D/zDGFOC0+F0crvyIiIiIiIj0ZUYNbSIiIiIiIr1fWB/yLiIiIiIiIt2Dgj8REREREZE+QMGfiIiIiIhIH6DgT0REREREpA9Q8CciIiIiItIHKPgTERERERHpAxT8iYiIiIiI9AEK/kRERERERPoABX8iIiIiIiJ9gII/ERERERGRPkDBn4iIiIiISB+g4E9ERERERKQPUPAnIiIiIiLSByj4ExERERER6QMU/ImIiIiIiPQBvTb4M8b82BjzcsC0ja1MuzjI8nnGmP8ZY2qMMeuMMSe1sa1YY8wjxpgKY8weY8x1Aeknuuuocdc5pAPLxhtj/mSMKTbGlBtj3vVL+74xZrO77C5jzN3GmKhQvoO73bvd5crcbUT7pb9tjKkzxlS5r/V+aT/xm15ljKk1xviMMRlu+m+MMTvcfG0zxvy0ld/tSmOMNcZ8PUhajJvnwlCXdb/TA8aYvcaYUmPMv40xOX7pacaYfxljqt18XeqXNsAY85L7e1hjTF7A9nKMMS+66y00xnzLLy3DGLPEGFNijNlvjHnfGHNMsHz3dL2hXBljxhpjlrn7fZkx5g1jzNgg2w+6DxpjHjLGrHf3+S+3kf+33H3Jv0xudctLc9l5rQPLTjbGLHKPA4XGmJsDlrnQGPOZMabSGLPWGHOOX9oDAWW23hhT6Zf+uDFmt/t7bQgsk+2s+2L39yg3xhQZY/5ujEnuwLrbOsYZY8ydbtkqMc6xxXT0f9ET9JKyFWOMec7dz60xZm6Q7bZ6jPabL98455/H/aa1d95JM8Y87e5HxcaYBf77od96jnfz9ouAfLV1PqwKeHmNMff5pX/dGFPgpr1ijBnol7YwYNkGY8yqEPN1pTFmuftbF7r7f5Rfnh82zrms0hjzsTHmNL9lZxtjXnd/533GmGeNMQP80lOMU1aL3NetAflpc38yxgwzxvzH3XaxMeY3gd9Juoe+cGyRDrLW9soXcAxQDkS6n/sDW4E9AdMsMDDI8u8DdwFxwPnAfiCzlW39GlgEpAJj3G3Md9My3HxcAHiA3wIfhLKsm/448BSQCUQC0/zShgMp7vs04C3gulC+A3CLu900d90fALf5Lfs28PUQf+tbgbf8Po8CEtz3OcAa4LyAZVKBdcDqYNsBfgq8CxQGSQu6LPAj4FMg2/2t/wE875f+JPA0kAjMcf8v49y0bOA7wFHuPpEXsM3/AX8AooFJQClwgpvmcb9zBGCAc9z0qK4uBypXQZdNAfLc/1UkcC2wMtR9EPgucCKwDPhyK3m/zF3W+u8H7m91Uju/cWvLrgV+6eZ5OLAbOMuvnDUAp7nf6wtADZDVyjYeBR7x+zwOiHXfj3Z/r2mhrBsYBGS47xOBBcC9oazbndbWMe6bwHog183HWuBbHflf9JQXvaNsxQDfxzm+7gbmBmy3zWO033yvudt4vI3f61YOPe/8yV0uGegHvAHcFbBMNPAJzvnuF37T2zwfBqwjAagCjnM/Hw8Uuft5DPBn4J028v02cHOI+fo2cKy73hxgOXCjXz5uxTmWRQBnAJW45y6c8nqB+3vEA48Ar/it+2/As25aHrAJ+Eoo+5Obn03AdW4+PMDEri5DerW6z/X6Y4teHdwnujoDYftizo5Sw8ELmAvdg907AdMKgiw7EqgHkvymLcLvoiNg/p3AKX6fbweect9fBbznl5YA1AKjQ1h2FFABJIfwfdNxTnZ/CuU74FwsXeCXdimww+/z24QQ/OFcDG4CrmwlPQdYBfwoYPoDOMFWi+0AQ4HPcE5ewYK/oMvinHR/4/f5C8B6v9+9ARjpl/4P4I6AdUcREPzhXNBa/A52wEPAP4LkLQI4050/6IV3T371hnIV5P/9XaCmI/ugO89iggQcOBeeG4DZdDD4a2fZGmCs3+dngR+772cBRQHr2gccFWQbCTgXice3kodROCfXCw9j3YnAY8DLIa67zWMc8B5wld/nr+F3sdDe/6InvXph2SqkZfDX6jHab9rFwDM4gU3Q4I8g5x1gIfAdv8/fBV4NWO5G4Dc4lR/+QVab58OAdVwJbAaM+/l3wP1+6QNxyu7wIMvmAV5gaCj5CrL8dcC/20hfCZzfStpUoNLvczEww+/zT4BFoexP7j6yqKvLjF6hvfrCsUWvjr16bbdPa20DsBQ4zp10HM4Ouzhg2rsAbveFG93p44DN1trKg2vkU3f6IYwxqTgH+09bmXecf5q1thrnpDUuhGVnAduA29xuFauMMecHbP9SY0wFzoF8EvBgiN/BuC/8PucaY/r5Tfu1u90lbTSxH4tTi/vPgHzdaIypwimkCcATfmkzgek4QVww9+GciGoDE9pZ9mHgGGPMQGNMPE4LykI3bSTgtdZu8Js/6P80CBPwt/n9+IC8rQTqgJeAv1pri0JYd4/SS8pV8zb24/y/7gN+FZCFVvfBEPwK5yJ3TyvpC9xuWK8ZYyZ1YNk/AFcYY6KNMaNwWqnfcNOWAZ8ZY84yxkQap1tmPc7FYKDzcYK3d/0nul3danBa1XcDzV2C2l23MWaOMaYcJ6g8381rKOtu7xh3yP+Z0Mtsj9ObylYb2jpGY5xumj8HftDOeoKdd+4HzjDGpLr5PD9g3UOAr7rrDxTK+bDZlcBj1r0KbWVZCDg/uK7ACZq2hJivQMfh9KRp+QWMycY5zwVNb2XZ1s5p7e1Ps4GtxunSWmyc20QmhJB/6QJ95NgiHdBrgz/XOxzcsY/F2dkXBUx7B8Bae4a19g53eiJO07S/ciApyDYS/dKDzdvWutpbNhfnYFyOUyiuBv5ujBnTPLO19glrbTLOQf8BYG+I32Eh8D1jTKYxpj9O1zdwuoAA3AAMw2m5ewj4tzFmeJDvfyXwnLW2yn+i+1sm4dQ2/qM5L8aYSJzuOddYa32BKzPGnIvT2vGvIGltLovTYrIdp/aoAqfbQPMJtSP/00O4B70lwM+MMR5jzFScC4v4gPkm4nSxuRTnoNpb9fRyhZu3FJyWtquBj5unt7UPtscYMx2ni819rcxyGU7t/xCcrsSvGmNSQlz2P8AXcQLSdcDD1tqP3O/ixWlxewInMHsC+KZ7cg0UePGKu47v4PxGxwLPu+sJad3W2sXW2n44x6zf4rRwtrtu2j/GBf6fy4FEY4z/RWtv0ivKVhvaOkaDU9P/sLV2RzvrCXbeWYHTwlHivrw454tm9wI/CzxXudo7HwJgjBmM083z736TXwYuNMZMNMbEATfjtPwdsqzrCpzWPX9t5ct/21/Bqfj8XZC0aJzu1n+31q4Lkj7Rzdf1fpNfAW40xiQZY0bgBKDNeW5vf8rFaaG9F6fc/hd40RgT09Z3kC7V248t0gG9Pfh7F5jj1ihkWms34nQjOtqdNp6A2m9XFc5FvL9knFrtYPM2pwebt611yoaTkQAAIABJREFUtbdsLdCI0w2kwVr7Ds4F4ymBmXC/2xoOnuza+w6/xLng/QTnN3nB3VaRu76l1tpKa229tfbvOMHP6f4rc090F3DoidA/T9Za+7H7PW5zJ38H5/6q9wPnN8Yk4HR9uSbY+tpa1vVnnH7k6Titjc9zsOa3I//TYC7D6Qq4w93OApxWzUNYa+ustU/inFQDW3V6i55erg5wA5gHgMeMMVkh7IOtMsZE4JS/71lrm4LNY61dYq2ttdbWWGt/jXPvxLHtLWuMScO5WPs5zj4+CDjVGPMdN/0kN99zcS6Ajwf+aoyZHLCeQW7aY63kz2utXYxzcfftjqzbXX6nm8+nQlk37R/jAv/PyUBVYODai/SastWKVo/R7v50EnB3Wyto47zzLE5wmeTmaRPO/aQYY87E6bb2dCurbfN86OcKYLF/y5219k2cewb/idOKvRXn9wgcKGoOzn1Vz/lNay9fzfOdA9wBnGatLQ5Ii8CpYG3AqTwJXHYEbnBrrV3kl3QtTvnbCLyIc098c57b259qcX6HhW6r0u9w/qdjkO6qtx9bpAN6e/D3Pk7N/lU4wQvW2gpglzttl/9B3M8aYJgxxr/GYRJBulNYa8twujFNamXeNf5p7sXlcGBNCMsG67LVlih33e1+B/cC9GprbY61dhhOTelyt5Y/GMuhXUQAzsMZ2OTtDuTrROBc44zktAc4Gvi9MeaPQD5Oq8giN+15YIA7b147yzZ/v0ettaXW2nqcFpSZxhkNbgMQZYzJD/Z7tMdau82tDcu01s7COdF92MYi0Tgtp71RTy9XgSJwarxzaH8fbEsyTs380+6yH7nTC40xx7ayTHO5am/ZYTjdlh+z1jZZawtxAqzmCpnJwLvW2mXWWp/bIrgU52La3xU491xsbue7+JfZUNcdbNn20ts7xh3yf6YDZbaH6m1lK1Bbx+i5OGVvu1sGfgicb4xZEbCO1s47k4AHrbXVbivaAxwsHycC0/3OHRcB3zfGvOj+JqGeD68gSGWntfZ+a22+tTYLJwiMwhmQzN+VOIPb+LfwtZkvAGPMfOAvwJnW2kNGCXVbwB/G6QJ7vrW2MSB9CE7X8Nuttf8IyHOptfYya21/a+04nONg8zmtvf1pJc6xS3qO3n5skY6w3eDGw3C+cGo29gLX+k27z522oI3lPsCpzfIA59L26EZ34DSXp+KMZrebgyMUZeI0XZ/vrutODh3dqK1lo4EC4Gc4J5NjcGpBmm+O/ToHR9wbi1NI7grlO+Bc6A7EufCcjdOidYqblgKc6i4XhdPqVQ2MCvjerwE/D5gWgTNCX6q77pnud7rWb939/V7v4dzE3s/dln/aeTgHpv44owC2uqy77r/hnHj7ub/dT4Cdfnl7Cqd2M4GDo1+N80v3uGkWZyAKj1/aGJwa5RjgSzj3WDb/lrNxRqCKwRkN6wb3/9Ri1Kze8qJnl6uTgSnuPpWM03Vpl9/+3uo+6C4f4867BPiG+755pFf/ZWe4+1KOu8xgd79rXv56nHvv0kNYNtn9rS51t9Uf52T+SzdPx7v75GT38xScC9hTAn7T9cBXA6Zl4XThSnR/k1NxyvvZoawb5/gw2P0OQ9zf/fkQ193eMe5bOAPvNB+v1nDoaJ9B/xddXT76atly02Pd5QpxWnA9HBwcpdVjNE4FjH8Z+B1OK1lmQN5bnHfc6f9zf6c49/UnYImblhSw7qdxWhjT3PRWz4d+6z/a3XeTAqZ7cFpNjFsO3gZ+FTBPnPv/mBcwvb18zcMpa8e18n98wP2/JwZJy8Fp/by+lWWH4xx7InEGtirm0PNhW9cPo3AGEDnJXf7/3G3FdHX50av1F7342KJXB/eFrs5A2L+gM3SsBab6TbvQnfZNv2kLgZ/4fc5zD+K1OBdMJ/mlXYZTU9H8ORZnGOUKtxBdF5CHk3Du0al115nXgWXH4VzkVeMMc36uX9rf3GWqcbqa/JZDA5a2vsNx7jI1btplfmmZOC0PlW4h/wA4OSBfOUATMCJgegROt69SnGb8DTgn+KAFlDZGFcWpCQ460mKwZXFOZAtwuursx7nvbqZfehpOd55qnPtOLg1Ynw18+aV9H+dCvdpd73S/tONxbkyudL/3O7Rysu4tL3pwucLpMrbO3T/34dyzE3SY8mD7oLutwH1lbpBl8/AbsROnLK9096ES4E3//aitZd1p83DKZTnOgDB/AeL90q/GCaQqcUYj/EHAOo8i+MVrprvP7nd/r1XANwLmaXXdOF3mCt11F+LcI5zegXW3dYwzOF1OS93Xb/A7loT6v+hJL3pw2XLTtwb5n+S5aW0eowPWcysBo33SynnHTRsK/BunbJXinIfyW1n3oxw62mer50O/eR4k+AjPKRws13vc/19kwDyX4HQJbfNCNUi+/ud+3yq/10I3bYj729YFpF/mpt/ipvunVQXsU7vc7/wJcGpAXlrdn9z083COCRXufOPa+m56df2LXnxs0atjr+baOBEREREREenFevs9fyIiIiIiIkIYgz9jzCPGmCJjTOBNz83pxhhzrzGmwBiz0h0+X0RERERERMIgnC1/jwLz20g/DWdkvXyckYb+HMa8iIiIiIiI9GlhC/6ste/i3HTdmrNxHzRsrf0ASDHGDAhXfkRERERERPqyrrznLwdnOOVmhe40EREREREROcKiunDbgQ8Mh1YeGmqMuQqnaygJCQnTRo8eHc58iXS65cuXF1trM7s6H80yMjJsXl5eV2dD5IjqbuUMVNakd+puZU3lTHqjwy1nXRn8FQKD/D7n4jxzpgVr7UM4z45i+vTpdtmyZeHPnUgnMsZs6+o8+MvLy0PlTHqb7lbOQGVNeqfuVtZUzqQ3Otxy1pXdPl8CrnBH/ZwNlFtrd3dhfkRERERERHqtsLX8GWOeBOYCGcaYQuAWIBrAWvsA8DJwOlAA1ABfCVdeRERERERE+rqwBX/W2kvaSbfAd8O1fRERERERETmoK7t9ioiIiIiISCdR8CciIiIiItIHKPgTERERERHpAxT8iYiIiIiI9AEK/kRERERERPoABX8iIiIiIiJ9gII/ERERERGRPkDBn4iIiIiISB+g4E9ERERERKQPUPAnIiIiIiLSByj4ExERERER6QMU/ImIiIiIiPQBCv5ERERERET6AAV/IiIiIiIifYCCPxERERERkT5AwZ+IiIiIiEgfoOBPRERERESkD1DwJyIiIiIi0gco+BMREREREekDFPyJiIiIiIj0AQr+RERERERE+gAFfyIiIiIiIn2Agj8REREREZE+QMGfiIiIiIhIH6DgT0REREREpA9Q8CciIiIiItIHKPgTERERERHpA8Ia/Blj5htj1htjCowxNwZJH2yM+Z8x5mNjzEpjzOnhzI9IV7HWdnUWRERERKSPC1vwZ4yJBO4HTgPGApcYY8YGzHYT8Iy1dgpwMfCncOVHpLPVNXp5bnkh59y/hKc+2tHV2RERERGRPi4qjOueCRRYazcDGGOeAs4G1vrNY4Fk930/YFcY8yPSKQqKqnhi6XaeW76DiromhmcmkBgbzqImIiIiItK+cF6R5gD+zR2FwKyAeW4FXjPGXAMkACcFW5Ex5irgKoDBgwcf8YyKfF4NTT5eW7uHBR9s5/3NJURHGk4d158vzR7CrKFpGGO6OosiIiIi0seFM/gLdrUbeOPTJcCj1trfG2OOAv5hjBlvrfUdspC1DwEPAUyfPl03T0m3UVRZx6NLtvLMsh0UVzWQmxrHj+aP4oJpg8hMiu3q7ImIiIiIHBDO4K8QGOT3OZeW3Tq/BswHsNa+b4zxABlAURjzJXJE1DV6ufQvS9m8r4p5o7O5bPZgjsvPJDJCrXwiIiIi0v2EM/j7CMg3xgwFduIM6HJpwDzbgROBR40xYwAPsC+MeRI5Yu57ayMFRVX87SszOGFUVldnR0RERESkTWEb7dNa2wRcDbwKfIYzqucaY8zPjTFnubP9APiGMeZT4Engy1Zj4ksPsHpnOQ+8s5kvTstV4CciIiIiPUJYhyC01r4MvBww7Wa/92uBY8KZB5EjrdHr4/rnVpKWEMPPvhD49BIRERERke5J48+LdNADb2/is90VPHj5NPrFR3d1dkREREREQhK2bp8ivdGGvZXc91YBX5g4gFPH9e/q7IiIiIiIhEzBn0iIvD7L9c+tJCE2ktvOGtfV2RERERER6RB1+xQJ0SOLt/Dpjv3cc/FkMhL1DD8RERER6VnU8icSgi3F1fzutfWcNCaLsyYN7OrsiIiIiIh0mII/kXb4fJYb/rmSmKgIfnHOBIzRQ9xFREREpOdRt0/pNOv3VPKvj3fSPzmWc6fm0i+uZ4yUuWDpNj7cUspvzp9I/36ers6OiIiIiMhhUfAnYVXf5GXhqj0sWLqNj7aWERlh8Posd76ynrMmDeSy2YOZmJvS1dlsVWFZDXcsXMex+RlcMD23q7MjIiIiInLYFPxJSDbvq+LeNzcyOC2eMQOSGTMgmcFp8UREBO8CubW4mic/3M6zywsprW5gSHo8Pzl9NF+cNoidZbU88eE2Xvh4F08v28GEnH5cNmswZ00eSHxM8F2ytsHLhr2VfLa7gs92V9Dos1w+ewhjBiSH7Ttba/nx86uwwK/OVXdPEREREenZFPxJu+oavXxnwQo276umyefDZ53p8TGRjOqfdCAYHDsgiX2V9SxYup1FG4uJjDCcPCabL80ewtHD0w8EimkJMfw6dyI/Pn0ML368k8c/2M6Nz6/il//9jHOn5nDOlBz21zTw2e5K1rrB3tbi6gPbTYiJxGfhiaXbOWFUJt+eO4IZeamfOziz1rK1pIYV28pYsb2M5dvKWLenktvOGsegtPjPtW4RERERka6m4E/adecr61i3p5KHr5zO0cMz2LC3knV7Kg4EZ//+dBdPLN1+YP4B/Txcd/JILpoxiOzk1u+RS/ZEc/lReXxp9hCWbytjwdLtPPXhDh57f9uBeXJT4xgzIJkzJg5k7AAn0ByUGk9lXRP/+GArjyzZyoUPvs+0Ial8+/jhzBud1WprZKCahiZWFpazfFsZH28vY8X2/ZRWNwCQFBvF5MEpnD81l8tnDznMX05Ewqm8tpFtJdVsKa5mW0kNANeemN/FuRIREem+FPxJm/63roi/LdnKl4/O48Qx2QBMGpTCpEEH79Oz1rJzfy2f7a4kOtIwZ0QGUZGhDyRrjGF6XhrT89L42RljWbRxHwP6xTF6QBLJnuCDwvSLj+bqefl8bc4wnl2+gwff2czXH1vGyOxEvnX8cM6cNJBoNw9V9U1sKqpiY1EVBUVVFBRVsrGoiu2lNVi3NXFYZgLzRmcxdXAq04akMiIrkcgQg0gRCa+GJh+vr91LQVGVE+yVOMFec2VNs3EDkxX8iYiItEHBn7SqqKKOHz77KaP7J3HjaaNbnc8YQ25qPLmpn79rZFpCDGdPzgl5/riYSK44Ko9LZg7mvyt38+e3N3HdM5/y+9c2MDwrkU1FVezcX3tg/uhIw7CMRMbn9OOcyTlMGtSPKYNSSU2I+dx5F5Ejr77Jy7cfX8Fb64oAGNjPw5D0BE4d15+89HiGpCcwNCOBwWnxxMVEdnFuRUREujcFfxKUz2f5wbOfUt3QxFOXzMYT3b0vqqIjIzhnSg5nTx7I/9YX8ddFWyipqmfm0DRGZCUyIiuR/KxEBqfFd6hVUkS6TqPXx9VPfMxb64q47axxXDRjULc/FomIiHRnCv4kqL8u3syijcX88tzx5GcndXV2QmaMYd7obOaNzu7qrIjI59Do9XHtkx/z+tq9/PzscVxxVF5XZ0lERKTHUxNIN1bf5OXlVbupbfB26nZXFZbz21fXM39cfy6dObhTty0i0uT18f2nP2Hh6j3cfMZYBX4iIiJHiFr+uqlVheX84NlP2LC3igum5fLbCyZ1ynar65u49qmPyUiM5Y7z9Ww7EelcXrfL+X9X7uanp4/hq3OGdnWWREREeg21/HUzDU0+7nptPef8aQnltY2cMXEAzy4vZOGq3Z2y/VteWsPWkmruvmgyKfEaBEVEOo/XZ7n+uU958ZNd/Gj+KL5x3LCuzpKIiEivopa/bmTNrnJ+8MynrNtTyflTc7n5jLHEx0ayvbSGH/9rFVOHpLb53LzP66VPd/Hc8kKumTeC2cPSw7YdEZFAPp/lx8+v5PkVO7nu5JF8Z+6Irs6SiIhIr6OWv26g0evjnjc2cvYfl1BS3cBfr5jO7y+cRL/4aKIjI7j7osnUNXr54bOf4vPZsORhR2kNP31+FVMHp/A9PSdLRDqRz2f56QureWZZIdeemK9n9YmIiISJWv7C5IPNJbz4yS4G9vOQkxpHbmo8OalxZCfFHvKogXV7KvjBM5+yZlcF50weyK1njWvR3XJ4ZiI3fWEsN72wmsfe38qXjzn8e2AavT72Vdazt6LOfTnv3/zMeYbWPRdP0aMQROSI+WhrKcu3lbU5z5pdFfz70118Z+5w/u8kBX4iIiLhouAvDOoavVz39Cfsq6qn0XtoS11khGFAPw85KXFkJMby2to99IuL5oEvTWP++P6trvOyWYN5a10Rv164jmNGZIT8+IWGJh93v7GBd9bvo6iyjpLqBmxA42FkhKF/soffXziJQWmf/0HtIiLWWh5evIVfvvxZi2NOIGPg23OHc/2pozTIlIiISBgp+AuDvy7azK7yOp78xmymDE5h5/5adpbVUlhWy879NQfef7JjP1+YMICbzxxHWkLbg6sYY7jz/InM/8O7fO+pT3jhu8cQE9V2C93u8lq+s2AFH2/fz5wRGUwalEJ2cizZyR6yk2PJSvKQnewhPSGGiAhdcInIkdHQ5ONnL6zm6WU7OH1Cf3517gRio1p/OLsx6OHtIiIinUDB3xFWVFnHn97exCljszlquDNoyvDMRIZnJn7udWcmxXLH+RP5xmPLuOv1Ddx42uhW511SUMw1T35MfaOX+y+dyhcmDvjc2xcRaU9pdQPfenw5H24p5dp5I/j+SSNVuSQiItJNKPg7wn7/6gYavT5+fPqYsKz/5LHZXDJzEA++u4kTRmUyK2BUTp/P8ud3NvH719YzPDORP39pGiOyPn/gKSLSno17K/na35exp6KOey6ezNmTc7o6SyLiKqpwbv1I8kSRHBdNYkyUKmZE+iAFf0fQ2l0VPLN8B189ZihDMxLCtp2bvjCW9zeVcN0zn7Lw+8eS7IkGoLymkeue+YQ31xVx1qSB/Pq8CSTE6l8sIuH3v/VFXPvEx3hiInn6qtlMGZza1VkS6dMKy2r4cEspSzeX8uHWUrYUVx+SbgwkxkaR7Ik+EBAme6LJSIwhK9lDf/cWkexkD1nJsaQnxBKpYFGkxwtrZGCMmQ/cA0QCf7XW3hFknguBWwELfGqtvTSceQoXay2/+O9a+sVFc+288I5WlxAbxd0XTeaLD7zPrS+u4a6LJrN6ZznfXrCcPeV13HbWOK44aogGThCRsLPW8siSrfzyv2sZ3T+Zv145nYEpcV2dLZE+Z2txNR9sLnECvi2l7NxfC0C/uGhm5KVx6czB5KTGUVXXREVdIxW1jVS47yvrmqiobaSwrIZPduynpLo+6OBwmYmxZCfHcucXJzK6f3IXfEsR+bzCFvwZYyKB+4GTgULgI2PMS9batX7z5AM/Bo6x1pYZY7LClZ9we/OzIt7bVMKtZ46lX3x02Lc3ZXAq18wbwR/e2EhMVATPf7yTtPgYnrrqKKYNUY27iHx+Xp+loclHo89Hk9fS5PXR4HXf+3w0ei2Pvb+VJz/cwfxx/bnroknEx6i3gUhne/yDbdz0wmoA0hNimDUsjW8cO5RZw9IZlZ3U4e6djV4fxVX1Bx4HVeT3aKi9lfUkqJyL9FghlV5jzD+BR4CF1lpfiOueCRRYaze763gKOBtY6zfPN4D7rbVlANbaolAz3p00NPn41cufMSwzgctmD+m07V59wgjeXr+Ppz7awTEj0rn34imkJ8Z22vZFpHdq8vr4y6It3PvmRmobve3Of/UJI7juZA3sItIV9lXWc+fCdRw1LJ3bzxnH8MzEz93zJzoyggH94hjQT634Ir1NqFU3fwa+AtxrjHkWeNRau66dZXKAHX6fC4FZAfOMBDDGLMHpGnqrtfaVwBUZY64CrgIYPHhwiFnuPAuWbmNzcTUPXzmd6E58QHpUZAQPXT6NxQXFnD05R33xRbrQ3oo6Fm8sJjc1jhFZiWGriLHWsn5vJZHGkJoQQ2p8zBEt+2t3VXDDP1eyamc5J43JYtqQNKIjDVERhqjICKIjDdGREc77CMPAlDgmDUo5YtsXkY6585V11DV5+cW544/IyOIi0ruFFPxZa98A3jDG9AMuAV43xuwA/gI8bq1tDLJYsKuRwEf9RgH5wFwgF1hkjBlvrd0fsP2HgIcApk+f3s7jgjvX/poG/vDGRuaMyGDe6M7vtZqV7OG8qbmdvl0RcTQ0+fjbEqeVrLrhYCtZWkIMI7ISyc9KdP8mkZ+dSFZS7Oeqlb/vrQLuen3Dgc/GQEpcNGkJMaQnxJKWEENaYgzDMhI4Y+JA+vfzhLTe+iYv979VwJ/e3kRKfDT3XzqV0yf0173DIt3Yiu1lPLe8kG8eP0yBn4iEJORO28aYdOBLwOXAx8ACYA5wJU7wFqgQGOT3ORfYFWSeD9zgcYsxZj1OMPhRqPnqave+WUBlXSM//cIYXSSJ9DHvbNjHbf9ew+Z91Zw0Jotr5uWzv7aRjXsr2bSvio17q/jPyt2U1x6sH5uRl8rfvzrzsO6Ne3t9EXe/sYHTJ/Rn/vgBlFbVU1rdQEl1w4G/BfuqKNvqvP/ly59xzPAMzpuaw6nj+rc6+u/H28v40XMr2VhUxXlTcvjZGWNJTYg57N9FRMLP67Pc8uIaspJiuSbMA82JSO8R6j1/zwOjgX8AZ1prd7tJTxtjlrWy2EdAvjFmKLATuBgIHMnzBZyWxEeNMRk43UA3d+wrdJ3N+6p47P2tXDRjEGMGaNQrkb5ie0kNt/93La+v3cvQjAT+9pUZnDDqYMv/8SMzD7y31rKvqp6Coio+3r6f37+2nmuf/JgHL5/eoe6aO0pr+P7TnzAqO4nfXdD+wCpbiqv518c7+dfHhVz3zKfEx6xm/vj+nD81l9nD0omMMNQ2ePnda+t5ZMkW+id7+NuXZ3BCF/RgEJGOe2bZDlbtLOeeiyeTqMc6iUiIQj1a/NFa+1awBGvt9FamNxljrgZexbmf7xFr7RpjzM+BZdbal9y0U4wxawEvcL21tqTD36KL/HrhOmKjIvi/k0d2dVZEpBPUNnj589sFPPDuZqIiDD+aP4qvzRlKbFRkq8sYY8hK8pCV5OHo4RkkeaK4+cU13PrSGn5+9riQegzUNXr5zoIVeH2WB740LaRWw6EZCVx38kj+76R8lm0r4/kVhfxn5W6eX7GTAf08nD5hAK+v3cv20hq+NHswN8wfTZIn/CMVi8jnt7+mgd+8so6ZeWmcNWlgV2dHRHqQUIO/McaYFc334hljUoFLrLV/amsha+3LwMsB0272e2+B69xXj/LepmJeX7uX608dRVZSaPfUiEjP9dqaPdz277Xs3F/LWZMG8pPTx4R8P52/K47KY2dZLQ++u5nc1Di+efzwdpe59aU1rNpZzl+umE5eRkKHtmeMYUZeGjPy0rjlzHG88dle/rViJ4++t5VBqXE8ddVsZg9L7/D3EJGuc9frGyivbeTWs0KrQBIRaRZq8PcNa+39zR/cZ/J9A2gz+OutvD7LL/7zGTkpcXxtztCuzo6IhNmW4mq++fhyRmUnHZFg6Yb5o9m5v5ZfL1zHgJS4Nmvun/5oO099tIPvnjCck8dmf67teqIjOWPiQM6YOJCq+iY8Uc6onSLSc6zdVcHjH2zjS7OHMHagbjkRkY4JNfiLMMYYt6Wu+QHufXY0gGeW7WDt7gruvWQKnujWu3uJSO+waOM+rIUHL5/GkPSOtbwFExFh+N0FkyiqrOeHz3xKdlIss4IElKsKy/nZi2uYMyKD604e9bm360/3CIn0PNZabnlpNSnxMVynW05E5DCEWuX7KvCMMeZEY8w84EmgxfP4+gL/fvZnThzQ1dkRkU7Q/Py+wWnxR2ydnuhIHrp8GoPS4vjGY8soKKo8JL2suoFvPb6czMRY7r1kip7jKSK8+MkuPtpaxvWnjiIlvs/WwYvI5xBq8HcD8BbwbeC7wJvAj8KVqe7st6+up6KuiZ+fo372In2B12d5f3MJc0ZkHPEynxIfw6NfmUlMVCRXPvIRRZV1B7b5vac/YV9lPX+6bCppeuyCSJ9XVd/Er17+jIm5/bhw+qD2FxARCSKk4M9a67PW/tla+0Vr7fnW2gettd72l+xdVhbu54kPt3PFUUMY3V/97EX6glU7y6msa+KYERlhWf+gtHj+9uUZlNU08NVHP6K6vol73tzIuxv2cetZ45g0KCUs2xWRnuW+NzdSVFnPbWeNU08AETlsIQV/xph8Y8xzxpi1xpjNza9wZ6478fksN7+4hvSEWD3aQaQHsdbS5PUd9vJLCooBOHp4+EbEnJDbj/svncraXRVc9ND73PvmRi6YlsslM1W7LyKwaV8VjyzZwgXTcpkyOLWrsyMiPViod/z/DbgFuBs4AfgK0KeqnZ5dvoNPduznrgsnkaxnYYn0GLf9ey2vrtnDO9efQExUx0e2XLyxmLEDkklPjA1D7g46YXQWvzhnAj/51yrGDUzm9nPGq2u5SJhYa6lv8lHb4KW20UtNg5e6xoPva93PkRGGuOhI4mLcV3Qk8e7fuJhIYqMiqW/yHrKe2kb3s/veZy3JnmiSPFEkx7l/PdHEx0S2KOM+n6WqoYnKuiYqahsP/P3Los14oiP50fzRXfSLifRsBUVVrN9TSf9+HnJT48hMjCWiAy3o1lr21zSyr6qeCANxMVEHjgexURFTWoFdAAAgAElEQVQtyrK1lqr6JvZW1FNUUcfeyjr2VtSzt6KOoop6ymsbafD6aPL6aPJZGr2WRvdzo9fS5PNx8YzBYWlwCjX4i7PWvumO+LkNuNUYswgnIOz19tc0cMfCdczIS+XcKTldnR0RCdGLnzjPswPn2ZxzR2V1aPnaBi/Lt5Xx5WPyjnzmgrh01mAGpcUxZkCyRhIWCaKyrpGVheXUN3mJjowgKiKC6EjjvHf/RkdGYK1lX2U9eyvr2Vtex96KOud9RZ1zIVZRT21j1969EhlhSPJEkeSJwudzvltlfRPOuOot3X7OeDKTwlsJJdKd1DZ4eeLD7Ty8aDNRkRHMHZXJ3FGZHDUsg7iYts+R1lrW763k5VV7eGX1bjbsrTokPSYyggEpHnJS4shJiSM3NZ6c1DgiDAeDtICAraGVXkTGgCfKCQQ90ZFERhiKq+qpaWh5jEmKjSIrOZZ+cdFER0YQHxNFdKQhKtI5lkVFOMeymMgIRmYnHf6P14ZQg786Y0wEsNEYczWwE+jYVVQP9rvX3EFezlZNvEhPsWlfFT95fhXThqSyYU8lC1ft6XDw99HWUhq8vrDd7xfMsfmZnbYtke6uvKaRD7eW8uGWEpZuKWX1znJ8rQRHbfFER5Cd7CE7ycP4nH6cOMZDWkLMwZY8v9a85gu4uOhIfNZS2+CjpqHpYIueX0thfZOP2KiIA/PHx0TiiYkk3m9dxphDW/LqGlu8j4gwJHuiSfZEkeSJJjkuym0tdN6nJcSQm3rkRhsW6QzWWjbsrWJoRkKHet5U1zfxjw+28ddFmymuamDm0DSSYqN4dlkhj72/jZioCGYNTWPuqCzmjspkWEYCxhistazeWcHLq3fzyuo9bCmuJsLAjLw0bj1zLNPz0thXWU/h/lp2ltVSWFbDzv21vLNhH0WV9YfkoTlIy072MCMvzXmf5CEzKRYL1DV43eOCj9rm44N7bPD6LBmJsWS7yze/spJiSegGj1kKNQffB+KBa4Hbcbp+XhmuTHUnqwrLWbB0O1celceYARrkRaQnqG3w8t0FK4iNjuSPl07hzoXreHXtHn7hHU90Bx5qvqSgmJjICGbk6R4bkc+jtLqBgqIqdpfXtmiti4qIICbqYI339pIalm4p5YPNJazfW4m1EBMVweRBKVx9wgim56WR5Ilyu0r5aHK7SzV3lWryWiyWzEQP2cmxZCV7SPZEqfJWpJM9t7yQ659bSUJMJEePyHBb7rLISYkLOn9FXSN/X7KVh5dsYX9NI8fmZ3DNvHxmDk0DoK7Ry0dbS3l7/T7eXl/E7f9Zy+3/gUFpcUwbnMqybWUUltUSGWE4eng6Xz92KKeM7R9Si3ldo5fd5XVYa8lO9nSLIC1c2v1m7gPdL7TWXg9U4dzv1yf4fJafvbia9IQYDfIi0oPc+tIa1u2p5NGvzGBAvzjmjx/AC5/sYunmUubkh96Kt7igmKlDUoiP6b0nAZEjxVpLUWU9BUVVbNxbycaiKgrcV0l1Q4fWFRcdybQhqZw+YQCzhqYxaVCKukKL9CBNXh/3vVXAqOwkpuel8vb6fby+di8A+VmJzB2VyfEjs5gxNJXaBi+PLNnK35ZsobKuiXmjs7h63gimBgxu5ImO5Nj8TI7Nz+RnZ4xlR2kNb2/Yxzvri1i0sZhJg1K49sR8Th6TTWoHH5HkiY5kaEbCEfv+3Vm7VzTWWq8xZpp7v99hdLbouZ5bXsgnO/bz+wsm0S9Og7yI9AT/XF7I08t2cPUJIw5085w7KpP4mEheXr075OCvtLqBNbsq+OEpqvgRCcZay+biat4rKGZxQTFLt5Syv6bxQHqSJ4qR2UmcNCab/OxERmQlkpMSh8/itNj5mlvsnNa6Jp+PhiZLZlIsE3L6HdYATSLSPbz06S62l9bw0OXTOGVcf6y1bNpX5bba7ePv723jL4u2OF2jgeoGL6eOy+aaefmMz+kX0jYGpcVz+ewhXD57SHi/TC8TanX2x8CLxphngermidba58OSq26gvKaRO15Zx/QhqZw3VYO8iPQEG/dWctMLq5k1NI3vn5R/YLonOpITRmfx2po93H72+JCekfXeJucRD515v59Id1dUUceSTcUsKShhSUExu8vrAMhJiePkMdmMz+nHiKxE8rMSyUyKVVdLkT7I67P88a0CxgxI5uSx2QAYYxiRlcSIrCS+fuwwquubeH9TCW9vKKKhycdX5wzVM7Q7SajBXxpQAszzm2aBXhv8/e619eyvaeDnZ8/SyUukB6hpaOLbC1aQEBvJfZdMISrg3r7Txw/gvyt389HWUmYPa/+ZfUsKikmKjWJCiDWQIr1RSVU9H24pZemWUt7bVHxgxLyU+GiOHp7O1SMymDMig8Fp8TpXiggA/1m5i83F1fz5sqmtHhcSYqM4aWw2J7nBoXSekII/a22vuc+vqr6JbSXV7qha0SR6olq0AqzeWc6Cpdu44qg8xg5ULYRId2et5aZ/rWbTvioe/9osspI9LeaZOyoTT3QEC1ftDin4W1xQzOzh6S2CSJHebG9FHUu3lLJ0szO6ZkGRE+x5oiOYPiSN86bmMmdEBmMHJHfoGVki0jf4fJb73ipgZHYip47r39XZkSBCCv6MMX/Daek7hLX2q0c8R2F2wz9X8t+Vuw+Zlhgbdcjwyrv215GmQV5Eeoxnlu3g+Y938v2T8lvtppkQG8XckVksXL2HW84c1+aF6/aSGnaU1vL1OcPClWWRbmPD3koeXrSFpVtK2FpSAzjnxel5zm0Ps4am6x48EQnJwtV7KCiq4t5LpqiCqJsKtdvnf/zee4BzgV1HPjvht2FPJVMGp3DpzMFU1DVRWddIRa3zrJ3m9+mJMXxn7ggN8iLSA3y2u4KbX1zDnBHOkNBtOW1Cf15Zs4cV28uYnpfW6nyLC3S/n/Qd97yxkTc+28txIzP50uwhzBqazpgBSWr1FpEOcVr9NjIsM4EvTBjQ1dmRVoTa7fOf/p+NMU8Cb4QlR2FkraWwrJZLZw3mgumDujo7IvI5lNc28sHmEu5YuI5+cdH84eLJ7Q7kMm90FjGRESxcvafN4G9JQTH9kz0Mz+wbwz5L32WtZdm2UuaP7889F0/p6uyISA/2+md7WbenkrsvmhTSwGrSNQ734VX5wOAjmZHOUFzVQG2jl0GpwR8uKSLdV32Tl+XbynivoITFBcWsLNyPz0JSbBR/vXI6GYntP8Q1yRPNcSMzWLhqNzd9YUzQG9F9PsuSTcWcODpbA1hIr7ervI69FfVMG5La/swiIq2w1nLvmxsZkh7PmRMHdnV2pA2h3vNXyaH3/O0BbghLjsJoR5lzL0NuanwX50REQrFpXxVvrN3L4oJiPtpaSl2jj8gIw+RBKVw9L59jhqczZXBqh+5FOm38AN74rIhPC8uZPCilRfra3RXsr2lkTn77g8KI9HTLt5UBtHiYsohIR7y1rog1uyr4zRcnqst4Nxdqt8+kcGekMxSW1QLOQyFFpHt7bnkhP35+JY1ey8jsRC6ZOZhjhmcwa1gaSZ7Dvx/3pDHZREcaFq7aHTT4O3C/33Dd7ye934ptZcRFRzK6f684zYtIF2hu9ctNjePcKXo2dncXasvfucBb1tpy93MKMNda+0I4M3ek7ShtbvlTt0+R7srns9z1+gb++L8CjhmRzu8umMSAfkeuzPaLj+aYERm8vHo3N542ukXXziUFxYzMTgz6uAiR3mbF9jImD0pRTb2IHLZ3NxbzaWE5vz5vAtE6lnR7of6HbmkO/ACstfuBW8KTpfApLKshPSGGhNjDvdVRRMKprtHLtU99zB//V8BF0wfx6FdmHtHAr9np4wewo7SWNbsqWmz/o62lGuVT+oSahibW7Kpg6pCWLeAiIqGw1nLPGxsY2M/D+VNzuzo7EoJQg79g8/W4CGpHaS256vIpEna7y2u54bmV/G99Eda2eERoUCVV9Vz6lw/4z0qnRe6O88NXg3jy2GwiIwwLVx/6zM8V28uoa/QxR8Gf9AErC8vx+qwGexGRQzR6fSzbWsrybaV4fW2fw9/bVMKK7fv59tzhehZoDxFqALfMGHMXcD/OwC/XAMvDlqsw2VFWw4Scfl2dDZFe778rd/P0sh08vWwH+VmJfG3OUM6ZkoMnOjLo/AVFlXzl0Y8oqqjnz5dN5bQwPx8oNSGGo4al8/KqPfzwlFEHun4uKSgmMsIwa5gGe5Heb8V2Z7CXKYMU/In0ZdZa1u2pZElBMUsKivlwSynVDV4AMhJjOXVcNqdPGMCsoWktuojf8+ZGspNj9Qi1HiTU4O8a4GfA0+7n14CbwpKjMPH6LLv213K6HjopEnYb91aRGh/NzWeO5S/vbuHG51fx21fXc/lRQ7h89hDS/R7L8F5BMd98fDmxURE8ddVspnTSqIOnTejPT/+1mvV7KxndPxmAxQUlTBmUQqK6hksfsGJbGcMzE0hNiOnqrIjIYfL5LBV1jZRUN1Ba3UBJVQPltQ1ERUQQFxPpvKKdV3xMJB73b02Dl/c3OY9Oem9TMcVVDQAMy0jgvKm5HDMinQav5ZXVu3l+xU4WLN1Oanw0J4/N5rQJAzhmeAYrtpfx4ZZSbjlzbKuVu9L9hDraZzVwY5jzElZ7Kupo9FoG6TEPImG3oaiSkdlJnDsll3Mm5/D+phL+ungLf3hjI39+exPnTc3la3OGsmJbGT/51yqGZSbw8JUzOnUk3lPG9udnL6zm5VV7GN0/mfKaRlYV7ueaefmdlgeRrmKtZcX2/Zw4OqursyIiIfpsdwVPf7SD9XsqnUCvuoGymoZ2u2a2JSMxljkjMjjGfQ1MOfQ++7MmDaS2wcs7G/axcPVuXl61h2eWFZLkiSIpNoqMxFgumdnjHv3dp4U62ufrwAXuQC8YY1KBp6y1p7az3HzgHiAS+Ku19o5W5vsi8Cwww1q7rAP5D1nzSJ+D0jTSp0g4WWsp2FvFOe5wz8YYjh6RwdEjMigoquThxVt5fkUhT364HYBj8zO4/7KpJH+OxzccjsykWGYOTWPhqt1cd/JI3t9cgs/CnHzd7ye939aSGkqrG3S/n0g3V9fo5eVVu1mwdDvLt5URExXBxJx+DEmPZ+qQFNISYkhLiCU9IcZ9H0NKfDRen6W20Uttg/tq9FLj/q1r9GKMYdbQNPKzEluMeh0oLiaS+eP7M398f+qbvCwpKOblVXt4Z8M+rjt5pFr9ephQ+zZlNAd+ANbaMmNMm9WFxphInHsETwYKgY+MMS9Za9cGzJcEXAss7VDOO+hA8KeWP5Gw2lNRR2V9EyOzE1ukjchK4tfnTeCHp4xkwdLtNHp9XHtifpcNDX36hAHc/OIaCoqcex0SYiKDPvtPpLdpfri7gj+R7mlLcTVPLN3Gs8sL2V/TyNCMBG76whjOn5rbpV21Y6MimTc6m3mjs7ssD/L5hBr8+Ywxg6212wGMMXk4A7+0ZSZQYK3d7C7zFHA2sDZgvtuB3wA/DDEvh2VHWS3G0KI5W0SOrA17qwDIz279odHpibFce2LXd688dVx/bn5xDQtX7WFJQTGzhqXrGUXSJyzfVkayJ4rhmS0raUSkazR5fby+di+PL93GkoISoiLM/7d35+FRVecDx78neyAhhLBKAgFkJxAgyCYRFBGwiFKsCwpogVq01WqLVKsitRUVtVqx7kD5UatVUURsBYksikKCIewBFEggBEL2PZM5vz/uTLaZLGDuJDN5P8+TJzNz7tx55868M/ede+45XDewM7NGdmN0r7B6j9AJ0RANLf4eBXYopbbarscCC+q5T1cgpcr1VGBk1QWUUkOBCK31BqVUrcWfUmqB/fG6dbu0fsWpmYV0aRMgw9AKYbKj6XkA9Kmj+GsuOrUJIKZ7KP/adYq0nGJmjere1CEJ4RLfn8piaLdQvLxkZ1KI5iC3uIx71iTwzfELdG0byO8n9eEXMRF0bBPQ1KEJD9PQAV/+q5SKwSjAEoFPgKJ67ubsG6XiaKFSygt4EZjbgMd/A3gDICYm5pLOak3Nkjn+hHCF5PQ82gcZ5x24gylRXfjzBqNDwtjLZYoH4flyi8s4kp4no18L0Uyk5xYz551dHDuXz7IZUdwcE4G3/DAjTNKgw2BKqXnAl8BDtr81wJJ67pYKVJ30Ixw4U+V6MDAI+EopdQIYBay3FZmNLiWrkPBQ6fIphNmS0/O5vKP7dCWbPKgzAO2D/OjrBkcrhfipEk9lozUMc9G0KkKI2h07l8+MV78hJbOQd+aO4NYruknhJ0zV0D6Q9wMjgJNa6wnAUOB8PffZDfRWSvVQSvkBtwLr7Y1a6xytdXutdaTWOhL4FrjBjNE+SyzlnM0tlsFehDCZ1ppj5/LdosunXde2gUzs34kbo7vK+RSiRdhzKgsvBUMiQpo6FCE8QnFZOTNe/ZoF/4wn2XbqQ0MknMxi5mvfUGIp571fjSa2TwcToxTC0NBz/oq11sVKKZRS/lrrw0qpvnXdQWttUUrdB/wPY6qHd7TWB5RSS4F4rfX6uu7fmM5kF6M1Lp1DTIiW6ExOMfklljoHe2mO3ppjSocDIZqlhJNZ9O3chmAXT68ihKd6Ne4Ye05l09rPm02H0pkxNJwHJvauc79z08F0fvPuHjq3CeCfd4+kW5jsowrXaGjxl6qUagt8DGxSSmVRvQunU1rrjcDGGrc9Xsuy4xsYy0WrnOZBun0KYSb7L5593KjbpxAtidWqSTyVzQ3RlzV1KEJ4hB8zCnht6w9Mj76MJdMG8o+tx1n1zQnW7z3NrJHdue/qy2kf5F/tPu/uOsWj6/YR1TWEt+eOcGgXwkwN6vaptb5Ja52ttV4CPAa8DdxoZmCNKSXLPsG7/KoihJncaaRPIdyd1aqZ+Y9vWPd9aoPvc/RcPnklFpnfT4hGoLXmifUH8Pfx4tGp/Qlt7ccjU/uz9Q/jmTk8nDXfniT22The+OIIucVlaK15cVMyf/xoH7F9OvCv+aOk8BMu19AjfxW01lvrX6p5Sckswtdb0UmGyxXCVMnp+bQP8m/SCWiFaClOZhYSfzKL09lFXB91WYOmMpLJ3YVoPP/df5Ztyed5YtqAalMydAkJ5OkZg5k/rifPb0rm5S3H+Oe3J4mOaMtXR84zc3g4T8+IknllRZNoEe+6lKxCurYNlNGThDDZ0fQ8+nSSLp9CuMLhtFwA0nKK+WhPw47+JZzMIqy1H92kJ4wQP0lBiYUnPz3IgC5tuLOWOWJ7dghixe3D2PCbKxkcbhR+907oxXMzB0vhJ5rMRR/5c0epmYXS5VMIk1mtmqPn8vlFTET9CwshfrJDabl4KejbuQ2vfnWcmcPD8alnh3LPqSyGdQ+VkW2F+Ile/vIoZ3OLWTFrWL15N6hrCP+8+woyC0rdZg5c4blaxM8OKVlFhMs0D0KY6nR2EYWl5fSWI39CuMShs3n0aN+a303szanMQjYkpdW5fGZBKT9mFEiXTyF+ouT0PN7e8SO/iAm/qHySwk80Bx5f/BWUWMgsKCWinYz0KYSZjp3LB2SwFyFc5VBaLv26tGFi/0707RTMirhjWK261uX32M73k8ndhbh0Wmse+3g/rf19eHhyv6YOR4iL5vHFX2pWEYBM8C6EySqneZDiTwiz5RaXkZpVxIAubfDyUiyc0Iuj5/L54uDZWu+TcCoLHy/F4HCZ3F2IS/Vx4mm++zGTRZP7EiYjdQo35PHFX8Ucf3LOnxCmSk7Pp2OwPyGtZOJoIcyWfNb4saVfZ+PHlp8NvozIsFa8EncMrZ0f/dtzMouBXUMI8PV2WZxCeJKcojL+8tlhhkS05dYR3Zo6HCEuiecXf1kywbsQrnD0XJ50+RTCRQ7ZRvrs36UNAN5eioXjL2f/6Vy2Jp93WL6s3Mre1GyGS5dPIS7Zi5uSuVBQwlPTB8kI8sJteX7xl1lEoK+3nGQrhImsVs3R9Hwu7yiDvQjhCofO5tEmwIcuIZVzi904tCuXhQTwyhbHo3+H0nIpLrMyrHtbV4cqhEfYfzqHf+48wR0juxMlXaeFG/P84i+rkIh2gTKstRAmOp1dRFFZuRz5E8JF7IO9VP1u8/Px4ldX9SL+ZBbf/ZhZbfk9Mrm7EJfMatU89sl+Qlv58ftJfZs6HCF+Es8v/jILZbAXIUxWMdiLTPMghOmsVs2Rs3kMsHX5rOqWERG0D/JnRdyxarcnnMrmspAAuoTIKRBCXKwPElL5/lQ2f5zaX85rF27Po4s/rTWpWUUy2IsQJktON6Z56C1H/oQwXUpWIYWl5RWDvVQV4OvN/HE92H40g8SU7Irb95zMYqgc9RPikvxr1yn6d2nDz4d1bepQhPjJPLr4yy4sI7/EQrgM9iKEqY6m59GpjT8hgfKLqBBmqznYS02zRnUnJNCXV7YYR//O5hRzOrtIBnsR4hLkFJaRlJrNtQM6ySlEwiN4dPFXMdKnHPkTwlTJMtKnEC5zKC0Ppag154L8fbhrbCSbD6Vz+Gwue07J+X5CXKpvjmdg1TCud/umDkWIRuHZxV+mTPAuhNmsVs2xc/n0lsndhXCJQ2m59AhrTaBf7fP1zR0TSWs/b1bEHSfhZBb+Pl61HikUQtRu29EMgvx9iI6QkXKFZ/Bp6gDMVHnkT7p9CmGWlKxCisusMtiLEC5y+GweUV3rHmq+bSs/7hwdyRvbjtMlJJAh4W3x8/Ho33uFaHRaa7Yln2d0rzB8vSV/hGfw6HdySmYhbVv5Ehwg5yEJYRYZ7EUI18kvsXAqs9DpYC81/fLKHvh6e3E6u4hh0uVTiIt24kIhp7OLiJUun8KDeHTxl5pVJF0+hTDZ0XPGNA+95cifEKY7crbuwV6q6hDsz21XdANgWDfpsibExdp+9DwA43p3aOJIhGg8Ht/tsyG/jgohLt3R9Hy6hATQRo6wC2G6Q2nGjy39ujTsu+03V19OgK83sX1k51WIi7X9aAYR7QLpHiYHEoTn8Ngjf1arliN/QrhAcnqedPkUwkUOpeUSHOBD17YNO5c9LMifxVP6EeBb++AwQghHZeVWdh6/wLjeHWSKB+FRPLb4O59fQqnFSrhM8yCEacptI3326ShdPoVwhcNn8+jfuY3sjAphssSUbPJLLHK+n/A4Hlv8pWTaRvqUCd6FME1KZiElFquc7yeEC1itmiNn8xrc5VMIcem2J5/HS8HoXlL8Cc/iucWfbZqHcOn2KYRpktPtg73IzqgQZkvNKiK/xCLz9QnhAtuOZjAkoi0hgXI+u/Asnlv82SZ4D5cjf0KY5ug52zQP0u1TCNMdso30KQOZCWGunMIyklKzZZRP4ZE8uPgrpGOwv5zkLoSJktPzuCwkQObSFMIFDqfloRT0leJPCFN9czwDq0bO9xMeydTiTyk1WSl1RCl1TCm12En7g0qpg0qpJKXUl0qp7o312ClZhUTIYC9CmCo5PV+6fArhIofScokMa00rP4+epUmIJrftaAbB/j4MiZD5MYXnMe0bRCnlDawArgVSgd1KqfVa64NVFvseiNFaFyqlfg08C9zSGI+fklnEiMjQxliVEMKJcqvm+Pl8rrw8rKlDEaJFOHw2V873E+ISBAcH8+OPP1JcXNyg5SddZuH6iE4cSz5icmRC1C8gIIDw8HB8fRunl5WZPx9eARzTWv8AoJT6NzAdqCj+tNZxVZb/FrijMR64rNxKWk4REe26NsbqhBBOnLxQQKnFKkf+hHCBghILJzMLmTEsvKlDEcLtzJ07l+DgYCIjI+udJqWkrJyy9Dy6tg0kLMjfRREK4ZzWmgsXLpCamkqPHj0aZZ1mdvvsCqRUuZ5qu602vwQ+d9aglFqglIpXSsWfP3++3gc+m1OMVSMTvAthouR0Y7CXPlL8CWG6I+l5aC2DvQhxKcLDwwkLC2vQ/Jh5JRYAggKke7VoekopwsLCGnzUuiHMLP6cZZh2uqBSdwAxwHPO2rXWb2itY7TWMR061D/ykn2Ov/B2MtKnEGY5ap/mQUb6FMJ0h9OMfJNun0JcPKVUgwo/gPxiC34+Xvj7yICBonlo6Hu3ocz8WSMViKhyPRw4U3MhpdRE4FHgKq11SWM8sH2OPznyJ4R5jp7Lp2vbQFr7y6+jQpjtUFouQf4+Mn2RECayak1BiYWQVjKCtfBcZh752w30Vkr1UEr5AbcC66suoJQaCrwO3KC1PtdYD5ySWYS3l6JLSEBjrVIIUUNyeh59OslRPyFc4fDZXPp1Dm70X4CFEJWKSssp15pgE7p8ent7Ex0dzZAhQxg2bBjffPNNnctnZ2fz6quv1rve8ePHEx8fX+cyJ06cQCnF3//+94rb7rvvPlatWtWg2BtL1VinTp1KdnZ2o6171apVnDlTeYxp3rx5HDx4sI57tFymFX9aawtwH/A/4BDwvtb6gFJqqVLqBttizwFBwH+UUolKqfW1rO6ipGQVclnbAHy8PXYaQyGalKXcyg/nC+R8PyFcQGvN4bQ86fIphMnyii0oMKVHS2BgIImJiezdu5enn36aP/7xj3Uu39Dir6E6duzISy+9RGlp6SXd32KxNFosABs3bqRt28abSqNm8ffWW28xYMCARlu/JzG1v5bWeiOwscZtj1e5PNGMx03JLJQun0KY6GRmIaXlMtKnEK6QmlVEXomFfl0k34T4qZ789AAHz+Q6bSsqKwcg0PfizvcbcFkbnpg2sMHL5+bmEhpqTEeWn5/P9OnTycrKoqysjKeeeorp06ezePFijh8/TnR0NNdeey3PPfcczz77LGvWrMHLy4spU6awbNkyAP7zn/+wcOFCsrOzefvttxk3bpzDY3bo0IGxY8eyevVq5s+fX60tMTGRe+65h8LCQnr16sU777xDaGgo48ePZ8yYMXz99dfccMMN7Nu3j8DAQA4fPszJkydZuXIlq1evZufOnYwcObLiSOKvf/1rdu/eTVFRETNnzuTJJ590iCcyMpL4+Hg++OADXglB5G8AACAASURBVHvtNQBycnKIjIwkLi6OL774gieeeIKSkhJ69erFypUrCQoKYunSpXz66acUFRUxZswYXn/9dT788EPi4+OZNWsWgYGB7Ny5kylTprB8+XJiYmJ49913+etf/4rWmuuvv55nnnmmwa+VJ/LIQ2MpWUVS/AlhIhnsRQjXOXzWyLd+neXInxBm0YDVqvHxMqdrdVFREdHR0fTr14958+bx2GOPAcYcbuvWrWPPnj3ExcXx0EMPobVm2bJl9OrVi8TERJ577jk+//xzPv74Y7777jv27t3LokWLKtZtsVjYtWsXf/vb35wWWnaLFy/m+eefp7y8vNrts2fP5plnniEpKYmoqKhq68jOzmbr1q089NBDAGRlZbFlyxZefPFFpk2bxu9+9zsOHDjAvn37SExMBOAvf/kL8fHxJCUlsXXrVpKSkmqN6Z577iExMZHdu3cTHh7Ogw8+SEZGBk899RSbN29mz549xMTE8MILLwBGd9Xdu3ezf/9+ioqK2LBhAzNnziQmJoa1a9eSmJhIYGDludFnzpzh4YcfZsuWLRWP8/HHHzf0ZfNIHjdSQ3FZOefzSuSkeCFMZJ/m4XIp/oQw3aE04yiFTPMgxE9X2xG6nMJSTmYW0qtDkKndPgF27tzJ7Nmz2b9/P1prHnnkEbZt24aXlxenT58mPT3d4f6bN2/mrrvuolUr4+BGu3btKtpmzJgBwPDhwzlx4kStMfTo0YMrrriCf/3rXxW35eTkkJ2dzVVXXQXAnDlzuPnmmyvab7nllmrrmDZtGkopoqKi6NSpE1FRUQAMHDiQEydOEB0dzfvvv88bb7yBxWIhLS2NgwcPMnjw4Dq3z/3338/VV1/NtGnT2LBhAwcPHmTs2LEAlJaWMnr0aADi4uJ49tlnKSwsJDMzk4EDBzJt2rRa17t7927Gjx+PfbaAWbNmsW3bNm688cY64/FkHlf8pdpH+mwnR/6EMEtyeh7hoTLSpxCucPhsLt3DWkm+CWGivBIL3krRys/8KR5Gjx5NRkYG58+fZ+PGjZw/f56EhAR8fX2JjIx0Oqeb1rrWAZ/8/Y3J6L29ves9N++RRx5h5syZxMbGNijW1q1bO30sLy+visv26xaLhR9//JHly5eze/duQkNDmTt3br1z1K1atYqTJ0/yyiuvAMZzvfbaa3n33XerLVdcXMzChQuJj48nIiKCJUuW1LturZ3OMteieVy3z5TMIgAiZI4/IUxzND1fBnsRwkUOpeXRX7p8CmEarTX5xRaCAnxcMqLu4cOHKS8vJywsjJycHDp27Iivry9xcXGcPHkSgODgYPLy8iruM2nSJN555x0KC42DHJmZmZf02P369WPAgAFs2LABgJCQEEJDQ9m+fTsAa9asqTgKeClyc3Np3bo1ISEhpKen8/nnn9e5fEJCAsuXL+f//u//8PIyypJRo0bx9ddfc+zYMQAKCwtJTk6uKPTat29Pfn4+H3zwQcV6am4vu5EjR7J161YyMjIoLy/n3Xff/UnPzxN43M+IMsefEOYqK7fyQ0Y+4/t1aOpQhPB4haUWTlwoYHr0ZU0dihAeq9RipbTcSocqR7Iam/2cPzCKzdWrV+Pt7c2sWbOYNm0aMTExFecEAoSFhTF27FgGDRrElClTeO6550hMTCQmJgY/Pz+mTp3KX//610uK5dFHH2Xo0KEV11evXl0x4EvPnj1ZuXLlJT/PIUOGMHToUAYOHEjPnj0rum7W5pVXXiEzM5MJEyYAEBMTw1tvvcWqVau47bbbKCkxpgB/6qmn6NOnD/PnzycqKorIyEhGjBhRsZ65c+dyzz33VAz4YtelSxeefvppJkyYgNaaqVOnMn369Et+fp5Audvh0JiYGF3XfCZ/3XiI1d+c4PCfJ8t8SMJtKKUStNYxTR2HXV15lllQyoPvJ3LriG5MHtTZxZEJcemaW55B/d9piSnZ3Ljia16/czjXDZR8E+6hueXali1b9NVXX11re0Z+CWeyi+jbORh/H/O7fQpxsQ4dOkT//v2r3XapeeZ5R/4yCwkPDZTCTwiTtGvtx6q7rmjqMIRoEeyDvUi3TyHMk19swc/HSwo/0SJ43jl/WYUy2IsQQgiPcDgtl9Z+3jKCtRAmsWpNfomFYBlQSbQQHvdOT8ksYmhEqPPG7BTY/SZkHK1++1UPw2XRkLILdrzoeL+JS6BDX/hhK3z3mmP75GUQ2h2S/wcJqxzbp70EQR3h4Cew99+O7Te9DgFtYO97cNDJ3CM3rwIff0h6H37cCl6+4O1r/PfxM+IDOLgeztaYS8UnAGJ/b1z+fq3RXl4G5aVgtUBgKEx+2miPe9rx/iERMPVZ4/Kmxx23XdjlMOnPxuWNiyAnpXp75yiY8Ihxef1voCCjenv4CBj3oHH5w/lQml+9vUcsjPq1cfm9O8BafW4aek+CmLuM5/T+bBz0vwGib4PiXFj3K8f2wb+AgTdB/jn49H7H9mFzoO9kyDoJ/13s2D7yV9BzPJxPhs1POLaPfQC6jXS83d2lJsD25Y63X/M4dOwPJ3bAzhWO7df9Bdr1hKObIf5tx/brX4A2XeDQp5D4L8f2G1813rNJ/4EDHzm2z1wJvgGw559wpOZJ5gpus63zuzfgh7jqzb6tYKYtpvh34EyikWfefuDlA63C4MoHjPa9/4YLx6rfv1VY5Xs1YbVjLgR3gRG/NC5/83fISTXet9YyKLdA+8thnDGPEhv/YOSKPc+9faDLEIi522jf/gIUZ9ty2baOrsNhmC0H3p9j5HhVl080Ht9abuQSgPKqfI59roNBP4eyIvhyqfGcvX2Nz4lyC/SeCL2uNuL63yOVnyPaaqxr2GzoO8X4nP18EQ6uWAC9JhifIZsed2wfez90GwVpSfDV047t9X1OX/MEdOzneLubi0pewbCgYrz+F1f5Wne/EobcYrwu78/GmKGsin4/g6GzoLQAPpznZKUzjde64AKsv8+xfegd0O964z268Q+O7SPmweXXQMYx2PSYY/uY30D3MXB2H8Q5OScp9g/QdRikxsP25x3br34MOg2AU9/BntWV70V7LoxaCG0uM+6f/F/H+49aCK3aGd/Zyf+tkme2v5+9AP7B9X/nJqx2XL/yglvXGpe/ex1++Kp6e9XPkR1/g5Tvqre3agfTbZ+NXy2DtL3V29t0hettn62bnoCM5OrtYb1g0lPG5c8XQ/bJ6u2dBsHVjxqXP73f+G6rquvwyn2Cj34FJTUmO4+8Ekbfa1x+f7axvaqyf454kKLSckLJoaOlDDK9QSnbnxeEhBsLFWaCpcaokl7eENTJ1n4BLCU12n2MfT8wPjdrfiZ7+0Jr27nzBecdt7WPv/G9AsbraK0xiqdPgPF+Asg7W/lZbOcbaHxfAuSlQc3TvPxaQ0CIcXtemuOG8Qsy9k2tVsg/69juH2z8WS2O7zMA/zbgH2Q8r4Lzju0BbcGvFVhKoTDDsT0w1HgOlhJj+zq0tzO+78uKocjJ4DetwoxtWFpofF/W1LqD8RqUFkBxjpP2jsbnTUm+Y56A8dp7eRv7lzX3XQGCOxvvoeIc4zGqUca+DkBRNpQV1mj2Mu5vEo8q/nKLy8gpKqs+0mf+OeON0zbCeHPtXAEd+hmJbWdP6LJCxx02qEzo2trtCVuS57zdnrDFuc7bta2gKc5xbNcYbwIwdpqOban8ErNajLaJS4z25P/B3ho7zIGhlR/0P3xlLOPtY9uh9TW2i13BecfH9/atvJx/zrE9IKRK+1knO7xV3ry5aY4fIO16Vmk/AyU1ErCwSkLnnDaee1VVE9rZtrUntLY6by+xjQxlLXfebk9oq6WWdlvClpc4b6+Z0J6i1lyx5VJpPblSWk+u1JpLti+34mzn7fadYGe5RJWcL8pybPet0mPg7L7KnUb7jmPrDpXF34F1cPSL6vdv36ey+Et6H059U739sqGVO02HPoVzh41c9LIVX1W/2DN/MH5wqLrDaimpLP6+/YfxZWTfGbavwy77lGOuFGVVXrY/d6vV9kNQmVG0g1H87VlT+dj2He+gjkbxZ7XAqW+Nx/P2BeVtbNoSe66U1ZIrti8/Sz25Ul5a93urrKiW91aJ421uTmvNpIJPCPAqh0T/ytfavkOovIyd/5qnOdT3uVds25HRtXzu2V/L8lpey/peK3t7ba91xXdqLa+lPRfy0+HHbcbj2L/zystg8K1G8ZeW6Lx4jL7d2ClO32+8l6t+53n7GI/vH2zkkNPvZPvniJPPGVWlW6CzzxG/KnOfFl5wbK9aIBRkOFl/lQ5Zzr6T/auMsuzsO9debIBREOSert4eGll5Ofe0405xze/cmnlV9XPEQ5RbNf5eVnyspWDVgDbeA8oL7Ls4xTmO28rbr7L4K8p2LBB8Aipfj6IsxwLBt1WV4u8CWIqqt/sFV+Z6QYbjaxEQUln8FZx3LA4D21UWf/nnHIvDVu0r9+HyHecVJEgbxR9W5+3Ky1b81dLu5WMUf1aL83Zvf6P4s5Y5b/cNNP7KS523+7U2ij9LsfN2/zZG8Vdbe0Bb4zusrNB5e6swwAfKCpy3t+4AeBvfbU63Xyfbd2Oek+K3SvFXkutY3CpvU4s/jxrw5cCZHK5/eQev3zqA63z2GL/OH/vSOPIzfYWRzEVZlckiRDPR3E6Or28QCiHcUXPLM6g7105nFzF22RaeunEQd4zq7uLIhLh0zS3X6hvwRYjmTgZ8qUVKZhEP+7zLxM++grI8o/vE2N/CkNuMBZSSwk8IIYRbOHTGNthLF5lTUwghROPwqAFfzueXUI4X5X2mwuxP4IF9lefrCSGEEG7k8Fmj+OsrI30K4faUUjz00EMV15cvX86SJUtcGsPcuXOrTYw+c+ZMfvjhhwbdd968eRw8eBCg2vyCJ06cYNCgQY0SX2JiIhs3bnTa9tVXXxESEkJ0dDSDBw9m4sSJnDvn5FzDBq6vqqCgIKe3L1myhFatWlV7nNqW/an27dvH3LlzTVl3TR5V/N05qjvznliJ381vGINweMmQvUIIIdzTobQ8urVrRZCMQiiE2/P39+ejjz4iI8PJ4CYNYLFY6l/oIhw4cIDy8nJ69uxZ/8LAW2+9xYABAwAueXL5+tRXrI0bN47ExESSkpIYMWIEK1Y4GVjuItbXEO3bt+f5552cW9wAWmusVmv9CwJRUVGkpqZy6tSpS3qsi+FRxR9AgK8UfEIIIdzfyJ7tuGVERP0LCiEuzsrrHf92vWm0lRY6b//eNsprwQXHtgbw8fFhwYIFvPii42jFJ0+e5JprrmHw4MFcc801FQXA3LlzefDBB5kwYQIPP/wwS5YsYc6cOUyaNInIyEg++ugjFi1aRFRUFJMnT6aszBjoa+nSpYwYMYJBgwaxYMECnI3vsXbtWqZPnw7A+++/z4MPGiOvv/TSSxUF4fHjx7nyyisBGD9+PPHx8SxevJiioiKio6OZNWsWAOXl5cyfP5+BAwcyadIkioqMwWsSExMZNWoUgwcP5qabbiIrK6vaugAyMjKIjIyktLSUxx9/nPfee4/o6Gjee++9Wrel1pq8vDxCQ40BbXbt2sWYMWMYOnQoY8aM4ciRI07Xl5+fz1133UVUVBSDBw/mww8/rFjno48+ypAhQxg1ahTp6ZUDuNx999289957ZGY6jij6wgsvMGjQIAYNGsTf/vY3wDgS2r9/fxYuXMiwYcNISUkhKCiIhx9+mOHDhzNx4kR27drF+PHj6dmzJ+vXr69Y37Rp0/j3v53MCtDIPK74E0IIITzB7NGR3Dvh8qYOQwjRSO69917Wrl1LTk71kc3vu+8+Zs+eTVJSErNmzeK3v/1tRVtycjKbN2+uOPp0/PhxPvvsMz755BPuuOMOJkyYwL59+wgMDOSzzz6rWN/u3bvZv38/RUVFbNiwwSGWr7/+muHDhwMQGxvL9u3bAdi+fTthYWGcPn2aHTt2MG7cuGr3W7ZsGYGBgSQmJrJ2rVEQHz16lHvvvZcDBw7Qtm3biqJq9uzZPPPMMyQlJREVFcWTTz5Z67bx8/Nj6dKl3HLLLSQmJnLLLbc4LLN9+3aio6Pp1q0bmzdv5u67jRGw+/Xrx7Zt2/j+++9ZunQpjzzyiNP1/fnPfyYkJIR9+/aRlJSEfRCggoICRo0axd69e4mNjeXNN9+seMygoCDuvvtuXnrppWqxJCQksHLlSr777ju+/fZb3nzzTb7//nsAjhw5wuzZs/n+++/p3r07BQUFjB8/noSEBIKDg/nTn/7Epk2bWLduHY8/Xjn1UUxMTMXrYCbpSyKEEEIIIVqOuz6rvc2vVd3trcPqbq9DmzZtmD17Ni+//DKBgZXTku3cuZOPPjLmrr3zzjtZtKhyrtSbb74Zb+/KXm1TpkzB19eXqKgoysvLmTx5MmB0Gzxx4gQAcXFxPPvssxQWFpKZmcnAgQOZNm1atVjS0tLo0MGYaqJz587k5+eTl5dHSkoKt99+O9u2bWP79u3MmDGj3ufVo0cPoqOjARg+fDgnTpwgJyeH7OxsrrrqKgDmzJnDzTfffLGbrJpx48ZVFLLPPPMMixYt4rXXXiMnJ4c5c+Zw9OhRlFIVR0Br2rx5c7Uja/Yjh35+fvzsZz+riH/Tpk3V7vfb3/6W6Ojoauds7tixg5tuuonWrVsDMGPGDLZv384NN9xA9+7dGTVqVMWyfn5+1V4nf3//itfQ/poBdOzYkTNnzlzq5mkwKf6EaGRlZWWkpqZSXFzs0BYQEEB4eDi+vr5O7imEaCjJMyFcQ3KtcT3wwAMMGzaMu+66q9ZlVJW5O+3FhZ2/vz8AXl5e+Pr6Vizr5eWFxWKhuLiYhQsXEh8fT0REBEuWLHH62gUGBla7ffTo0axcuZK+ffsybtw43nnnHXbu3Nmg893sMQF4e3tXdPusjY+PT8W5cM5ia4gbbriBn//85wA89thjTJgwgXXr1nHixAnGjx/v9D5a62rb1q7qdvT29nY4v7Jt27bcfvvtvPrqq9XWVZuar1nN16nqa1j1sYqLi6v9KGAW6fYpRCNLTU0lODiYfv360b9//4q/fv36ERwcTGpqalOHKITbkzwTwjUk1xpXu3bt+MUvfsHbb79dcduYMWMqjkitXbu24jy7S2Evptq3b09+fn610T2r6t+/P8eOHau4Hhsby/Lly4mNjWXo0KHExcXh7+9PSEiIw319fX1rPbpmFxISQmhoaEU3xjVr1lQcBYyMjCQhIQGgWnzBwcHk5eU16Hnu2LGDXr16AZCTk0PXrl0BWLVqVa3rmzRpEq+88krFdfs5iA3x4IMP8vrrr1cUa7GxsXz88ccUFhZSUFDAunXrHLrIXqzk5ORGGzm1LlL8CdHIiouLCQsLc/h1SSlFWFjYJf/KJYSoJHkmhGtIrjW+hx56qNqony+//DIrV65k8ODBrFmzxuH8sovRtm1b5s+fT1RUFDfeeCMjRoxwutz111/PV199VXF93LhxpKSkEBsbi7e3NxEREbUWoQsWLGDw4MEVA77UZvXq1fzhD39g8ODBJCYmVpzf9vvf/55//OMfjBkzptp2mDBhAgcPHqx1wBf7OX9DhgxhzZo1FUclFy1axB//+EfGjh1LeXl5rev705/+RFZWFoMGDWLIkCHExcXVGX9V7du356abbqKkpASAYcOGMXfuXK644gpGjhzJvHnzGDp0aIPX50xcXBzXX9+wAYR+ClXXYcvmKCYmRttHCBKiOTp06BD9+/e/qHalVILWOsbs2BpK8kw0d56QZyC5Jpo/T8i1LVu2aPvgHsJQVFTEhAkT+Prrr6udUyiaRklJCVdddRU7duzAx8fxrLzGzDM58ieEEEIIIUQLEhgYyJNPPsnp06ebOhQBnDp1imXLljkt/BqbDPgihBBCCCFEC3Pdddc1dQjCpnfv3vTu3dsljyVH/oQwQW3dqd2tm7UQzZnkmRCu4e65prV2m1iFqKmx37tS/AnRyAICArhw4YJDsmqtuXDhAgEBAU0UmRCeQ/JMCNfwhFxLTU11+hyEaO7MyDPp9ilEIwsPDyc1NZXz5887tNnnRBJC/DSSZ0K4hifk2qpVq4iNjXX6HIRo7ho7z6T4E6KR+fr60qNHj6YOQwiPJnkmhGt4Qq7l5eW5/XMQorGY2u1TKTVZKXVEKXVMKbXYSbu/Uuo9W/t3SqlIM+MRQgghhBBCiJbKtOJPKeUNrACmAAOA25RSA2os9ksgS2t9OfAi8IxZ8QghhBBCCCFES2bmkb8rgGNa6x+01qXAv4HpNZaZDqy2Xf4AuEYppUyMSQghhBBCCCFaJDPP+esKpFS5ngqMrG0ZrbVFKZUDhAEZVRdSSi0AFtiu5iuljtTxuO1r3r+Zc6d43SlWcK94+zZ1AFUlJCRkKKVO1rOYO21fd4oV3Cted4q1u1Jqgdb6jaYOxK4BueZO2xfcK153ihXcK153+05zp20L7hWvO8UK7hXvJX2nmVn8OTuCV3OM3YYsg+1JNeiJKaXitdYxDVm2OXCneN0pVnCveJVS8U0dQ1Va6w71LeNu29ddYgX3itedYoWKXGs2xV99ueaO29dd4nWnWMG94nW37zR32rbgXvG6U6zgnvFykd9pZnb7TAUiqlwPB87UtoxSygcIATJNjEkIIYQQQgghWiQzi7/dQG+lVA+llB9wK7C+xjLrgTm2yzOBLVpm4BRCCCGEEEKIRmdat0/bOXz3Af8DvIF3tNYHlFJLgXit9XrgbWCNUuoYxhG/WxvhoZtNd54Gcqd43SlWcK943SlWO3eK2Z1iBfeK151iBYnXbO4UrzvFCu4VrzvFChKvmdwpVmgB8So50CaEEEIIIYQQns/USd6FEEIIIYQQQjQPUvwJIYQQQgghRAvgUcWfUmqyUuqIUuqYUmpxU8dTH6XUCaXUPqVUYnMbFlkp9Y5S6pxSan+V29oppTYppY7a/oc2ZYxV1RLvEqXUadv2TVRKTW3KGO2UUhFKqTil1CGl1AGl1P2225vt9q1K8qxxuVOuSZ65ljvlmuRZ43GnPAP3zzV3yjNo3rnmTnkG7pVrjZlnHlP8KaW8gRXAFGAAcJtSakDTRtUgE7TW0c1wTpFVwOQaty0GvtRa9wa+tF1vLlbhGC/Ai7btG6213ujimGpjAR7SWvcHRgH32t6rzXn7ApJnJlmF++TaKiTPXMJNc03yrHGswn3yDNw419w0z6D55toq3CfPwL1yrdHyzGOKP+AK4JjW+getdSnwb2B6E8fktrTW23Ccc3E6sNp2eTVwo0uDqkMt8TZLWus0rfUe2+U84BDQlWa8fauQPGtk7pRrkmcuJbnWiCTPzOPmuSZ51ojcKc/AvXKtMfPMk4q/rkBKleupttuaMw18oZRKUEotaOpgGqCT1joNjDch0LGJ42mI+5RSSbZD+82mq4GdUioSGAp8h3tsX8kz13CH90JVkmeNz91yTfLMfM06z8Atc83d8gzcL9fc4X1QU7POtZ+aZ55U/CkntzX3eSzGaq2HYXQ3uFcpFdvUAXmYfwC9gGggDXi+acOpTikVBHwIPKC1zm3qeBpI8kzUJHlmDnfLNckzczXrPAO3zTV3yzOQXDNbs861xsgzTyr+UoGIKtfDgTNNFEuDaK3P2P6fA9ZhdD9oztKVUl0AbP/PNXE8ddJap2uty7XWVuBNmtH2VUr5YiTvWq31R7ab3WH7Sp65hju8FwDJMxO5Va5JnpmrOecZuHWuuVWegVvmmju8Dyo051xrrDzzpOJvN9BbKdVDKeUH3Aqsb+KYaqWUaq2UCrZfBiYB++u+V5NbD8yxXZ4DfNKEsdTLngw2N9FMtq9SSgFvA4e01i9UaXKH7St55hru8F4AJM9M5Da5JnlmvuaaZ+D2ueY2eQZum2vu8D6o0FxzrVHzTGvtMX/AVCAZOA482tTx1BNrT2Cv7e9Ac4sXeBfjcHcZxi9jvwTCMEYSOmr7366p46wn3jXAPiDJlhxdmjpOW6xXYnQrSQISbX9Tm/P2rRG/5Fnjxug2uSZ55vLn4Ba5JnnmklibZZ7Z4nXrXHOXPLPF2qxzzZ3yrI54m2WuNWaeKdsKhRBCCCGEEEJ4ME/q9imEEEIIIYQQohZS/AkhhBBCCCFECyDFnxBCCCGEEEK0AFL8CSGEEEIIIUQLIMWfEEIIIYQQQrQAUvyJi6aUGq+U2tDUcQjhySTPhDCf5JkQriG51nxI8SeEEEIIIYQQLYAUfx5MKXWHUmqXUipRKfW6UspbKZWvlHpeKbVHKfWlUqqDbdlopdS3SqkkpdQ6pVSo7fbLlVKblVJ7bffpZVt9kFLqA6XUYaXUWqWUsi2/TCl10Lae5U301IVwGckzIcwneSaEa0iueT4p/jyUUqo/cAswVmsdDZQDs4DWwB6t9TBgK/CE7S7/BB7WWg8G9lW5fS2wQms9BBgDpNluHwo8AAwAegJjlVLtgJuAgbb1PGXusxSiaUmeCWE+yTMhXENyrWWQ4s9zXQMMB3YrpRJt13sCVuA92zL/B1yplAoB2mqtt9puXw3EKqWCga5a63UAWutirXWhbZldWutUrbUVSAQigVygGHhLKTUDsC8rhKeSPBPCfJJnQriG5FoLIMWf51LAaq11tO2vr9Z6iZPldD3rqE1JlcvlgI/W2gJcAXwI3Aj89yJjFsLdSJ4JYT7JMyFcQ3KtBZDiz3N9CcxUSnUEUEq1U0p1x3jNZ9qWuR3YobXOAbKUUuNst98JbNVa5wKpSqkbbevwV0q1qu0BlVJBQIjWeiPGYf1oM56YEM2I5JkQ5pM8E8I1JNdaAJ+mDkCYQ2t9UCn1J+ALpZQXUAbcCxQAA5VSCUAORt9ugDnAa7YE/QG4y3b7ncDrSqmltnXcXMfDBgOfKKUCMH75+V0jPy0hmhXJMyHMJ3kmhGtIrrUMSuu6jtwKT6OUytdaBzV1HEJ4MskzIcwneSaEa0iueRbpGicP2QAAAFZJREFU9imEEEIIIYQQLYAc+RNCCCGEEEKIFkCO/AkhhBBCCCFECyDFnxBCCCGEEEK0AFL8CSGEEEIIIUQLIMWfEEIIIYQQQrQAUvwJIYQQQgghRAvw/6zOjW5UE4StAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_scale_list = np.logspace(0, -4, num=16)\n",
    "x = np.arange(max_epochs)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i, w in enumerate(weight_scale_list):\n",
    "    print('==========' + str(i+1) + '/16' + '==========')\n",
    "    train_acc_list, bn_train_acc_list = __train(w)\n",
    "    \n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.title('W:' + str(w))\n",
    "    if i == 15:\n",
    "        plt.plot(x, bn_train_acc_list, label='Batch Normalizeatio', markevery=2)\n",
    "        plt.plot(x, train_acc_list, linestyle='--', label='Normal(without BatchNorm)', markevery=2)\n",
    "    else:\n",
    "        plt.plot(x, bn_train_acc_list, markevery=2)\n",
    "        plt.plot(x, train_acc_list, linestyle='--', markevery=2)\n",
    "        \n",
    "    plt.ylim(0, 1.0)\n",
    "    if i % 4:\n",
    "        plt.yticks([])\n",
    "    else:\n",
    "        plt.ylabel('accuracy')\n",
    "    if i < 12:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('epochs')\n",
    "    plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 최적화 구하기\n",
    "> 최적화의 핵심은 하이퍼파라미터의 '최적값'이 존재하는 범위를 조금씩 줄여간다는 것.<br>\n",
    "대략적인 범위를 설정하고 그 범위에서 무작위로 값을 샘플링 후 그 값으로 정확도를 평가한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋을 사용하여 학습진도 차이를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.util import shuffle_dataset\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 불러와서 테스트용으로 데이터 양을 줄인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:500]\n",
    "t_train = t_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MNIST는 검증 데이터가 따로 없다. 훈련 데이터에서 20% 정도를 분리해서 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rate = 0.20\n",
    "validation_num = int(x_train.shape[0] * validation_rate)\n",
    "x_train, t_train = shuffle_dataset(x_train, t_train)\n",
    "x_val = x_train[:validation_num]\n",
    "t_val = t_train[:validation_num]\n",
    "x_train = x_train[validation_num:]\n",
    "t_train = t_train[validation_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __train(lr, weight_decay, epochs=50):\n",
    "    network = MultiLayerNet(input_size=784,\n",
    "                            hidden_size_list=[100 for _ in range(6)],\n",
    "                            output_size=10,\n",
    "                            weight_decay_lambda=weight_decay,\n",
    "    )\n",
    "    trainer = Trainer(network, x_train, t_train, x_val, t_val,\n",
    "                      epochs=epochs, mini_batch_size=100,\n",
    "                      optimizer='sgd', optimizer_param={'lr': lr}, verbose=True,\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer.test_acc_list, trainer.train_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4365707250076265\n",
      "=== epoch:1, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.3902507956736208\n",
      "train loss:2.448883921107657\n",
      "train loss:2.3686358343327987\n",
      "train loss:2.448976428752847\n",
      "=== epoch:2, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.4170950222483003\n",
      "train loss:2.4724664175570923\n",
      "train loss:2.3500288830170026\n",
      "train loss:2.396781791798814\n",
      "=== epoch:3, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.3847794227732253\n",
      "train loss:2.41610870156877\n",
      "train loss:2.389676565094848\n",
      "train loss:2.418703011598976\n",
      "=== epoch:4, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.4472413990253292\n",
      "train loss:2.3878673626134153\n",
      "train loss:2.440406805341973\n",
      "train loss:2.4251953054899946\n",
      "=== epoch:5, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4133160767870154\n",
      "train loss:2.412109984400908\n",
      "train loss:2.5438161194603426\n",
      "train loss:2.3200981219707955\n",
      "=== epoch:6, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4705072182795393\n",
      "train loss:2.4465503033469584\n",
      "train loss:2.388892065416239\n",
      "train loss:2.5197331547592263\n",
      "=== epoch:7, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4145176686547725\n",
      "train loss:2.4672314898505\n",
      "train loss:2.3897653193939568\n",
      "train loss:2.476021599347297\n",
      "=== epoch:8, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.441234419020787\n",
      "train loss:2.6057822529311614\n",
      "train loss:2.379291154707675\n",
      "train loss:2.5020338255158805\n",
      "=== epoch:9, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.35435903292314\n",
      "train loss:2.419904200279179\n",
      "train loss:2.53060172136302\n",
      "train loss:2.338992840113339\n",
      "=== epoch:10, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.435461686259304\n",
      "train loss:2.392772111907872\n",
      "train loss:2.457346682623551\n",
      "train loss:2.3833377753230187\n",
      "=== epoch:11, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.353752719908595\n",
      "train loss:2.410022878054002\n",
      "train loss:2.5333144275434094\n",
      "train loss:2.450121516543806\n",
      "=== epoch:12, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.478305469142767\n",
      "train loss:2.398482278813195\n",
      "train loss:2.3745956470080563\n",
      "train loss:2.332093977309896\n",
      "=== epoch:13, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.430498864175144\n",
      "train loss:2.4609739763407052\n",
      "train loss:2.399683682738894\n",
      "train loss:2.3541517749486505\n",
      "=== epoch:14, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4267750263811423\n",
      "train loss:2.3438810900125007\n",
      "train loss:2.438737752663106\n",
      "train loss:2.4465581448995364\n",
      "=== epoch:15, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.390599487101087\n",
      "train loss:2.380422191367508\n",
      "train loss:2.353667648523297\n",
      "train loss:2.4243705802827233\n",
      "=== epoch:16, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.470523405181371\n",
      "train loss:2.4487226541465437\n",
      "train loss:2.4863349802871264\n",
      "train loss:2.462539948480377\n",
      "=== epoch:17, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.304794423860942\n",
      "train loss:2.393771505574277\n",
      "train loss:2.470628997534104\n",
      "train loss:2.4369978773617214\n",
      "=== epoch:18, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.472785491481146\n",
      "train loss:2.496024269310577\n",
      "train loss:2.3854917286049973\n",
      "train loss:2.440957269003761\n",
      "=== epoch:19, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.5567148670903914\n",
      "train loss:2.5780062753637987\n",
      "train loss:2.4080153118365275\n",
      "train loss:2.54234902316317\n",
      "=== epoch:20, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.372224575876665\n",
      "train loss:2.271765841664409\n",
      "train loss:2.4947896489692827\n",
      "train loss:2.4806994012919468\n",
      "=== epoch:21, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.3605933718362646\n",
      "train loss:2.458217498563818\n",
      "train loss:2.4108364103275415\n",
      "train loss:2.3774727400475446\n",
      "=== epoch:22, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4960363102983103\n",
      "train loss:2.429075983065842\n",
      "train loss:2.4089836495354113\n",
      "train loss:2.3919283734710106\n",
      "=== epoch:23, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.376981200633879\n",
      "train loss:2.4864600251199533\n",
      "train loss:2.442781940620903\n",
      "train loss:2.436403305929512\n",
      "=== epoch:24, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.3572127331286876\n",
      "train loss:2.4988987510449854\n",
      "train loss:2.4603183944098457\n",
      "train loss:2.4762380681634233\n",
      "=== epoch:25, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.3935492927370947\n",
      "train loss:2.4588552350115003\n",
      "train loss:2.4032021952842233\n",
      "train loss:2.401661873869738\n",
      "=== epoch:26, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.378448214288227\n",
      "train loss:2.403875349847124\n",
      "train loss:2.440781749091809\n",
      "train loss:2.392077797286212\n",
      "=== epoch:27, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.41900276409635\n",
      "train loss:2.54779557948927\n",
      "train loss:2.4697200742863035\n",
      "train loss:2.4653354810002477\n",
      "=== epoch:28, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.5011641128600504\n",
      "train loss:2.36589066232844\n",
      "train loss:2.4268424620839726\n",
      "train loss:2.466439438604473\n",
      "=== epoch:29, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.376326427218792\n",
      "train loss:2.418107219996784\n",
      "train loss:2.3677787608619396\n",
      "train loss:2.395307995206719\n",
      "=== epoch:30, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.467204241417947\n",
      "train loss:2.396168218935552\n",
      "train loss:2.4577147680418663\n",
      "train loss:2.4146374903571024\n",
      "=== epoch:31, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.54106092242679\n",
      "train loss:2.381486283625155\n",
      "train loss:2.383706612870463\n",
      "train loss:2.42574602023393\n",
      "=== epoch:32, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.3962436586286584\n",
      "train loss:2.550552707156462\n",
      "train loss:2.4406528812211956\n",
      "train loss:2.5181392695561953\n",
      "=== epoch:33, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4626170750621568\n",
      "train loss:2.4439295038060136\n",
      "train loss:2.4315912267472775\n",
      "train loss:2.382700698947884\n",
      "=== epoch:34, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4777022108997744\n",
      "train loss:2.5392468811183617\n",
      "train loss:2.5064642125751906\n",
      "train loss:2.451832581666549\n",
      "=== epoch:35, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.453687123130164\n",
      "train loss:2.411120653727225\n",
      "train loss:2.370340388008556\n",
      "train loss:2.3819660086670185\n",
      "=== epoch:36, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.509424101662793\n",
      "train loss:2.3243610777227697\n",
      "train loss:2.41073484854036\n",
      "train loss:2.573800267940886\n",
      "=== epoch:37, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.398243223841628\n",
      "train loss:2.348259640393182\n",
      "train loss:2.3443262826270854\n",
      "train loss:2.454175189246617\n",
      "=== epoch:38, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.418043680672309\n",
      "train loss:2.405558304205674\n",
      "train loss:2.428018371848852\n",
      "train loss:2.46879178099849\n",
      "=== epoch:39, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.470458775650837\n",
      "train loss:2.450161292405568\n",
      "train loss:2.469915685550035\n",
      "train loss:2.4505972395536664\n",
      "=== epoch:40, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.4546036393179285\n",
      "train loss:2.474848898164626\n",
      "train loss:2.407255506988802\n",
      "train loss:2.443772352534575\n",
      "=== epoch:41, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.3040748734355616\n",
      "train loss:2.4034001776419185\n",
      "train loss:2.39372531666074\n",
      "train loss:2.493304784049274\n",
      "=== epoch:42, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.4570024783966438\n",
      "train loss:2.4834231750577698\n",
      "train loss:2.411769113085058\n",
      "train loss:2.4550718764413104\n",
      "=== epoch:43, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.3771642094201106\n",
      "train loss:2.3564845852896372\n",
      "train loss:2.4683348572240322\n",
      "train loss:2.4183668565350853\n",
      "=== epoch:44, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.5034320273593935\n",
      "train loss:2.4497122859533316\n",
      "train loss:2.3361566025104676\n",
      "train loss:2.5428875095336045\n",
      "=== epoch:45, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.428631553587113\n",
      "train loss:2.3997331441227443\n",
      "train loss:2.4778338252738608\n",
      "train loss:2.3981980546452175\n",
      "=== epoch:46, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.413111808142515\n",
      "train loss:2.3966839924976617\n",
      "train loss:2.303828863460218\n",
      "train loss:2.36113919092603\n",
      "=== epoch:47, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.38376207900211\n",
      "train loss:2.4191242063623855\n",
      "train loss:2.4439246353533046\n",
      "train loss:2.4275173616764\n",
      "=== epoch:48, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.4486875638357635\n",
      "train loss:2.4413430342918927\n",
      "train loss:2.4091766031905277\n",
      "train loss:2.3794618792006257\n",
      "=== epoch:49, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.378721281515726\n",
      "train loss:2.536119112085043\n",
      "train loss:2.4128252355391484\n",
      "train loss:2.475181321049038\n",
      "=== epoch:50, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.382548939204045\n",
      "train loss:2.4523205010975757\n",
      "train loss:2.441282255550973\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.08\n",
      "val_acc: 0.0800 | lr: 0.0000, weight_decay: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4174363330494857\n",
      "=== epoch:1, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4458500327970585\n",
      "train loss:2.4682183530754216\n",
      "train loss:2.502223588078713\n",
      "train loss:2.566430735367473\n",
      "=== epoch:2, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.5031767893975028\n",
      "train loss:2.430496930256888\n",
      "train loss:2.471989946772015\n",
      "train loss:2.5487778967081756\n",
      "=== epoch:3, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4388382257856187\n",
      "train loss:2.507690704495185\n",
      "train loss:2.41789627432079\n",
      "train loss:2.49001272660275\n",
      "=== epoch:4, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.470507379889822\n",
      "train loss:2.561162961476489\n",
      "train loss:2.4449711120316224\n",
      "train loss:2.380190576161172\n",
      "=== epoch:5, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4610246929944037\n",
      "train loss:2.5097753624451844\n",
      "train loss:2.526759477535059\n",
      "train loss:2.481339018728299\n",
      "=== epoch:6, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.45586700750805\n",
      "train loss:2.407009384369929\n",
      "train loss:2.47541988454887\n",
      "train loss:2.45708823294425\n",
      "=== epoch:7, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.341651003054543\n",
      "train loss:2.4564660876061613\n",
      "train loss:2.5050920485613424\n",
      "train loss:2.4053591468159854\n",
      "=== epoch:8, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.437218972954772\n",
      "train loss:2.4917690493957037\n",
      "train loss:2.5735466915983314\n",
      "train loss:2.4677542751013384\n",
      "=== epoch:9, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.421297591765526\n",
      "train loss:2.425252866975423\n",
      "train loss:2.46905349389684\n",
      "train loss:2.416937205186247\n",
      "=== epoch:10, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4832606999050086\n",
      "train loss:2.4547456087071575\n",
      "train loss:2.5228149563144187\n",
      "train loss:2.4935877898003707\n",
      "=== epoch:11, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.5690943086300186\n",
      "train loss:2.502030188121947\n",
      "train loss:2.4361007790666713\n",
      "train loss:2.4312503136043215\n",
      "=== epoch:12, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.5102035672400866\n",
      "train loss:2.4476384694119515\n",
      "train loss:2.487259497314128\n",
      "train loss:2.492404745865273\n",
      "=== epoch:13, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4907384507651544\n",
      "train loss:2.386160028294264\n",
      "train loss:2.503126264444902\n",
      "train loss:2.4456239299607883\n",
      "=== epoch:14, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4620387852361634\n",
      "train loss:2.4892312075516285\n",
      "train loss:2.4282807387038163\n",
      "train loss:2.473804321300636\n",
      "=== epoch:15, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.566973749482044\n",
      "train loss:2.4486613969539763\n",
      "train loss:2.452648528633838\n",
      "train loss:2.418236600722384\n",
      "=== epoch:16, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.5128239790422295\n",
      "train loss:2.44005238092292\n",
      "train loss:2.379067725134164\n",
      "train loss:2.433862035215741\n",
      "=== epoch:17, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.481764630231175\n",
      "train loss:2.410485335528023\n",
      "train loss:2.5070162947554318\n",
      "train loss:2.4421871059502807\n",
      "=== epoch:18, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.5040860946059755\n",
      "train loss:2.469308843105982\n",
      "train loss:2.4502250991358787\n",
      "train loss:2.5025793547861452\n",
      "=== epoch:19, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4366662374764374\n",
      "train loss:2.4535435131498713\n",
      "train loss:2.4409501773757754\n",
      "train loss:2.3951745521739634\n",
      "=== epoch:20, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.5575718432209786\n",
      "train loss:2.3979611989701737\n",
      "train loss:2.4099528576101323\n",
      "train loss:2.4006749430822545\n",
      "=== epoch:21, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.45024337149547\n",
      "train loss:2.407347230454331\n",
      "train loss:2.4206166137194383\n",
      "train loss:2.429833940880244\n",
      "=== epoch:22, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4970061462756887\n",
      "train loss:2.4317637912066554\n",
      "train loss:2.4587207262161943\n",
      "train loss:2.469478343886408\n",
      "=== epoch:23, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.3923092402255586\n",
      "train loss:2.4107311157915223\n",
      "train loss:2.5384748235342367\n",
      "train loss:2.38587540656839\n",
      "=== epoch:24, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.444981021219524\n",
      "train loss:2.404974587484465\n",
      "train loss:2.4733183008754978\n",
      "train loss:2.4570546347324806\n",
      "=== epoch:25, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.418009390472837\n",
      "train loss:2.5815316763968634\n",
      "train loss:2.49851245664454\n",
      "train loss:2.3626869591628616\n",
      "=== epoch:26, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4470593372352423\n",
      "train loss:2.4614470951115432\n",
      "train loss:2.417953566610126\n",
      "train loss:2.4110508754533364\n",
      "=== epoch:27, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4012735354739463\n",
      "train loss:2.4663462840952284\n",
      "train loss:2.427970453433279\n",
      "train loss:2.49975080650356\n",
      "=== epoch:28, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4486078277137553\n",
      "train loss:2.433719262950376\n",
      "train loss:2.4942947498890944\n",
      "train loss:2.392525749974085\n",
      "=== epoch:29, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.4209254350967226\n",
      "train loss:2.4462111189456404\n",
      "train loss:2.3535159656293465\n",
      "train loss:2.3741604669207006\n",
      "=== epoch:30, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.470005406491324\n",
      "train loss:2.506101142900088\n",
      "train loss:2.5194625733638785\n",
      "train loss:2.470015650366588\n",
      "=== epoch:31, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.379652337473562\n",
      "train loss:2.4876733619934703\n",
      "train loss:2.44353511352427\n",
      "train loss:2.4393129215365605\n",
      "=== epoch:32, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.3974233555521294\n",
      "train loss:2.4515573232465306\n",
      "train loss:2.473930397608545\n",
      "train loss:2.5255429157654725\n",
      "=== epoch:33, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.433694008586375\n",
      "train loss:2.443634967272986\n",
      "train loss:2.459605008848179\n",
      "train loss:2.5324918206896796\n",
      "=== epoch:34, train acc:0.0975, test acc:0.2 ===\n",
      "train loss:2.3959793491841688\n",
      "train loss:2.4559432315759624\n",
      "train loss:2.414504060746136\n",
      "train loss:2.4309576707530187\n",
      "=== epoch:35, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.479314900933789\n",
      "train loss:2.433354128422343\n",
      "train loss:2.4471416080706674\n",
      "train loss:2.4706583142224283\n",
      "=== epoch:36, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.370255165053911\n",
      "train loss:2.43098756086706\n",
      "train loss:2.432253996172648\n",
      "train loss:2.492313412520519\n",
      "=== epoch:37, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.439238988869029\n",
      "train loss:2.478580940571908\n",
      "train loss:2.3928651032018258\n",
      "train loss:2.489721738204503\n",
      "=== epoch:38, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.433385896347989\n",
      "train loss:2.460324950572732\n",
      "train loss:2.4119274633515726\n",
      "train loss:2.360423483602493\n",
      "=== epoch:39, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.4533071674938287\n",
      "train loss:2.4098394859665757\n",
      "train loss:2.501944624402725\n",
      "train loss:2.465722852172696\n",
      "=== epoch:40, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.435315571878378\n",
      "train loss:2.463419583099496\n",
      "train loss:2.448547729431933\n",
      "train loss:2.4673114452067253\n",
      "=== epoch:41, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.4741820063953193\n",
      "train loss:2.425787603204384\n",
      "train loss:2.4887306256041786\n",
      "train loss:2.423629151197655\n",
      "=== epoch:42, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.4628033925226016\n",
      "train loss:2.404019649739948\n",
      "train loss:2.474297294557985\n",
      "train loss:2.43965183353664\n",
      "=== epoch:43, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.4615565135252115\n",
      "train loss:2.4634929115675996\n",
      "train loss:2.4503564486939284\n",
      "train loss:2.4836860615922633\n",
      "=== epoch:44, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.484254613631335\n",
      "train loss:2.4528961827419877\n",
      "train loss:2.394215574203013\n",
      "train loss:2.4854291067007273\n",
      "=== epoch:45, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.3851139135812134\n",
      "train loss:2.4277820451647707\n",
      "train loss:2.4821133431105933\n",
      "train loss:2.447381586877394\n",
      "=== epoch:46, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.4353049490126026\n",
      "train loss:2.4837791290269595\n",
      "train loss:2.445065439804081\n",
      "train loss:2.3814935883869994\n",
      "=== epoch:47, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.4747959724055697\n",
      "train loss:2.4893845721475025\n",
      "train loss:2.4287984638021083\n",
      "train loss:2.515269735807112\n",
      "=== epoch:48, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.4818089841679702\n",
      "train loss:2.4789460446154483\n",
      "train loss:2.4058436611977267\n",
      "train loss:2.3943426392766924\n",
      "=== epoch:49, train acc:0.0975, test acc:0.19 ===\n",
      "train loss:2.4142172656194933\n",
      "train loss:2.498819838011608\n",
      "train loss:2.4427727976857794\n",
      "train loss:2.421583422249232\n",
      "=== epoch:50, train acc:0.1025, test acc:0.19 ===\n",
      "train loss:2.5048869604007473\n",
      "train loss:2.4409766070569723\n",
      "train loss:2.3932218498353506\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.19\n",
      "val_acc: 0.1900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.272895291119115\n",
      "=== epoch:1, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.290789293548345\n",
      "train loss:2.342742025637922\n",
      "train loss:2.3742493886855325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.325442010318178\n",
      "=== epoch:2, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.31275933765995\n",
      "train loss:2.3444534311959964\n",
      "train loss:2.3669334720787814\n",
      "train loss:2.328110229193937\n",
      "=== epoch:3, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3081837689466087\n",
      "train loss:2.3403596379656517\n",
      "train loss:2.3557199869367165\n",
      "train loss:2.332121879766479\n",
      "=== epoch:4, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.347106561975337\n",
      "train loss:2.3663611020206345\n",
      "train loss:2.3348267237988147\n",
      "train loss:2.3091977674261708\n",
      "=== epoch:5, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3168898449782565\n",
      "train loss:2.344189987573877\n",
      "train loss:2.3252779213451724\n",
      "train loss:2.3905066607881182\n",
      "=== epoch:6, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3361386091603444\n",
      "train loss:2.337034763794825\n",
      "train loss:2.3741642258304\n",
      "train loss:2.3520858507211546\n",
      "=== epoch:7, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.2848539998943354\n",
      "train loss:2.313371115810347\n",
      "train loss:2.365674047133244\n",
      "train loss:2.3479501572601578\n",
      "=== epoch:8, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3275417188850884\n",
      "train loss:2.3528988014997547\n",
      "train loss:2.300358532163189\n",
      "train loss:2.28458973643191\n",
      "=== epoch:9, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3303479103477933\n",
      "train loss:2.347339481801196\n",
      "train loss:2.3495029571817825\n",
      "train loss:2.355594441436707\n",
      "=== epoch:10, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.33823703695883\n",
      "train loss:2.362749858184643\n",
      "train loss:2.3286181304000473\n",
      "train loss:2.3166656105698347\n",
      "=== epoch:11, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3238349188058143\n",
      "train loss:2.341100822233813\n",
      "train loss:2.3213831169557566\n",
      "train loss:2.292882765954977\n",
      "=== epoch:12, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.4059497462334853\n",
      "train loss:2.3583229168684383\n",
      "train loss:2.3426434079546343\n",
      "train loss:2.332233646795453\n",
      "=== epoch:13, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3115588342275397\n",
      "train loss:2.3546093050959045\n",
      "train loss:2.345512451673423\n",
      "train loss:2.3189230473936937\n",
      "=== epoch:14, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.327756314477917\n",
      "train loss:2.3290662570685607\n",
      "train loss:2.306413972545633\n",
      "train loss:2.3160312079378143\n",
      "=== epoch:15, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.344222824973714\n",
      "train loss:2.3515092135996047\n",
      "train loss:2.317805186854292\n",
      "train loss:2.3377870124583913\n",
      "=== epoch:16, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3255382105848654\n",
      "train loss:2.332437443388436\n",
      "train loss:2.299662414927377\n",
      "train loss:2.281989699111918\n",
      "=== epoch:17, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.331217891426694\n",
      "train loss:2.3310600712179577\n",
      "train loss:2.3471406081662574\n",
      "train loss:2.322926238841597\n",
      "=== epoch:18, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.307882669797935\n",
      "train loss:2.3286020252643347\n",
      "train loss:2.293858051490879\n",
      "train loss:2.37422053946841\n",
      "=== epoch:19, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3291454847043735\n",
      "train loss:2.333433985728352\n",
      "train loss:2.335964405606894\n",
      "train loss:2.365406420266208\n",
      "=== epoch:20, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3140798633612363\n",
      "train loss:2.3549385387227892\n",
      "train loss:2.3340098771326714\n",
      "train loss:2.3194753210683525\n",
      "=== epoch:21, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3118456392995865\n",
      "train loss:2.338363644883804\n",
      "train loss:2.3585189814045506\n",
      "train loss:2.3418102404680496\n",
      "=== epoch:22, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3450541941705367\n",
      "train loss:2.3164935736580055\n",
      "train loss:2.3226918402865766\n",
      "train loss:2.3218773526442296\n",
      "=== epoch:23, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3208538071129574\n",
      "train loss:2.3252058634839674\n",
      "train loss:2.3102400441452113\n",
      "train loss:2.3078028816680574\n",
      "=== epoch:24, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.33739662202118\n",
      "train loss:2.327869730065867\n",
      "train loss:2.2986177709734052\n",
      "train loss:2.3349960869013433\n",
      "=== epoch:25, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.343998448033179\n",
      "train loss:2.339985050629911\n",
      "train loss:2.3473841711938896\n",
      "train loss:2.3306418173918058\n",
      "=== epoch:26, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.2925119919479124\n",
      "train loss:2.299220883097866\n",
      "train loss:2.3436423461801708\n",
      "train loss:2.3298145502588943\n",
      "=== epoch:27, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3350071945538025\n",
      "train loss:2.327135742360717\n",
      "train loss:2.345307053389878\n",
      "train loss:2.3097292447507782\n",
      "=== epoch:28, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3379920201852813\n",
      "train loss:2.302332548524765\n",
      "train loss:2.3422800871003613\n",
      "train loss:2.311893531045775\n",
      "=== epoch:29, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.34108489766055\n",
      "train loss:2.315492059727523\n",
      "train loss:2.3241275871616667\n",
      "train loss:2.3480268870234466\n",
      "=== epoch:30, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3610867303310488\n",
      "train loss:2.2932245134145113\n",
      "train loss:2.3172596350863763\n",
      "train loss:2.288069933900197\n",
      "=== epoch:31, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3441789073160026\n",
      "train loss:2.3346511990654717\n",
      "train loss:2.3471609458222282\n",
      "train loss:2.3487293660547075\n",
      "=== epoch:32, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.3436706233519673\n",
      "train loss:2.301510430480297\n",
      "train loss:2.3165990747898\n",
      "train loss:2.366825412426068\n",
      "=== epoch:33, train acc:0.0675, test acc:0.06 ===\n",
      "train loss:2.3404889715877006\n",
      "train loss:2.2983376202942143\n",
      "train loss:2.2885297722095905\n",
      "train loss:2.30098241532496\n",
      "=== epoch:34, train acc:0.0675, test acc:0.06 ===\n",
      "train loss:2.3261149200353963\n",
      "train loss:2.3642201955277367\n",
      "train loss:2.3318394601189505\n",
      "train loss:2.331120549466397\n",
      "=== epoch:35, train acc:0.0675, test acc:0.06 ===\n",
      "train loss:2.2982164928473283\n",
      "train loss:2.3080907988209374\n",
      "train loss:2.345724333200734\n",
      "train loss:2.3009113476540013\n",
      "=== epoch:36, train acc:0.0675, test acc:0.06 ===\n",
      "train loss:2.3468260492557205\n",
      "train loss:2.3830275574174524\n",
      "train loss:2.3366560051617165\n",
      "train loss:2.3203627317608375\n",
      "=== epoch:37, train acc:0.0675, test acc:0.06 ===\n",
      "train loss:2.3167169124749045\n",
      "train loss:2.3530841782732344\n",
      "train loss:2.334627474883337\n",
      "train loss:2.3475296987114787\n",
      "=== epoch:38, train acc:0.07, test acc:0.06 ===\n",
      "train loss:2.3413230152746447\n",
      "train loss:2.3536188821049375\n",
      "train loss:2.3452686688504394\n",
      "train loss:2.302651078887615\n",
      "=== epoch:39, train acc:0.07, test acc:0.06 ===\n",
      "train loss:2.342641443925738\n",
      "train loss:2.301495000211424\n",
      "train loss:2.317260402892118\n",
      "train loss:2.341936176140414\n",
      "=== epoch:40, train acc:0.07, test acc:0.06 ===\n",
      "train loss:2.342616495391192\n",
      "train loss:2.317934816223596\n",
      "train loss:2.3055787831618217\n",
      "train loss:2.2980389742532794\n",
      "=== epoch:41, train acc:0.07, test acc:0.06 ===\n",
      "train loss:2.325109930529805\n",
      "train loss:2.2965366688850213\n",
      "train loss:2.3692733709466642\n",
      "train loss:2.3474895533615836\n",
      "=== epoch:42, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3022812631937493\n",
      "train loss:2.3382748390444617\n",
      "train loss:2.333942791652895\n",
      "train loss:2.297832246356654\n",
      "=== epoch:43, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3240693917653683\n",
      "train loss:2.35693083385473\n",
      "train loss:2.3026035042689736\n",
      "train loss:2.366969006489399\n",
      "=== epoch:44, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3441090958602095\n",
      "train loss:2.3663603759329264\n",
      "train loss:2.3255247692762913\n",
      "train loss:2.3236178668303737\n",
      "=== epoch:45, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3032937949571655\n",
      "train loss:2.320999249342251\n",
      "train loss:2.3153240675689157\n",
      "train loss:2.335921913149683\n",
      "=== epoch:46, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3033229535476725\n",
      "train loss:2.3616214919141525\n",
      "train loss:2.3447045135645155\n",
      "train loss:2.2764114574152465\n",
      "=== epoch:47, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.321703101978549\n",
      "train loss:2.3011503391973345\n",
      "train loss:2.2993787335384295\n",
      "train loss:2.3347010326550093\n",
      "=== epoch:48, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3479507673748468\n",
      "train loss:2.345004621213547\n",
      "train loss:2.332006975457879\n",
      "train loss:2.32504320475135\n",
      "=== epoch:49, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3028926427878673\n",
      "train loss:2.3443399020603657\n",
      "train loss:2.3022667178240344\n",
      "train loss:2.3250523360213284\n",
      "=== epoch:50, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3225606968800707\n",
      "train loss:2.2798313985029757\n",
      "train loss:2.352088142877478\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.06\n",
      "val_acc: 0.0600 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.411586888469556\n",
      "=== epoch:1, train acc:0.115, test acc:0.11 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.345381950569681\n",
      "train loss:2.3554320197657064\n",
      "train loss:2.360649287586213\n",
      "train loss:2.3806734821682007\n",
      "=== epoch:2, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.3605598846512152\n",
      "train loss:2.298748750851142\n",
      "train loss:2.306416002755872\n",
      "train loss:2.370457984466565\n",
      "=== epoch:3, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.337690864972702\n",
      "train loss:2.270210870520178\n",
      "train loss:2.2408392549265654\n",
      "train loss:2.302911960982414\n",
      "=== epoch:4, train acc:0.13, test acc:0.11 ===\n",
      "train loss:2.300458597132948\n",
      "train loss:2.316008894870868\n",
      "train loss:2.2864367126133853\n",
      "train loss:2.2856464757678805\n",
      "=== epoch:5, train acc:0.13, test acc:0.12 ===\n",
      "train loss:2.2592888103151827\n",
      "train loss:2.2783207632755085\n",
      "train loss:2.295640577716044\n",
      "train loss:2.266399483797215\n",
      "=== epoch:6, train acc:0.1475, test acc:0.12 ===\n",
      "train loss:2.230381361953187\n",
      "train loss:2.275424966466375\n",
      "train loss:2.260938124562673\n",
      "train loss:2.2345533108414677\n",
      "=== epoch:7, train acc:0.1625, test acc:0.13 ===\n",
      "train loss:2.2726689123086805\n",
      "train loss:2.236398400476723\n",
      "train loss:2.218160309097429\n",
      "train loss:2.252999909733483\n",
      "=== epoch:8, train acc:0.1775, test acc:0.13 ===\n",
      "train loss:2.210800685260544\n",
      "train loss:2.2747904921052435\n",
      "train loss:2.2336696457193783\n",
      "train loss:2.207724254147048\n",
      "=== epoch:9, train acc:0.1875, test acc:0.14 ===\n",
      "train loss:2.216269473049793\n",
      "train loss:2.197730101285601\n",
      "train loss:2.1940184572722154\n",
      "train loss:2.1680401487276963\n",
      "=== epoch:10, train acc:0.2, test acc:0.15 ===\n",
      "train loss:2.248145196264659\n",
      "train loss:2.205942674518347\n",
      "train loss:2.1840397928932473\n",
      "train loss:2.2026686112109974\n",
      "=== epoch:11, train acc:0.2125, test acc:0.14 ===\n",
      "train loss:2.171879827097368\n",
      "train loss:2.189259114444596\n",
      "train loss:2.1982726356966427\n",
      "train loss:2.1662785419801103\n",
      "=== epoch:12, train acc:0.225, test acc:0.18 ===\n",
      "train loss:2.155227551508043\n",
      "train loss:2.2074732691378407\n",
      "train loss:2.126497583257388\n",
      "train loss:2.136466131716377\n",
      "=== epoch:13, train acc:0.2325, test acc:0.21 ===\n",
      "train loss:2.220678166458445\n",
      "train loss:2.1463380701857124\n",
      "train loss:2.135229129377011\n",
      "train loss:2.1578497647554515\n",
      "=== epoch:14, train acc:0.245, test acc:0.24 ===\n",
      "train loss:2.1678443430549996\n",
      "train loss:2.139140350727002\n",
      "train loss:2.13948482567781\n",
      "train loss:2.203798109016546\n",
      "=== epoch:15, train acc:0.265, test acc:0.23 ===\n",
      "train loss:2.1553150927188094\n",
      "train loss:2.160405103851855\n",
      "train loss:2.0841372027314318\n",
      "train loss:2.175755277160473\n",
      "=== epoch:16, train acc:0.265, test acc:0.25 ===\n",
      "train loss:2.126954898175829\n",
      "train loss:2.17868845070693\n",
      "train loss:2.089737302493325\n",
      "train loss:2.0437012755815167\n",
      "=== epoch:17, train acc:0.2725, test acc:0.28 ===\n",
      "train loss:2.156113961673452\n",
      "train loss:2.155528365892035\n",
      "train loss:2.12100668146815\n",
      "train loss:2.1278787851957794\n",
      "=== epoch:18, train acc:0.28, test acc:0.26 ===\n",
      "train loss:2.0876694418602035\n",
      "train loss:2.0840572657685117\n",
      "train loss:2.1089016645104826\n",
      "train loss:2.155322237261141\n",
      "=== epoch:19, train acc:0.295, test acc:0.28 ===\n",
      "train loss:2.0793589237790235\n",
      "train loss:2.081842588810063\n",
      "train loss:2.0750714141185567\n",
      "train loss:2.080037837267255\n",
      "=== epoch:20, train acc:0.3025, test acc:0.28 ===\n",
      "train loss:2.157491074164501\n",
      "train loss:2.115693224556099\n",
      "train loss:2.12306013507701\n",
      "train loss:2.134118573840402\n",
      "=== epoch:21, train acc:0.3225, test acc:0.3 ===\n",
      "train loss:2.072532433927327\n",
      "train loss:2.1078043865073854\n",
      "train loss:2.108897494332808\n",
      "train loss:2.0515088138027067\n",
      "=== epoch:22, train acc:0.32, test acc:0.28 ===\n",
      "train loss:2.0505745649537728\n",
      "train loss:2.079817685403452\n",
      "train loss:2.0388706295316674\n",
      "train loss:2.040501297699795\n",
      "=== epoch:23, train acc:0.3175, test acc:0.29 ===\n",
      "train loss:2.050807901836835\n",
      "train loss:2.0749000358791645\n",
      "train loss:2.105964595112768\n",
      "train loss:2.054171388423508\n",
      "=== epoch:24, train acc:0.32, test acc:0.3 ===\n",
      "train loss:2.0495889812369725\n",
      "train loss:2.0785876672177688\n",
      "train loss:2.051866655288022\n",
      "train loss:1.9962629555034221\n",
      "=== epoch:25, train acc:0.33, test acc:0.3 ===\n",
      "train loss:2.0999918662054275\n",
      "train loss:2.0519376393814728\n",
      "train loss:2.0043746766746047\n",
      "train loss:2.027434270616824\n",
      "=== epoch:26, train acc:0.3325, test acc:0.3 ===\n",
      "train loss:2.0686442948708685\n",
      "train loss:2.046789253862311\n",
      "train loss:2.081393570313889\n",
      "train loss:1.9245595121566637\n",
      "=== epoch:27, train acc:0.3325, test acc:0.3 ===\n",
      "train loss:2.0249099721011996\n",
      "train loss:2.050900445631091\n",
      "train loss:1.9940689107264626\n",
      "train loss:1.9729382998843346\n",
      "=== epoch:28, train acc:0.345, test acc:0.31 ===\n",
      "train loss:2.0361069748308873\n",
      "train loss:1.972528375713548\n",
      "train loss:1.9571841080998849\n",
      "train loss:1.9628622604231973\n",
      "=== epoch:29, train acc:0.3475, test acc:0.33 ===\n",
      "train loss:2.020979421524602\n",
      "train loss:2.002849383408299\n",
      "train loss:2.0292353595263455\n",
      "train loss:1.993015702578141\n",
      "=== epoch:30, train acc:0.355, test acc:0.34 ===\n",
      "train loss:1.9925261424265301\n",
      "train loss:2.0060518853773255\n",
      "train loss:1.9955164905691116\n",
      "train loss:1.973675902279229\n",
      "=== epoch:31, train acc:0.3675, test acc:0.35 ===\n",
      "train loss:2.0148268307368498\n",
      "train loss:2.018983904139501\n",
      "train loss:2.0251352899839823\n",
      "train loss:2.0080986598571924\n",
      "=== epoch:32, train acc:0.3675, test acc:0.34 ===\n",
      "train loss:1.923093744318536\n",
      "train loss:1.9322820947140522\n",
      "train loss:1.9995841094489855\n",
      "train loss:1.932478200412582\n",
      "=== epoch:33, train acc:0.38, test acc:0.34 ===\n",
      "train loss:1.9553039218214379\n",
      "train loss:1.9122322009969746\n",
      "train loss:1.886149951214501\n",
      "train loss:1.948678766601405\n",
      "=== epoch:34, train acc:0.38, test acc:0.34 ===\n",
      "train loss:1.8984890801985983\n",
      "train loss:1.9432638872463255\n",
      "train loss:1.9641761023334816\n",
      "train loss:1.9481270937464283\n",
      "=== epoch:35, train acc:0.375, test acc:0.34 ===\n",
      "train loss:1.9991191482162542\n",
      "train loss:1.879017597100005\n",
      "train loss:1.9143382534264377\n",
      "train loss:1.9731815751541606\n",
      "=== epoch:36, train acc:0.3975, test acc:0.34 ===\n",
      "train loss:1.893982490194888\n",
      "train loss:1.9360114871362168\n",
      "train loss:1.8674222877918154\n",
      "train loss:1.9587815658178676\n",
      "=== epoch:37, train acc:0.4, test acc:0.34 ===\n",
      "train loss:1.8886848645697922\n",
      "train loss:1.8935746324139342\n",
      "train loss:1.8245529546426864\n",
      "train loss:1.9092250331601623\n",
      "=== epoch:38, train acc:0.395, test acc:0.33 ===\n",
      "train loss:1.914377388800122\n",
      "train loss:1.898577904347161\n",
      "train loss:1.898653569707287\n",
      "train loss:1.9563511105615465\n",
      "=== epoch:39, train acc:0.4075, test acc:0.35 ===\n",
      "train loss:1.8692604573936018\n",
      "train loss:1.9122533658771799\n",
      "train loss:1.8569202567223941\n",
      "train loss:2.0078540452675675\n",
      "=== epoch:40, train acc:0.415, test acc:0.36 ===\n",
      "train loss:1.8664652075919694\n",
      "train loss:1.8440214474319558\n",
      "train loss:1.9205902498863225\n",
      "train loss:1.8712661257145844\n",
      "=== epoch:41, train acc:0.425, test acc:0.38 ===\n",
      "train loss:1.9373508029787991\n",
      "train loss:1.878132629907345\n",
      "train loss:1.8815043041573123\n",
      "train loss:1.8470447828287044\n",
      "=== epoch:42, train acc:0.43, test acc:0.39 ===\n",
      "train loss:1.844939393663686\n",
      "train loss:1.780292076638621\n",
      "train loss:1.7625543270369088\n",
      "train loss:1.9204124037547516\n",
      "=== epoch:43, train acc:0.4375, test acc:0.4 ===\n",
      "train loss:1.9064596244003824\n",
      "train loss:1.8890214921309316\n",
      "train loss:1.8981336910515774\n",
      "train loss:1.8803955644240402\n",
      "=== epoch:44, train acc:0.455, test acc:0.4 ===\n",
      "train loss:1.855717572242357\n",
      "train loss:1.8552505801746981\n",
      "train loss:1.8503878561915839\n",
      "train loss:1.849687584680253\n",
      "=== epoch:45, train acc:0.48, test acc:0.42 ===\n",
      "train loss:1.8667621939974564\n",
      "train loss:1.8011219520113204\n",
      "train loss:1.8335429221775477\n",
      "train loss:1.8340836115559753\n",
      "=== epoch:46, train acc:0.4875, test acc:0.39 ===\n",
      "train loss:1.9096541566263099\n",
      "train loss:1.8254407195100788\n",
      "train loss:1.7811673494358182\n",
      "train loss:1.8206526923472885\n",
      "=== epoch:47, train acc:0.5, test acc:0.4 ===\n",
      "train loss:1.7827400721977185\n",
      "train loss:1.7489445407423436\n",
      "train loss:1.7271987415488905\n",
      "train loss:1.8657524410423434\n",
      "=== epoch:48, train acc:0.5075, test acc:0.42 ===\n",
      "train loss:1.7785733846322027\n",
      "train loss:1.762385907853834\n",
      "train loss:1.7974016849817533\n",
      "train loss:1.7642040003467667\n",
      "=== epoch:49, train acc:0.5125, test acc:0.44 ===\n",
      "train loss:1.7850242051189658\n",
      "train loss:1.6774080739047166\n",
      "train loss:1.7600600458433773\n",
      "train loss:1.7928168957236368\n",
      "=== epoch:50, train acc:0.5225, test acc:0.42 ===\n",
      "train loss:1.7436512988848039\n",
      "train loss:1.7358590442170307\n",
      "train loss:1.6798013056912406\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.44\n",
      "val_acc: 0.4200 | lr: 0.0025, weight_decay: 0.0000\n",
      "train loss:2.39100519082805\n",
      "=== epoch:1, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.4128735930204077\n",
      "train loss:2.401312192587991\n",
      "train loss:2.363032017055753\n",
      "train loss:2.430241750106101\n",
      "=== epoch:2, train acc:0.085, test acc:0.07 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3900603531525295\n",
      "train loss:2.404254330729707\n",
      "train loss:2.3974479439943703\n",
      "train loss:2.4005786658946224\n",
      "=== epoch:3, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.3794240385309764\n",
      "train loss:2.4332368170728835\n",
      "train loss:2.4265264179474086\n",
      "train loss:2.3994125564091457\n",
      "=== epoch:4, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.3604734075265723\n",
      "train loss:2.38314117747249\n",
      "train loss:2.4323403826278245\n",
      "train loss:2.364448339492337\n",
      "=== epoch:5, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.393236533536691\n",
      "train loss:2.360521045301672\n",
      "train loss:2.41240830531813\n",
      "train loss:2.4065681095579463\n",
      "=== epoch:6, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.4195764517800553\n",
      "train loss:2.4083609539104085\n",
      "train loss:2.3857029180722913\n",
      "train loss:2.3600127936645197\n",
      "=== epoch:7, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.4178510519612684\n",
      "train loss:2.3803100517171876\n",
      "train loss:2.41380627206224\n",
      "train loss:2.413564733620434\n",
      "=== epoch:8, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.4505161035039307\n",
      "train loss:2.405570587684259\n",
      "train loss:2.412558854782746\n",
      "train loss:2.428439176038138\n",
      "=== epoch:9, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.4168160984003295\n",
      "train loss:2.4117344454089333\n",
      "train loss:2.3880082847106885\n",
      "train loss:2.373144850460565\n",
      "=== epoch:10, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.381127475893556\n",
      "train loss:2.405887967333773\n",
      "train loss:2.3171959549533945\n",
      "train loss:2.396759434085586\n",
      "=== epoch:11, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.4168014197881944\n",
      "train loss:2.3540945405011975\n",
      "train loss:2.36389096292851\n",
      "train loss:2.4234619746551838\n",
      "=== epoch:12, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.433219915200631\n",
      "train loss:2.385974727104614\n",
      "train loss:2.429093745078679\n",
      "train loss:2.41775119081947\n",
      "=== epoch:13, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.4136309680135404\n",
      "train loss:2.3595973048515155\n",
      "train loss:2.3961912353740606\n",
      "train loss:2.3588323987410806\n",
      "=== epoch:14, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.390434216929885\n",
      "train loss:2.3512030660994045\n",
      "train loss:2.435980005047785\n",
      "train loss:2.4373216253409526\n",
      "=== epoch:15, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.4423564476356097\n",
      "train loss:2.4166261067264494\n",
      "train loss:2.4517548514754086\n",
      "train loss:2.3788192430224684\n",
      "=== epoch:16, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.346559246411643\n",
      "train loss:2.426982445425072\n",
      "train loss:2.4238509916506352\n",
      "train loss:2.367656499050405\n",
      "=== epoch:17, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4031580976851887\n",
      "train loss:2.41752957831029\n",
      "train loss:2.409695937327121\n",
      "train loss:2.3445716611880463\n",
      "=== epoch:18, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4005450786425016\n",
      "train loss:2.4394744037625524\n",
      "train loss:2.323337643016009\n",
      "train loss:2.388169657383686\n",
      "=== epoch:19, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.457198992208922\n",
      "train loss:2.4122206571772926\n",
      "train loss:2.4274012117984705\n",
      "train loss:2.357048169420533\n",
      "=== epoch:20, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.393144894852428\n",
      "train loss:2.390273599275385\n",
      "train loss:2.4013960092559423\n",
      "train loss:2.3560181900464228\n",
      "=== epoch:21, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4439004310567842\n",
      "train loss:2.3744171426748193\n",
      "train loss:2.389645341823632\n",
      "train loss:2.343787488892214\n",
      "=== epoch:22, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4241140432735224\n",
      "train loss:2.372218562390846\n",
      "train loss:2.388669088067544\n",
      "train loss:2.3779629936627873\n",
      "=== epoch:23, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4467388170177764\n",
      "train loss:2.3533833663024195\n",
      "train loss:2.4019958340735323\n",
      "train loss:2.398726455703994\n",
      "=== epoch:24, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3994817102156887\n",
      "train loss:2.3735911394028033\n",
      "train loss:2.368297713498885\n",
      "train loss:2.366912141070862\n",
      "=== epoch:25, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.416164677168978\n",
      "train loss:2.4654870158944133\n",
      "train loss:2.387336457194019\n",
      "train loss:2.3724734741584275\n",
      "=== epoch:26, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.361123184993942\n",
      "train loss:2.4290399890729035\n",
      "train loss:2.400635163936378\n",
      "train loss:2.4205239242988372\n",
      "=== epoch:27, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3783478838893815\n",
      "train loss:2.4233108005668784\n",
      "train loss:2.3897504939696317\n",
      "train loss:2.423934261708325\n",
      "=== epoch:28, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.405931016747362\n",
      "train loss:2.3665980106565123\n",
      "train loss:2.3620774317135953\n",
      "train loss:2.4034835012760665\n",
      "=== epoch:29, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3600750037265548\n",
      "train loss:2.4301931171597086\n",
      "train loss:2.419529069306091\n",
      "train loss:2.3581417206557034\n",
      "=== epoch:30, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.42771821532975\n",
      "train loss:2.388160912415502\n",
      "train loss:2.400873578545861\n",
      "train loss:2.432135376482549\n",
      "=== epoch:31, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3996966734236107\n",
      "train loss:2.3812109863566135\n",
      "train loss:2.387948807117227\n",
      "train loss:2.394541136829163\n",
      "=== epoch:32, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.369535466286491\n",
      "train loss:2.4089621233902627\n",
      "train loss:2.385734024664903\n",
      "train loss:2.4083929062775047\n",
      "=== epoch:33, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3783365118065674\n",
      "train loss:2.39754929180881\n",
      "train loss:2.3904127164623152\n",
      "train loss:2.4144699626968964\n",
      "=== epoch:34, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3587350684588\n",
      "train loss:2.3992449785714234\n",
      "train loss:2.4276926151957117\n",
      "train loss:2.40015040213585\n",
      "=== epoch:35, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3862677658943348\n",
      "train loss:2.418713993482891\n",
      "train loss:2.415057188628444\n",
      "train loss:2.40233032088257\n",
      "=== epoch:36, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3947892534866195\n",
      "train loss:2.3411883130557674\n",
      "train loss:2.3847189625950267\n",
      "train loss:2.3734269370462333\n",
      "=== epoch:37, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.42136204689279\n",
      "train loss:2.4147609550581772\n",
      "train loss:2.369983536573313\n",
      "train loss:2.2993248008586966\n",
      "=== epoch:38, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3931093797471026\n",
      "train loss:2.4208391430207348\n",
      "train loss:2.367733931369071\n",
      "train loss:2.404226882462986\n",
      "=== epoch:39, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.417722310598443\n",
      "train loss:2.4318995731797424\n",
      "train loss:2.375853362521453\n",
      "train loss:2.3651432749205616\n",
      "=== epoch:40, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.39839989421256\n",
      "train loss:2.3408831728046864\n",
      "train loss:2.4183708485690065\n",
      "train loss:2.3437235960304754\n",
      "=== epoch:41, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4003077499811947\n",
      "train loss:2.4270664631489938\n",
      "train loss:2.450259201265118\n",
      "train loss:2.416286699977015\n",
      "=== epoch:42, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3455481145787505\n",
      "train loss:2.347090429687453\n",
      "train loss:2.40079974852434\n",
      "train loss:2.4197114636517276\n",
      "=== epoch:43, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.369550544547411\n",
      "train loss:2.4040788267062116\n",
      "train loss:2.4073448202479986\n",
      "train loss:2.3950655445932556\n",
      "=== epoch:44, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.395010820289587\n",
      "train loss:2.384166799400719\n",
      "train loss:2.4070554531602317\n",
      "train loss:2.4493694610104235\n",
      "=== epoch:45, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3521786559110294\n",
      "train loss:2.40815721808635\n",
      "train loss:2.3683691446430055\n",
      "train loss:2.3385911036393288\n",
      "=== epoch:46, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.401004671698174\n",
      "train loss:2.4071427368015392\n",
      "train loss:2.382207904785176\n",
      "train loss:2.341689598211714\n",
      "=== epoch:47, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.359907632385459\n",
      "train loss:2.385154279316947\n",
      "train loss:2.3369489546933853\n",
      "train loss:2.40754206279808\n",
      "=== epoch:48, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4009466167734503\n",
      "train loss:2.3440292050569402\n",
      "train loss:2.3116869065632195\n",
      "train loss:2.425939780657527\n",
      "=== epoch:49, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.3929530129597962\n",
      "train loss:2.3944477560547255\n",
      "train loss:2.3845449148166424\n",
      "train loss:2.4348889095988437\n",
      "=== epoch:50, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.368815693446506\n",
      "train loss:2.4113939303020646\n",
      "train loss:2.3762233949189855\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0001, weight_decay: 0.0001\n",
      "train loss:2.4172846796561327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:1, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.418688776271965\n",
      "train loss:2.4914009549105707\n",
      "train loss:2.407563178872346\n",
      "train loss:2.4473551988290434\n",
      "=== epoch:2, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.407362125196296\n",
      "train loss:2.392729469011784\n",
      "train loss:2.362808882681184\n",
      "train loss:2.361053898231597\n",
      "=== epoch:3, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.337757387219916\n",
      "train loss:2.4231562012466963\n",
      "train loss:2.4012525517573162\n",
      "train loss:2.387007712047183\n",
      "=== epoch:4, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4293579581924813\n",
      "train loss:2.3832623567903783\n",
      "train loss:2.4122848830086694\n",
      "train loss:2.4299350431542885\n",
      "=== epoch:5, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.468601789825129\n",
      "train loss:2.4261741186326464\n",
      "train loss:2.4479001329792367\n",
      "train loss:2.391105820019311\n",
      "=== epoch:6, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.437999497232469\n",
      "train loss:2.4246961928919317\n",
      "train loss:2.44251455755261\n",
      "train loss:2.3311742782760785\n",
      "=== epoch:7, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.373670427038614\n",
      "train loss:2.415187411156395\n",
      "train loss:2.4127052089471754\n",
      "train loss:2.412738324598548\n",
      "=== epoch:8, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.335712221034575\n",
      "train loss:2.3655148731922946\n",
      "train loss:2.426420261200527\n",
      "train loss:2.4109853343825867\n",
      "=== epoch:9, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4349077024006274\n",
      "train loss:2.3990533061295873\n",
      "train loss:2.322092730033468\n",
      "train loss:2.3339188049909407\n",
      "=== epoch:10, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4341318163648533\n",
      "train loss:2.348157855338789\n",
      "train loss:2.3720517890323873\n",
      "train loss:2.4442529802192476\n",
      "=== epoch:11, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4039101351949053\n",
      "train loss:2.3544897432318854\n",
      "train loss:2.405691031746917\n",
      "train loss:2.389355575580825\n",
      "=== epoch:12, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.385547270330335\n",
      "train loss:2.425368507444093\n",
      "train loss:2.417603157373345\n",
      "train loss:2.370024235178098\n",
      "=== epoch:13, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4788010584776377\n",
      "train loss:2.4373225171618444\n",
      "train loss:2.4051503880070992\n",
      "train loss:2.4054878563304842\n",
      "=== epoch:14, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.491152047658629\n",
      "train loss:2.4063150554025627\n",
      "train loss:2.3580853401199415\n",
      "train loss:2.392265743037693\n",
      "=== epoch:15, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3678167744961556\n",
      "train loss:2.345956704387716\n",
      "train loss:2.4652605769484186\n",
      "train loss:2.3895407097053374\n",
      "=== epoch:16, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.405725559126431\n",
      "train loss:2.359668927035612\n",
      "train loss:2.4165821903337092\n",
      "train loss:2.4016942003921433\n",
      "=== epoch:17, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.375901539138532\n",
      "train loss:2.434154649393919\n",
      "train loss:2.411780447016935\n",
      "train loss:2.410616469455253\n",
      "=== epoch:18, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.346465046750059\n",
      "train loss:2.4861134211297755\n",
      "train loss:2.3899592065311874\n",
      "train loss:2.3372714590489605\n",
      "=== epoch:19, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3845094836077503\n",
      "train loss:2.3946330904646103\n",
      "train loss:2.3400425451082723\n",
      "train loss:2.406532194820304\n",
      "=== epoch:20, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.360592327228813\n",
      "train loss:2.374255218848822\n",
      "train loss:2.380332787249865\n",
      "train loss:2.4101231392509517\n",
      "=== epoch:21, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3933452209338864\n",
      "train loss:2.3458621155827033\n",
      "train loss:2.35999337980882\n",
      "train loss:2.4687422886062316\n",
      "=== epoch:22, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.399485204551591\n",
      "train loss:2.3570798893435527\n",
      "train loss:2.3939435254461054\n",
      "train loss:2.410963629313463\n",
      "=== epoch:23, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3926928199171016\n",
      "train loss:2.4341158520272503\n",
      "train loss:2.352245877209902\n",
      "train loss:2.3704503603870664\n",
      "=== epoch:24, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3645574654226955\n",
      "train loss:2.3673857492386627\n",
      "train loss:2.364648471131295\n",
      "train loss:2.387759996934706\n",
      "=== epoch:25, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3748696991298894\n",
      "train loss:2.335373045751087\n",
      "train loss:2.4445852350332054\n",
      "train loss:2.4163354866186304\n",
      "=== epoch:26, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4048374129597976\n",
      "train loss:2.425887543627382\n",
      "train loss:2.384739076304556\n",
      "train loss:2.4356447991553978\n",
      "=== epoch:27, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4281822533554553\n",
      "train loss:2.437521408393064\n",
      "train loss:2.3317417019888396\n",
      "train loss:2.3819261692075764\n",
      "=== epoch:28, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.370891432218283\n",
      "train loss:2.3884121724459026\n",
      "train loss:2.3241806030996464\n",
      "train loss:2.3479108205743415\n",
      "=== epoch:29, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.307895230298276\n",
      "train loss:2.388451878288343\n",
      "train loss:2.3849934357407436\n",
      "train loss:2.3696765728005222\n",
      "=== epoch:30, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3995320157288487\n",
      "train loss:2.4300568452150615\n",
      "train loss:2.4262279937184004\n",
      "train loss:2.3812902456223917\n",
      "=== epoch:31, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3885803589953216\n",
      "train loss:2.330036711019589\n",
      "train loss:2.306118265840173\n",
      "train loss:2.3627170910688697\n",
      "=== epoch:32, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.414898809236848\n",
      "train loss:2.4051017644512176\n",
      "train loss:2.3822770551866643\n",
      "train loss:2.340003970886217\n",
      "=== epoch:33, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3619541107545006\n",
      "train loss:2.445619155668343\n",
      "train loss:2.381074232170013\n",
      "train loss:2.427471185647587\n",
      "=== epoch:34, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.422087983307192\n",
      "train loss:2.405313071145215\n",
      "train loss:2.3786007568221024\n",
      "train loss:2.3883528640046334\n",
      "=== epoch:35, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3699583590910986\n",
      "train loss:2.314618620717053\n",
      "train loss:2.354062918025762\n",
      "train loss:2.365989236264922\n",
      "=== epoch:36, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3536454794476898\n",
      "train loss:2.365780424868172\n",
      "train loss:2.346532675042509\n",
      "train loss:2.448146930944744\n",
      "=== epoch:37, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4011676674456393\n",
      "train loss:2.4257776727284117\n",
      "train loss:2.33736904974392\n",
      "train loss:2.359875343609556\n",
      "=== epoch:38, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.370029113958088\n",
      "train loss:2.40104129918782\n",
      "train loss:2.456454573786731\n",
      "train loss:2.3793816267095442\n",
      "=== epoch:39, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.378639778292187\n",
      "train loss:2.451377462292681\n",
      "train loss:2.4008035205532545\n",
      "train loss:2.3854586457591545\n",
      "=== epoch:40, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.367505608508091\n",
      "train loss:2.4452216887685525\n",
      "train loss:2.4018762306949237\n",
      "train loss:2.390592050501804\n",
      "=== epoch:41, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.455621668772103\n",
      "train loss:2.3827775723258187\n",
      "train loss:2.455948263512699\n",
      "train loss:2.3770826385771517\n",
      "=== epoch:42, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.33120917917553\n",
      "train loss:2.3902752022573273\n",
      "train loss:2.3939795021970345\n",
      "train loss:2.3828528637671615\n",
      "=== epoch:43, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3351460384916947\n",
      "train loss:2.3479371128892734\n",
      "train loss:2.399643809974717\n",
      "train loss:2.397466461207137\n",
      "=== epoch:44, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.33245293859694\n",
      "train loss:2.3179773505502284\n",
      "train loss:2.364322323843662\n",
      "train loss:2.3579125374068046\n",
      "=== epoch:45, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3620910362851038\n",
      "train loss:2.39718539957191\n",
      "train loss:2.3622506766545004\n",
      "train loss:2.4195911882401213\n",
      "=== epoch:46, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.4043673848828817\n",
      "train loss:2.3422348898068144\n",
      "train loss:2.3346591079651895\n",
      "train loss:2.3838940156321553\n",
      "=== epoch:47, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3718270460811186\n",
      "train loss:2.3355284193660917\n",
      "train loss:2.39822940787416\n",
      "train loss:2.3443982935432697\n",
      "=== epoch:48, train acc:0.1025, test acc:0.11 ===\n",
      "train loss:2.3643480285678917\n",
      "train loss:2.347547369207833\n",
      "train loss:2.4052604923771717\n",
      "train loss:2.3827738237652847\n",
      "=== epoch:49, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.372105141082502\n",
      "train loss:2.3577038392407776\n",
      "train loss:2.341731404328615\n",
      "train loss:2.4483162324654426\n",
      "=== epoch:50, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.390966570238963\n",
      "train loss:2.3553299802490355\n",
      "train loss:2.360376481598766\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4878338690449056\n",
      "=== epoch:1, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.442074881651141\n",
      "train loss:2.450323616690117\n",
      "train loss:2.5087380808214674\n",
      "train loss:2.4467601989394114\n",
      "=== epoch:2, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.4808723447835517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.491821467600192\n",
      "train loss:2.3849245637013223\n",
      "train loss:2.4317882415473924\n",
      "=== epoch:3, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.4729689605567815\n",
      "train loss:2.4706638571827746\n",
      "train loss:2.4684819072726962\n",
      "train loss:2.4165462661989845\n",
      "=== epoch:4, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.4375508668442687\n",
      "train loss:2.4323852801627166\n",
      "train loss:2.336247611266009\n",
      "train loss:2.3988571902630555\n",
      "=== epoch:5, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.4809769067369074\n",
      "train loss:2.481045298738881\n",
      "train loss:2.417331971908778\n",
      "train loss:2.4272511495512337\n",
      "=== epoch:6, train acc:0.0825, test acc:0.07 ===\n",
      "train loss:2.4526923524387483\n",
      "train loss:2.4063765808035793\n",
      "train loss:2.4675308499190978\n",
      "train loss:2.479134572087202\n",
      "=== epoch:7, train acc:0.0825, test acc:0.07 ===\n",
      "train loss:2.37903326810879\n",
      "train loss:2.4289955473812244\n",
      "train loss:2.420444300695944\n",
      "train loss:2.4824997639114197\n",
      "=== epoch:8, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.495431797363368\n",
      "train loss:2.417925916053195\n",
      "train loss:2.4610247449765277\n",
      "train loss:2.4747609914413533\n",
      "=== epoch:9, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.435015329105715\n",
      "train loss:2.4205098864584427\n",
      "train loss:2.3792884478053438\n",
      "train loss:2.394504708956668\n",
      "=== epoch:10, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4680576513102737\n",
      "train loss:2.4042882753983843\n",
      "train loss:2.4167302147004293\n",
      "train loss:2.4676150323995403\n",
      "=== epoch:11, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4217438489307104\n",
      "train loss:2.4260682764389903\n",
      "train loss:2.4478020356703536\n",
      "train loss:2.37217149870995\n",
      "=== epoch:12, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3890197886246645\n",
      "train loss:2.3775110477708674\n",
      "train loss:2.4675376246175484\n",
      "train loss:2.3995270577549856\n",
      "=== epoch:13, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4094830206133198\n",
      "train loss:2.4594832203508323\n",
      "train loss:2.4234344727133403\n",
      "train loss:2.4169522027838437\n",
      "=== epoch:14, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.460039198406835\n",
      "train loss:2.427343458590591\n",
      "train loss:2.3613598195398566\n",
      "train loss:2.4053132600506584\n",
      "=== epoch:15, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.460836600199034\n",
      "train loss:2.4514795654872117\n",
      "train loss:2.466352816773882\n",
      "train loss:2.4145906519291103\n",
      "=== epoch:16, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.434898616088022\n",
      "train loss:2.394667705465236\n",
      "train loss:2.4834723240592824\n",
      "train loss:2.480459053831238\n",
      "=== epoch:17, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4297060736476683\n",
      "train loss:2.436471549005654\n",
      "train loss:2.382166664758334\n",
      "train loss:2.4418755607679516\n",
      "=== epoch:18, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4643429357390545\n",
      "train loss:2.3538943948318223\n",
      "train loss:2.5075343776944132\n",
      "train loss:2.4570231942112786\n",
      "=== epoch:19, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.3760801605548965\n",
      "train loss:2.451264432986515\n",
      "train loss:2.5266994054275775\n",
      "train loss:2.3982026723613097\n",
      "=== epoch:20, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.445818554605673\n",
      "train loss:2.4203457715952688\n",
      "train loss:2.475691177219337\n",
      "train loss:2.419703636939603\n",
      "=== epoch:21, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.4784228341532146\n",
      "train loss:2.3885739020897105\n",
      "train loss:2.4412433950137697\n",
      "train loss:2.4480333086668757\n",
      "=== epoch:22, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.4525060565980223\n",
      "train loss:2.44366230487128\n",
      "train loss:2.4867398657884867\n",
      "train loss:2.4384032481529685\n",
      "=== epoch:23, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.3727711616380325\n",
      "train loss:2.5077522456835295\n",
      "train loss:2.3673982417374213\n",
      "train loss:2.4516312684490273\n",
      "=== epoch:24, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.385570985383232\n",
      "train loss:2.415347862374227\n",
      "train loss:2.42703866723476\n",
      "train loss:2.354223527410289\n",
      "=== epoch:25, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.4500273161691686\n",
      "train loss:2.4711732846768353\n",
      "train loss:2.415804110481666\n",
      "train loss:2.3954687385310085\n",
      "=== epoch:26, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.408213602789441\n",
      "train loss:2.416536228682746\n",
      "train loss:2.376505822599726\n",
      "train loss:2.46908757556996\n",
      "=== epoch:27, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.429720365709108\n",
      "train loss:2.4869157728728166\n",
      "train loss:2.4727602623397913\n",
      "train loss:2.4606245993252385\n",
      "=== epoch:28, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.4291180015058917\n",
      "train loss:2.362945207489386\n",
      "train loss:2.385022125178115\n",
      "train loss:2.4197471695045993\n",
      "=== epoch:29, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.3417316130160977\n",
      "train loss:2.4411535944237817\n",
      "train loss:2.3565926299896818\n",
      "train loss:2.4825554987895866\n",
      "=== epoch:30, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.3839440353489563\n",
      "train loss:2.385359385732126\n",
      "train loss:2.41170659130795\n",
      "train loss:2.3610834616462895\n",
      "=== epoch:31, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.3392089934763067\n",
      "train loss:2.3756353048207455\n",
      "train loss:2.4266619679265955\n",
      "train loss:2.373639385613481\n",
      "=== epoch:32, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.4357766366277995\n",
      "train loss:2.408331571935887\n",
      "train loss:2.41857298493855\n",
      "train loss:2.340941366048003\n",
      "=== epoch:33, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.420139130336973\n",
      "train loss:2.3812413438814146\n",
      "train loss:2.400551516444024\n",
      "train loss:2.324429033853287\n",
      "=== epoch:34, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.4089028156232937\n",
      "train loss:2.4794645881214468\n",
      "train loss:2.37232657819639\n",
      "train loss:2.447099447876005\n",
      "=== epoch:35, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.329924281643962\n",
      "train loss:2.404355309483187\n",
      "train loss:2.366579179730792\n",
      "train loss:2.347617187183361\n",
      "=== epoch:36, train acc:0.09, test acc:0.06 ===\n",
      "train loss:2.3869436887414706\n",
      "train loss:2.338024315621628\n",
      "train loss:2.3372521103339277\n",
      "train loss:2.496321901989164\n",
      "=== epoch:37, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.36469504023666\n",
      "train loss:2.432379472390645\n",
      "train loss:2.4160603942249064\n",
      "train loss:2.351486780898484\n",
      "=== epoch:38, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.4312118355111356\n",
      "train loss:2.411154082773746\n",
      "train loss:2.395023181992341\n",
      "train loss:2.439954154432702\n",
      "=== epoch:39, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.3871596843349088\n",
      "train loss:2.3741390246937395\n",
      "train loss:2.417737251332776\n",
      "train loss:2.4199585970955324\n",
      "=== epoch:40, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.388832796987524\n",
      "train loss:2.4545787724498145\n",
      "train loss:2.4071989874885906\n",
      "train loss:2.378898852589656\n",
      "=== epoch:41, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.4181163006281507\n",
      "train loss:2.415669279041806\n",
      "train loss:2.4123809673467624\n",
      "train loss:2.3665527923076173\n",
      "=== epoch:42, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.4081105330687373\n",
      "train loss:2.4365863031834527\n",
      "train loss:2.3268327184520765\n",
      "train loss:2.389574685572208\n",
      "=== epoch:43, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.398484704767946\n",
      "train loss:2.444861357516174\n",
      "train loss:2.4296396975126453\n",
      "train loss:2.3598400838918168\n",
      "=== epoch:44, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.385003890487631\n",
      "train loss:2.336657518099812\n",
      "train loss:2.4960573312270222\n",
      "train loss:2.3871655669727097\n",
      "=== epoch:45, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.3674695953394886\n",
      "train loss:2.3812632680835204\n",
      "train loss:2.3555764135493593\n",
      "train loss:2.4043033442779467\n",
      "=== epoch:46, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.39089739462269\n",
      "train loss:2.387855250522357\n",
      "train loss:2.4359904651458963\n",
      "train loss:2.383315734118854\n",
      "=== epoch:47, train acc:0.0925, test acc:0.05 ===\n",
      "train loss:2.38334584955544\n",
      "train loss:2.395805773444857\n",
      "train loss:2.3640270261132614\n",
      "train loss:2.3919757387124827\n",
      "=== epoch:48, train acc:0.0925, test acc:0.05 ===\n",
      "train loss:2.3767361278139694\n",
      "train loss:2.345896847998887\n",
      "train loss:2.4010237378431953\n",
      "train loss:2.4239221056165916\n",
      "=== epoch:49, train acc:0.0925, test acc:0.05 ===\n",
      "train loss:2.418755936392328\n",
      "train loss:2.345801775031928\n",
      "train loss:2.344717609796995\n",
      "train loss:2.3483277305481556\n",
      "=== epoch:50, train acc:0.0925, test acc:0.05 ===\n",
      "train loss:2.3657543647797947\n",
      "train loss:2.386473136548797\n",
      "train loss:2.381533101025307\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.05\n",
      "val_acc: 0.0500 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.306140887640622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:1, train acc:0.07, test acc:0.12 ===\n",
      "train loss:2.426873557664094\n",
      "train loss:2.4135234083432926\n",
      "train loss:2.323574726530153\n",
      "train loss:2.3949040107175024\n",
      "=== epoch:2, train acc:0.07, test acc:0.12 ===\n",
      "train loss:2.3457693166897333\n",
      "train loss:2.3381311271871184\n",
      "train loss:2.3712040891344697\n",
      "train loss:2.3445333820793595\n",
      "=== epoch:3, train acc:0.07, test acc:0.12 ===\n",
      "train loss:2.3561755454993585\n",
      "train loss:2.3691322745523693\n",
      "train loss:2.321356620474292\n",
      "train loss:2.3761961129040032\n",
      "=== epoch:4, train acc:0.075, test acc:0.15 ===\n",
      "train loss:2.33200212009334\n",
      "train loss:2.302685109293504\n",
      "train loss:2.377946334143758\n",
      "train loss:2.3427020088921244\n",
      "=== epoch:5, train acc:0.075, test acc:0.15 ===\n",
      "train loss:2.3628167707436534\n",
      "train loss:2.3022883879500835\n",
      "train loss:2.3107046136152687\n",
      "train loss:2.256296841213715\n",
      "=== epoch:6, train acc:0.08, test acc:0.15 ===\n",
      "train loss:2.287987082262919\n",
      "train loss:2.351984023863182\n",
      "train loss:2.3166355874121645\n",
      "train loss:2.31350785548663\n",
      "=== epoch:7, train acc:0.0925, test acc:0.15 ===\n",
      "train loss:2.2985532264622135\n",
      "train loss:2.3427160933947113\n",
      "train loss:2.2838321330022744\n",
      "train loss:2.2956505479060167\n",
      "=== epoch:8, train acc:0.095, test acc:0.15 ===\n",
      "train loss:2.3284045434124074\n",
      "train loss:2.2959417632653016\n",
      "train loss:2.31899671704292\n",
      "train loss:2.3431194355528033\n",
      "=== epoch:9, train acc:0.0975, test acc:0.15 ===\n",
      "train loss:2.3093508733556596\n",
      "train loss:2.330333486937903\n",
      "train loss:2.394846657408651\n",
      "train loss:2.3334689432463036\n",
      "=== epoch:10, train acc:0.1025, test acc:0.15 ===\n",
      "train loss:2.318289988429362\n",
      "train loss:2.311918807889282\n",
      "train loss:2.251163254054561\n",
      "train loss:2.3055458001855214\n",
      "=== epoch:11, train acc:0.11, test acc:0.16 ===\n",
      "train loss:2.2652678875155994\n",
      "train loss:2.3079429105527627\n",
      "train loss:2.2841525900072233\n",
      "train loss:2.2273788145719613\n",
      "=== epoch:12, train acc:0.1175, test acc:0.16 ===\n",
      "train loss:2.2477132809399314\n",
      "train loss:2.3054052526736295\n",
      "train loss:2.338646521097761\n",
      "train loss:2.2885454970370964\n",
      "=== epoch:13, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.309550733380503\n",
      "train loss:2.29622906593085\n",
      "train loss:2.2886816952036186\n",
      "train loss:2.317732240643051\n",
      "=== epoch:14, train acc:0.1375, test acc:0.15 ===\n",
      "train loss:2.2685128385190794\n",
      "train loss:2.3211258929619345\n",
      "train loss:2.316076404116425\n",
      "train loss:2.3111443275200156\n",
      "=== epoch:15, train acc:0.145, test acc:0.15 ===\n",
      "train loss:2.243630895553662\n",
      "train loss:2.2601408054627377\n",
      "train loss:2.3073307170095734\n",
      "train loss:2.220758546771323\n",
      "=== epoch:16, train acc:0.1475, test acc:0.16 ===\n",
      "train loss:2.259943633263231\n",
      "train loss:2.2860911095547447\n",
      "train loss:2.2539357933824373\n",
      "train loss:2.2998151830920435\n",
      "=== epoch:17, train acc:0.15, test acc:0.16 ===\n",
      "train loss:2.2718460212841416\n",
      "train loss:2.2528029449254086\n",
      "train loss:2.2718445462660113\n",
      "train loss:2.3208207672677665\n",
      "=== epoch:18, train acc:0.1525, test acc:0.15 ===\n",
      "train loss:2.269084462934765\n",
      "train loss:2.271203824967778\n",
      "train loss:2.272010724449047\n",
      "train loss:2.2302535009893467\n",
      "=== epoch:19, train acc:0.1525, test acc:0.15 ===\n",
      "train loss:2.2898358363395945\n",
      "train loss:2.270300643582597\n",
      "train loss:2.2616507877923593\n",
      "train loss:2.2291365366542526\n",
      "=== epoch:20, train acc:0.1625, test acc:0.15 ===\n",
      "train loss:2.2658858410648555\n",
      "train loss:2.2387228453224957\n",
      "train loss:2.266440233038656\n",
      "train loss:2.2519709195748634\n",
      "=== epoch:21, train acc:0.165, test acc:0.16 ===\n",
      "train loss:2.3137359231750247\n",
      "train loss:2.21702946370063\n",
      "train loss:2.2631032524194055\n",
      "train loss:2.2611577654297754\n",
      "=== epoch:22, train acc:0.17, test acc:0.16 ===\n",
      "train loss:2.2838178113983014\n",
      "train loss:2.2568156594125868\n",
      "train loss:2.226886336114947\n",
      "train loss:2.271319512684387\n",
      "=== epoch:23, train acc:0.185, test acc:0.16 ===\n",
      "train loss:2.262882970204276\n",
      "train loss:2.2195348292399983\n",
      "train loss:2.2470222211823905\n",
      "train loss:2.22883955006483\n",
      "=== epoch:24, train acc:0.1875, test acc:0.17 ===\n",
      "train loss:2.2719104386645776\n",
      "train loss:2.2427886178819008\n",
      "train loss:2.2441948285087348\n",
      "train loss:2.2279908697120527\n",
      "=== epoch:25, train acc:0.19, test acc:0.17 ===\n",
      "train loss:2.22726142360419\n",
      "train loss:2.213470068761949\n",
      "train loss:2.246834231755232\n",
      "train loss:2.246743065094606\n",
      "=== epoch:26, train acc:0.19, test acc:0.18 ===\n",
      "train loss:2.207981755682667\n",
      "train loss:2.2690175186761787\n",
      "train loss:2.270588224780223\n",
      "train loss:2.164887070579829\n",
      "=== epoch:27, train acc:0.1925, test acc:0.18 ===\n",
      "train loss:2.2684099711690715\n",
      "train loss:2.253856445042607\n",
      "train loss:2.2088362781382047\n",
      "train loss:2.254111013891868\n",
      "=== epoch:28, train acc:0.195, test acc:0.19 ===\n",
      "train loss:2.223582899480765\n",
      "train loss:2.2107858992717038\n",
      "train loss:2.160937208399741\n",
      "train loss:2.1825524175701445\n",
      "=== epoch:29, train acc:0.195, test acc:0.19 ===\n",
      "train loss:2.297381451564047\n",
      "train loss:2.2072893139539254\n",
      "train loss:2.2427582417421226\n",
      "train loss:2.220730712422002\n",
      "=== epoch:30, train acc:0.1975, test acc:0.2 ===\n",
      "train loss:2.2245190037145344\n",
      "train loss:2.2426232723142063\n",
      "train loss:2.198856925994217\n",
      "train loss:2.239106357811396\n",
      "=== epoch:31, train acc:0.2, test acc:0.2 ===\n",
      "train loss:2.241740189902938\n",
      "train loss:2.200042548558908\n",
      "train loss:2.2369948801507715\n",
      "train loss:2.2547208166963135\n",
      "=== epoch:32, train acc:0.205, test acc:0.2 ===\n",
      "train loss:2.2471301094952727\n",
      "train loss:2.1899965756297037\n",
      "train loss:2.270378212320803\n",
      "train loss:2.2019417992963883\n",
      "=== epoch:33, train acc:0.2075, test acc:0.2 ===\n",
      "train loss:2.2099193969083073\n",
      "train loss:2.2012954263822073\n",
      "train loss:2.193986058533735\n",
      "train loss:2.191920585192714\n",
      "=== epoch:34, train acc:0.2175, test acc:0.21 ===\n",
      "train loss:2.2194338317269273\n",
      "train loss:2.205034339514989\n",
      "train loss:2.176102859119119\n",
      "train loss:2.22029517799122\n",
      "=== epoch:35, train acc:0.22, test acc:0.23 ===\n",
      "train loss:2.19503507381449\n",
      "train loss:2.1986984175607724\n",
      "train loss:2.21736967384231\n",
      "train loss:2.192643089100105\n",
      "=== epoch:36, train acc:0.23, test acc:0.22 ===\n",
      "train loss:2.167351716068279\n",
      "train loss:2.2012661107453106\n",
      "train loss:2.261688266435925\n",
      "train loss:2.2130347195768607\n",
      "=== epoch:37, train acc:0.2325, test acc:0.23 ===\n",
      "train loss:2.1624969007654182\n",
      "train loss:2.1724122849382437\n",
      "train loss:2.204234992628155\n",
      "train loss:2.2391302818614456\n",
      "=== epoch:38, train acc:0.2325, test acc:0.24 ===\n",
      "train loss:2.169478048188671\n",
      "train loss:2.2481971214559873\n",
      "train loss:2.1960205812227267\n",
      "train loss:2.222205479957953\n",
      "=== epoch:39, train acc:0.235, test acc:0.24 ===\n",
      "train loss:2.2125462771155946\n",
      "train loss:2.1358599126578763\n",
      "train loss:2.226976274373231\n",
      "train loss:2.2440179308786643\n",
      "=== epoch:40, train acc:0.235, test acc:0.24 ===\n",
      "train loss:2.193498605444417\n",
      "train loss:2.158367252867129\n",
      "train loss:2.2012233674745003\n",
      "train loss:2.152799588594125\n",
      "=== epoch:41, train acc:0.2375, test acc:0.24 ===\n",
      "train loss:2.2111719806975225\n",
      "train loss:2.1536398374772197\n",
      "train loss:2.1849899323491457\n",
      "train loss:2.1589093780756516\n",
      "=== epoch:42, train acc:0.2375, test acc:0.24 ===\n",
      "train loss:2.1716816876880056\n",
      "train loss:2.1948922030263747\n",
      "train loss:2.217120273682908\n",
      "train loss:2.187678169505832\n",
      "=== epoch:43, train acc:0.2425, test acc:0.25 ===\n",
      "train loss:2.1370514832193743\n",
      "train loss:2.145416956920706\n",
      "train loss:2.169978338246773\n",
      "train loss:2.1252429695482955\n",
      "=== epoch:44, train acc:0.245, test acc:0.25 ===\n",
      "train loss:2.150710397938595\n",
      "train loss:2.2003796789656924\n",
      "train loss:2.14470053920693\n",
      "train loss:2.178652811489906\n",
      "=== epoch:45, train acc:0.2475, test acc:0.25 ===\n",
      "train loss:2.1972010733425327\n",
      "train loss:2.1639004190437294\n",
      "train loss:2.2015337980002085\n",
      "train loss:2.114019024760607\n",
      "=== epoch:46, train acc:0.25, test acc:0.25 ===\n",
      "train loss:2.2031236430767454\n",
      "train loss:2.193706425987261\n",
      "train loss:2.1613121654262843\n",
      "train loss:2.166624870777181\n",
      "=== epoch:47, train acc:0.25, test acc:0.25 ===\n",
      "train loss:2.081163656815078\n",
      "train loss:2.168185605101937\n",
      "train loss:2.2061414784281923\n",
      "train loss:2.203213187242252\n",
      "=== epoch:48, train acc:0.2575, test acc:0.25 ===\n",
      "train loss:2.138856760693389\n",
      "train loss:2.182012991461226\n",
      "train loss:2.191129064795841\n",
      "train loss:2.13700744674517\n",
      "=== epoch:49, train acc:0.2575, test acc:0.25 ===\n",
      "train loss:2.176068226470778\n",
      "train loss:2.138386979417235\n",
      "train loss:2.173723613739823\n",
      "train loss:2.1482545028536815\n",
      "=== epoch:50, train acc:0.2625, test acc:0.25 ===\n",
      "train loss:2.1363831346652953\n",
      "train loss:2.1483849947700193\n",
      "train loss:2.148136027334634\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.26\n",
      "val_acc: 0.2500 | lr: 0.0011, weight_decay: 0.0000\n",
      "train loss:2.425468495022556\n",
      "=== epoch:1, train acc:0.08, test acc:0.1 ===\n",
      "train loss:2.4008808722765878\n",
      "train loss:2.402202748308226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3487017374474815\n",
      "train loss:2.3835016839539795\n",
      "=== epoch:2, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.384685592749158\n",
      "train loss:2.2425437725703183\n",
      "train loss:2.392424552792421\n",
      "train loss:2.409192932559415\n",
      "=== epoch:3, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.330844973569381\n",
      "train loss:2.3385712569730286\n",
      "train loss:2.356550795728803\n",
      "train loss:2.3352531729176693\n",
      "=== epoch:4, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.3506003944070324\n",
      "train loss:2.457240554626064\n",
      "train loss:2.401398449200189\n",
      "train loss:2.382344918344221\n",
      "=== epoch:5, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.3247967565285745\n",
      "train loss:2.4286926310112897\n",
      "train loss:2.323841918235333\n",
      "train loss:2.3964109307660366\n",
      "=== epoch:6, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.4309647586230003\n",
      "train loss:2.408809954163357\n",
      "train loss:2.3944946261965505\n",
      "train loss:2.3807843612039745\n",
      "=== epoch:7, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.3879685022642123\n",
      "train loss:2.427488978950502\n",
      "train loss:2.385231173249338\n",
      "train loss:2.3557749787711484\n",
      "=== epoch:8, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.388779333999\n",
      "train loss:2.3940906325172677\n",
      "train loss:2.3845103061133583\n",
      "train loss:2.357091193698653\n",
      "=== epoch:9, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.347929082517794\n",
      "train loss:2.325988388828009\n",
      "train loss:2.3768206751049874\n",
      "train loss:2.3743499531811763\n",
      "=== epoch:10, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.4259627545811835\n",
      "train loss:2.295949687507407\n",
      "train loss:2.3521920332969417\n",
      "train loss:2.3459515460639335\n",
      "=== epoch:11, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.388022086464774\n",
      "train loss:2.336258639915699\n",
      "train loss:2.3644463814728254\n",
      "train loss:2.367844252574647\n",
      "=== epoch:12, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.3919992418205767\n",
      "train loss:2.3795128495624662\n",
      "train loss:2.3242219771810935\n",
      "train loss:2.354770330345113\n",
      "=== epoch:13, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.3372343156226334\n",
      "train loss:2.307999951369605\n",
      "train loss:2.289614783789583\n",
      "train loss:2.350180943802177\n",
      "=== epoch:14, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.3703246096317603\n",
      "train loss:2.4144186712779865\n",
      "train loss:2.3243119704892075\n",
      "train loss:2.3338895301447415\n",
      "=== epoch:15, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.347384983687189\n",
      "train loss:2.3282269896501835\n",
      "train loss:2.385367010435866\n",
      "train loss:2.375360642988086\n",
      "=== epoch:16, train acc:0.0875, test acc:0.11 ===\n",
      "train loss:2.3940807497108616\n",
      "train loss:2.353747477452057\n",
      "train loss:2.443019481446495\n",
      "train loss:2.3248496124610725\n",
      "=== epoch:17, train acc:0.0875, test acc:0.11 ===\n",
      "train loss:2.3868850969912336\n",
      "train loss:2.254035065509453\n",
      "train loss:2.42982245891447\n",
      "train loss:2.273925988016375\n",
      "=== epoch:18, train acc:0.0875, test acc:0.12 ===\n",
      "train loss:2.4457976860699238\n",
      "train loss:2.2612262852463236\n",
      "train loss:2.3371398817047715\n",
      "train loss:2.4141106860546175\n",
      "=== epoch:19, train acc:0.0875, test acc:0.11 ===\n",
      "train loss:2.3259878135370387\n",
      "train loss:2.4129797544305314\n",
      "train loss:2.3149368627252174\n",
      "train loss:2.417989568272837\n",
      "=== epoch:20, train acc:0.0875, test acc:0.11 ===\n",
      "train loss:2.327629635794611\n",
      "train loss:2.3678471286878606\n",
      "train loss:2.3697628749095436\n",
      "train loss:2.385908406184488\n",
      "=== epoch:21, train acc:0.0875, test acc:0.11 ===\n",
      "train loss:2.344936826189675\n",
      "train loss:2.334407951064619\n",
      "train loss:2.3940188297929423\n",
      "train loss:2.3546213232432605\n",
      "=== epoch:22, train acc:0.0875, test acc:0.11 ===\n",
      "train loss:2.352538703449024\n",
      "train loss:2.379326177137391\n",
      "train loss:2.3988257803434854\n",
      "train loss:2.3528189816128218\n",
      "=== epoch:23, train acc:0.0875, test acc:0.11 ===\n",
      "train loss:2.323669952689818\n",
      "train loss:2.3570321802796523\n",
      "train loss:2.3782745898881767\n",
      "train loss:2.3912623509726214\n",
      "=== epoch:24, train acc:0.0875, test acc:0.12 ===\n",
      "train loss:2.3454524679252224\n",
      "train loss:2.3738715311076484\n",
      "train loss:2.344519406540908\n",
      "train loss:2.375417391257352\n",
      "=== epoch:25, train acc:0.09, test acc:0.12 ===\n",
      "train loss:2.3206729714931686\n",
      "train loss:2.284587940604078\n",
      "train loss:2.373905934313995\n",
      "train loss:2.322744087952319\n",
      "=== epoch:26, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3216406981137583\n",
      "train loss:2.3474543195501116\n",
      "train loss:2.3250601136760323\n",
      "train loss:2.346204526747551\n",
      "=== epoch:27, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.2964453158465434\n",
      "train loss:2.393718406656793\n",
      "train loss:2.3362757068212314\n",
      "train loss:2.368539244638977\n",
      "=== epoch:28, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.402351178623161\n",
      "train loss:2.353654062593807\n",
      "train loss:2.367775693650209\n",
      "train loss:2.3464176891527995\n",
      "=== epoch:29, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3620441897841924\n",
      "train loss:2.3291076254928873\n",
      "train loss:2.3552392030438933\n",
      "train loss:2.3411928339533308\n",
      "=== epoch:30, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.346255477557397\n",
      "train loss:2.364171898687294\n",
      "train loss:2.313476081744737\n",
      "train loss:2.4230160199867146\n",
      "=== epoch:31, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.431137557917377\n",
      "train loss:2.3765926583713997\n",
      "train loss:2.369736370013536\n",
      "train loss:2.347852786173365\n",
      "=== epoch:32, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3318248167317797\n",
      "train loss:2.342958965233374\n",
      "train loss:2.3959736828218814\n",
      "train loss:2.3603012253058036\n",
      "=== epoch:33, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3193311953481177\n",
      "train loss:2.3590793652228363\n",
      "train loss:2.3370893749685315\n",
      "train loss:2.320215439859407\n",
      "=== epoch:34, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.4045021321778073\n",
      "train loss:2.3056688848345366\n",
      "train loss:2.304556100687489\n",
      "train loss:2.349604103680396\n",
      "=== epoch:35, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.316874873725984\n",
      "train loss:2.3185024329236437\n",
      "train loss:2.3403695631119437\n",
      "train loss:2.3585497174829597\n",
      "=== epoch:36, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.366038727265607\n",
      "train loss:2.3678308694265087\n",
      "train loss:2.3336407882738452\n",
      "train loss:2.372358892810953\n",
      "=== epoch:37, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.34585764839566\n",
      "train loss:2.3352177077917786\n",
      "train loss:2.3046011745374164\n",
      "train loss:2.3681535002293224\n",
      "=== epoch:38, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.2993967141541676\n",
      "train loss:2.3986162581325954\n",
      "train loss:2.3246686000915306\n",
      "train loss:2.3197136657139867\n",
      "=== epoch:39, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3360379619028784\n",
      "train loss:2.340217446556458\n",
      "train loss:2.289760535196569\n",
      "train loss:2.3263886573056505\n",
      "=== epoch:40, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3464376092296857\n",
      "train loss:2.3923801038077634\n",
      "train loss:2.338095966593197\n",
      "train loss:2.360875803021657\n",
      "=== epoch:41, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.297348842983309\n",
      "train loss:2.3519771356484243\n",
      "train loss:2.3452992629598826\n",
      "train loss:2.3420116215369045\n",
      "=== epoch:42, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3503218764697698\n",
      "train loss:2.346037403259537\n",
      "train loss:2.370655963210058\n",
      "train loss:2.380007081853307\n",
      "=== epoch:43, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3242720384882283\n",
      "train loss:2.318171452351535\n",
      "train loss:2.361734479738618\n",
      "train loss:2.3436760777881727\n",
      "=== epoch:44, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3565475100727893\n",
      "train loss:2.370555379674517\n",
      "train loss:2.399104021883388\n",
      "train loss:2.3334487884695636\n",
      "=== epoch:45, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.351948015105026\n",
      "train loss:2.3883572168111473\n",
      "train loss:2.3204677292509146\n",
      "train loss:2.3674949643886576\n",
      "=== epoch:46, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.352579776001086\n",
      "train loss:2.3692548779639226\n",
      "train loss:2.3670232245030105\n",
      "train loss:2.330756414934989\n",
      "=== epoch:47, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3505024831859282\n",
      "train loss:2.342222441290214\n",
      "train loss:2.3286367262923107\n",
      "train loss:2.396808924755028\n",
      "=== epoch:48, train acc:0.1, test acc:0.13 ===\n",
      "train loss:2.393460754631036\n",
      "train loss:2.3412977770073784\n",
      "train loss:2.3468049669545548\n",
      "train loss:2.3103608046078867\n",
      "=== epoch:49, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.344803999395599\n",
      "train loss:2.30718498323876\n",
      "train loss:2.259673201316529\n",
      "train loss:2.370119172793681\n",
      "=== epoch:50, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3276652994791855\n",
      "train loss:2.349124324232068\n",
      "train loss:2.362613409583875\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0002, weight_decay: 0.0001\n",
      "train loss:2.4089775150539494\n",
      "=== epoch:1, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.3935886327007765\n",
      "train loss:2.3077825949934883\n",
      "train loss:2.291073468619155\n",
      "train loss:2.3341583938206565\n",
      "=== epoch:2, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.345092487842578\n",
      "train loss:2.418522546159325\n",
      "train loss:2.368618469755092\n",
      "train loss:2.363775682648709\n",
      "=== epoch:3, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.380746483893453\n",
      "train loss:2.4319564890888974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3763164695690433\n",
      "train loss:2.3369422786926757\n",
      "=== epoch:4, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.403674695770827\n",
      "train loss:2.332611577683008\n",
      "train loss:2.3078084265211847\n",
      "train loss:2.3268879883984637\n",
      "=== epoch:5, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3150206398794757\n",
      "train loss:2.344356420467621\n",
      "train loss:2.31548429467661\n",
      "train loss:2.325951812716923\n",
      "=== epoch:6, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.395269399632702\n",
      "train loss:2.3113556744836625\n",
      "train loss:2.331607132753598\n",
      "train loss:2.372629661716564\n",
      "=== epoch:7, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3868847252811474\n",
      "train loss:2.335442360662839\n",
      "train loss:2.382219963695108\n",
      "train loss:2.4071399872163264\n",
      "=== epoch:8, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.389398238990237\n",
      "train loss:2.3250579019522086\n",
      "train loss:2.353006687696493\n",
      "train loss:2.387639104614438\n",
      "=== epoch:9, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.37782718993504\n",
      "train loss:2.36265269879362\n",
      "train loss:2.3914042151772463\n",
      "train loss:2.3848375841458895\n",
      "=== epoch:10, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.392567596662509\n",
      "train loss:2.362951556034656\n",
      "train loss:2.340118614943502\n",
      "train loss:2.3390052422729464\n",
      "=== epoch:11, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.357189943879866\n",
      "train loss:2.358106280385205\n",
      "train loss:2.370545024252504\n",
      "train loss:2.3779732114954952\n",
      "=== epoch:12, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.325795611476771\n",
      "train loss:2.3058024416294787\n",
      "train loss:2.4008389751567667\n",
      "train loss:2.4008425638247433\n",
      "=== epoch:13, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.35769314294274\n",
      "train loss:2.2916151094182995\n",
      "train loss:2.351094626825656\n",
      "train loss:2.3231327110838516\n",
      "=== epoch:14, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.346990462311015\n",
      "train loss:2.4092286029498355\n",
      "train loss:2.4050620260083457\n",
      "train loss:2.332709384090455\n",
      "=== epoch:15, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3876760927137446\n",
      "train loss:2.3454074371092855\n",
      "train loss:2.298648637388397\n",
      "train loss:2.403651885765151\n",
      "=== epoch:16, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.352504664599107\n",
      "train loss:2.3899833797641588\n",
      "train loss:2.373867215418434\n",
      "train loss:2.3383220860751033\n",
      "=== epoch:17, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.324741491062504\n",
      "train loss:2.304492106053983\n",
      "train loss:2.368980199214121\n",
      "train loss:2.439047753427569\n",
      "=== epoch:18, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.2988425057002644\n",
      "train loss:2.3761114460784674\n",
      "train loss:2.366620430813625\n",
      "train loss:2.3364324322506005\n",
      "=== epoch:19, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.339160012595671\n",
      "train loss:2.358744180505378\n",
      "train loss:2.3054444650187205\n",
      "train loss:2.3687863510320692\n",
      "=== epoch:20, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3012150491180448\n",
      "train loss:2.384124807010935\n",
      "train loss:2.319600053175795\n",
      "train loss:2.370951053548337\n",
      "=== epoch:21, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3469268794891898\n",
      "train loss:2.3403656425015864\n",
      "train loss:2.295079861439986\n",
      "train loss:2.3396685007244518\n",
      "=== epoch:22, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.325847983020445\n",
      "train loss:2.340531560381941\n",
      "train loss:2.3512415271062252\n",
      "train loss:2.3389269937717625\n",
      "=== epoch:23, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3614957376308108\n",
      "train loss:2.3345933054402397\n",
      "train loss:2.3331699336473344\n",
      "train loss:2.408472818799511\n",
      "=== epoch:24, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.347532922487439\n",
      "train loss:2.3221324665080534\n",
      "train loss:2.406902264211385\n",
      "train loss:2.325504610841067\n",
      "=== epoch:25, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3524493344908044\n",
      "train loss:2.2915245509813014\n",
      "train loss:2.3488216914489297\n",
      "train loss:2.3572879221460927\n",
      "=== epoch:26, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.381208017394742\n",
      "train loss:2.3261651587882564\n",
      "train loss:2.3777363312373794\n",
      "train loss:2.3362010637213015\n",
      "=== epoch:27, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.339360959768165\n",
      "train loss:2.3187490527760235\n",
      "train loss:2.3280992415632524\n",
      "train loss:2.3687456431465845\n",
      "=== epoch:28, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.326360334574204\n",
      "train loss:2.3654353177032266\n",
      "train loss:2.308417280570654\n",
      "train loss:2.3925334446247595\n",
      "=== epoch:29, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.3467763767680307\n",
      "train loss:2.3872150787094375\n",
      "train loss:2.3329387664148418\n",
      "train loss:2.341110013748981\n",
      "=== epoch:30, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.334090650868289\n",
      "train loss:2.3645558543775045\n",
      "train loss:2.3255680282130142\n",
      "train loss:2.335347324842546\n",
      "=== epoch:31, train acc:0.1, test acc:0.11 ===\n",
      "train loss:2.335568305791212\n",
      "train loss:2.3799423036835115\n",
      "train loss:2.3319993947039115\n",
      "train loss:2.3174591675163807\n",
      "=== epoch:32, train acc:0.1, test acc:0.11 ===\n",
      "train loss:2.3353320519860343\n",
      "train loss:2.3169988866013562\n",
      "train loss:2.327772321438563\n",
      "train loss:2.402764578395281\n",
      "=== epoch:33, train acc:0.1, test acc:0.11 ===\n",
      "train loss:2.3348945739155265\n",
      "train loss:2.4051567067041812\n",
      "train loss:2.3495446011969245\n",
      "train loss:2.276928321856818\n",
      "=== epoch:34, train acc:0.1, test acc:0.11 ===\n",
      "train loss:2.3273727314221344\n",
      "train loss:2.378026901531557\n",
      "train loss:2.3344397559951906\n",
      "train loss:2.2867693429694227\n",
      "=== epoch:35, train acc:0.1, test acc:0.11 ===\n",
      "train loss:2.385123018942011\n",
      "train loss:2.38629522537198\n",
      "train loss:2.2998216928785338\n",
      "train loss:2.3019550465689163\n",
      "=== epoch:36, train acc:0.1, test acc:0.11 ===\n",
      "train loss:2.309836654078308\n",
      "train loss:2.319138537360741\n",
      "train loss:2.3531334649284155\n",
      "train loss:2.2898950401040494\n",
      "=== epoch:37, train acc:0.1, test acc:0.11 ===\n",
      "train loss:2.357512647681383\n",
      "train loss:2.351687695888271\n",
      "train loss:2.339704497373672\n",
      "train loss:2.3186375279635882\n",
      "=== epoch:38, train acc:0.1, test acc:0.11 ===\n",
      "train loss:2.345955556243011\n",
      "train loss:2.3516298641199715\n",
      "train loss:2.3308096692136955\n",
      "train loss:2.3440345820152872\n",
      "=== epoch:39, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.3062973511593907\n",
      "train loss:2.3406063003556206\n",
      "train loss:2.4075186152989083\n",
      "train loss:2.348183085564948\n",
      "=== epoch:40, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.3245779845055536\n",
      "train loss:2.3222387989164215\n",
      "train loss:2.3282063436513627\n",
      "train loss:2.3458516249446575\n",
      "=== epoch:41, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.32593051742275\n",
      "train loss:2.337708869273811\n",
      "train loss:2.32431357855659\n",
      "train loss:2.3392451299580945\n",
      "=== epoch:42, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.304977709168667\n",
      "train loss:2.3319901779065253\n",
      "train loss:2.262787740224033\n",
      "train loss:2.3672694014575653\n",
      "=== epoch:43, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.3350864976265178\n",
      "train loss:2.3526135450048153\n",
      "train loss:2.3402491884286447\n",
      "train loss:2.2792580299518996\n",
      "=== epoch:44, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.348243068775843\n",
      "train loss:2.3307383475003194\n",
      "train loss:2.343435681081067\n",
      "train loss:2.327954331221082\n",
      "=== epoch:45, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.342021759739076\n",
      "train loss:2.351354334135655\n",
      "train loss:2.274739664037298\n",
      "train loss:2.328275718708707\n",
      "=== epoch:46, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.3019459610002846\n",
      "train loss:2.293155865914491\n",
      "train loss:2.3567463082749875\n",
      "train loss:2.3353092441612273\n",
      "=== epoch:47, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.358433202580015\n",
      "train loss:2.3711345783118354\n",
      "train loss:2.428350457223994\n",
      "train loss:2.322389977563114\n",
      "=== epoch:48, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.337715383237601\n",
      "train loss:2.259118748794312\n",
      "train loss:2.3799389344684645\n",
      "train loss:2.2971556737320076\n",
      "=== epoch:49, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3198766311799273\n",
      "train loss:2.303076565846591\n",
      "train loss:2.3015629502618338\n",
      "train loss:2.310548566708143\n",
      "=== epoch:50, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3307537942621037\n",
      "train loss:2.34134392931143\n",
      "train loss:2.311718516343279\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0002, weight_decay: 0.0000\n",
      "train loss:2.50035725206075\n",
      "=== epoch:1, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.5520094669154827\n",
      "train loss:2.4750541143619285\n",
      "train loss:2.4846449895678906\n",
      "train loss:2.4632843242240887\n",
      "=== epoch:2, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4860739477587215\n",
      "train loss:2.4952554362362322\n",
      "train loss:2.452324668515861\n",
      "train loss:2.5616969264936063\n",
      "=== epoch:3, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.50826551817513\n",
      "train loss:2.502998348430093\n",
      "train loss:2.511469415223083\n",
      "train loss:2.4720891278882418\n",
      "=== epoch:4, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4851336123432786\n",
      "train loss:2.5281239760956615\n",
      "train loss:2.484685683164318\n",
      "train loss:2.556796168285454\n",
      "=== epoch:5, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.483316165995784\n",
      "train loss:2.4860475221686724\n",
      "train loss:2.5816393453144797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.5507695590514983\n",
      "=== epoch:6, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4894224698972187\n",
      "train loss:2.429879612803287\n",
      "train loss:2.577706727399156\n",
      "train loss:2.4779807033194716\n",
      "=== epoch:7, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.444378176142594\n",
      "train loss:2.5097354703346895\n",
      "train loss:2.495047858149948\n",
      "train loss:2.483267041443331\n",
      "=== epoch:8, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.5089522660338806\n",
      "train loss:2.4855881344590127\n",
      "train loss:2.628936727131642\n",
      "train loss:2.509234570401625\n",
      "=== epoch:9, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3880748253390007\n",
      "train loss:2.6115468384833584\n",
      "train loss:2.383240528037656\n",
      "train loss:2.482951961064634\n",
      "=== epoch:10, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.523010840215073\n",
      "train loss:2.472355474572874\n",
      "train loss:2.553886953828679\n",
      "train loss:2.3838334988261805\n",
      "=== epoch:11, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4902972275575785\n",
      "train loss:2.507052110407309\n",
      "train loss:2.5811564009787764\n",
      "train loss:2.4967396215436466\n",
      "=== epoch:12, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.478287732485894\n",
      "train loss:2.591647199857534\n",
      "train loss:2.4262309515551013\n",
      "train loss:2.482209252425664\n",
      "=== epoch:13, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4716885875340515\n",
      "train loss:2.552233639472755\n",
      "train loss:2.543751386117059\n",
      "train loss:2.5437710973326038\n",
      "=== epoch:14, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.540592033730281\n",
      "train loss:2.423585866393609\n",
      "train loss:2.371360961585348\n",
      "train loss:2.5924813466840897\n",
      "=== epoch:15, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.561963575887864\n",
      "train loss:2.5377855682143067\n",
      "train loss:2.502914451441763\n",
      "train loss:2.520415092891472\n",
      "=== epoch:16, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.462216402432418\n",
      "train loss:2.5254094216498175\n",
      "train loss:2.571593002978454\n",
      "train loss:2.5284043248832893\n",
      "=== epoch:17, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.563590773179181\n",
      "train loss:2.4786776642286976\n",
      "train loss:2.4858703700584805\n",
      "train loss:2.416721272296225\n",
      "=== epoch:18, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4773823559677943\n",
      "train loss:2.527459749228134\n",
      "train loss:2.5303491799109645\n",
      "train loss:2.4593814775699996\n",
      "=== epoch:19, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4752506052773695\n",
      "train loss:2.5686563284608632\n",
      "train loss:2.516092327402601\n",
      "train loss:2.4837010421241015\n",
      "=== epoch:20, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.489362509347252\n",
      "train loss:2.511843852903086\n",
      "train loss:2.4395711864983327\n",
      "train loss:2.4837960524695517\n",
      "=== epoch:21, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.583867268961267\n",
      "train loss:2.48378405156248\n",
      "train loss:2.5366817274360187\n",
      "train loss:2.4589115476273036\n",
      "=== epoch:22, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4759369278147867\n",
      "train loss:2.448143734427076\n",
      "train loss:2.406277391564998\n",
      "train loss:2.6002771571947085\n",
      "=== epoch:23, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4856048967487516\n",
      "train loss:2.5063705830796557\n",
      "train loss:2.5146346165875277\n",
      "train loss:2.4774374359313334\n",
      "=== epoch:24, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4783196565424452\n",
      "train loss:2.4494597610538706\n",
      "train loss:2.517095167627288\n",
      "train loss:2.582120035921193\n",
      "=== epoch:25, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.5084810797352204\n",
      "train loss:2.4839563738033448\n",
      "train loss:2.4948167708421263\n",
      "train loss:2.6013800495855643\n",
      "=== epoch:26, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.521001817023533\n",
      "train loss:2.512496192802436\n",
      "train loss:2.556549455358617\n",
      "train loss:2.6273266054632227\n",
      "=== epoch:27, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.490651154481739\n",
      "train loss:2.489217604228194\n",
      "train loss:2.3879025681025245\n",
      "train loss:2.475565668811423\n",
      "=== epoch:28, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4109035840574946\n",
      "train loss:2.55412665319578\n",
      "train loss:2.4072132332576985\n",
      "train loss:2.4507963360339757\n",
      "=== epoch:29, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.501095515837693\n",
      "train loss:2.483036180037219\n",
      "train loss:2.638748367508504\n",
      "train loss:2.499230790401709\n",
      "=== epoch:30, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.520355271406847\n",
      "train loss:2.4440790492492432\n",
      "train loss:2.41381935717053\n",
      "train loss:2.4432524611983037\n",
      "=== epoch:31, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.5027168159316346\n",
      "train loss:2.4744724282660853\n",
      "train loss:2.4490633653365244\n",
      "train loss:2.504054295327756\n",
      "=== epoch:32, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.496697547955654\n",
      "train loss:2.492526536061487\n",
      "train loss:2.4643541707829018\n",
      "train loss:2.488683576002166\n",
      "=== epoch:33, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4465672322435505\n",
      "train loss:2.5464628571525196\n",
      "train loss:2.4885396650335925\n",
      "train loss:2.5056990857946824\n",
      "=== epoch:34, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.5598085276589795\n",
      "train loss:2.6024559647296654\n",
      "train loss:2.460135364437362\n",
      "train loss:2.6084196626619804\n",
      "=== epoch:35, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4971801100854543\n",
      "train loss:2.4911893558920606\n",
      "train loss:2.5541787970765166\n",
      "train loss:2.4813642822463375\n",
      "=== epoch:36, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.5122447436391595\n",
      "train loss:2.5684417715307797\n",
      "train loss:2.4595737162755795\n",
      "train loss:2.5606948739316344\n",
      "=== epoch:37, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4557223508289834\n",
      "train loss:2.418639186220176\n",
      "train loss:2.501756183926699\n",
      "train loss:2.4577369417824837\n",
      "=== epoch:38, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.60645910514711\n",
      "train loss:2.458494741733103\n",
      "train loss:2.5003279486213588\n",
      "train loss:2.5005185259590905\n",
      "=== epoch:39, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4719763518777498\n",
      "train loss:2.549281998215669\n",
      "train loss:2.383251056540862\n",
      "train loss:2.4631695154896853\n",
      "=== epoch:40, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4876056273298146\n",
      "train loss:2.5068423635673707\n",
      "train loss:2.49493356529779\n",
      "train loss:2.5285424490883455\n",
      "=== epoch:41, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.5032900403997176\n",
      "train loss:2.4153821805863975\n",
      "train loss:2.569559176083621\n",
      "train loss:2.4851130022426724\n",
      "=== epoch:42, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4432996147364765\n",
      "train loss:2.409211097222727\n",
      "train loss:2.438670910644917\n",
      "train loss:2.4575587592822523\n",
      "=== epoch:43, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.5741732917133167\n",
      "train loss:2.475290579960226\n",
      "train loss:2.4479473736673545\n",
      "train loss:2.4850833743039162\n",
      "=== epoch:44, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.429498592491696\n",
      "train loss:2.4967767495668074\n",
      "train loss:2.4791776557708336\n",
      "train loss:2.433489072177945\n",
      "=== epoch:45, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.517753729332729\n",
      "train loss:2.495482112126081\n",
      "train loss:2.446330167394436\n",
      "train loss:2.4475938050192365\n",
      "=== epoch:46, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.445340726853311\n",
      "train loss:2.613285723615466\n",
      "train loss:2.5796558543007415\n",
      "train loss:2.5245787879067447\n",
      "=== epoch:47, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4761865891834023\n",
      "train loss:2.560592468961791\n",
      "train loss:2.477919036707206\n",
      "train loss:2.6197198185840485\n",
      "=== epoch:48, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.527976023237409\n",
      "train loss:2.586475453992472\n",
      "train loss:2.5160519406452617\n",
      "train loss:2.5760643711305575\n",
      "=== epoch:49, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.526617363724474\n",
      "train loss:2.5256503880961323\n",
      "train loss:2.443620540436805\n",
      "train loss:2.460397649078297\n",
      "=== epoch:50, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.5538928181117653\n",
      "train loss:2.417850754749227\n",
      "train loss:2.4648605359382136\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.11\n",
      "val_acc: 0.1100 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4647700104472\n",
      "=== epoch:1, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.433876265052704\n",
      "train loss:2.3744959366661917\n",
      "train loss:2.323900886375257\n",
      "train loss:2.4168728360762404\n",
      "=== epoch:2, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.4090906468945743\n",
      "train loss:2.455298420657681\n",
      "train loss:2.347262389114563\n",
      "train loss:2.3676934907463973\n",
      "=== epoch:3, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.391475761306093\n",
      "train loss:2.335206223218825\n",
      "train loss:2.3367493911541755\n",
      "train loss:2.342409607875668\n",
      "=== epoch:4, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.389703277426368\n",
      "train loss:2.3968532674153624\n",
      "train loss:2.332953669110295\n",
      "train loss:2.40651219458367\n",
      "=== epoch:5, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.3898942695397705\n",
      "train loss:2.3441369216253674\n",
      "train loss:2.3525913922057526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.390340357105969\n",
      "=== epoch:6, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.423225514340734\n",
      "train loss:2.3576751060483603\n",
      "train loss:2.29384666234671\n",
      "train loss:2.346055447703301\n",
      "=== epoch:7, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.352861703202961\n",
      "train loss:2.4092065390107145\n",
      "train loss:2.326660415401158\n",
      "train loss:2.3733951659130637\n",
      "=== epoch:8, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.3565970162354772\n",
      "train loss:2.3389932799464646\n",
      "train loss:2.446892825504342\n",
      "train loss:2.3926788149552705\n",
      "=== epoch:9, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.44664895110946\n",
      "train loss:2.419723910536724\n",
      "train loss:2.410113036063241\n",
      "train loss:2.291118802902761\n",
      "=== epoch:10, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.3779512888972234\n",
      "train loss:2.358444914299939\n",
      "train loss:2.3533089858747833\n",
      "train loss:2.3385658612761904\n",
      "=== epoch:11, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.4103024196299163\n",
      "train loss:2.360620383028332\n",
      "train loss:2.3591548849048136\n",
      "train loss:2.4613838573529376\n",
      "=== epoch:12, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.363714370277154\n",
      "train loss:2.407269497154677\n",
      "train loss:2.357341132489433\n",
      "train loss:2.365340987773938\n",
      "=== epoch:13, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.3374201140749538\n",
      "train loss:2.410135938868377\n",
      "train loss:2.3507968773372916\n",
      "train loss:2.333625043805837\n",
      "=== epoch:14, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.414321489370633\n",
      "train loss:2.4207704855113628\n",
      "train loss:2.398167608808308\n",
      "train loss:2.3878762219956906\n",
      "=== epoch:15, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.368955143015265\n",
      "train loss:2.3181417560734245\n",
      "train loss:2.3558098728289054\n",
      "train loss:2.4091287281412357\n",
      "=== epoch:16, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.363647912231899\n",
      "train loss:2.330733733460683\n",
      "train loss:2.299439985917206\n",
      "train loss:2.337451084574656\n",
      "=== epoch:17, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3267211873546065\n",
      "train loss:2.3743790581223605\n",
      "train loss:2.3835766697366805\n",
      "train loss:2.4086361876535363\n",
      "=== epoch:18, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3773359381420573\n",
      "train loss:2.3852044187804835\n",
      "train loss:2.4328468332628397\n",
      "train loss:2.44068817829271\n",
      "=== epoch:19, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.358711350848527\n",
      "train loss:2.401631926527589\n",
      "train loss:2.428917177651985\n",
      "train loss:2.3567886726596012\n",
      "=== epoch:20, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3111341004950017\n",
      "train loss:2.413058957195767\n",
      "train loss:2.3431183415408734\n",
      "train loss:2.405746707985328\n",
      "=== epoch:21, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.321248969947284\n",
      "train loss:2.386017415481491\n",
      "train loss:2.477259764565114\n",
      "train loss:2.359046601778252\n",
      "=== epoch:22, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.460676567135998\n",
      "train loss:2.346071747623454\n",
      "train loss:2.3895783964574244\n",
      "train loss:2.386721674597047\n",
      "=== epoch:23, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3248730385119414\n",
      "train loss:2.37962779365703\n",
      "train loss:2.4390070953470815\n",
      "train loss:2.302205187939083\n",
      "=== epoch:24, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.370888491057272\n",
      "train loss:2.3816791721447195\n",
      "train loss:2.358255502833527\n",
      "train loss:2.3848311559646107\n",
      "=== epoch:25, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3729429678066047\n",
      "train loss:2.35846931940382\n",
      "train loss:2.3853820289350662\n",
      "train loss:2.410745100078531\n",
      "=== epoch:26, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3411070700676078\n",
      "train loss:2.34340758080768\n",
      "train loss:2.4398336518410226\n",
      "train loss:2.4625143544146075\n",
      "=== epoch:27, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3548685067678763\n",
      "train loss:2.4197713245321957\n",
      "train loss:2.3686228124721467\n",
      "train loss:2.404381360022858\n",
      "=== epoch:28, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.375132866030262\n",
      "train loss:2.390042418559517\n",
      "train loss:2.445053851711792\n",
      "train loss:2.407574272181425\n",
      "=== epoch:29, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.4150097421194516\n",
      "train loss:2.32810779264009\n",
      "train loss:2.388464451297261\n",
      "train loss:2.5044282897014187\n",
      "=== epoch:30, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.26623826363183\n",
      "train loss:2.416026326869042\n",
      "train loss:2.360761696250255\n",
      "train loss:2.4062821586559773\n",
      "=== epoch:31, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3818604852503507\n",
      "train loss:2.407594121734682\n",
      "train loss:2.349532389094335\n",
      "train loss:2.3336800956322286\n",
      "=== epoch:32, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3074849095339904\n",
      "train loss:2.3013380282888853\n",
      "train loss:2.3358538005301415\n",
      "train loss:2.377730629258136\n",
      "=== epoch:33, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.4329258374918674\n",
      "train loss:2.3067621049418956\n",
      "train loss:2.442137339810984\n",
      "train loss:2.375249085735292\n",
      "=== epoch:34, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.339144514378822\n",
      "train loss:2.396277054318447\n",
      "train loss:2.3469343403650065\n",
      "train loss:2.371286681267117\n",
      "=== epoch:35, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.4915866154502666\n",
      "train loss:2.3651797712803426\n",
      "train loss:2.4200078507141525\n",
      "train loss:2.4047015017222795\n",
      "=== epoch:36, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3633429296359916\n",
      "train loss:2.3913670148722144\n",
      "train loss:2.3113661795540743\n",
      "train loss:2.3695195210734274\n",
      "=== epoch:37, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.362955667810769\n",
      "train loss:2.360235509731341\n",
      "train loss:2.4324743326622027\n",
      "train loss:2.276442391656411\n",
      "=== epoch:38, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3864368470864417\n",
      "train loss:2.388875614056151\n",
      "train loss:2.408050788651726\n",
      "train loss:2.349094776284288\n",
      "=== epoch:39, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.4298932390604726\n",
      "train loss:2.394318053522776\n",
      "train loss:2.309503930136753\n",
      "train loss:2.3807055581380805\n",
      "=== epoch:40, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.368152124727561\n",
      "train loss:2.3935191684818276\n",
      "train loss:2.369642353124086\n",
      "train loss:2.3723450479241412\n",
      "=== epoch:41, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.2926915933057104\n",
      "train loss:2.3584272693552824\n",
      "train loss:2.3752016309719632\n",
      "train loss:2.3868314902494983\n",
      "=== epoch:42, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.39761282328587\n",
      "train loss:2.4083601475650327\n",
      "train loss:2.353117536121826\n",
      "train loss:2.3892714728013544\n",
      "=== epoch:43, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3437463482013823\n",
      "train loss:2.3702064588963423\n",
      "train loss:2.414118430643079\n",
      "train loss:2.345228536346641\n",
      "=== epoch:44, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.344994962504251\n",
      "train loss:2.4442205769622727\n",
      "train loss:2.3524818467019535\n",
      "train loss:2.4128478131976223\n",
      "=== epoch:45, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3503273433950014\n",
      "train loss:2.303083248331535\n",
      "train loss:2.3446891327012476\n",
      "train loss:2.2569706124514397\n",
      "=== epoch:46, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.347440146058361\n",
      "train loss:2.3878193311844056\n",
      "train loss:2.410764647948699\n",
      "train loss:2.380844091790132\n",
      "=== epoch:47, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3231918677134247\n",
      "train loss:2.346944186669574\n",
      "train loss:2.3404210074872918\n",
      "train loss:2.3804521137898345\n",
      "=== epoch:48, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.2796395822137585\n",
      "train loss:2.32818279342663\n",
      "train loss:2.325984086024124\n",
      "train loss:2.321657545667015\n",
      "=== epoch:49, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3593312431255056\n",
      "train loss:2.3877941770808513\n",
      "train loss:2.4159216267445935\n",
      "train loss:2.4385045672025205\n",
      "=== epoch:50, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.384714871670604\n",
      "train loss:2.3663226768207264\n",
      "train loss:2.377445796596435\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3562743084570283\n",
      "=== epoch:1, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.2806885513207034\n",
      "train loss:2.3393329835216625\n",
      "train loss:2.313987751546365\n",
      "train loss:2.3249681439124754\n",
      "=== epoch:2, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3646743754233177\n",
      "train loss:2.298887929829915\n",
      "train loss:2.2679147876308114\n",
      "train loss:2.330172596648208\n",
      "=== epoch:3, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.2278661546193614\n",
      "train loss:2.2963183633853266\n",
      "train loss:2.3079282859908514\n",
      "train loss:2.3315648462486225\n",
      "=== epoch:4, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3285411760000176\n",
      "train loss:2.3571073351715253\n",
      "train loss:2.3587121131690094\n",
      "train loss:2.4107047445346046\n",
      "=== epoch:5, train acc:0.12, test acc:0.19 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.368877530635481\n",
      "train loss:2.2988794605230347\n",
      "train loss:2.3789569933061214\n",
      "train loss:2.334029864230644\n",
      "=== epoch:6, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.355916078207246\n",
      "train loss:2.3564666835809556\n",
      "train loss:2.30247074215506\n",
      "train loss:2.357347274462998\n",
      "=== epoch:7, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3691653915991133\n",
      "train loss:2.2718479090569748\n",
      "train loss:2.343836877517685\n",
      "train loss:2.290012190321703\n",
      "=== epoch:8, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3232449926093035\n",
      "train loss:2.325195917684153\n",
      "train loss:2.3604434762806927\n",
      "train loss:2.30411394859443\n",
      "=== epoch:9, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3508984484546707\n",
      "train loss:2.3354332147068164\n",
      "train loss:2.385300155931617\n",
      "train loss:2.346978407260602\n",
      "=== epoch:10, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3618161737526506\n",
      "train loss:2.3623797782933584\n",
      "train loss:2.3470676614409114\n",
      "train loss:2.2618914319660997\n",
      "=== epoch:11, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3230404082574547\n",
      "train loss:2.3669129871867858\n",
      "train loss:2.3412206090806946\n",
      "train loss:2.3123804525471496\n",
      "=== epoch:12, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3146566125758494\n",
      "train loss:2.3437300793697555\n",
      "train loss:2.4096101580793823\n",
      "train loss:2.3474104546724366\n",
      "=== epoch:13, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.332957547091142\n",
      "train loss:2.354258512989513\n",
      "train loss:2.395478400720236\n",
      "train loss:2.323736178280401\n",
      "=== epoch:14, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.393615565601531\n",
      "train loss:2.3997126905446255\n",
      "train loss:2.369797694666909\n",
      "train loss:2.4331987919353666\n",
      "=== epoch:15, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.334611882004436\n",
      "train loss:2.3266580744141563\n",
      "train loss:2.3899056196982857\n",
      "train loss:2.3719454432356653\n",
      "=== epoch:16, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3613606350990515\n",
      "train loss:2.352177795567078\n",
      "train loss:2.329543882686981\n",
      "train loss:2.3307484805051684\n",
      "=== epoch:17, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3246371019043632\n",
      "train loss:2.225591561238888\n",
      "train loss:2.377990325403603\n",
      "train loss:2.3251782413755837\n",
      "=== epoch:18, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.343057310375796\n",
      "train loss:2.379801130803869\n",
      "train loss:2.3604830193381927\n",
      "train loss:2.32655495588131\n",
      "=== epoch:19, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.324393153550831\n",
      "train loss:2.318447937349418\n",
      "train loss:2.317987101767309\n",
      "train loss:2.329790206153393\n",
      "=== epoch:20, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3705876665819887\n",
      "train loss:2.3871810245918974\n",
      "train loss:2.397991729513159\n",
      "train loss:2.3061445601325614\n",
      "=== epoch:21, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3034817339511022\n",
      "train loss:2.325692470844235\n",
      "train loss:2.346655003987021\n",
      "train loss:2.3312841801284763\n",
      "=== epoch:22, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3583182599031467\n",
      "train loss:2.2730282929546473\n",
      "train loss:2.3420781199650773\n",
      "train loss:2.3127514206924067\n",
      "=== epoch:23, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.318454162476292\n",
      "train loss:2.3567981104784987\n",
      "train loss:2.297629938375541\n",
      "train loss:2.289621873061398\n",
      "=== epoch:24, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.379896417176248\n",
      "train loss:2.36521542868857\n",
      "train loss:2.4022824334767794\n",
      "train loss:2.263154670681171\n",
      "=== epoch:25, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3367359413976456\n",
      "train loss:2.359424561882705\n",
      "train loss:2.279655539136376\n",
      "train loss:2.275589752513672\n",
      "=== epoch:26, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.2687398052838588\n",
      "train loss:2.3753322699879136\n",
      "train loss:2.285876182770313\n",
      "train loss:2.2850399636853256\n",
      "=== epoch:27, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.2869735260878765\n",
      "train loss:2.364216459562026\n",
      "train loss:2.3160310942501128\n",
      "train loss:2.319286558072387\n",
      "=== epoch:28, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3344745038335355\n",
      "train loss:2.281399340912691\n",
      "train loss:2.361709362765609\n",
      "train loss:2.34560334993296\n",
      "=== epoch:29, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3419737068060584\n",
      "train loss:2.343918318812051\n",
      "train loss:2.383480462507477\n",
      "train loss:2.345165657059697\n",
      "=== epoch:30, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3287930058305464\n",
      "train loss:2.329675338817253\n",
      "train loss:2.391907736018715\n",
      "train loss:2.379762668280789\n",
      "=== epoch:31, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3466651492525283\n",
      "train loss:2.3118395501683806\n",
      "train loss:2.3612554288338883\n",
      "train loss:2.3428129235133226\n",
      "=== epoch:32, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.2609302810082648\n",
      "train loss:2.386607051044796\n",
      "train loss:2.367851463759973\n",
      "train loss:2.325024867536441\n",
      "=== epoch:33, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.327603462843799\n",
      "train loss:2.2921131146447613\n",
      "train loss:2.379706526898615\n",
      "train loss:2.4211441223098893\n",
      "=== epoch:34, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.373970071651061\n",
      "train loss:2.345688490046203\n",
      "train loss:2.2884010336955516\n",
      "train loss:2.345869172008602\n",
      "=== epoch:35, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.2587524722021963\n",
      "train loss:2.3789637430221715\n",
      "train loss:2.353433848371107\n",
      "train loss:2.3455220442212315\n",
      "=== epoch:36, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.4193424067798817\n",
      "train loss:2.365246097745546\n",
      "train loss:2.3899165369620756\n",
      "train loss:2.363804597530521\n",
      "=== epoch:37, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3456951214392068\n",
      "train loss:2.3724898976789786\n",
      "train loss:2.3192400297280398\n",
      "train loss:2.3836902710461927\n",
      "=== epoch:38, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3547447488308384\n",
      "train loss:2.35130396648641\n",
      "train loss:2.367155686904711\n",
      "train loss:2.3392355278655375\n",
      "=== epoch:39, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.285794885795467\n",
      "train loss:2.3025372548401415\n",
      "train loss:2.312465846555864\n",
      "train loss:2.3213484042453456\n",
      "=== epoch:40, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.325527061231459\n",
      "train loss:2.3155109402922895\n",
      "train loss:2.2936977927359226\n",
      "train loss:2.3426793974979487\n",
      "=== epoch:41, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.306224266579954\n",
      "train loss:2.3888701798353185\n",
      "train loss:2.33557108587765\n",
      "train loss:2.390275798226663\n",
      "=== epoch:42, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3694035359823404\n",
      "train loss:2.3903920392784834\n",
      "train loss:2.3032176007384817\n",
      "train loss:2.2989465323510836\n",
      "=== epoch:43, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3993105402516406\n",
      "train loss:2.3143584243649222\n",
      "train loss:2.3255090085589827\n",
      "train loss:2.3465386005769524\n",
      "=== epoch:44, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3693852349279854\n",
      "train loss:2.3503125533633575\n",
      "train loss:2.296107387269725\n",
      "train loss:2.38481595151629\n",
      "=== epoch:45, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.261942011463941\n",
      "train loss:2.3229045902420657\n",
      "train loss:2.293487893290824\n",
      "train loss:2.3713976112835127\n",
      "=== epoch:46, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.27171034391452\n",
      "train loss:2.3659967065384007\n",
      "train loss:2.2771151687793614\n",
      "train loss:2.370368681683524\n",
      "=== epoch:47, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3105127706680064\n",
      "train loss:2.3453619891921256\n",
      "train loss:2.3597972321870895\n",
      "train loss:2.2763979180330196\n",
      "=== epoch:48, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.300728793239898\n",
      "train loss:2.365748924166661\n",
      "train loss:2.332723957631706\n",
      "train loss:2.3279143672408984\n",
      "=== epoch:49, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.329382460647902\n",
      "train loss:2.342617965065474\n",
      "train loss:2.3351992386046847\n",
      "train loss:2.267009879494446\n",
      "=== epoch:50, train acc:0.12, test acc:0.19 ===\n",
      "train loss:2.3131376129865586\n",
      "train loss:2.4070914242039887\n",
      "train loss:2.3051529636302774\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.19\n",
      "val_acc: 0.1900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.358960068445509\n",
      "=== epoch:1, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.4085595554086625\n",
      "train loss:2.456724852530375\n",
      "train loss:2.42466850881331\n",
      "train loss:2.43009843894975\n",
      "=== epoch:2, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.395235494895783\n",
      "train loss:2.3260248791012743\n",
      "train loss:2.3756624461983766\n",
      "train loss:2.453122766722736\n",
      "=== epoch:3, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.334167529982109\n",
      "train loss:2.4166977768083124\n",
      "train loss:2.4354959247173036\n",
      "train loss:2.4108795959006275\n",
      "=== epoch:4, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.5028384188691515\n",
      "train loss:2.4343167588996715\n",
      "train loss:2.368349826939662\n",
      "train loss:2.372426610982822\n",
      "=== epoch:5, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.4485279521528738\n",
      "train loss:2.322664435449634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.402180920912192\n",
      "train loss:2.424196704630001\n",
      "=== epoch:6, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.3868899918856994\n",
      "train loss:2.379272314522716\n",
      "train loss:2.446983175875142\n",
      "train loss:2.435740579906847\n",
      "=== epoch:7, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.375830006357626\n",
      "train loss:2.399382779250906\n",
      "train loss:2.3234975947142003\n",
      "train loss:2.3791767348569\n",
      "=== epoch:8, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.399990082293354\n",
      "train loss:2.44491688758406\n",
      "train loss:2.366499960869183\n",
      "train loss:2.4647706599672055\n",
      "=== epoch:9, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.479902036616867\n",
      "train loss:2.364934294065801\n",
      "train loss:2.3865323206459594\n",
      "train loss:2.3858570554514285\n",
      "=== epoch:10, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.4562179730805442\n",
      "train loss:2.429964540015927\n",
      "train loss:2.4466336584191954\n",
      "train loss:2.4195410559553783\n",
      "=== epoch:11, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.383602790632572\n",
      "train loss:2.4349415756560457\n",
      "train loss:2.4113592624500737\n",
      "train loss:2.355445837532041\n",
      "=== epoch:12, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.4379985304888323\n",
      "train loss:2.353608961606994\n",
      "train loss:2.431377254785291\n",
      "train loss:2.4123371609801807\n",
      "=== epoch:13, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.3934489869103603\n",
      "train loss:2.44521245793012\n",
      "train loss:2.385640795072214\n",
      "train loss:2.380394387885931\n",
      "=== epoch:14, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.420692899073575\n",
      "train loss:2.42008706382591\n",
      "train loss:2.429869543831812\n",
      "train loss:2.4258499645754776\n",
      "=== epoch:15, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3567525470799886\n",
      "train loss:2.4280083612276973\n",
      "train loss:2.4391873965102473\n",
      "train loss:2.3692136300760525\n",
      "=== epoch:16, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.405032832806955\n",
      "train loss:2.4011389445264006\n",
      "train loss:2.3071559762571305\n",
      "train loss:2.352104211696522\n",
      "=== epoch:17, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.4174253064004723\n",
      "train loss:2.3328874485118303\n",
      "train loss:2.374543353458777\n",
      "train loss:2.386379719033086\n",
      "=== epoch:18, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.395191421442649\n",
      "train loss:2.4503225912629096\n",
      "train loss:2.455423766066102\n",
      "train loss:2.4327854116689\n",
      "=== epoch:19, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.443161092305251\n",
      "train loss:2.4283927582788083\n",
      "train loss:2.4784829671787225\n",
      "train loss:2.429863852064494\n",
      "=== epoch:20, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3586674645365866\n",
      "train loss:2.361543894402388\n",
      "train loss:2.4301571902443504\n",
      "train loss:2.408645019048595\n",
      "=== epoch:21, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3369988660636865\n",
      "train loss:2.3396568377055647\n",
      "train loss:2.4376889958137045\n",
      "train loss:2.3530689625914345\n",
      "=== epoch:22, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.4344622411715844\n",
      "train loss:2.4007345336843664\n",
      "train loss:2.3569024691038165\n",
      "train loss:2.4160302520278907\n",
      "=== epoch:23, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.342508080467147\n",
      "train loss:2.4237118659727743\n",
      "train loss:2.4417350581455453\n",
      "train loss:2.3953017124419085\n",
      "=== epoch:24, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.509013862298669\n",
      "train loss:2.364162314054719\n",
      "train loss:2.4377122617699305\n",
      "train loss:2.3736061126864576\n",
      "=== epoch:25, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.385517617059589\n",
      "train loss:2.4108116916519426\n",
      "train loss:2.3769956745127288\n",
      "train loss:2.4389842142990736\n",
      "=== epoch:26, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.415865989657472\n",
      "train loss:2.3829542130180514\n",
      "train loss:2.4104132077670823\n",
      "train loss:2.412290164072719\n",
      "=== epoch:27, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.364726621564709\n",
      "train loss:2.416115807078287\n",
      "train loss:2.435834833915017\n",
      "train loss:2.3698392640526222\n",
      "=== epoch:28, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.4242759123835853\n",
      "train loss:2.450904674687452\n",
      "train loss:2.400917488984116\n",
      "train loss:2.3874510164827396\n",
      "=== epoch:29, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.4170330831391094\n",
      "train loss:2.4413442546855846\n",
      "train loss:2.388796928616792\n",
      "train loss:2.4163788378133697\n",
      "=== epoch:30, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.358684777889481\n",
      "train loss:2.4242196128228026\n",
      "train loss:2.401720079545938\n",
      "train loss:2.3947858658469654\n",
      "=== epoch:31, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3584159197015113\n",
      "train loss:2.375681529017017\n",
      "train loss:2.4633831737902905\n",
      "train loss:2.389974583882171\n",
      "=== epoch:32, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.403007146253614\n",
      "train loss:2.4579831293351586\n",
      "train loss:2.389812451237035\n",
      "train loss:2.392414330547301\n",
      "=== epoch:33, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3993073722958975\n",
      "train loss:2.3880486281852393\n",
      "train loss:2.31359044153554\n",
      "train loss:2.40662877553261\n",
      "=== epoch:34, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.346574410681689\n",
      "train loss:2.3765769902755287\n",
      "train loss:2.3551612394602848\n",
      "train loss:2.4232807425643874\n",
      "=== epoch:35, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.34643310544063\n",
      "train loss:2.37130470048739\n",
      "train loss:2.4297686554134557\n",
      "train loss:2.4630933640031514\n",
      "=== epoch:36, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.463812475982849\n",
      "train loss:2.4448683653715824\n",
      "train loss:2.3772975114436488\n",
      "train loss:2.36210863323916\n",
      "=== epoch:37, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3819453741823073\n",
      "train loss:2.356458932276377\n",
      "train loss:2.3187916722231106\n",
      "train loss:2.4469177321460998\n",
      "=== epoch:38, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.4385297652836986\n",
      "train loss:2.35679818277777\n",
      "train loss:2.3613337078890777\n",
      "train loss:2.385284789305337\n",
      "=== epoch:39, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.424792197775181\n",
      "train loss:2.3895867963423028\n",
      "train loss:2.4241821310900376\n",
      "train loss:2.396960681854788\n",
      "=== epoch:40, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.4076160500593793\n",
      "train loss:2.4417849678103978\n",
      "train loss:2.3973608764051457\n",
      "train loss:2.397753206572658\n",
      "=== epoch:41, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3664991908571995\n",
      "train loss:2.4410621801572874\n",
      "train loss:2.391491699586635\n",
      "train loss:2.388728750294761\n",
      "=== epoch:42, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.434577843693008\n",
      "train loss:2.396060998586775\n",
      "train loss:2.3678212063670814\n",
      "train loss:2.32613547472199\n",
      "=== epoch:43, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.414547306812642\n",
      "train loss:2.404515209048905\n",
      "train loss:2.4387783185840686\n",
      "train loss:2.4185804819894643\n",
      "=== epoch:44, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.344821030657846\n",
      "train loss:2.3922613754405164\n",
      "train loss:2.45234279839556\n",
      "train loss:2.4486123770444705\n",
      "=== epoch:45, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.409265847528788\n",
      "train loss:2.4399213801126596\n",
      "train loss:2.410314913810824\n",
      "train loss:2.3879264036126067\n",
      "=== epoch:46, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3819139714646917\n",
      "train loss:2.4250795353338055\n",
      "train loss:2.319220228805668\n",
      "train loss:2.488748942947899\n",
      "=== epoch:47, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3618449268571773\n",
      "train loss:2.3385658270568332\n",
      "train loss:2.342269476966416\n",
      "train loss:2.384140271668313\n",
      "=== epoch:48, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3744023773645027\n",
      "train loss:2.3839959205982693\n",
      "train loss:2.4068870797676296\n",
      "train loss:2.4105043673029387\n",
      "=== epoch:49, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.378345214026237\n",
      "train loss:2.3635763610337177\n",
      "train loss:2.4675897997004164\n",
      "train loss:2.3623947748129654\n",
      "=== epoch:50, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.408278164484535\n",
      "train loss:2.3728441625567895\n",
      "train loss:2.3613023768619112\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3422259438794555\n",
      "=== epoch:1, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3651299286025194\n",
      "train loss:2.355286065981557\n",
      "train loss:2.3994441904757258\n",
      "train loss:2.405465145224652\n",
      "=== epoch:2, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4141723358680234\n",
      "train loss:2.434831090039647\n",
      "train loss:2.4232026588376683\n",
      "train loss:2.3407758460993575\n",
      "=== epoch:3, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2917312754086328\n",
      "train loss:2.3464571616930914\n",
      "train loss:2.462602355700034\n",
      "train loss:2.315276885394119\n",
      "=== epoch:4, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3343329466736162\n",
      "train loss:2.3257802790461444\n",
      "train loss:2.3365389683257196\n",
      "train loss:2.2796082561658078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:5, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.341359295201813\n",
      "train loss:2.359525524373462\n",
      "train loss:2.357527478257759\n",
      "train loss:2.3290950829349524\n",
      "=== epoch:6, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3626597778990903\n",
      "train loss:2.2755564522576663\n",
      "train loss:2.3664224658693125\n",
      "train loss:2.3624215439945146\n",
      "=== epoch:7, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.32338099385593\n",
      "train loss:2.2961996808889573\n",
      "train loss:2.294970066550016\n",
      "train loss:2.3462450244841784\n",
      "=== epoch:8, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3470515874752222\n",
      "train loss:2.295739337809241\n",
      "train loss:2.352319162348013\n",
      "train loss:2.2978986106311083\n",
      "=== epoch:9, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.286883088137731\n",
      "train loss:2.342435054301162\n",
      "train loss:2.2693080838688333\n",
      "train loss:2.3117563177065015\n",
      "=== epoch:10, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3154814850525227\n",
      "train loss:2.338703356612794\n",
      "train loss:2.274049524257089\n",
      "train loss:2.274186677968028\n",
      "=== epoch:11, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2750999924983852\n",
      "train loss:2.317173495223163\n",
      "train loss:2.3416711499875484\n",
      "train loss:2.2744965006154545\n",
      "=== epoch:12, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.288954091502988\n",
      "train loss:2.2923676664136003\n",
      "train loss:2.3406611096843926\n",
      "train loss:2.3021227460612304\n",
      "=== epoch:13, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3129347123687185\n",
      "train loss:2.2701718128533437\n",
      "train loss:2.2842395820062653\n",
      "train loss:2.253442419957642\n",
      "=== epoch:14, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2899863693753346\n",
      "train loss:2.2677032877164534\n",
      "train loss:2.2941648614662586\n",
      "train loss:2.3185928084118435\n",
      "=== epoch:15, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2796224777594456\n",
      "train loss:2.298421784326933\n",
      "train loss:2.3045143551405007\n",
      "train loss:2.260775703355608\n",
      "=== epoch:16, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2314512217843996\n",
      "train loss:2.244434533000349\n",
      "train loss:2.3217207949795715\n",
      "train loss:2.2936370470350296\n",
      "=== epoch:17, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.289055202772071\n",
      "train loss:2.2218764174468615\n",
      "train loss:2.1935121345942052\n",
      "train loss:2.262204456108192\n",
      "=== epoch:18, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2567040496570185\n",
      "train loss:2.2907092743114243\n",
      "train loss:2.1985804093423282\n",
      "train loss:2.297457081189896\n",
      "=== epoch:19, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3410136705235147\n",
      "train loss:2.2910173677639727\n",
      "train loss:2.2883497218219175\n",
      "train loss:2.257850774097114\n",
      "=== epoch:20, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2583878081118853\n",
      "train loss:2.282320862912618\n",
      "train loss:2.249761877088586\n",
      "train loss:2.204342224049441\n",
      "=== epoch:21, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.268145996287161\n",
      "train loss:2.234601604487567\n",
      "train loss:2.2443323803159316\n",
      "train loss:2.2232408694045915\n",
      "=== epoch:22, train acc:0.1125, test acc:0.08 ===\n",
      "train loss:2.2143927962024055\n",
      "train loss:2.264782128863127\n",
      "train loss:2.186522755935269\n",
      "train loss:2.2220443366951157\n",
      "=== epoch:23, train acc:0.1125, test acc:0.08 ===\n",
      "train loss:2.1906869462966854\n",
      "train loss:2.260146725832476\n",
      "train loss:2.301116695756277\n",
      "train loss:2.261683217516677\n",
      "=== epoch:24, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.1927663526662418\n",
      "train loss:2.2351948769901733\n",
      "train loss:2.2531380556726166\n",
      "train loss:2.245465939214549\n",
      "=== epoch:25, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.2391887104316512\n",
      "train loss:2.2075512755893225\n",
      "train loss:2.250743818701472\n",
      "train loss:2.2097118123616375\n",
      "=== epoch:26, train acc:0.1175, test acc:0.08 ===\n",
      "train loss:2.179317616504105\n",
      "train loss:2.2450673874857774\n",
      "train loss:2.2089277861719596\n",
      "train loss:2.2385755503786413\n",
      "=== epoch:27, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.263253282721858\n",
      "train loss:2.1947931763111406\n",
      "train loss:2.2149395380162775\n",
      "train loss:2.189832456040023\n",
      "=== epoch:28, train acc:0.125, test acc:0.08 ===\n",
      "train loss:2.2793699149166153\n",
      "train loss:2.2125983255053736\n",
      "train loss:2.235739081797817\n",
      "train loss:2.219916593447335\n",
      "=== epoch:29, train acc:0.1275, test acc:0.1 ===\n",
      "train loss:2.2222369046219193\n",
      "train loss:2.272997395603999\n",
      "train loss:2.206698308931616\n",
      "train loss:2.1680293613624206\n",
      "=== epoch:30, train acc:0.13, test acc:0.1 ===\n",
      "train loss:2.1812894818908846\n",
      "train loss:2.170141090156175\n",
      "train loss:2.17605620001281\n",
      "train loss:2.234634323634559\n",
      "=== epoch:31, train acc:0.1325, test acc:0.11 ===\n",
      "train loss:2.226110430192018\n",
      "train loss:2.205320722886289\n",
      "train loss:2.1902858511800276\n",
      "train loss:2.185409541301298\n",
      "=== epoch:32, train acc:0.135, test acc:0.11 ===\n",
      "train loss:2.1339613919846907\n",
      "train loss:2.2228774502318536\n",
      "train loss:2.21169709643094\n",
      "train loss:2.150898068196345\n",
      "=== epoch:33, train acc:0.14, test acc:0.11 ===\n",
      "train loss:2.1880804460260186\n",
      "train loss:2.236447208956291\n",
      "train loss:2.178875103755012\n",
      "train loss:2.152297888090023\n",
      "=== epoch:34, train acc:0.1475, test acc:0.11 ===\n",
      "train loss:2.1621269105293837\n",
      "train loss:2.173523871330577\n",
      "train loss:2.214061561688964\n",
      "train loss:2.187146296101263\n",
      "=== epoch:35, train acc:0.1475, test acc:0.11 ===\n",
      "train loss:2.2400963341136366\n",
      "train loss:2.1641519706776062\n",
      "train loss:2.209692538955263\n",
      "train loss:2.1757626243849097\n",
      "=== epoch:36, train acc:0.15, test acc:0.11 ===\n",
      "train loss:2.1444402871677792\n",
      "train loss:2.2119434649140177\n",
      "train loss:2.1910935285467974\n",
      "train loss:2.1834373793928417\n",
      "=== epoch:37, train acc:0.155, test acc:0.11 ===\n",
      "train loss:2.1869504790353638\n",
      "train loss:2.2341379269191277\n",
      "train loss:2.201516189935332\n",
      "train loss:2.221832750776726\n",
      "=== epoch:38, train acc:0.1575, test acc:0.11 ===\n",
      "train loss:2.1466022899734782\n",
      "train loss:2.191578143944704\n",
      "train loss:2.1178836240968724\n",
      "train loss:2.2382295285126874\n",
      "=== epoch:39, train acc:0.1675, test acc:0.11 ===\n",
      "train loss:2.190117308855045\n",
      "train loss:2.186412988806458\n",
      "train loss:2.1329186573347307\n",
      "train loss:2.1733861319829195\n",
      "=== epoch:40, train acc:0.1725, test acc:0.11 ===\n",
      "train loss:2.191216041883781\n",
      "train loss:2.204192607069814\n",
      "train loss:2.150335901044931\n",
      "train loss:2.1573130234073243\n",
      "=== epoch:41, train acc:0.175, test acc:0.11 ===\n",
      "train loss:2.107742462083728\n",
      "train loss:2.155815100107152\n",
      "train loss:2.1302127629865355\n",
      "train loss:2.1855395819127037\n",
      "=== epoch:42, train acc:0.18, test acc:0.12 ===\n",
      "train loss:2.137684788501546\n",
      "train loss:2.2058577704072717\n",
      "train loss:2.131450085679622\n",
      "train loss:2.1789682272043556\n",
      "=== epoch:43, train acc:0.1875, test acc:0.13 ===\n",
      "train loss:2.2065610477023645\n",
      "train loss:2.142349526020855\n",
      "train loss:2.11326380591385\n",
      "train loss:2.1999484489724956\n",
      "=== epoch:44, train acc:0.195, test acc:0.13 ===\n",
      "train loss:2.109162026771946\n",
      "train loss:2.1676084578654686\n",
      "train loss:2.216290771091849\n",
      "train loss:2.158312777084934\n",
      "=== epoch:45, train acc:0.21, test acc:0.13 ===\n",
      "train loss:2.1401612174356015\n",
      "train loss:2.1597091135035535\n",
      "train loss:2.1500502553120113\n",
      "train loss:2.1336008252808916\n",
      "=== epoch:46, train acc:0.215, test acc:0.13 ===\n",
      "train loss:2.165205726424843\n",
      "train loss:2.0770949300595443\n",
      "train loss:2.108953334752858\n",
      "train loss:2.1327737811540928\n",
      "=== epoch:47, train acc:0.2175, test acc:0.13 ===\n",
      "train loss:2.1919668124371117\n",
      "train loss:2.1690268246965014\n",
      "train loss:2.095604317440174\n",
      "train loss:2.1768241918711695\n",
      "=== epoch:48, train acc:0.22, test acc:0.13 ===\n",
      "train loss:2.1451967731869135\n",
      "train loss:2.1749697225269626\n",
      "train loss:2.180073907634618\n",
      "train loss:2.1566610463479976\n",
      "=== epoch:49, train acc:0.2225, test acc:0.13 ===\n",
      "train loss:2.181939899550425\n",
      "train loss:2.2062037688157514\n",
      "train loss:2.121740097830605\n",
      "train loss:2.0691714337360545\n",
      "=== epoch:50, train acc:0.2275, test acc:0.14 ===\n",
      "train loss:2.0739557423478856\n",
      "train loss:2.115777090543546\n",
      "train loss:2.156519663532733\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.14\n",
      "val_acc: 0.1400 | lr: 0.0018, weight_decay: 0.0000\n",
      "train loss:2.3271325508792415\n",
      "=== epoch:1, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.419946144228057\n",
      "train loss:2.3311029946261277\n",
      "train loss:2.422060054414584\n",
      "train loss:2.2934586932498235\n",
      "=== epoch:2, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3979870123473015\n",
      "train loss:2.3867956600581923\n",
      "train loss:2.3665801188392073\n",
      "train loss:2.3026284337091885\n",
      "=== epoch:3, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.357694295979772\n",
      "train loss:2.367019475807849\n",
      "train loss:2.3684996164969494\n",
      "train loss:2.2928120761469932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:4, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3681322392025583\n",
      "train loss:2.282807990353665\n",
      "train loss:2.292459729980876\n",
      "train loss:2.335889747074488\n",
      "=== epoch:5, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3351971590787435\n",
      "train loss:2.381116410851113\n",
      "train loss:2.3393347721912336\n",
      "train loss:2.3348839078816632\n",
      "=== epoch:6, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4255892853006737\n",
      "train loss:2.326665929741227\n",
      "train loss:2.3810686183036265\n",
      "train loss:2.3248673822598023\n",
      "=== epoch:7, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3793196354577124\n",
      "train loss:2.255084487470251\n",
      "train loss:2.3655292916196884\n",
      "train loss:2.24196853008917\n",
      "=== epoch:8, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3261699798520166\n",
      "train loss:2.3754945899437483\n",
      "train loss:2.3934677787471252\n",
      "train loss:2.352630970475725\n",
      "=== epoch:9, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.347137074666891\n",
      "train loss:2.300746234073244\n",
      "train loss:2.3290770098783784\n",
      "train loss:2.3640152796135037\n",
      "=== epoch:10, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3716550042683977\n",
      "train loss:2.377538882430942\n",
      "train loss:2.3708779483257714\n",
      "train loss:2.354335982904354\n",
      "=== epoch:11, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.28732934906288\n",
      "train loss:2.3683356049850857\n",
      "train loss:2.3245792426422014\n",
      "train loss:2.340993771845237\n",
      "=== epoch:12, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3686154021860424\n",
      "train loss:2.2998860361116495\n",
      "train loss:2.341153620502455\n",
      "train loss:2.3394525616342725\n",
      "=== epoch:13, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.360582780328858\n",
      "train loss:2.414133796822403\n",
      "train loss:2.2671852593822486\n",
      "train loss:2.2847267314819297\n",
      "=== epoch:14, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3107884932772635\n",
      "train loss:2.3232400432509404\n",
      "train loss:2.335843471511441\n",
      "train loss:2.3340176286756766\n",
      "=== epoch:15, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.336423215594435\n",
      "train loss:2.3306189902234116\n",
      "train loss:2.323335589425749\n",
      "train loss:2.407922975093785\n",
      "=== epoch:16, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3398456919751025\n",
      "train loss:2.3549313816377997\n",
      "train loss:2.3696446482277107\n",
      "train loss:2.3289430175481436\n",
      "=== epoch:17, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.424101372759802\n",
      "train loss:2.336366858896147\n",
      "train loss:2.367086642753163\n",
      "train loss:2.4187889423174798\n",
      "=== epoch:18, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.367338845446829\n",
      "train loss:2.3107174899565566\n",
      "train loss:2.3122646007686503\n",
      "train loss:2.3289584288920833\n",
      "=== epoch:19, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3205342681386725\n",
      "train loss:2.3380003848854516\n",
      "train loss:2.292045623599549\n",
      "train loss:2.384963863138292\n",
      "=== epoch:20, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3137907738807493\n",
      "train loss:2.3495733044007094\n",
      "train loss:2.402306989478504\n",
      "train loss:2.349762770664638\n",
      "=== epoch:21, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.314127274324378\n",
      "train loss:2.3261766299765063\n",
      "train loss:2.331808755856149\n",
      "train loss:2.3005210911694047\n",
      "=== epoch:22, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3064588019408028\n",
      "train loss:2.332033117476102\n",
      "train loss:2.3561304823136533\n",
      "train loss:2.3209413647695856\n",
      "=== epoch:23, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.2932185088975157\n",
      "train loss:2.354212096154448\n",
      "train loss:2.3361854221605336\n",
      "train loss:2.415893716197937\n",
      "=== epoch:24, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.330314618654445\n",
      "train loss:2.344112718601978\n",
      "train loss:2.3372987969665866\n",
      "train loss:2.322668404083278\n",
      "=== epoch:25, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.381749518061605\n",
      "train loss:2.2695721554016965\n",
      "train loss:2.3570100701208743\n",
      "train loss:2.3738717560490614\n",
      "=== epoch:26, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.370130016474058\n",
      "train loss:2.3479934694518234\n",
      "train loss:2.3382406322584295\n",
      "train loss:2.2988778224108533\n",
      "=== epoch:27, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.305369394301296\n",
      "train loss:2.3968481248187645\n",
      "train loss:2.2922635373550406\n",
      "train loss:2.3662254706166364\n",
      "=== epoch:28, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3935179017650916\n",
      "train loss:2.4235692392434163\n",
      "train loss:2.317560731750961\n",
      "train loss:2.2953972794825703\n",
      "=== epoch:29, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3951907407938267\n",
      "train loss:2.323364248576053\n",
      "train loss:2.3358680153827125\n",
      "train loss:2.262293126534146\n",
      "=== epoch:30, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3249846944761647\n",
      "train loss:2.3356650083327204\n",
      "train loss:2.39075836748704\n",
      "train loss:2.3054022313884652\n",
      "=== epoch:31, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.32491472755239\n",
      "train loss:2.270214610275206\n",
      "train loss:2.346811318019657\n",
      "train loss:2.354943030437957\n",
      "=== epoch:32, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.344893961770394\n",
      "train loss:2.3164059463782745\n",
      "train loss:2.3604701291923296\n",
      "train loss:2.29880195245083\n",
      "=== epoch:33, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3591982937436207\n",
      "train loss:2.2411461042342227\n",
      "train loss:2.3251484861088096\n",
      "train loss:2.267642301073341\n",
      "=== epoch:34, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3592194790779843\n",
      "train loss:2.3909359460869544\n",
      "train loss:2.4019779882922974\n",
      "train loss:2.278266730719741\n",
      "=== epoch:35, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.272331887389149\n",
      "train loss:2.3478906028610123\n",
      "train loss:2.3960728228256176\n",
      "train loss:2.3833538971174395\n",
      "=== epoch:36, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.400228653039792\n",
      "train loss:2.2805440899401126\n",
      "train loss:2.3320719450865774\n",
      "train loss:2.352624489342787\n",
      "=== epoch:37, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.2905117345198174\n",
      "train loss:2.3378738940552037\n",
      "train loss:2.3162110341978055\n",
      "train loss:2.3220778092491123\n",
      "=== epoch:38, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.310322038669808\n",
      "train loss:2.2981166225273206\n",
      "train loss:2.308805154687112\n",
      "train loss:2.3051028035826584\n",
      "=== epoch:39, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3216276160702725\n",
      "train loss:2.35346319079347\n",
      "train loss:2.329835330294121\n",
      "train loss:2.340366262676487\n",
      "=== epoch:40, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.353746199174556\n",
      "train loss:2.331949225951969\n",
      "train loss:2.3646619124239985\n",
      "train loss:2.331025232176991\n",
      "=== epoch:41, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.345596814926266\n",
      "train loss:2.2990415060554055\n",
      "train loss:2.3808644342052974\n",
      "train loss:2.4096352215827013\n",
      "=== epoch:42, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3334194743874814\n",
      "train loss:2.3767167380652143\n",
      "train loss:2.3193328137981344\n",
      "train loss:2.313621583187975\n",
      "=== epoch:43, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3128538671438856\n",
      "train loss:2.351418430980794\n",
      "train loss:2.3571480223097545\n",
      "train loss:2.3973538824032348\n",
      "=== epoch:44, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.305447950355102\n",
      "train loss:2.3445203220965825\n",
      "train loss:2.390289294032447\n",
      "train loss:2.3155930654971435\n",
      "=== epoch:45, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3013610342450312\n",
      "train loss:2.4055953990141443\n",
      "train loss:2.3619658789148175\n",
      "train loss:2.3482875129102587\n",
      "=== epoch:46, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.360944701588361\n",
      "train loss:2.3336018056072123\n",
      "train loss:2.3272753581940813\n",
      "train loss:2.3740824946790187\n",
      "=== epoch:47, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3683966066088833\n",
      "train loss:2.38090461723011\n",
      "train loss:2.3500004301384214\n",
      "train loss:2.397536906746292\n",
      "=== epoch:48, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3750728344452465\n",
      "train loss:2.3060697470325398\n",
      "train loss:2.305796178988384\n",
      "train loss:2.3770050769254047\n",
      "=== epoch:49, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4216589185650244\n",
      "train loss:2.357860332387139\n",
      "train loss:2.3260423221397897\n",
      "train loss:2.3817040041896957\n",
      "=== epoch:50, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.372648929538478\n",
      "train loss:2.3301753397299922\n",
      "train loss:2.353214004199623\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.408033717082786\n",
      "=== epoch:1, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.449312822485908\n",
      "train loss:2.4124368937275853\n",
      "train loss:2.3979717078263483\n",
      "train loss:2.43916630921817\n",
      "=== epoch:2, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.468758455227668\n",
      "train loss:2.372746993404624\n",
      "train loss:2.458493046289857\n",
      "train loss:2.4635929148379114\n",
      "=== epoch:3, train acc:0.105, test acc:0.08 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.5275558960149147\n",
      "train loss:2.4326854121437185\n",
      "train loss:2.3906000936807508\n",
      "train loss:2.452600095598714\n",
      "=== epoch:4, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3373887194765315\n",
      "train loss:2.3247623467988694\n",
      "train loss:2.4640742442214782\n",
      "train loss:2.49226830417209\n",
      "=== epoch:5, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3609973329070684\n",
      "train loss:2.4108158470557703\n",
      "train loss:2.4527505376193903\n",
      "train loss:2.4442813607874165\n",
      "=== epoch:6, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.448560627119169\n",
      "train loss:2.4214162966696846\n",
      "train loss:2.3965610039233884\n",
      "train loss:2.4095851494476217\n",
      "=== epoch:7, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.430284096251701\n",
      "train loss:2.444787459687463\n",
      "train loss:2.4724704777570534\n",
      "train loss:2.3960431056592943\n",
      "=== epoch:8, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4076388025919986\n",
      "train loss:2.4368097585930353\n",
      "train loss:2.4468901712081084\n",
      "train loss:2.4287419836859914\n",
      "=== epoch:9, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3831886471962656\n",
      "train loss:2.4054567829200053\n",
      "train loss:2.376958866788916\n",
      "train loss:2.379717355899104\n",
      "=== epoch:10, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4164532929611977\n",
      "train loss:2.393793769015312\n",
      "train loss:2.431188715575001\n",
      "train loss:2.509952058647949\n",
      "=== epoch:11, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4932334257458546\n",
      "train loss:2.387131218227658\n",
      "train loss:2.469565139870324\n",
      "train loss:2.4356227120129073\n",
      "=== epoch:12, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4146034191722023\n",
      "train loss:2.429525569887072\n",
      "train loss:2.3744176016852934\n",
      "train loss:2.3884707336021487\n",
      "=== epoch:13, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4168843840894256\n",
      "train loss:2.323983608492402\n",
      "train loss:2.3668395995512643\n",
      "train loss:2.455266008097162\n",
      "=== epoch:14, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3901333775127713\n",
      "train loss:2.4094717995590513\n",
      "train loss:2.3619170635486277\n",
      "train loss:2.409424714279253\n",
      "=== epoch:15, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3866939053602008\n",
      "train loss:2.395834712564194\n",
      "train loss:2.4339403359325162\n",
      "train loss:2.322780132554246\n",
      "=== epoch:16, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4589148314846163\n",
      "train loss:2.3391496727676735\n",
      "train loss:2.392095722488369\n",
      "train loss:2.392488193393511\n",
      "=== epoch:17, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.425997463744089\n",
      "train loss:2.5168673300829494\n",
      "train loss:2.44772163956855\n",
      "train loss:2.4128679895919105\n",
      "=== epoch:18, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.394925294324412\n",
      "train loss:2.369570926938376\n",
      "train loss:2.400769099638851\n",
      "train loss:2.4600219425119274\n",
      "=== epoch:19, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3786645642337443\n",
      "train loss:2.418361906802745\n",
      "train loss:2.4401997398745596\n",
      "train loss:2.4170404494278546\n",
      "=== epoch:20, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4236342585613246\n",
      "train loss:2.371142840943954\n",
      "train loss:2.402133650706543\n",
      "train loss:2.458053803982316\n",
      "=== epoch:21, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4618745695364987\n",
      "train loss:2.382011911274758\n",
      "train loss:2.45813125726719\n",
      "train loss:2.4644791447358423\n",
      "=== epoch:22, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.401649288958326\n",
      "train loss:2.424303732086018\n",
      "train loss:2.415410713051077\n",
      "train loss:2.406345698373231\n",
      "=== epoch:23, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4338398662943113\n",
      "train loss:2.4454142339088882\n",
      "train loss:2.43986356489832\n",
      "train loss:2.455788097740107\n",
      "=== epoch:24, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3650931989451593\n",
      "train loss:2.438400536601524\n",
      "train loss:2.469736485141794\n",
      "train loss:2.4264453102443744\n",
      "=== epoch:25, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4320246949787485\n",
      "train loss:2.4280221502352166\n",
      "train loss:2.407255846730619\n",
      "train loss:2.337744849939111\n",
      "=== epoch:26, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4384608509369206\n",
      "train loss:2.391316092833698\n",
      "train loss:2.4270789228281924\n",
      "train loss:2.458957593301388\n",
      "=== epoch:27, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.430848911980636\n",
      "train loss:2.4479009349429313\n",
      "train loss:2.4315082806009616\n",
      "train loss:2.336784267610991\n",
      "=== epoch:28, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4389436243670284\n",
      "train loss:2.329905340509054\n",
      "train loss:2.3401398803394264\n",
      "train loss:2.408147912468211\n",
      "=== epoch:29, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3549158778220685\n",
      "train loss:2.463382438898904\n",
      "train loss:2.389020423247509\n",
      "train loss:2.4451992545970795\n",
      "=== epoch:30, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.419322117807922\n",
      "train loss:2.465071739399651\n",
      "train loss:2.4055213322606215\n",
      "train loss:2.4219880414996022\n",
      "=== epoch:31, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4234050229549693\n",
      "train loss:2.5327137621099953\n",
      "train loss:2.496282954770999\n",
      "train loss:2.397997692192038\n",
      "=== epoch:32, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3950113466302745\n",
      "train loss:2.425836317692101\n",
      "train loss:2.4528568631983334\n",
      "train loss:2.4252119026989996\n",
      "=== epoch:33, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4194435725886234\n",
      "train loss:2.420748005166501\n",
      "train loss:2.3978770090279315\n",
      "train loss:2.446762483352912\n",
      "=== epoch:34, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.457414108145371\n",
      "train loss:2.419411123348057\n",
      "train loss:2.3738586171120017\n",
      "train loss:2.4789646883024337\n",
      "=== epoch:35, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4229121504358506\n",
      "train loss:2.4458815516288537\n",
      "train loss:2.4334004862256675\n",
      "train loss:2.383091719341013\n",
      "=== epoch:36, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.3882778739797685\n",
      "train loss:2.314846415464108\n",
      "train loss:2.4457766955127522\n",
      "train loss:2.4540853905518762\n",
      "=== epoch:37, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.435997314576797\n",
      "train loss:2.428400263524932\n",
      "train loss:2.4045766370858765\n",
      "train loss:2.416954820945868\n",
      "=== epoch:38, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4298210458667997\n",
      "train loss:2.3596865087788514\n",
      "train loss:2.4720419827447686\n",
      "train loss:2.4212821915798957\n",
      "=== epoch:39, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.434318257163783\n",
      "train loss:2.418262314697006\n",
      "train loss:2.397386950892717\n",
      "train loss:2.449742056775299\n",
      "=== epoch:40, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4650255375415737\n",
      "train loss:2.464130254404415\n",
      "train loss:2.4105294314835954\n",
      "train loss:2.4317083127018533\n",
      "=== epoch:41, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4686522880817714\n",
      "train loss:2.3804795701388493\n",
      "train loss:2.458128130903991\n",
      "train loss:2.396777841366858\n",
      "=== epoch:42, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.35244185362517\n",
      "train loss:2.4524507021818156\n",
      "train loss:2.4568427251553278\n",
      "train loss:2.436126090634644\n",
      "=== epoch:43, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.43513530174404\n",
      "train loss:2.447488845135886\n",
      "train loss:2.388516058158251\n",
      "train loss:2.473850590045248\n",
      "=== epoch:44, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.423565407843804\n",
      "train loss:2.342275839414909\n",
      "train loss:2.4575173492729308\n",
      "train loss:2.3710604558910653\n",
      "=== epoch:45, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4555108963959182\n",
      "train loss:2.431004133166994\n",
      "train loss:2.3760111309846756\n",
      "train loss:2.50638515333689\n",
      "=== epoch:46, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.377534256003309\n",
      "train loss:2.41779301929302\n",
      "train loss:2.4009619653238565\n",
      "train loss:2.449780119606239\n",
      "=== epoch:47, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4640614044033553\n",
      "train loss:2.3955608132898516\n",
      "train loss:2.3995287838921\n",
      "train loss:2.386738026179945\n",
      "=== epoch:48, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.446495290589433\n",
      "train loss:2.398262726265142\n",
      "train loss:2.39843189074948\n",
      "train loss:2.414204308789245\n",
      "=== epoch:49, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.397299631953008\n",
      "train loss:2.4205498657117466\n",
      "train loss:2.412105841747157\n",
      "train loss:2.364702144441988\n",
      "=== epoch:50, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.4015350060513962\n",
      "train loss:2.411145535065169\n",
      "train loss:2.349346717323014\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.08\n",
      "val_acc: 0.0800 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.475932566056\n",
      "=== epoch:1, train acc:0.08, test acc:0.12 ===\n",
      "train loss:2.407121147578637\n",
      "train loss:2.347916213914989\n",
      "train loss:2.411428809014601\n",
      "train loss:2.428006599826337\n",
      "=== epoch:2, train acc:0.0825, test acc:0.12 ===\n",
      "train loss:2.4383589664064482\n",
      "train loss:2.455632043684022\n",
      "train loss:2.4718927568074838\n",
      "train loss:2.5094113087972154\n",
      "=== epoch:3, train acc:0.0825, test acc:0.12 ===\n",
      "train loss:2.4814699413047046\n",
      "train loss:2.3255277448936926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.334253058391353\n",
      "train loss:2.3650501471243848\n",
      "=== epoch:4, train acc:0.085, test acc:0.12 ===\n",
      "train loss:2.4273738225059827\n",
      "train loss:2.463011240494129\n",
      "train loss:2.407666769037599\n",
      "train loss:2.3648137543139485\n",
      "=== epoch:5, train acc:0.085, test acc:0.12 ===\n",
      "train loss:2.311087651312451\n",
      "train loss:2.458790580765432\n",
      "train loss:2.4437688149593386\n",
      "train loss:2.393316908719323\n",
      "=== epoch:6, train acc:0.0875, test acc:0.12 ===\n",
      "train loss:2.413706270144963\n",
      "train loss:2.345227749445208\n",
      "train loss:2.4202344317043507\n",
      "train loss:2.3903643749194865\n",
      "=== epoch:7, train acc:0.0875, test acc:0.12 ===\n",
      "train loss:2.4304858772628504\n",
      "train loss:2.359906193183042\n",
      "train loss:2.338724279486027\n",
      "train loss:2.4326642558572185\n",
      "=== epoch:8, train acc:0.0875, test acc:0.12 ===\n",
      "train loss:2.414874466359805\n",
      "train loss:2.4760754888987857\n",
      "train loss:2.4226649571452685\n",
      "train loss:2.372714435235446\n",
      "=== epoch:9, train acc:0.09, test acc:0.12 ===\n",
      "train loss:2.4087987654734846\n",
      "train loss:2.432161675643201\n",
      "train loss:2.3748745687364146\n",
      "train loss:2.4702050101491695\n",
      "=== epoch:10, train acc:0.09, test acc:0.12 ===\n",
      "train loss:2.39188660505107\n",
      "train loss:2.429709370551172\n",
      "train loss:2.4198938471524114\n",
      "train loss:2.3478139112186747\n",
      "=== epoch:11, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.4611166632441033\n",
      "train loss:2.323226953440822\n",
      "train loss:2.4034142922288444\n",
      "train loss:2.383189691050858\n",
      "=== epoch:12, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.470647492478937\n",
      "train loss:2.403353736826288\n",
      "train loss:2.438330794047628\n",
      "train loss:2.4022850601052017\n",
      "=== epoch:13, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3927608428565184\n",
      "train loss:2.378677496424963\n",
      "train loss:2.3627869440806673\n",
      "train loss:2.301713864307633\n",
      "=== epoch:14, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3605910124009597\n",
      "train loss:2.3846266960678224\n",
      "train loss:2.485533863503155\n",
      "train loss:2.4424015209501904\n",
      "=== epoch:15, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.5077336802270342\n",
      "train loss:2.3737334624402604\n",
      "train loss:2.3669199196404334\n",
      "train loss:2.364609019581557\n",
      "=== epoch:16, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.429240574841246\n",
      "train loss:2.4205322898395214\n",
      "train loss:2.360761899405261\n",
      "train loss:2.374808936993586\n",
      "=== epoch:17, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3579416389543506\n",
      "train loss:2.3765873593696143\n",
      "train loss:2.4165050466354527\n",
      "train loss:2.4067175282785365\n",
      "=== epoch:18, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3187547143328637\n",
      "train loss:2.3474853441345753\n",
      "train loss:2.3518768072181593\n",
      "train loss:2.3506573827669053\n",
      "=== epoch:19, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.37772707342003\n",
      "train loss:2.380725293688304\n",
      "train loss:2.306488240065527\n",
      "train loss:2.4025422925455118\n",
      "=== epoch:20, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.308338976814078\n",
      "train loss:2.41944298664492\n",
      "train loss:2.4357874235379637\n",
      "train loss:2.3493055791406134\n",
      "=== epoch:21, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4097490153358505\n",
      "train loss:2.3469954329539595\n",
      "train loss:2.3506033055618647\n",
      "train loss:2.310194880325104\n",
      "=== epoch:22, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3939514153602666\n",
      "train loss:2.348680654088846\n",
      "train loss:2.3368566465507152\n",
      "train loss:2.4095705681581903\n",
      "=== epoch:23, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.339937148035044\n",
      "train loss:2.3532981399920567\n",
      "train loss:2.3675590041929087\n",
      "train loss:2.253565059216951\n",
      "=== epoch:24, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.3878518553730865\n",
      "train loss:2.346032026771676\n",
      "train loss:2.36363370956831\n",
      "train loss:2.353133548881336\n",
      "=== epoch:25, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.3952756110064115\n",
      "train loss:2.4028649872688232\n",
      "train loss:2.4455431430660015\n",
      "train loss:2.346842484648764\n",
      "=== epoch:26, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3089751971969537\n",
      "train loss:2.3883775221064822\n",
      "train loss:2.3273318028145633\n",
      "train loss:2.434185488165431\n",
      "=== epoch:27, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3204064771793456\n",
      "train loss:2.352001575620992\n",
      "train loss:2.321125728316958\n",
      "train loss:2.337019536491469\n",
      "=== epoch:28, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.357796991022178\n",
      "train loss:2.2991360740802587\n",
      "train loss:2.325916131589413\n",
      "train loss:2.3198528173338215\n",
      "=== epoch:29, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.321157111040116\n",
      "train loss:2.379517319899312\n",
      "train loss:2.335469684610284\n",
      "train loss:2.3569769207281333\n",
      "=== epoch:30, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.4080713894498804\n",
      "train loss:2.403854167539468\n",
      "train loss:2.347555943171309\n",
      "train loss:2.312983044900821\n",
      "=== epoch:31, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.3129093778811707\n",
      "train loss:2.3554593232718886\n",
      "train loss:2.382336622487047\n",
      "train loss:2.3355672541361283\n",
      "=== epoch:32, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.347922517819743\n",
      "train loss:2.363486693909772\n",
      "train loss:2.3639087931745384\n",
      "train loss:2.320859730635124\n",
      "=== epoch:33, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.3316015763118156\n",
      "train loss:2.410023302571869\n",
      "train loss:2.344228884220041\n",
      "train loss:2.3300569365756982\n",
      "=== epoch:34, train acc:0.1075, test acc:0.12 ===\n",
      "train loss:2.2754801978240313\n",
      "train loss:2.3398346287110243\n",
      "train loss:2.313460308990551\n",
      "train loss:2.3215961294601555\n",
      "=== epoch:35, train acc:0.1075, test acc:0.12 ===\n",
      "train loss:2.3505299320558275\n",
      "train loss:2.2529720146797776\n",
      "train loss:2.3661511270097733\n",
      "train loss:2.368967756040085\n",
      "=== epoch:36, train acc:0.1075, test acc:0.12 ===\n",
      "train loss:2.3778305832074618\n",
      "train loss:2.3596307750951517\n",
      "train loss:2.2669746462930163\n",
      "train loss:2.3268332283350692\n",
      "=== epoch:37, train acc:0.1075, test acc:0.12 ===\n",
      "train loss:2.373910642661777\n",
      "train loss:2.4168261759667606\n",
      "train loss:2.2537456731641097\n",
      "train loss:2.298856398179925\n",
      "=== epoch:38, train acc:0.1075, test acc:0.13 ===\n",
      "train loss:2.251604528534856\n",
      "train loss:2.302797011815024\n",
      "train loss:2.3549185735234963\n",
      "train loss:2.3603364052550084\n",
      "=== epoch:39, train acc:0.1075, test acc:0.13 ===\n",
      "train loss:2.299137377129632\n",
      "train loss:2.3137819858533715\n",
      "train loss:2.354405427432786\n",
      "train loss:2.355038643004605\n",
      "=== epoch:40, train acc:0.1075, test acc:0.13 ===\n",
      "train loss:2.249782215571487\n",
      "train loss:2.3598190352475834\n",
      "train loss:2.3006006994408303\n",
      "train loss:2.3766532362153043\n",
      "=== epoch:41, train acc:0.1075, test acc:0.13 ===\n",
      "train loss:2.323780072826842\n",
      "train loss:2.3733406241723154\n",
      "train loss:2.343809361014323\n",
      "train loss:2.3345530918339956\n",
      "=== epoch:42, train acc:0.1075, test acc:0.13 ===\n",
      "train loss:2.2598622285861363\n",
      "train loss:2.329947850951898\n",
      "train loss:2.3440629248318077\n",
      "train loss:2.2992559362474685\n",
      "=== epoch:43, train acc:0.1075, test acc:0.13 ===\n",
      "train loss:2.3537631107197736\n",
      "train loss:2.343972246183935\n",
      "train loss:2.2992267633770185\n",
      "train loss:2.298502750644582\n",
      "=== epoch:44, train acc:0.11, test acc:0.13 ===\n",
      "train loss:2.3306223137181643\n",
      "train loss:2.3362499678445228\n",
      "train loss:2.3438225095704195\n",
      "train loss:2.3771219603660594\n",
      "=== epoch:45, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.3196412341349806\n",
      "train loss:2.250200117925081\n",
      "train loss:2.325436340890933\n",
      "train loss:2.287091052296404\n",
      "=== epoch:46, train acc:0.115, test acc:0.13 ===\n",
      "train loss:2.241499414154271\n",
      "train loss:2.271316040967253\n",
      "train loss:2.3045417531786896\n",
      "train loss:2.2690380272078263\n",
      "=== epoch:47, train acc:0.115, test acc:0.13 ===\n",
      "train loss:2.2822563784402905\n",
      "train loss:2.3158333583744883\n",
      "train loss:2.367653804091116\n",
      "train loss:2.315316137811253\n",
      "=== epoch:48, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.375582368917829\n",
      "train loss:2.293977497829694\n",
      "train loss:2.3139261854343185\n",
      "train loss:2.3180155561542968\n",
      "=== epoch:49, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.3444083688608712\n",
      "train loss:2.2876743591731143\n",
      "train loss:2.317651371272378\n",
      "train loss:2.3441774023652915\n",
      "=== epoch:50, train acc:0.12, test acc:0.13 ===\n",
      "train loss:2.2878175347644416\n",
      "train loss:2.3160881037824748\n",
      "train loss:2.302582655843436\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.13\n",
      "val_acc: 0.1300 | lr: 0.0004, weight_decay: 0.0000\n",
      "train loss:2.325718256973017\n",
      "=== epoch:1, train acc:0.1075, test acc:0.08 ===\n",
      "train loss:2.3688091994334353\n",
      "train loss:2.2442356121007814\n",
      "train loss:2.3371489733382167\n",
      "train loss:2.3765831743963104\n",
      "=== epoch:2, train acc:0.1075, test acc:0.08 ===\n",
      "train loss:2.3564286083160315\n",
      "train loss:2.319480413586699\n",
      "train loss:2.419876786355847\n",
      "train loss:2.352173141375725\n",
      "=== epoch:3, train acc:0.1075, test acc:0.08 ===\n",
      "train loss:2.4247613409086077\n",
      "train loss:2.288670007903218\n",
      "train loss:2.3392098198102587\n",
      "train loss:2.386417850025685\n",
      "=== epoch:4, train acc:0.1075, test acc:0.08 ===\n",
      "train loss:2.2698748194704326\n",
      "train loss:2.347966053405186\n",
      "train loss:2.416330686327046\n",
      "train loss:2.4219972089728246\n",
      "=== epoch:5, train acc:0.11, test acc:0.08 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4333967315738803\n",
      "train loss:2.3089858102504963\n",
      "train loss:2.4912197546125294\n",
      "train loss:2.39426420445912\n",
      "=== epoch:6, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2552299433041783\n",
      "train loss:2.293370400334906\n",
      "train loss:2.394098194407474\n",
      "train loss:2.40023042521356\n",
      "=== epoch:7, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.354048181581007\n",
      "train loss:2.418724839502022\n",
      "train loss:2.3849474769636974\n",
      "train loss:2.3326565607639624\n",
      "=== epoch:8, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.42626769212376\n",
      "train loss:2.441283874264958\n",
      "train loss:2.3063485502579346\n",
      "train loss:2.3597217372918036\n",
      "=== epoch:9, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.383808377417324\n",
      "train loss:2.479229510052093\n",
      "train loss:2.429871148916682\n",
      "train loss:2.32334547253536\n",
      "=== epoch:10, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.328705488806328\n",
      "train loss:2.409907995717865\n",
      "train loss:2.444417383321809\n",
      "train loss:2.3837646076047654\n",
      "=== epoch:11, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4442454680278716\n",
      "train loss:2.4316759661038443\n",
      "train loss:2.394888316304035\n",
      "train loss:2.358893826011486\n",
      "=== epoch:12, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.387509734210907\n",
      "train loss:2.3724150435485405\n",
      "train loss:2.446886498358976\n",
      "train loss:2.353856934146602\n",
      "=== epoch:13, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.363176825297438\n",
      "train loss:2.4219661588667414\n",
      "train loss:2.406442260701886\n",
      "train loss:2.3688418664840616\n",
      "=== epoch:14, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3771009014546736\n",
      "train loss:2.394334927420353\n",
      "train loss:2.449971390436575\n",
      "train loss:2.382255468168916\n",
      "=== epoch:15, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4018414571804487\n",
      "train loss:2.417169639340726\n",
      "train loss:2.364554490404526\n",
      "train loss:2.290617958425824\n",
      "=== epoch:16, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.389133000194094\n",
      "train loss:2.337533482221312\n",
      "train loss:2.405273185446024\n",
      "train loss:2.4078990600679404\n",
      "=== epoch:17, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3385696311308504\n",
      "train loss:2.392275823882197\n",
      "train loss:2.3994759740350062\n",
      "train loss:2.357076022533673\n",
      "=== epoch:18, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3525896855179154\n",
      "train loss:2.3742266245524615\n",
      "train loss:2.3679504012623616\n",
      "train loss:2.3434366635435353\n",
      "=== epoch:19, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2903574730355496\n",
      "train loss:2.3801129007070547\n",
      "train loss:2.377551894303883\n",
      "train loss:2.3933585496524845\n",
      "=== epoch:20, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3358913150145986\n",
      "train loss:2.33868385548752\n",
      "train loss:2.4074679622530915\n",
      "train loss:2.382417928458958\n",
      "=== epoch:21, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.460903350508525\n",
      "train loss:2.3074678402347772\n",
      "train loss:2.4397591002067753\n",
      "train loss:2.364888040251282\n",
      "=== epoch:22, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.404487992582528\n",
      "train loss:2.371631839202282\n",
      "train loss:2.3824607126519424\n",
      "train loss:2.456126993179452\n",
      "=== epoch:23, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2842243962258997\n",
      "train loss:2.372662360568887\n",
      "train loss:2.4197242121721647\n",
      "train loss:2.415041418230777\n",
      "=== epoch:24, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.393966699058688\n",
      "train loss:2.356240739585685\n",
      "train loss:2.4592326627116945\n",
      "train loss:2.361063252996903\n",
      "=== epoch:25, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.413083287292842\n",
      "train loss:2.362264090242378\n",
      "train loss:2.3003184356749324\n",
      "train loss:2.3455316885838036\n",
      "=== epoch:26, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3241261907900252\n",
      "train loss:2.4463899320767157\n",
      "train loss:2.352065709281309\n",
      "train loss:2.3201090942102\n",
      "=== epoch:27, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.33072063869363\n",
      "train loss:2.385836163316876\n",
      "train loss:2.3564720020129766\n",
      "train loss:2.3583362547792763\n",
      "=== epoch:28, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4051317066098385\n",
      "train loss:2.3820272294124134\n",
      "train loss:2.3969862185618838\n",
      "train loss:2.32246032882276\n",
      "=== epoch:29, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3170256777498794\n",
      "train loss:2.3486674111991315\n",
      "train loss:2.4049145333200492\n",
      "train loss:2.348383416669365\n",
      "=== epoch:30, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3562273053154654\n",
      "train loss:2.403520760837761\n",
      "train loss:2.3631121093538385\n",
      "train loss:2.4569793153297077\n",
      "=== epoch:31, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.429214016668278\n",
      "train loss:2.3238962508374317\n",
      "train loss:2.3218666361311278\n",
      "train loss:2.412073734122194\n",
      "=== epoch:32, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3534481414460133\n",
      "train loss:2.3878916729889528\n",
      "train loss:2.4228034771354716\n",
      "train loss:2.3322451344338564\n",
      "=== epoch:33, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3454886407734294\n",
      "train loss:2.41085909880967\n",
      "train loss:2.322048934014441\n",
      "train loss:2.3589753948693617\n",
      "=== epoch:34, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.387020610204491\n",
      "train loss:2.4013950672318005\n",
      "train loss:2.3527947203072452\n",
      "train loss:2.355655300200166\n",
      "=== epoch:35, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.309687655193495\n",
      "train loss:2.3358917162834105\n",
      "train loss:2.318352626248602\n",
      "train loss:2.2710993753478963\n",
      "=== epoch:36, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3989967025055345\n",
      "train loss:2.3686870134571527\n",
      "train loss:2.398440175307273\n",
      "train loss:2.3290901746427237\n",
      "=== epoch:37, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3018431579520087\n",
      "train loss:2.35701616940029\n",
      "train loss:2.3311118024664035\n",
      "train loss:2.3811025696980965\n",
      "=== epoch:38, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4411464473139706\n",
      "train loss:2.4160828335540487\n",
      "train loss:2.2832987865602483\n",
      "train loss:2.377284248492229\n",
      "=== epoch:39, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3935632698971863\n",
      "train loss:2.3393627292385015\n",
      "train loss:2.442826552669877\n",
      "train loss:2.2883908060374796\n",
      "=== epoch:40, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.325266412211161\n",
      "train loss:2.3599658427468526\n",
      "train loss:2.3744117256079167\n",
      "train loss:2.409948596631687\n",
      "=== epoch:41, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2636853949778186\n",
      "train loss:2.358004824776382\n",
      "train loss:2.391431411380566\n",
      "train loss:2.334220252551267\n",
      "=== epoch:42, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4159825265009\n",
      "train loss:2.3463579872058173\n",
      "train loss:2.3489328314780615\n",
      "train loss:2.3819383897661632\n",
      "=== epoch:43, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.391134676543463\n",
      "train loss:2.46917099746554\n",
      "train loss:2.4230767322413045\n",
      "train loss:2.3852581105878374\n",
      "=== epoch:44, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4091515664532253\n",
      "train loss:2.353077771458066\n",
      "train loss:2.4342117769121963\n",
      "train loss:2.3465061866222108\n",
      "=== epoch:45, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3847113794476487\n",
      "train loss:2.430238686676621\n",
      "train loss:2.298619151513824\n",
      "train loss:2.3995777656501045\n",
      "=== epoch:46, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3710171773136177\n",
      "train loss:2.372804380676388\n",
      "train loss:2.471191190579943\n",
      "train loss:2.3803544167395656\n",
      "=== epoch:47, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2613827002985003\n",
      "train loss:2.4012236427614475\n",
      "train loss:2.315021862609796\n",
      "train loss:2.3849585829529176\n",
      "=== epoch:48, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.370578917657277\n",
      "train loss:2.3982075069172724\n",
      "train loss:2.3003748028119797\n",
      "train loss:2.3039445443168227\n",
      "=== epoch:49, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3797502755619355\n",
      "train loss:2.3295589658115365\n",
      "train loss:2.381382322093261\n",
      "train loss:2.342319250369112\n",
      "=== epoch:50, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4043068484980332\n",
      "train loss:2.396635997581096\n",
      "train loss:2.4061990647068034\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0800 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.399436510061546\n",
      "=== epoch:1, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.362554036189382\n",
      "train loss:2.484418852133628\n",
      "train loss:2.390243322978729\n",
      "train loss:2.434552318571422\n",
      "=== epoch:2, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.440558598331499\n",
      "train loss:2.435033243148293\n",
      "train loss:2.404701077976014\n",
      "train loss:2.4251161125477547\n",
      "=== epoch:3, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.3635878013328275\n",
      "train loss:2.4061263467544953\n",
      "train loss:2.3837890515998317\n",
      "train loss:2.379869111366062\n",
      "=== epoch:4, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.377441078951315\n",
      "train loss:2.3785591363537377\n",
      "train loss:2.45019339030984\n",
      "train loss:2.4471735002225343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:5, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.4048080538566348\n",
      "train loss:2.377684162629283\n",
      "train loss:2.4157927374924646\n",
      "train loss:2.3872394961983527\n",
      "=== epoch:6, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.3956582273836964\n",
      "train loss:2.389718355691363\n",
      "train loss:2.4279733146872102\n",
      "train loss:2.4527208218142547\n",
      "=== epoch:7, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.4381833415253698\n",
      "train loss:2.456658745033826\n",
      "train loss:2.437993859126281\n",
      "train loss:2.4168389918447377\n",
      "=== epoch:8, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.4164085186633097\n",
      "train loss:2.3914493095809806\n",
      "train loss:2.4219155174694538\n",
      "train loss:2.3979549547775867\n",
      "=== epoch:9, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.4033216974747864\n",
      "train loss:2.45669508574182\n",
      "train loss:2.390988936486732\n",
      "train loss:2.3605979829068757\n",
      "=== epoch:10, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.411836259947473\n",
      "train loss:2.4598660681656375\n",
      "train loss:2.477382255685984\n",
      "train loss:2.378189286694523\n",
      "=== epoch:11, train acc:0.0825, test acc:0.1 ===\n",
      "train loss:2.40167449087031\n",
      "train loss:2.4223903449434663\n",
      "train loss:2.3520149235216876\n",
      "train loss:2.3838829671087263\n",
      "=== epoch:12, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.379676167138111\n",
      "train loss:2.4809129600250333\n",
      "train loss:2.3768141759914445\n",
      "train loss:2.408635316566439\n",
      "=== epoch:13, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.4311354029936108\n",
      "train loss:2.4269418482905483\n",
      "train loss:2.4835654494329966\n",
      "train loss:2.4143138129056143\n",
      "=== epoch:14, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.4191649890363562\n",
      "train loss:2.4059333225667667\n",
      "train loss:2.3710230177255855\n",
      "train loss:2.4258056463124684\n",
      "=== epoch:15, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.452653114299277\n",
      "train loss:2.4927971401063984\n",
      "train loss:2.4276906780350713\n",
      "train loss:2.4289046391539806\n",
      "=== epoch:16, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.4208196330785596\n",
      "train loss:2.4084212488651966\n",
      "train loss:2.4080058474164288\n",
      "train loss:2.445243221372376\n",
      "=== epoch:17, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.4148418415933817\n",
      "train loss:2.4924133331072724\n",
      "train loss:2.3691243841778897\n",
      "train loss:2.4706190619643253\n",
      "=== epoch:18, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.4042081292549247\n",
      "train loss:2.436653276390841\n",
      "train loss:2.4267388315785534\n",
      "train loss:2.4327554228850037\n",
      "=== epoch:19, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.4432443224264566\n",
      "train loss:2.341332519631533\n",
      "train loss:2.481213439295758\n",
      "train loss:2.4239410497295033\n",
      "=== epoch:20, train acc:0.085, test acc:0.1 ===\n",
      "train loss:2.4070835209587185\n",
      "train loss:2.4566598567118803\n",
      "train loss:2.3904948669022548\n",
      "train loss:2.392106576107348\n",
      "=== epoch:21, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.4285021374826474\n",
      "train loss:2.4376894560350344\n",
      "train loss:2.405395245448768\n",
      "train loss:2.4010984194755296\n",
      "=== epoch:22, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.3797867239640507\n",
      "train loss:2.3722325926656445\n",
      "train loss:2.4520929109755354\n",
      "train loss:2.392236397522948\n",
      "=== epoch:23, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.4063713044092947\n",
      "train loss:2.3651100914078484\n",
      "train loss:2.3903221228257023\n",
      "train loss:2.349610733419763\n",
      "=== epoch:24, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.4511389528585426\n",
      "train loss:2.447322256075267\n",
      "train loss:2.4240607019531706\n",
      "train loss:2.4407903702326186\n",
      "=== epoch:25, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.372348471722726\n",
      "train loss:2.440896952949772\n",
      "train loss:2.4385330092793196\n",
      "train loss:2.3606298878086824\n",
      "=== epoch:26, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.374373839953\n",
      "train loss:2.3740078222789167\n",
      "train loss:2.35558254212852\n",
      "train loss:2.3599076919666238\n",
      "=== epoch:27, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.397127015304986\n",
      "train loss:2.4094117547196827\n",
      "train loss:2.3699897439865034\n",
      "train loss:2.3680480303188616\n",
      "=== epoch:28, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.3843478145991384\n",
      "train loss:2.443415118209408\n",
      "train loss:2.3718682038154695\n",
      "train loss:2.4443976314603026\n",
      "=== epoch:29, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.42346063040423\n",
      "train loss:2.4589635125942917\n",
      "train loss:2.3731854217444224\n",
      "train loss:2.428180785817421\n",
      "=== epoch:30, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.3788461581698184\n",
      "train loss:2.3893036933979195\n",
      "train loss:2.4050160882439564\n",
      "train loss:2.4566583853179487\n",
      "=== epoch:31, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.4170229134371057\n",
      "train loss:2.3910894021997655\n",
      "train loss:2.408040159315835\n",
      "train loss:2.4228167033781274\n",
      "=== epoch:32, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.3747406963376094\n",
      "train loss:2.3550361420794164\n",
      "train loss:2.4141174090918605\n",
      "train loss:2.4137472703767044\n",
      "=== epoch:33, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.37320354970386\n",
      "train loss:2.427323602552049\n",
      "train loss:2.3728105901892236\n",
      "train loss:2.364903416494635\n",
      "=== epoch:34, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.371338051399366\n",
      "train loss:2.4404095496034364\n",
      "train loss:2.4657383952228873\n",
      "train loss:2.40640013946354\n",
      "=== epoch:35, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.4169128426252473\n",
      "train loss:2.4326431421151256\n",
      "train loss:2.3738440859120797\n",
      "train loss:2.36721293959339\n",
      "=== epoch:36, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.4184673557743173\n",
      "train loss:2.4698844852597026\n",
      "train loss:2.4537634890876627\n",
      "train loss:2.3370006510819215\n",
      "=== epoch:37, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.4077340346462757\n",
      "train loss:2.428348376937966\n",
      "train loss:2.3364137209752176\n",
      "train loss:2.4005195611389247\n",
      "=== epoch:38, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.371054848525554\n",
      "train loss:2.490681880277322\n",
      "train loss:2.3853038302636405\n",
      "train loss:2.366283791533696\n",
      "=== epoch:39, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.3604310242857753\n",
      "train loss:2.485416201441626\n",
      "train loss:2.352134719498941\n",
      "train loss:2.419420120917194\n",
      "=== epoch:40, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.4060057569202558\n",
      "train loss:2.3759187748314714\n",
      "train loss:2.390480436505051\n",
      "train loss:2.3570431185582197\n",
      "=== epoch:41, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.414282524862332\n",
      "train loss:2.4547260148638723\n",
      "train loss:2.38759468937626\n",
      "train loss:2.3384266720217797\n",
      "=== epoch:42, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.4327290600527234\n",
      "train loss:2.319922014750709\n",
      "train loss:2.415745998544735\n",
      "train loss:2.40805318180779\n",
      "=== epoch:43, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.416447698357068\n",
      "train loss:2.4420605545112837\n",
      "train loss:2.4031037110561684\n",
      "train loss:2.3993115679899493\n",
      "=== epoch:44, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.3360447358777865\n",
      "train loss:2.3874385597104344\n",
      "train loss:2.382874255362505\n",
      "train loss:2.368370185527262\n",
      "=== epoch:45, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.3763861611887305\n",
      "train loss:2.3212338466529983\n",
      "train loss:2.4020195443417913\n",
      "train loss:2.4343339577297165\n",
      "=== epoch:46, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.4469161118899208\n",
      "train loss:2.384508382547522\n",
      "train loss:2.434990952602253\n",
      "train loss:2.4557091585620054\n",
      "=== epoch:47, train acc:0.09, test acc:0.1 ===\n",
      "train loss:2.424457106721155\n",
      "train loss:2.379298696469689\n",
      "train loss:2.4125565368588977\n",
      "train loss:2.398050969347399\n",
      "=== epoch:48, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3309516789271623\n",
      "train loss:2.4164798826207017\n",
      "train loss:2.37582207669416\n",
      "train loss:2.4073046123746966\n",
      "=== epoch:49, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.343936362320975\n",
      "train loss:2.4024922513321503\n",
      "train loss:2.4273181105051163\n",
      "train loss:2.3892629755957246\n",
      "=== epoch:50, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4392910951293794\n",
      "train loss:2.385387041842779\n",
      "train loss:2.358808218891311\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.3833013634725235\n",
      "=== epoch:1, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.3691990330297457\n",
      "train loss:2.444916995703371\n",
      "train loss:2.399183113706779\n",
      "train loss:2.4229787976236414\n",
      "=== epoch:2, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.361633828527652\n",
      "train loss:2.4326606276307525\n",
      "train loss:2.3631382886207852\n",
      "train loss:2.362415452316002\n",
      "=== epoch:3, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.3744124947985\n",
      "train loss:2.2926751492739363\n",
      "train loss:2.3217634240807574\n",
      "train loss:2.412179434998083\n",
      "=== epoch:4, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.3545375210116246\n",
      "train loss:2.323613250827963\n",
      "train loss:2.302314015664536\n",
      "train loss:2.3697327930174668\n",
      "=== epoch:5, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.4054450263790663\n",
      "train loss:2.370752690339197\n",
      "train loss:2.365606190992596\n",
      "train loss:2.466516898819235\n",
      "=== epoch:6, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.3270162277403763\n",
      "train loss:2.370658878163724\n",
      "train loss:2.41411595154583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3245884797217755\n",
      "=== epoch:7, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.3769846165141564\n",
      "train loss:2.47097024889141\n",
      "train loss:2.350738285407365\n",
      "train loss:2.395045950173643\n",
      "=== epoch:8, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.357312246205034\n",
      "train loss:2.3631949169166724\n",
      "train loss:2.3448160828707647\n",
      "train loss:2.3626989081272542\n",
      "=== epoch:9, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.3622510664341854\n",
      "train loss:2.360505504106223\n",
      "train loss:2.3876978761229237\n",
      "train loss:2.3593937403057588\n",
      "=== epoch:10, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3937402191859474\n",
      "train loss:2.3444030847460313\n",
      "train loss:2.344342058243551\n",
      "train loss:2.389480615987089\n",
      "=== epoch:11, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.332216273974848\n",
      "train loss:2.3928338199693253\n",
      "train loss:2.4077839318360517\n",
      "train loss:2.3612104016809403\n",
      "=== epoch:12, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3751848489402487\n",
      "train loss:2.310407545525413\n",
      "train loss:2.3718835741162647\n",
      "train loss:2.37476450604959\n",
      "=== epoch:13, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3953962815248944\n",
      "train loss:2.4270940367883718\n",
      "train loss:2.366855872450002\n",
      "train loss:2.3779787672781265\n",
      "=== epoch:14, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3687215152035574\n",
      "train loss:2.3866521351524588\n",
      "train loss:2.4556016493533184\n",
      "train loss:2.348558315621986\n",
      "=== epoch:15, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3600756619960745\n",
      "train loss:2.345296124863758\n",
      "train loss:2.410206173482264\n",
      "train loss:2.3274576696072513\n",
      "=== epoch:16, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3220765292167878\n",
      "train loss:2.342540966935025\n",
      "train loss:2.3467814828416658\n",
      "train loss:2.413268427223163\n",
      "=== epoch:17, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.284702277609453\n",
      "train loss:2.33850447522272\n",
      "train loss:2.377574152668917\n",
      "train loss:2.314144902605481\n",
      "=== epoch:18, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.4031750379626784\n",
      "train loss:2.3381636259854632\n",
      "train loss:2.3279958535498126\n",
      "train loss:2.3572255935946886\n",
      "=== epoch:19, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.393152566578298\n",
      "train loss:2.3266511878896687\n",
      "train loss:2.3414033889653485\n",
      "train loss:2.435043756226316\n",
      "=== epoch:20, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.316912624240511\n",
      "train loss:2.411449890137912\n",
      "train loss:2.357229346038828\n",
      "train loss:2.3979562081265158\n",
      "=== epoch:21, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3506383036499225\n",
      "train loss:2.3932269491133833\n",
      "train loss:2.3643526051234023\n",
      "train loss:2.3329610740296505\n",
      "=== epoch:22, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.347205069826527\n",
      "train loss:2.3477875268514343\n",
      "train loss:2.322266744633978\n",
      "train loss:2.39516215247992\n",
      "=== epoch:23, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.319550658359838\n",
      "train loss:2.367685057718922\n",
      "train loss:2.333108748485787\n",
      "train loss:2.331591707568443\n",
      "=== epoch:24, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3232804559070983\n",
      "train loss:2.3925760122023454\n",
      "train loss:2.354091158770585\n",
      "train loss:2.385622064993764\n",
      "=== epoch:25, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3351991561112095\n",
      "train loss:2.3508796807723495\n",
      "train loss:2.3915050800793374\n",
      "train loss:2.3853261104139794\n",
      "=== epoch:26, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3211752896953346\n",
      "train loss:2.3676291777518865\n",
      "train loss:2.2818793574236227\n",
      "train loss:2.362592678391359\n",
      "=== epoch:27, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3773565405529005\n",
      "train loss:2.329748011524317\n",
      "train loss:2.409679525773735\n",
      "train loss:2.3219859411302615\n",
      "=== epoch:28, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3738023687095384\n",
      "train loss:2.3258748626372054\n",
      "train loss:2.3473370202988426\n",
      "train loss:2.34741837585681\n",
      "=== epoch:29, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.349660738070214\n",
      "train loss:2.32563381032882\n",
      "train loss:2.351248736743916\n",
      "train loss:2.3989614514032955\n",
      "=== epoch:30, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.4075809402900847\n",
      "train loss:2.320365216797141\n",
      "train loss:2.3473424359262203\n",
      "train loss:2.3370816892204904\n",
      "=== epoch:31, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3645635781069068\n",
      "train loss:2.343989776594719\n",
      "train loss:2.4075188405758094\n",
      "train loss:2.3662066602621614\n",
      "=== epoch:32, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3785051323750026\n",
      "train loss:2.408253298447046\n",
      "train loss:2.2971007527061955\n",
      "train loss:2.339259827143672\n",
      "=== epoch:33, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.338344712571328\n",
      "train loss:2.3301598516424518\n",
      "train loss:2.3584291787545726\n",
      "train loss:2.3613064741629475\n",
      "=== epoch:34, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3623279763347647\n",
      "train loss:2.3447015925758086\n",
      "train loss:2.3137355467301157\n",
      "train loss:2.379053546664426\n",
      "=== epoch:35, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3895286152605797\n",
      "train loss:2.337017454559239\n",
      "train loss:2.3525150237691514\n",
      "train loss:2.2997264754689963\n",
      "=== epoch:36, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.373746907764047\n",
      "train loss:2.327220207812538\n",
      "train loss:2.3288859593518123\n",
      "train loss:2.42858141465242\n",
      "=== epoch:37, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.393942431960308\n",
      "train loss:2.3061038526435604\n",
      "train loss:2.3413204969884496\n",
      "train loss:2.320121835409662\n",
      "=== epoch:38, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.361352038729412\n",
      "train loss:2.3459172643400725\n",
      "train loss:2.327562856833383\n",
      "train loss:2.364860675439548\n",
      "=== epoch:39, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.347405606868121\n",
      "train loss:2.3249130352503578\n",
      "train loss:2.3388275077879452\n",
      "train loss:2.3890981382121765\n",
      "=== epoch:40, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.318306422321118\n",
      "train loss:2.3089125026765536\n",
      "train loss:2.3483127213038073\n",
      "train loss:2.311489821944462\n",
      "=== epoch:41, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.377946193324368\n",
      "train loss:2.3382672168367042\n",
      "train loss:2.3366833369465545\n",
      "train loss:2.372118337353576\n",
      "=== epoch:42, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3879339824039785\n",
      "train loss:2.3017546101060415\n",
      "train loss:2.3276222038039145\n",
      "train loss:2.3645385335372118\n",
      "=== epoch:43, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3320427854842234\n",
      "train loss:2.3503797861581552\n",
      "train loss:2.348661701983733\n",
      "train loss:2.332281212319971\n",
      "=== epoch:44, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3820829543158495\n",
      "train loss:2.370843532523193\n",
      "train loss:2.358543183815999\n",
      "train loss:2.331238003111755\n",
      "=== epoch:45, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.375096455412573\n",
      "train loss:2.366159414176914\n",
      "train loss:2.3974078220560315\n",
      "train loss:2.3674737096777716\n",
      "=== epoch:46, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3198406664454074\n",
      "train loss:2.365653493061067\n",
      "train loss:2.3746031432972443\n",
      "train loss:2.3139816209557145\n",
      "=== epoch:47, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.2704898802237836\n",
      "train loss:2.3232302212724414\n",
      "train loss:2.3214650420531124\n",
      "train loss:2.3585793441808063\n",
      "=== epoch:48, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3614923319343144\n",
      "train loss:2.37180825456329\n",
      "train loss:2.4116153400181974\n",
      "train loss:2.34425944528428\n",
      "=== epoch:49, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.3247214092863935\n",
      "train loss:2.3294810637217833\n",
      "train loss:2.2814731008752664\n",
      "train loss:2.3621310890442557\n",
      "=== epoch:50, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.3965779480959486\n",
      "train loss:2.3246910720744443\n",
      "train loss:2.3873116231786358\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.5405361055865856\n",
      "=== epoch:1, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.5724746210141953\n",
      "train loss:2.4573446753511736\n",
      "train loss:2.432685809852383\n",
      "train loss:2.4639288242894386\n",
      "=== epoch:2, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.420492652713883\n",
      "train loss:2.4908502166992306\n",
      "train loss:2.3944955209331726\n",
      "train loss:2.4692027016468514\n",
      "=== epoch:3, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.5601836752186773\n",
      "train loss:2.468064858416775\n",
      "train loss:2.5540296878421564\n",
      "train loss:2.424450028649868\n",
      "=== epoch:4, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.5145418849196353\n",
      "train loss:2.558255087944257\n",
      "train loss:2.4432657232527504\n",
      "train loss:2.3924729711443704\n",
      "=== epoch:5, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.566887908865282\n",
      "train loss:2.4365715549481655\n",
      "train loss:2.3324908705793987\n",
      "train loss:2.4277692219635476\n",
      "=== epoch:6, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.502227319092297\n",
      "train loss:2.4864776731528018\n",
      "train loss:2.4934674425421757\n",
      "train loss:2.484299583953479\n",
      "=== epoch:7, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.5984156569343324\n",
      "train loss:2.5462088489453056\n",
      "train loss:2.5329647623992377\n",
      "train loss:2.4742069937102094\n",
      "=== epoch:8, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.499565416695098\n",
      "train loss:2.4891777922039395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4456847973757827\n",
      "train loss:2.4476885280408833\n",
      "=== epoch:9, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4241070581152897\n",
      "train loss:2.4654261014688226\n",
      "train loss:2.519573243551219\n",
      "train loss:2.409734856566408\n",
      "=== epoch:10, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.44785205013191\n",
      "train loss:2.5130948660800465\n",
      "train loss:2.429566122584536\n",
      "train loss:2.4683824707491984\n",
      "=== epoch:11, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.5461565049041703\n",
      "train loss:2.568322570259179\n",
      "train loss:2.5994094430017927\n",
      "train loss:2.460478003330473\n",
      "=== epoch:12, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.5153162404720995\n",
      "train loss:2.4700141918490863\n",
      "train loss:2.5095389006295723\n",
      "train loss:2.466965454737195\n",
      "=== epoch:13, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4921046634718835\n",
      "train loss:2.422164782600011\n",
      "train loss:2.402093130736884\n",
      "train loss:2.4986705643931364\n",
      "=== epoch:14, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.426739702796998\n",
      "train loss:2.559530885262143\n",
      "train loss:2.574635934305577\n",
      "train loss:2.419722893884977\n",
      "=== epoch:15, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4672211978536778\n",
      "train loss:2.5238157349696757\n",
      "train loss:2.4536056150604098\n",
      "train loss:2.46910819648247\n",
      "=== epoch:16, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4920696902164896\n",
      "train loss:2.480706556252392\n",
      "train loss:2.62563897808285\n",
      "train loss:2.425402350763772\n",
      "=== epoch:17, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.519211710175443\n",
      "train loss:2.4277099085803937\n",
      "train loss:2.4896908554882344\n",
      "train loss:2.4516815611766005\n",
      "=== epoch:18, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4949175940876653\n",
      "train loss:2.4327072082301187\n",
      "train loss:2.532198195928414\n",
      "train loss:2.5284110761270866\n",
      "=== epoch:19, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4222084178232817\n",
      "train loss:2.329589921837904\n",
      "train loss:2.5503371725125428\n",
      "train loss:2.57102827857816\n",
      "=== epoch:20, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.556231273744543\n",
      "train loss:2.4640588029716683\n",
      "train loss:2.479587667492211\n",
      "train loss:2.459222949326583\n",
      "=== epoch:21, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.455784017162742\n",
      "train loss:2.5149221860543562\n",
      "train loss:2.4712409070454973\n",
      "train loss:2.4340552959961728\n",
      "=== epoch:22, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.558275382524245\n",
      "train loss:2.5829432480438355\n",
      "train loss:2.524534364830051\n",
      "train loss:2.538365425219971\n",
      "=== epoch:23, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.538617147092302\n",
      "train loss:2.4621116718649128\n",
      "train loss:2.5028686622388254\n",
      "train loss:2.528367733273064\n",
      "=== epoch:24, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.5435828389539084\n",
      "train loss:2.466784087927362\n",
      "train loss:2.4687623510198593\n",
      "train loss:2.506566752872461\n",
      "=== epoch:25, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.5973071154213105\n",
      "train loss:2.6220241405570324\n",
      "train loss:2.4287293081771706\n",
      "train loss:2.385004672913259\n",
      "=== epoch:26, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.507478651000011\n",
      "train loss:2.4883853011253\n",
      "train loss:2.4531137296043797\n",
      "train loss:2.5097691241703526\n",
      "=== epoch:27, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.545132849761627\n",
      "train loss:2.403574801128092\n",
      "train loss:2.4501480470616084\n",
      "train loss:2.4755169290491974\n",
      "=== epoch:28, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.6015014852939267\n",
      "train loss:2.432734353624014\n",
      "train loss:2.5331505509890246\n",
      "train loss:2.486379199541894\n",
      "=== epoch:29, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.515942045773164\n",
      "train loss:2.413493448499072\n",
      "train loss:2.3828442529954508\n",
      "train loss:2.407492908229812\n",
      "=== epoch:30, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.44539265270025\n",
      "train loss:2.474160137544113\n",
      "train loss:2.4407662873499887\n",
      "train loss:2.468347950611043\n",
      "=== epoch:31, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.5215239380814984\n",
      "train loss:2.465147986264\n",
      "train loss:2.4923404332880614\n",
      "train loss:2.431421552417821\n",
      "=== epoch:32, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.3576178537111843\n",
      "train loss:2.4054230189024595\n",
      "train loss:2.5322695130620576\n",
      "train loss:2.4939833791293857\n",
      "=== epoch:33, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.5173094855868956\n",
      "train loss:2.520718693729607\n",
      "train loss:2.502758954362048\n",
      "train loss:2.455491960161425\n",
      "=== epoch:34, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4739526147862105\n",
      "train loss:2.4562796449806723\n",
      "train loss:2.484115083533612\n",
      "train loss:2.482245922249115\n",
      "=== epoch:35, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4246500666773936\n",
      "train loss:2.388380786746187\n",
      "train loss:2.4817548174754456\n",
      "train loss:2.5006013759989334\n",
      "=== epoch:36, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.5525224361092733\n",
      "train loss:2.4617048864577113\n",
      "train loss:2.469080610674239\n",
      "train loss:2.559761071383274\n",
      "=== epoch:37, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4878990492187203\n",
      "train loss:2.459588333571738\n",
      "train loss:2.509557186329816\n",
      "train loss:2.5248063980261706\n",
      "=== epoch:38, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.5631980077867973\n",
      "train loss:2.4602377077569004\n",
      "train loss:2.5324770782057064\n",
      "train loss:2.53291210369972\n",
      "=== epoch:39, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.56198508528002\n",
      "train loss:2.5182263244282197\n",
      "train loss:2.483518588869218\n",
      "train loss:2.466901993279412\n",
      "=== epoch:40, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.464379331008086\n",
      "train loss:2.4660877879719534\n",
      "train loss:2.5008381725229616\n",
      "train loss:2.4500288692284844\n",
      "=== epoch:41, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4676434695815836\n",
      "train loss:2.4329737331021377\n",
      "train loss:2.476914779581239\n",
      "train loss:2.468430782869374\n",
      "=== epoch:42, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4593990037501756\n",
      "train loss:2.5565780795433364\n",
      "train loss:2.5670814181492347\n",
      "train loss:2.581826112167021\n",
      "=== epoch:43, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.490552776058731\n",
      "train loss:2.5421357376495677\n",
      "train loss:2.4448678846248844\n",
      "train loss:2.3676333946019827\n",
      "=== epoch:44, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.51677749301378\n",
      "train loss:2.4618648467617943\n",
      "train loss:2.5046679901695073\n",
      "train loss:2.398193075821872\n",
      "=== epoch:45, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4387174428453835\n",
      "train loss:2.4398579052789504\n",
      "train loss:2.5154770884376987\n",
      "train loss:2.6214900806652244\n",
      "=== epoch:46, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.496037702573319\n",
      "train loss:2.374521213186084\n",
      "train loss:2.4171977601995644\n",
      "train loss:2.5469544145900143\n",
      "=== epoch:47, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.498481265846112\n",
      "train loss:2.5902721506200477\n",
      "train loss:2.562546252918152\n",
      "train loss:2.55701067981961\n",
      "=== epoch:48, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.462487307457692\n",
      "train loss:2.3993802230000045\n",
      "train loss:2.5516448996296246\n",
      "train loss:2.4854502530903475\n",
      "=== epoch:49, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.4956729304618515\n",
      "train loss:2.4902278787984544\n",
      "train loss:2.503561043055132\n",
      "train loss:2.3605568040612877\n",
      "=== epoch:50, train acc:0.06, test acc:0.06 ===\n",
      "train loss:2.3785629766442\n",
      "train loss:2.550690611930938\n",
      "train loss:2.4174528466950735\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.06\n",
      "val_acc: 0.0600 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.255948066048101\n",
      "=== epoch:1, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2764779280127345\n",
      "train loss:2.301759998406752\n",
      "train loss:2.327309555601496\n",
      "train loss:2.3264010483553528\n",
      "=== epoch:2, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.298497160728905\n",
      "train loss:2.3041710952941346\n",
      "train loss:2.358326787439289\n",
      "train loss:2.2842668783392086\n",
      "=== epoch:3, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2876453775085084\n",
      "train loss:2.348149626554296\n",
      "train loss:2.2924422073879542\n",
      "train loss:2.283952977204035\n",
      "=== epoch:4, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3007366284188038\n",
      "train loss:2.2979354613195575\n",
      "train loss:2.2820060682545535\n",
      "train loss:2.3240614161171425\n",
      "=== epoch:5, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2879281398951172\n",
      "train loss:2.30355080115297\n",
      "train loss:2.289911513293526\n",
      "train loss:2.2982879197655013\n",
      "=== epoch:6, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.297840235664081\n",
      "train loss:2.350996512025387\n",
      "train loss:2.3002225496697566\n",
      "train loss:2.272140828016874\n",
      "=== epoch:7, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.31758953801474\n",
      "train loss:2.291582438339846\n",
      "train loss:2.3182841998009667\n",
      "train loss:2.327113068238118\n",
      "=== epoch:8, train acc:0.105, test acc:0.1 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.307963478906958\n",
      "train loss:2.260232666526471\n",
      "train loss:2.3115390895525674\n",
      "train loss:2.318202536371361\n",
      "=== epoch:9, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2711969625065933\n",
      "train loss:2.279670348537425\n",
      "train loss:2.25922295404417\n",
      "train loss:2.3115794579921682\n",
      "=== epoch:10, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3175940409980202\n",
      "train loss:2.325547709809969\n",
      "train loss:2.297687997247823\n",
      "train loss:2.2736895385256637\n",
      "=== epoch:11, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.307199221660818\n",
      "train loss:2.267632289839844\n",
      "train loss:2.3098909297667976\n",
      "train loss:2.313605893695011\n",
      "=== epoch:12, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3021149397904654\n",
      "train loss:2.325240731355927\n",
      "train loss:2.2500844160413553\n",
      "train loss:2.3228880601450657\n",
      "=== epoch:13, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.269778954691167\n",
      "train loss:2.3112605426279527\n",
      "train loss:2.290438612217772\n",
      "train loss:2.293652222802846\n",
      "=== epoch:14, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2919041054593072\n",
      "train loss:2.2882917306419532\n",
      "train loss:2.276961772926742\n",
      "train loss:2.2961102480797013\n",
      "=== epoch:15, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3075141734605933\n",
      "train loss:2.247697347899749\n",
      "train loss:2.3152400053409568\n",
      "train loss:2.2970675041284583\n",
      "=== epoch:16, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.288324778203158\n",
      "train loss:2.3330491520515673\n",
      "train loss:2.250376387662493\n",
      "train loss:2.2761921611031375\n",
      "=== epoch:17, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.296901811327458\n",
      "train loss:2.2506070710860464\n",
      "train loss:2.288522291998558\n",
      "train loss:2.2644592681947966\n",
      "=== epoch:18, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.331651177819699\n",
      "train loss:2.2877883555114744\n",
      "train loss:2.343551152375689\n",
      "train loss:2.293611537713365\n",
      "=== epoch:19, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.291113886465539\n",
      "train loss:2.3044311649448694\n",
      "train loss:2.2784066145556285\n",
      "train loss:2.2529328411562277\n",
      "=== epoch:20, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.272073336695042\n",
      "train loss:2.3285240479647533\n",
      "train loss:2.3207441144648024\n",
      "train loss:2.3461634718504434\n",
      "=== epoch:21, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.328097962276396\n",
      "train loss:2.308110848035284\n",
      "train loss:2.317119546146176\n",
      "train loss:2.283876290019919\n",
      "=== epoch:22, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.305628066184678\n",
      "train loss:2.3278784966017194\n",
      "train loss:2.2787171246350773\n",
      "train loss:2.2816044057879274\n",
      "=== epoch:23, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3048676931431875\n",
      "train loss:2.2964932183310194\n",
      "train loss:2.324559317466901\n",
      "train loss:2.261867135591633\n",
      "=== epoch:24, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2886076638740227\n",
      "train loss:2.3595052454794256\n",
      "train loss:2.26782244725407\n",
      "train loss:2.283224053521687\n",
      "=== epoch:25, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.320026682722297\n",
      "train loss:2.2819367147318625\n",
      "train loss:2.3131545419478146\n",
      "train loss:2.290291764148221\n",
      "=== epoch:26, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2997298410665947\n",
      "train loss:2.2749036897468464\n",
      "train loss:2.3340639652881214\n",
      "train loss:2.334386569319665\n",
      "=== epoch:27, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3527472601602772\n",
      "train loss:2.329522123480471\n",
      "train loss:2.312481876711772\n",
      "train loss:2.3148075494150833\n",
      "=== epoch:28, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2963201457804696\n",
      "train loss:2.310650111759966\n",
      "train loss:2.309948525407348\n",
      "train loss:2.3107390949791218\n",
      "=== epoch:29, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2969624370189314\n",
      "train loss:2.2762546664621612\n",
      "train loss:2.3238908349110416\n",
      "train loss:2.295812258173886\n",
      "=== epoch:30, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.284034189242258\n",
      "train loss:2.3277724167651277\n",
      "train loss:2.2914530232728034\n",
      "train loss:2.3440713712153456\n",
      "=== epoch:31, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2984520700377695\n",
      "train loss:2.2585706247649813\n",
      "train loss:2.287780603791959\n",
      "train loss:2.2942273678548397\n",
      "=== epoch:32, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2864303498663254\n",
      "train loss:2.351783968077128\n",
      "train loss:2.3334964481464118\n",
      "train loss:2.305030632075028\n",
      "=== epoch:33, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3071341730517227\n",
      "train loss:2.274031418970482\n",
      "train loss:2.326859191203235\n",
      "train loss:2.25086957002915\n",
      "=== epoch:34, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.372515132456692\n",
      "train loss:2.3003863756961045\n",
      "train loss:2.255118776747944\n",
      "train loss:2.3322877483302737\n",
      "=== epoch:35, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2830816253535424\n",
      "train loss:2.340923134477137\n",
      "train loss:2.3541451105225075\n",
      "train loss:2.3070440590743373\n",
      "=== epoch:36, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.256501768804155\n",
      "train loss:2.324366613155223\n",
      "train loss:2.238774243810045\n",
      "train loss:2.2788764843276157\n",
      "=== epoch:37, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.349591117113814\n",
      "train loss:2.2757067185450093\n",
      "train loss:2.2620408540104138\n",
      "train loss:2.2891162754581917\n",
      "=== epoch:38, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3260620788526802\n",
      "train loss:2.271261979972207\n",
      "train loss:2.253791732963552\n",
      "train loss:2.264374590518759\n",
      "=== epoch:39, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2864182102356336\n",
      "train loss:2.2992999636746405\n",
      "train loss:2.3039548011513693\n",
      "train loss:2.294743158317654\n",
      "=== epoch:40, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2778783316739566\n",
      "train loss:2.2870121248581783\n",
      "train loss:2.360651998763888\n",
      "train loss:2.264962459978719\n",
      "=== epoch:41, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.321182635811285\n",
      "train loss:2.244956700115555\n",
      "train loss:2.315639801040004\n",
      "train loss:2.3382324983112577\n",
      "=== epoch:42, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3118180737042735\n",
      "train loss:2.2872434840183042\n",
      "train loss:2.3215852100856074\n",
      "train loss:2.2785425906136907\n",
      "=== epoch:43, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2574611684305395\n",
      "train loss:2.263634599004223\n",
      "train loss:2.305067807368283\n",
      "train loss:2.3047164504261075\n",
      "=== epoch:44, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.290047862345114\n",
      "train loss:2.3198972132112616\n",
      "train loss:2.3294220575048303\n",
      "train loss:2.308120604893381\n",
      "=== epoch:45, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.288087090064949\n",
      "train loss:2.32720809313576\n",
      "train loss:2.277439110276055\n",
      "train loss:2.337530076506826\n",
      "=== epoch:46, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.301847498596601\n",
      "train loss:2.2942131400747976\n",
      "train loss:2.3508965752995423\n",
      "train loss:2.2713499506781276\n",
      "=== epoch:47, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3171316805627535\n",
      "train loss:2.2988781807931127\n",
      "train loss:2.227201679940173\n",
      "train loss:2.2647006563202106\n",
      "=== epoch:48, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.334152088980928\n",
      "train loss:2.322997974418245\n",
      "train loss:2.258708037810833\n",
      "train loss:2.282404745259136\n",
      "=== epoch:49, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.272336193513839\n",
      "train loss:2.3263364818572314\n",
      "train loss:2.3156189784403645\n",
      "train loss:2.2732912073365172\n",
      "=== epoch:50, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3065606396006224\n",
      "train loss:2.302045324576349\n",
      "train loss:2.338900229628664\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.293705107877679\n",
      "=== epoch:1, train acc:0.0875, test acc:0.14 ===\n",
      "train loss:2.305046314995762\n",
      "train loss:2.306167815401839\n",
      "train loss:2.2795547037657387\n",
      "train loss:2.31710950602526\n",
      "=== epoch:2, train acc:0.1325, test acc:0.21 ===\n",
      "train loss:2.305157339368325\n",
      "train loss:2.277890501967128\n",
      "train loss:2.258831338976421\n",
      "train loss:2.2900728377054795\n",
      "=== epoch:3, train acc:0.17, test acc:0.27 ===\n",
      "train loss:2.2695055401111457\n",
      "train loss:2.285963610198921\n",
      "train loss:2.3165989629041945\n",
      "train loss:2.2621606024078873\n",
      "=== epoch:4, train acc:0.1975, test acc:0.28 ===\n",
      "train loss:2.283421473062987\n",
      "train loss:2.2575969529825\n",
      "train loss:2.264367412722919\n",
      "train loss:2.1713241334401094\n",
      "=== epoch:5, train acc:0.2425, test acc:0.35 ===\n",
      "train loss:2.2237851447469787\n",
      "train loss:2.2279220512951334\n",
      "train loss:2.2439945979860494\n",
      "train loss:2.1977342952840013\n",
      "=== epoch:6, train acc:0.2575, test acc:0.34 ===\n",
      "train loss:2.2269626040544446\n",
      "train loss:2.2282880322909375\n",
      "train loss:2.2265700506859627\n",
      "train loss:2.236971412186303\n",
      "=== epoch:7, train acc:0.2775, test acc:0.35 ===\n",
      "train loss:2.22671332112143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.238014026212455\n",
      "train loss:2.1897032308548288\n",
      "train loss:2.2013070203438816\n",
      "=== epoch:8, train acc:0.305, test acc:0.34 ===\n",
      "train loss:2.196385239423358\n",
      "train loss:2.190048852279485\n",
      "train loss:2.151175751307689\n",
      "train loss:2.132467223249243\n",
      "=== epoch:9, train acc:0.3125, test acc:0.37 ===\n",
      "train loss:2.162284661913372\n",
      "train loss:2.178660085090147\n",
      "train loss:2.1628397078532795\n",
      "train loss:2.1729143546787406\n",
      "=== epoch:10, train acc:0.3225, test acc:0.37 ===\n",
      "train loss:2.150502336937017\n",
      "train loss:2.1210630576401144\n",
      "train loss:2.1592720217324572\n",
      "train loss:2.176650349604264\n",
      "=== epoch:11, train acc:0.335, test acc:0.36 ===\n",
      "train loss:2.136172901249306\n",
      "train loss:2.116944158945672\n",
      "train loss:2.1313650806774125\n",
      "train loss:2.165819781162506\n",
      "=== epoch:12, train acc:0.35, test acc:0.37 ===\n",
      "train loss:2.1131992475202583\n",
      "train loss:2.107898375166741\n",
      "train loss:2.055644151678122\n",
      "train loss:2.1235007034618567\n",
      "=== epoch:13, train acc:0.36, test acc:0.38 ===\n",
      "train loss:2.1050874708370766\n",
      "train loss:2.0722558566609846\n",
      "train loss:2.0429846571058943\n",
      "train loss:2.1113116555337585\n",
      "=== epoch:14, train acc:0.3725, test acc:0.4 ===\n",
      "train loss:2.0346485702560573\n",
      "train loss:2.058995416245527\n",
      "train loss:2.055926322268021\n",
      "train loss:2.063717702046814\n",
      "=== epoch:15, train acc:0.3925, test acc:0.4 ===\n",
      "train loss:1.9849577336089874\n",
      "train loss:2.0248506828366106\n",
      "train loss:2.024275796467302\n",
      "train loss:2.0902669045319406\n",
      "=== epoch:16, train acc:0.4075, test acc:0.38 ===\n",
      "train loss:2.019338041695327\n",
      "train loss:1.989615666038963\n",
      "train loss:2.0360978464722614\n",
      "train loss:2.0200193697569584\n",
      "=== epoch:17, train acc:0.42, test acc:0.38 ===\n",
      "train loss:1.9907355383139658\n",
      "train loss:1.9496328611611875\n",
      "train loss:2.000547639681326\n",
      "train loss:1.99420047237963\n",
      "=== epoch:18, train acc:0.4225, test acc:0.38 ===\n",
      "train loss:1.9508185951563664\n",
      "train loss:1.9933946151467308\n",
      "train loss:1.9510649542265448\n",
      "train loss:1.9700779409808677\n",
      "=== epoch:19, train acc:0.435, test acc:0.38 ===\n",
      "train loss:1.960989449375701\n",
      "train loss:1.9609938711108565\n",
      "train loss:1.934407638786659\n",
      "train loss:1.9800277967403788\n",
      "=== epoch:20, train acc:0.45, test acc:0.4 ===\n",
      "train loss:1.8616398031360788\n",
      "train loss:1.8934199072344058\n",
      "train loss:1.8992620154152609\n",
      "train loss:1.8768241888816064\n",
      "=== epoch:21, train acc:0.4575, test acc:0.43 ===\n",
      "train loss:1.8812925389580013\n",
      "train loss:1.8887800079810932\n",
      "train loss:1.8637954020089393\n",
      "train loss:1.848143801283793\n",
      "=== epoch:22, train acc:0.485, test acc:0.43 ===\n",
      "train loss:1.8627018146476588\n",
      "train loss:1.772979791489654\n",
      "train loss:1.8326141154337054\n",
      "train loss:1.8315103719529928\n",
      "=== epoch:23, train acc:0.4925, test acc:0.44 ===\n",
      "train loss:1.864288872382013\n",
      "train loss:1.8205255060031873\n",
      "train loss:1.8408773806063767\n",
      "train loss:1.8623605035626665\n",
      "=== epoch:24, train acc:0.5175, test acc:0.49 ===\n",
      "train loss:1.7921160131189813\n",
      "train loss:1.828648234970302\n",
      "train loss:1.751479171161825\n",
      "train loss:1.7800440909436857\n",
      "=== epoch:25, train acc:0.515, test acc:0.5 ===\n",
      "train loss:1.7619936157063487\n",
      "train loss:1.7418461690308253\n",
      "train loss:1.6581529933618746\n",
      "train loss:1.7788830245311353\n",
      "=== epoch:26, train acc:0.5175, test acc:0.5 ===\n",
      "train loss:1.777077376280984\n",
      "train loss:1.720827246214594\n",
      "train loss:1.678293831340447\n",
      "train loss:1.7611669411756121\n",
      "=== epoch:27, train acc:0.545, test acc:0.51 ===\n",
      "train loss:1.6182632494093594\n",
      "train loss:1.7328314841417776\n",
      "train loss:1.6764421404021643\n",
      "train loss:1.6809673794841535\n",
      "=== epoch:28, train acc:0.545, test acc:0.54 ===\n",
      "train loss:1.7461707148598917\n",
      "train loss:1.6346521089895751\n",
      "train loss:1.5974667625485892\n",
      "train loss:1.622024980862536\n",
      "=== epoch:29, train acc:0.545, test acc:0.59 ===\n",
      "train loss:1.4980451787266775\n",
      "train loss:1.5353172338830692\n",
      "train loss:1.5526031254880082\n",
      "train loss:1.5675106590165269\n",
      "=== epoch:30, train acc:0.555, test acc:0.58 ===\n",
      "train loss:1.5563855267126852\n",
      "train loss:1.5009789674965293\n",
      "train loss:1.5991038485326112\n",
      "train loss:1.6053673351780435\n",
      "=== epoch:31, train acc:0.5625, test acc:0.56 ===\n",
      "train loss:1.4873834299043491\n",
      "train loss:1.5436690614039457\n",
      "train loss:1.584648356399659\n",
      "train loss:1.4966869121469175\n",
      "=== epoch:32, train acc:0.6, test acc:0.6 ===\n",
      "train loss:1.4836704599166919\n",
      "train loss:1.50315213753994\n",
      "train loss:1.3992501083444016\n",
      "train loss:1.5444255021325535\n",
      "=== epoch:33, train acc:0.59, test acc:0.57 ===\n",
      "train loss:1.565246885732778\n",
      "train loss:1.5110576173599388\n",
      "train loss:1.5317550372843463\n",
      "train loss:1.4326696598745365\n",
      "=== epoch:34, train acc:0.6175, test acc:0.61 ===\n",
      "train loss:1.4860089246574173\n",
      "train loss:1.4225433896384596\n",
      "train loss:1.4383624049887935\n",
      "train loss:1.3635921998553087\n",
      "=== epoch:35, train acc:0.6325, test acc:0.61 ===\n",
      "train loss:1.3344573788035354\n",
      "train loss:1.4128447188395068\n",
      "train loss:1.3068254202170513\n",
      "train loss:1.3980241845957502\n",
      "=== epoch:36, train acc:0.63, test acc:0.6 ===\n",
      "train loss:1.3889642037468766\n",
      "train loss:1.3966213477442715\n",
      "train loss:1.2163347021903466\n",
      "train loss:1.2857441653308004\n",
      "=== epoch:37, train acc:0.635, test acc:0.64 ===\n",
      "train loss:1.298031613428892\n",
      "train loss:1.3837024943279395\n",
      "train loss:1.3028293732331182\n",
      "train loss:1.3028853809580134\n",
      "=== epoch:38, train acc:0.6725, test acc:0.67 ===\n",
      "train loss:1.3417518952792193\n",
      "train loss:1.3063229274289985\n",
      "train loss:1.254073711261499\n",
      "train loss:1.2640498823048423\n",
      "=== epoch:39, train acc:0.695, test acc:0.67 ===\n",
      "train loss:1.3351959767474004\n",
      "train loss:1.2938101268105595\n",
      "train loss:1.2097394219285955\n",
      "train loss:1.1946784066814053\n",
      "=== epoch:40, train acc:0.7225, test acc:0.7 ===\n",
      "train loss:1.105282729888616\n",
      "train loss:1.2588700446283247\n",
      "train loss:1.2895823081093112\n",
      "train loss:1.3454659930161725\n",
      "=== epoch:41, train acc:0.745, test acc:0.73 ===\n",
      "train loss:1.234050551934161\n",
      "train loss:1.1903281527518532\n",
      "train loss:1.0983928113865262\n",
      "train loss:1.1649066739155363\n",
      "=== epoch:42, train acc:0.745, test acc:0.72 ===\n",
      "train loss:1.2173586798143046\n",
      "train loss:1.1896759502208987\n",
      "train loss:1.187007072664811\n",
      "train loss:1.059137160251319\n",
      "=== epoch:43, train acc:0.7625, test acc:0.75 ===\n",
      "train loss:1.1671920920438907\n",
      "train loss:1.143436038135047\n",
      "train loss:1.1154998840172186\n",
      "train loss:1.0276954020225557\n",
      "=== epoch:44, train acc:0.785, test acc:0.77 ===\n",
      "train loss:1.0829956255449984\n",
      "train loss:1.0792625593541578\n",
      "train loss:1.002241850868485\n",
      "train loss:1.1388412547302404\n",
      "=== epoch:45, train acc:0.7775, test acc:0.76 ===\n",
      "train loss:1.149251009409954\n",
      "train loss:1.1646590820959697\n",
      "train loss:1.0321350642221838\n",
      "train loss:0.9948619732648749\n",
      "=== epoch:46, train acc:0.775, test acc:0.78 ===\n",
      "train loss:1.025430383550075\n",
      "train loss:1.0315418652063084\n",
      "train loss:1.0400663050495245\n",
      "train loss:1.0306043725067695\n",
      "=== epoch:47, train acc:0.785, test acc:0.79 ===\n",
      "train loss:1.0377769712756544\n",
      "train loss:1.0706859486621385\n",
      "train loss:0.9580578592874968\n",
      "train loss:1.0097930909836836\n",
      "=== epoch:48, train acc:0.81, test acc:0.78 ===\n",
      "train loss:1.0610325337932907\n",
      "train loss:0.9526309706320264\n",
      "train loss:0.8107661066545131\n",
      "train loss:0.9263504944343554\n",
      "=== epoch:49, train acc:0.8125, test acc:0.81 ===\n",
      "train loss:0.9345835852209456\n",
      "train loss:0.9862421141685426\n",
      "train loss:0.8310106273075896\n",
      "train loss:1.0503816168795088\n",
      "=== epoch:50, train acc:0.8, test acc:0.79 ===\n",
      "train loss:0.9099938644892448\n",
      "train loss:1.0121346290160933\n",
      "train loss:0.9048415836520086\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.81\n",
      "val_acc: 0.7900 | lr: 0.0057, weight_decay: 0.0000\n",
      "train loss:2.4254651308800104\n",
      "=== epoch:1, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3467937900398046\n",
      "train loss:2.329461137013964\n",
      "train loss:2.3037244708136937\n",
      "train loss:2.37840393508769\n",
      "=== epoch:2, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3873167950423513\n",
      "train loss:2.3634258360017895\n",
      "train loss:2.350997372195742\n",
      "train loss:2.3292603410968047\n",
      "=== epoch:3, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.327524866495817\n",
      "train loss:2.3734265632044313\n",
      "train loss:2.32285593669941\n",
      "train loss:2.3709559830706244\n",
      "=== epoch:4, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.378947488506821\n",
      "train loss:2.3690119481371474\n",
      "train loss:2.367510039902557\n",
      "train loss:2.3004821545957634\n",
      "=== epoch:5, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.2661634219195164\n",
      "train loss:2.360103542453884\n",
      "train loss:2.328707113820209\n",
      "train loss:2.402198493804983\n",
      "=== epoch:6, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3283306140810027\n",
      "train loss:2.3063254635082697\n",
      "train loss:2.3713637915756913\n",
      "train loss:2.3513867976704472\n",
      "=== epoch:7, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3714660743557885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.372052846225373\n",
      "train loss:2.335261234497934\n",
      "train loss:2.355699895245165\n",
      "=== epoch:8, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3533220972756936\n",
      "train loss:2.340100546927455\n",
      "train loss:2.3498369627991895\n",
      "train loss:2.362190475754273\n",
      "=== epoch:9, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.318804624542815\n",
      "train loss:2.3484988105699682\n",
      "train loss:2.327271885429239\n",
      "train loss:2.377180605711772\n",
      "=== epoch:10, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.354582083644818\n",
      "train loss:2.346818056980196\n",
      "train loss:2.3383130252203954\n",
      "train loss:2.354144237570273\n",
      "=== epoch:11, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.351225077918022\n",
      "train loss:2.2941324072887963\n",
      "train loss:2.3552009012814152\n",
      "train loss:2.360061457251646\n",
      "=== epoch:12, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3471552861910716\n",
      "train loss:2.3669558774699504\n",
      "train loss:2.3689653513421467\n",
      "train loss:2.299092079086329\n",
      "=== epoch:13, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3500691236768936\n",
      "train loss:2.361900673517901\n",
      "train loss:2.3665982758016506\n",
      "train loss:2.3288188278071527\n",
      "=== epoch:14, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3851097062552085\n",
      "train loss:2.373202376845216\n",
      "train loss:2.359446155648827\n",
      "train loss:2.4454680174800623\n",
      "=== epoch:15, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3873553554757394\n",
      "train loss:2.3774127661897184\n",
      "train loss:2.365457755403522\n",
      "train loss:2.350784137339678\n",
      "=== epoch:16, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3654195197506045\n",
      "train loss:2.3597952890476046\n",
      "train loss:2.3912882914391362\n",
      "train loss:2.38870449697443\n",
      "=== epoch:17, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.358311191883015\n",
      "train loss:2.338253801835354\n",
      "train loss:2.3192359293153366\n",
      "train loss:2.3589649699139152\n",
      "=== epoch:18, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.320234784465036\n",
      "train loss:2.3509025730685984\n",
      "train loss:2.3333011290582473\n",
      "train loss:2.331381308861409\n",
      "=== epoch:19, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3559945348010847\n",
      "train loss:2.3217025243032614\n",
      "train loss:2.348243096163221\n",
      "train loss:2.3650926002279866\n",
      "=== epoch:20, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.397280831441167\n",
      "train loss:2.3423470252652447\n",
      "train loss:2.3614233429494744\n",
      "train loss:2.324628217495143\n",
      "=== epoch:21, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.4291300057949865\n",
      "train loss:2.3552688389308774\n",
      "train loss:2.3708323862036824\n",
      "train loss:2.328167730114865\n",
      "=== epoch:22, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.374579652874006\n",
      "train loss:2.3849331528243902\n",
      "train loss:2.2987343041230184\n",
      "train loss:2.360095398667475\n",
      "=== epoch:23, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.422867345032479\n",
      "train loss:2.3668862440205123\n",
      "train loss:2.417535943214803\n",
      "train loss:2.346009761964941\n",
      "=== epoch:24, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3476649948888966\n",
      "train loss:2.337536677147512\n",
      "train loss:2.365019082778795\n",
      "train loss:2.3307410169791662\n",
      "=== epoch:25, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3778020148697343\n",
      "train loss:2.394418828057507\n",
      "train loss:2.3715888862230496\n",
      "train loss:2.3806348287784465\n",
      "=== epoch:26, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.351612473184188\n",
      "train loss:2.397700905868303\n",
      "train loss:2.3811308134491456\n",
      "train loss:2.3723362617496324\n",
      "=== epoch:27, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3950016047544898\n",
      "train loss:2.3380810141676767\n",
      "train loss:2.314455863046483\n",
      "train loss:2.3460818270177723\n",
      "=== epoch:28, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3622211181106554\n",
      "train loss:2.313012023041489\n",
      "train loss:2.3790243292245905\n",
      "train loss:2.388329146838207\n",
      "=== epoch:29, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3310646822190755\n",
      "train loss:2.291529889180186\n",
      "train loss:2.3549973107149706\n",
      "train loss:2.311109315590477\n",
      "=== epoch:30, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3699486173916084\n",
      "train loss:2.2916143055667217\n",
      "train loss:2.3326651094453545\n",
      "train loss:2.3987116407057827\n",
      "=== epoch:31, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3920440308603794\n",
      "train loss:2.401658531518648\n",
      "train loss:2.3634059314457208\n",
      "train loss:2.4045178249767405\n",
      "=== epoch:32, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3271927668894388\n",
      "train loss:2.3229306333733204\n",
      "train loss:2.326850585307246\n",
      "train loss:2.3374807749419793\n",
      "=== epoch:33, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.4163977278698603\n",
      "train loss:2.3090914655849066\n",
      "train loss:2.3677558337446682\n",
      "train loss:2.365911019368485\n",
      "=== epoch:34, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.332325251990488\n",
      "train loss:2.3614430870352456\n",
      "train loss:2.3470057150210004\n",
      "train loss:2.3367509429557747\n",
      "=== epoch:35, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3689279285796245\n",
      "train loss:2.343205789050252\n",
      "train loss:2.3430749868184884\n",
      "train loss:2.3180183691600185\n",
      "=== epoch:36, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.333027336607865\n",
      "train loss:2.3945171545609467\n",
      "train loss:2.3255062611848003\n",
      "train loss:2.385411606434424\n",
      "=== epoch:37, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.327317315486344\n",
      "train loss:2.3343684857035014\n",
      "train loss:2.309905784732338\n",
      "train loss:2.334198254094782\n",
      "=== epoch:38, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3652721963030614\n",
      "train loss:2.279413850348025\n",
      "train loss:2.4251214879945127\n",
      "train loss:2.3767194147101938\n",
      "=== epoch:39, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3940712561718773\n",
      "train loss:2.352163920634107\n",
      "train loss:2.3778358479577792\n",
      "train loss:2.392994262166062\n",
      "=== epoch:40, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3275816899891373\n",
      "train loss:2.3965441765736757\n",
      "train loss:2.3103575187192456\n",
      "train loss:2.359489968209179\n",
      "=== epoch:41, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3776761624754057\n",
      "train loss:2.3713270860685376\n",
      "train loss:2.338493332951036\n",
      "train loss:2.325082206396267\n",
      "=== epoch:42, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.353198520667925\n",
      "train loss:2.338505382486672\n",
      "train loss:2.3738871760218587\n",
      "train loss:2.339778693227951\n",
      "=== epoch:43, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.327874821064344\n",
      "train loss:2.348121840894896\n",
      "train loss:2.3696285724990074\n",
      "train loss:2.363353735435615\n",
      "=== epoch:44, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.294014509083133\n",
      "train loss:2.367873574223351\n",
      "train loss:2.3627769369269793\n",
      "train loss:2.3661505347123146\n",
      "=== epoch:45, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3931467779849935\n",
      "train loss:2.3385477300755113\n",
      "train loss:2.366795066433395\n",
      "train loss:2.3490415838406027\n",
      "=== epoch:46, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3503688769710918\n",
      "train loss:2.3559163513378802\n",
      "train loss:2.357686101413565\n",
      "train loss:2.3744936740372298\n",
      "=== epoch:47, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3764678624064093\n",
      "train loss:2.3825834956689933\n",
      "train loss:2.3816321904845297\n",
      "train loss:2.34152231510012\n",
      "=== epoch:48, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3270067960085075\n",
      "train loss:2.366269993054682\n",
      "train loss:2.357739858749126\n",
      "train loss:2.3815603453523075\n",
      "=== epoch:49, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3942380399955083\n",
      "train loss:2.345252727494755\n",
      "train loss:2.396527286871757\n",
      "train loss:2.3516354460329296\n",
      "=== epoch:50, train acc:0.0825, test acc:0.05 ===\n",
      "train loss:2.3907540116878976\n",
      "train loss:2.395732466655671\n",
      "train loss:2.349126438721448\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.05\n",
      "val_acc: 0.0500 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.2957738875096534\n",
      "=== epoch:1, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3100920797648032\n",
      "train loss:2.321435974903052\n",
      "train loss:2.2430476712401823\n",
      "train loss:2.3400553433672786\n",
      "=== epoch:2, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3749222931405054\n",
      "train loss:2.3019722690841036\n",
      "train loss:2.33580549895567\n",
      "train loss:2.3335008697144515\n",
      "=== epoch:3, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.323603744982662\n",
      "train loss:2.298192018848281\n",
      "train loss:2.324664875743109\n",
      "train loss:2.28447675430225\n",
      "=== epoch:4, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.356867710472246\n",
      "train loss:2.388878358347787\n",
      "train loss:2.267143916984835\n",
      "train loss:2.3257838879238357\n",
      "=== epoch:5, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.352836227286377\n",
      "train loss:2.3331190436753886\n",
      "train loss:2.300405481878152\n",
      "train loss:2.297286848743517\n",
      "=== epoch:6, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.347343593865525\n",
      "train loss:2.288774522764415\n",
      "train loss:2.36635755837648\n",
      "train loss:2.32084590649886\n",
      "=== epoch:7, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3040427429324493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.320404498585688\n",
      "train loss:2.3175168987790444\n",
      "train loss:2.3355591396419197\n",
      "=== epoch:8, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3058743637881958\n",
      "train loss:2.3045298278564994\n",
      "train loss:2.3300019670641765\n",
      "train loss:2.338823214094449\n",
      "=== epoch:9, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.295409810415243\n",
      "train loss:2.3137850946337233\n",
      "train loss:2.3234552859342172\n",
      "train loss:2.2887346292165964\n",
      "=== epoch:10, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.341076666481511\n",
      "train loss:2.2707249766218234\n",
      "train loss:2.2952941754094867\n",
      "train loss:2.3186234247547075\n",
      "=== epoch:11, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.2860613056487273\n",
      "train loss:2.330569250875099\n",
      "train loss:2.2957756137240235\n",
      "train loss:2.3480104835181193\n",
      "=== epoch:12, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.266590060926181\n",
      "train loss:2.346520883770909\n",
      "train loss:2.3083055047336103\n",
      "train loss:2.333139058392244\n",
      "=== epoch:13, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.334616049219621\n",
      "train loss:2.387280613212652\n",
      "train loss:2.315256026265026\n",
      "train loss:2.2838363257573144\n",
      "=== epoch:14, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.297345931906752\n",
      "train loss:2.3176374629019234\n",
      "train loss:2.3214098474308806\n",
      "train loss:2.3886076336676054\n",
      "=== epoch:15, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3067463220600013\n",
      "train loss:2.3313314392662923\n",
      "train loss:2.3069640175083435\n",
      "train loss:2.343613665299191\n",
      "=== epoch:16, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3164305540114287\n",
      "train loss:2.3588540495906254\n",
      "train loss:2.310553700710823\n",
      "train loss:2.33654723909958\n",
      "=== epoch:17, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3390512187294177\n",
      "train loss:2.329976135047374\n",
      "train loss:2.2830945314601268\n",
      "train loss:2.314825971101954\n",
      "=== epoch:18, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3403169750366777\n",
      "train loss:2.311849494458403\n",
      "train loss:2.330685607470376\n",
      "train loss:2.2764037991803723\n",
      "=== epoch:19, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3970850235865937\n",
      "train loss:2.2890233041426407\n",
      "train loss:2.3601810128005334\n",
      "train loss:2.2817000330163393\n",
      "=== epoch:20, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3234164160105593\n",
      "train loss:2.3089432390473776\n",
      "train loss:2.3443844744448263\n",
      "train loss:2.3236192464659005\n",
      "=== epoch:21, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.36193419646675\n",
      "train loss:2.3520386136786673\n",
      "train loss:2.271895456084552\n",
      "train loss:2.2902884008679165\n",
      "=== epoch:22, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3185724912177563\n",
      "train loss:2.3599843713077244\n",
      "train loss:2.270587432447202\n",
      "train loss:2.309878699339285\n",
      "=== epoch:23, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3104272794033758\n",
      "train loss:2.3466644507546155\n",
      "train loss:2.3013537421385766\n",
      "train loss:2.345868855641466\n",
      "=== epoch:24, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3130625246786813\n",
      "train loss:2.3559565070904562\n",
      "train loss:2.347498165335621\n",
      "train loss:2.3682903169044724\n",
      "=== epoch:25, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3062902739937794\n",
      "train loss:2.274390373546079\n",
      "train loss:2.320583882216531\n",
      "train loss:2.3245370464607684\n",
      "=== epoch:26, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3462553752707898\n",
      "train loss:2.3731484438978865\n",
      "train loss:2.3251638178214895\n",
      "train loss:2.3089366184031004\n",
      "=== epoch:27, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3627181397541275\n",
      "train loss:2.3054809021074982\n",
      "train loss:2.335050466039215\n",
      "train loss:2.303111870784566\n",
      "=== epoch:28, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.288907323262411\n",
      "train loss:2.2878819369884553\n",
      "train loss:2.3314126076332164\n",
      "train loss:2.336332935599237\n",
      "=== epoch:29, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3332240725845645\n",
      "train loss:2.3276347480938413\n",
      "train loss:2.3470680676655906\n",
      "train loss:2.332715161789656\n",
      "=== epoch:30, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3302280252647183\n",
      "train loss:2.296198235108368\n",
      "train loss:2.299895470916302\n",
      "train loss:2.2933024152628336\n",
      "=== epoch:31, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.2871577292575727\n",
      "train loss:2.298053195874896\n",
      "train loss:2.339017504684087\n",
      "train loss:2.36540377903657\n",
      "=== epoch:32, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.348527919169139\n",
      "train loss:2.3030362137345386\n",
      "train loss:2.3390375339931695\n",
      "train loss:2.359905405435529\n",
      "=== epoch:33, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.2950562437115924\n",
      "train loss:2.363837852583291\n",
      "train loss:2.339977883856794\n",
      "train loss:2.3075470294847182\n",
      "=== epoch:34, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.355126642914984\n",
      "train loss:2.2914126146861924\n",
      "train loss:2.374942131210259\n",
      "train loss:2.295027926577804\n",
      "=== epoch:35, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.297544065229895\n",
      "train loss:2.333780755904432\n",
      "train loss:2.331692357393768\n",
      "train loss:2.3465473346300096\n",
      "=== epoch:36, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.2833687484193277\n",
      "train loss:2.349958071538159\n",
      "train loss:2.353391359901212\n",
      "train loss:2.3588902283562\n",
      "=== epoch:37, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.284633824193726\n",
      "train loss:2.292534581039166\n",
      "train loss:2.370916205195581\n",
      "train loss:2.3307057594474654\n",
      "=== epoch:38, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.315496779110688\n",
      "train loss:2.350743774918055\n",
      "train loss:2.377546632983223\n",
      "train loss:2.3038642438077392\n",
      "=== epoch:39, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3127927908135546\n",
      "train loss:2.3140831234203865\n",
      "train loss:2.3484473393108183\n",
      "train loss:2.3857713875777207\n",
      "=== epoch:40, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.253523993070658\n",
      "train loss:2.3281823209988755\n",
      "train loss:2.2778160891372816\n",
      "train loss:2.265918654978579\n",
      "=== epoch:41, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.2589359347262032\n",
      "train loss:2.3282646245356236\n",
      "train loss:2.2927043071208355\n",
      "train loss:2.284562931461359\n",
      "=== epoch:42, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.316438182913242\n",
      "train loss:2.3075558291849423\n",
      "train loss:2.328977356249099\n",
      "train loss:2.3273643874122603\n",
      "=== epoch:43, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3726013129266064\n",
      "train loss:2.310174665403507\n",
      "train loss:2.3431543013724268\n",
      "train loss:2.3561715172025948\n",
      "=== epoch:44, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.304263603564225\n",
      "train loss:2.280812628926552\n",
      "train loss:2.277384560338641\n",
      "train loss:2.254573233176004\n",
      "=== epoch:45, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3188850847449256\n",
      "train loss:2.345085742640357\n",
      "train loss:2.350497575744236\n",
      "train loss:2.2738230227795526\n",
      "=== epoch:46, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.324778382003611\n",
      "train loss:2.3593398197726927\n",
      "train loss:2.3737433010079774\n",
      "train loss:2.297606259266408\n",
      "=== epoch:47, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.3723419364697746\n",
      "train loss:2.377288422395471\n",
      "train loss:2.326447488536425\n",
      "train loss:2.313681560216489\n",
      "=== epoch:48, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.311881087996028\n",
      "train loss:2.352348032114059\n",
      "train loss:2.3196680049829954\n",
      "train loss:2.2793484955284193\n",
      "=== epoch:49, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.272920798337133\n",
      "train loss:2.3406585629849253\n",
      "train loss:2.2863535694095\n",
      "train loss:2.284800521617624\n",
      "=== epoch:50, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.343296976804669\n",
      "train loss:2.3200987541547224\n",
      "train loss:2.3474912386286064\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.537831742832597\n",
      "=== epoch:1, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.648439403637936\n",
      "train loss:2.4990383562606917\n",
      "train loss:2.4693758504032255\n",
      "train loss:2.4873867985778753\n",
      "=== epoch:2, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4558119063322663\n",
      "train loss:2.606592054217166\n",
      "train loss:2.6194556537679152\n",
      "train loss:2.422066002443179\n",
      "=== epoch:3, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5598297210045833\n",
      "train loss:2.5139498942408625\n",
      "train loss:2.7329248750436497\n",
      "train loss:2.4631323624109984\n",
      "=== epoch:4, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5628103094448185\n",
      "train loss:2.4597915371226104\n",
      "train loss:2.616683496310489\n",
      "train loss:2.496930684631359\n",
      "=== epoch:5, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.639269118075321\n",
      "train loss:2.6009094601426637\n",
      "train loss:2.575976919113042\n",
      "train loss:2.5146198138970055\n",
      "=== epoch:6, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4649131356060754\n",
      "train loss:2.51139278362983\n",
      "train loss:2.5005807677148897\n",
      "train loss:2.560775402814133\n",
      "=== epoch:7, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.461764280739249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.538395957887172\n",
      "train loss:2.4902246423704253\n",
      "train loss:2.5414459806181435\n",
      "=== epoch:8, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5861777912379935\n",
      "train loss:2.489302638960712\n",
      "train loss:2.4623454923346206\n",
      "train loss:2.5062396018898645\n",
      "=== epoch:9, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.476415024882053\n",
      "train loss:2.4945626072893314\n",
      "train loss:2.5340479581914646\n",
      "train loss:2.5739974263516716\n",
      "=== epoch:10, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.6835894144785777\n",
      "train loss:2.5987648857900303\n",
      "train loss:2.469469471054985\n",
      "train loss:2.5303321836490444\n",
      "=== epoch:11, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5533629961835844\n",
      "train loss:2.5557866628596146\n",
      "train loss:2.561945570049242\n",
      "train loss:2.489732330363233\n",
      "=== epoch:12, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.6186906614106884\n",
      "train loss:2.6187128022838686\n",
      "train loss:2.5205838238177782\n",
      "train loss:2.5467008072918524\n",
      "=== epoch:13, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.560764369667043\n",
      "train loss:2.538756506062427\n",
      "train loss:2.523456668732639\n",
      "train loss:2.589487161556979\n",
      "=== epoch:14, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5783698467651126\n",
      "train loss:2.543132549636695\n",
      "train loss:2.525921822982681\n",
      "train loss:2.571939269511042\n",
      "=== epoch:15, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4852817355447425\n",
      "train loss:2.5285980321243557\n",
      "train loss:2.421193607363167\n",
      "train loss:2.466827347911303\n",
      "=== epoch:16, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4427068286797473\n",
      "train loss:2.5295864016266663\n",
      "train loss:2.435174892259723\n",
      "train loss:2.540693533938941\n",
      "=== epoch:17, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.425522819674996\n",
      "train loss:2.4377388349900144\n",
      "train loss:2.5461768589424008\n",
      "train loss:2.450283320702429\n",
      "=== epoch:18, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4812153352386854\n",
      "train loss:2.4124814128231504\n",
      "train loss:2.429179357494475\n",
      "train loss:2.4923347850613373\n",
      "=== epoch:19, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5814465974769054\n",
      "train loss:2.6198237899842276\n",
      "train loss:2.523206732696406\n",
      "train loss:2.4594436155680595\n",
      "=== epoch:20, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.48991074948934\n",
      "train loss:2.6255153787398453\n",
      "train loss:2.401756684111118\n",
      "train loss:2.4702755923744144\n",
      "=== epoch:21, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4198413685948696\n",
      "train loss:2.52897248626981\n",
      "train loss:2.5675965795146634\n",
      "train loss:2.4060751070945927\n",
      "=== epoch:22, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.544215394342496\n",
      "train loss:2.447355652425996\n",
      "train loss:2.509850545715532\n",
      "train loss:2.5341271751129324\n",
      "=== epoch:23, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4756684185706477\n",
      "train loss:2.5935805212818184\n",
      "train loss:2.5089021890576766\n",
      "train loss:2.520570568315834\n",
      "=== epoch:24, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.54117882287967\n",
      "train loss:2.5384873004090958\n",
      "train loss:2.542983486488055\n",
      "train loss:2.5312056051035965\n",
      "=== epoch:25, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.537207795188133\n",
      "train loss:2.5170808259366977\n",
      "train loss:2.4714023485139545\n",
      "train loss:2.501611663515401\n",
      "=== epoch:26, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.453941695251864\n",
      "train loss:2.6210996147120524\n",
      "train loss:2.4932215445486694\n",
      "train loss:2.511860119004414\n",
      "=== epoch:27, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.607667993183097\n",
      "train loss:2.5606209309144923\n",
      "train loss:2.546113925637621\n",
      "train loss:2.5208922121111685\n",
      "=== epoch:28, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4912093084924436\n",
      "train loss:2.499733627652462\n",
      "train loss:2.6993123827679115\n",
      "train loss:2.393446862752892\n",
      "=== epoch:29, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.540304010361707\n",
      "train loss:2.557230161459257\n",
      "train loss:2.6016125017699285\n",
      "train loss:2.469297253705208\n",
      "=== epoch:30, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4868612166008153\n",
      "train loss:2.5743093591573185\n",
      "train loss:2.560713443533892\n",
      "train loss:2.5224573028909654\n",
      "=== epoch:31, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5217848750402196\n",
      "train loss:2.6728945646253233\n",
      "train loss:2.4256702309085685\n",
      "train loss:2.4900666490257692\n",
      "=== epoch:32, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.500145703722217\n",
      "train loss:2.569651536286163\n",
      "train loss:2.449090482518012\n",
      "train loss:2.51094592439304\n",
      "=== epoch:33, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5498839618650266\n",
      "train loss:2.408918778776906\n",
      "train loss:2.5828916357335436\n",
      "train loss:2.4465161191559295\n",
      "=== epoch:34, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.508443482873386\n",
      "train loss:2.5367428568687282\n",
      "train loss:2.574436315334289\n",
      "train loss:2.4486800743540873\n",
      "=== epoch:35, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.566192043527118\n",
      "train loss:2.550413031927849\n",
      "train loss:2.5854223049471035\n",
      "train loss:2.567523239915424\n",
      "=== epoch:36, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.3567700645951963\n",
      "train loss:2.612999862048706\n",
      "train loss:2.519522085891481\n",
      "train loss:2.47002904416459\n",
      "=== epoch:37, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.564846237919295\n",
      "train loss:2.5547264191892873\n",
      "train loss:2.6318805011276996\n",
      "train loss:2.537891168519869\n",
      "=== epoch:38, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.526558289079287\n",
      "train loss:2.6086793576325156\n",
      "train loss:2.579731285217621\n",
      "train loss:2.4599133791467787\n",
      "=== epoch:39, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5481438402389847\n",
      "train loss:2.4931369426284893\n",
      "train loss:2.4948915424070277\n",
      "train loss:2.4805953557775635\n",
      "=== epoch:40, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4611641461909817\n",
      "train loss:2.440812424283858\n",
      "train loss:2.5501335607091717\n",
      "train loss:2.622693215994626\n",
      "=== epoch:41, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.315176224374778\n",
      "train loss:2.5519125090558803\n",
      "train loss:2.488026724780828\n",
      "train loss:2.6088083787497935\n",
      "=== epoch:42, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.433100071033495\n",
      "train loss:2.4389883896760076\n",
      "train loss:2.437034832735144\n",
      "train loss:2.4992750709030425\n",
      "=== epoch:43, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.573482769793126\n",
      "train loss:2.418314539519999\n",
      "train loss:2.483213531079814\n",
      "train loss:2.488061849307507\n",
      "=== epoch:44, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4907326586999146\n",
      "train loss:2.6029464561187723\n",
      "train loss:2.5889116000328465\n",
      "train loss:2.5735122085045923\n",
      "=== epoch:45, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.4574257266827564\n",
      "train loss:2.4990358056954607\n",
      "train loss:2.4685034112916857\n",
      "train loss:2.6024364169887306\n",
      "=== epoch:46, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.545686485316381\n",
      "train loss:2.537504829796175\n",
      "train loss:2.5308994749848313\n",
      "train loss:2.428965350102724\n",
      "=== epoch:47, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.549208075887186\n",
      "train loss:2.522353016349696\n",
      "train loss:2.439421895574272\n",
      "train loss:2.480996951724443\n",
      "=== epoch:48, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.596496010875836\n",
      "train loss:2.4532328798489647\n",
      "train loss:2.4273008512256706\n",
      "train loss:2.552200371359718\n",
      "=== epoch:49, train acc:0.1075, test acc:0.1 ===\n",
      "train loss:2.5094415904707574\n",
      "train loss:2.5450257009582504\n",
      "train loss:2.623565316363656\n",
      "train loss:2.506025542999451\n",
      "=== epoch:50, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.464842125013327\n",
      "train loss:2.4883180743345723\n",
      "train loss:2.4932363401855406\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4468127275349403\n",
      "=== epoch:1, train acc:0.11, test acc:0.07 ===\n",
      "train loss:2.4787510556421855\n",
      "train loss:2.4311205188228056\n",
      "train loss:2.4779785609139227\n",
      "train loss:2.3803687623008254\n",
      "=== epoch:2, train acc:0.1075, test acc:0.08 ===\n",
      "train loss:2.3851097086993414\n",
      "train loss:2.4243065769132617\n",
      "train loss:2.4525138391902295\n",
      "train loss:2.3438896766478052\n",
      "=== epoch:3, train acc:0.1125, test acc:0.08 ===\n",
      "train loss:2.400747216108319\n",
      "train loss:2.444825395493038\n",
      "train loss:2.41181132211436\n",
      "train loss:2.459265598206327\n",
      "=== epoch:4, train acc:0.11, test acc:0.07 ===\n",
      "train loss:2.4194814184762845\n",
      "train loss:2.419722564963239\n",
      "train loss:2.352721076305962\n",
      "train loss:2.413497933275941\n",
      "=== epoch:5, train acc:0.1075, test acc:0.07 ===\n",
      "train loss:2.433922182555929\n",
      "train loss:2.3865914081538673\n",
      "train loss:2.3647633328351376\n",
      "train loss:2.3809428032397633\n",
      "=== epoch:6, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.3260894762900053\n",
      "train loss:2.3385775048561075\n",
      "train loss:2.355143730172203\n",
      "train loss:2.317454026605602\n",
      "=== epoch:7, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.3832090805597113\n",
      "train loss:2.4166638106646894\n",
      "train loss:2.3308188147738838\n",
      "train loss:2.388838772033141\n",
      "=== epoch:8, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.372268201479482\n",
      "train loss:2.3569671381485557\n",
      "train loss:2.389631241331396\n",
      "train loss:2.3435250091534763\n",
      "=== epoch:9, train acc:0.1225, test acc:0.07 ===\n",
      "train loss:2.471711649904645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3892731079773135\n",
      "train loss:2.3307610381358956\n",
      "train loss:2.3692720632107034\n",
      "=== epoch:10, train acc:0.12, test acc:0.08 ===\n",
      "train loss:2.331931086204033\n",
      "train loss:2.3233695167489445\n",
      "train loss:2.41875244500314\n",
      "train loss:2.3206268651232165\n",
      "=== epoch:11, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.3280106032185057\n",
      "train loss:2.3005297983439803\n",
      "train loss:2.398688553818647\n",
      "train loss:2.3009600391887277\n",
      "=== epoch:12, train acc:0.13, test acc:0.08 ===\n",
      "train loss:2.2322484744964632\n",
      "train loss:2.334106690528342\n",
      "train loss:2.3305828463401816\n",
      "train loss:2.2922832684357113\n",
      "=== epoch:13, train acc:0.1325, test acc:0.09 ===\n",
      "train loss:2.3226318967296584\n",
      "train loss:2.313230064778918\n",
      "train loss:2.3264518556227993\n",
      "train loss:2.3376568786396126\n",
      "=== epoch:14, train acc:0.135, test acc:0.09 ===\n",
      "train loss:2.306442861808389\n",
      "train loss:2.2525093427969605\n",
      "train loss:2.2506944591689044\n",
      "train loss:2.216357898774805\n",
      "=== epoch:15, train acc:0.14, test acc:0.09 ===\n",
      "train loss:2.303698731818456\n",
      "train loss:2.3433804174790316\n",
      "train loss:2.223490481000768\n",
      "train loss:2.2597490071855617\n",
      "=== epoch:16, train acc:0.1425, test acc:0.1 ===\n",
      "train loss:2.24447450852697\n",
      "train loss:2.291951669401925\n",
      "train loss:2.262142162561893\n",
      "train loss:2.2688178117933737\n",
      "=== epoch:17, train acc:0.1425, test acc:0.11 ===\n",
      "train loss:2.3329195001505445\n",
      "train loss:2.226888459742554\n",
      "train loss:2.2543334379830395\n",
      "train loss:2.2221689431136507\n",
      "=== epoch:18, train acc:0.1475, test acc:0.11 ===\n",
      "train loss:2.283893667051589\n",
      "train loss:2.2849285701739737\n",
      "train loss:2.2494569679270193\n",
      "train loss:2.2532944234220134\n",
      "=== epoch:19, train acc:0.145, test acc:0.1 ===\n",
      "train loss:2.2218629147879194\n",
      "train loss:2.3116612542876296\n",
      "train loss:2.23263209937089\n",
      "train loss:2.2657100368315195\n",
      "=== epoch:20, train acc:0.145, test acc:0.12 ===\n",
      "train loss:2.2267501958710083\n",
      "train loss:2.25713759437684\n",
      "train loss:2.251212526099505\n",
      "train loss:2.2357037778720126\n",
      "=== epoch:21, train acc:0.145, test acc:0.12 ===\n",
      "train loss:2.2429876848283987\n",
      "train loss:2.260845371070997\n",
      "train loss:2.2345037582991587\n",
      "train loss:2.232347145114076\n",
      "=== epoch:22, train acc:0.15, test acc:0.11 ===\n",
      "train loss:2.260397464930901\n",
      "train loss:2.2431689526043757\n",
      "train loss:2.2375266011829886\n",
      "train loss:2.218081974996638\n",
      "=== epoch:23, train acc:0.155, test acc:0.11 ===\n",
      "train loss:2.1448250657108936\n",
      "train loss:2.1963359858926905\n",
      "train loss:2.249048028370479\n",
      "train loss:2.2522600105129835\n",
      "=== epoch:24, train acc:0.1675, test acc:0.12 ===\n",
      "train loss:2.2396700347811165\n",
      "train loss:2.202150396048547\n",
      "train loss:2.1961020662914996\n",
      "train loss:2.2221749218027393\n",
      "=== epoch:25, train acc:0.1675, test acc:0.12 ===\n",
      "train loss:2.255136726578138\n",
      "train loss:2.2583967824440765\n",
      "train loss:2.201741571709613\n",
      "train loss:2.277881582705059\n",
      "=== epoch:26, train acc:0.1675, test acc:0.12 ===\n",
      "train loss:2.157994694548926\n",
      "train loss:2.2424692070433587\n",
      "train loss:2.2173190268153173\n",
      "train loss:2.2091963000744137\n",
      "=== epoch:27, train acc:0.17, test acc:0.12 ===\n",
      "train loss:2.1803804674346763\n",
      "train loss:2.1902330547813804\n",
      "train loss:2.170797896889049\n",
      "train loss:2.247129664027569\n",
      "=== epoch:28, train acc:0.175, test acc:0.12 ===\n",
      "train loss:2.2267854249101773\n",
      "train loss:2.235884119797646\n",
      "train loss:2.219025665135306\n",
      "train loss:2.2037515806162045\n",
      "=== epoch:29, train acc:0.18, test acc:0.14 ===\n",
      "train loss:2.20291668985835\n",
      "train loss:2.111166564405321\n",
      "train loss:2.1706243471963798\n",
      "train loss:2.181981476009183\n",
      "=== epoch:30, train acc:0.1925, test acc:0.14 ===\n",
      "train loss:2.1542564639120125\n",
      "train loss:2.1948913335183224\n",
      "train loss:2.1355045029062736\n",
      "train loss:2.176435981051299\n",
      "=== epoch:31, train acc:0.1925, test acc:0.14 ===\n",
      "train loss:2.1479626525730535\n",
      "train loss:2.1150081469212783\n",
      "train loss:2.166343060536748\n",
      "train loss:2.2203717350370615\n",
      "=== epoch:32, train acc:0.205, test acc:0.14 ===\n",
      "train loss:2.1601893615889685\n",
      "train loss:2.2008531260943993\n",
      "train loss:2.172609144990615\n",
      "train loss:2.1523786499945645\n",
      "=== epoch:33, train acc:0.2125, test acc:0.14 ===\n",
      "train loss:2.1376629200106603\n",
      "train loss:2.162341662441563\n",
      "train loss:2.13172940442777\n",
      "train loss:2.1161371770948194\n",
      "=== epoch:34, train acc:0.215, test acc:0.16 ===\n",
      "train loss:2.100739533705161\n",
      "train loss:2.1232319523968446\n",
      "train loss:2.187127919071585\n",
      "train loss:2.1185116548987684\n",
      "=== epoch:35, train acc:0.2175, test acc:0.16 ===\n",
      "train loss:2.111324220527196\n",
      "train loss:2.1944100971570375\n",
      "train loss:2.047917616547418\n",
      "train loss:2.14719256723277\n",
      "=== epoch:36, train acc:0.22, test acc:0.17 ===\n",
      "train loss:2.074117149724439\n",
      "train loss:2.1401750100297665\n",
      "train loss:2.0575697902166152\n",
      "train loss:2.1008258631934185\n",
      "=== epoch:37, train acc:0.235, test acc:0.18 ===\n",
      "train loss:2.1830342182108398\n",
      "train loss:2.083316663868625\n",
      "train loss:2.160268962566109\n",
      "train loss:2.1242493973170147\n",
      "=== epoch:38, train acc:0.2375, test acc:0.19 ===\n",
      "train loss:2.10161674069047\n",
      "train loss:2.176832181776843\n",
      "train loss:2.149753991590785\n",
      "train loss:2.183701015975373\n",
      "=== epoch:39, train acc:0.2425, test acc:0.19 ===\n",
      "train loss:2.1667016347388968\n",
      "train loss:2.1077601448597467\n",
      "train loss:2.0498926495337684\n",
      "train loss:2.090874014574364\n",
      "=== epoch:40, train acc:0.255, test acc:0.18 ===\n",
      "train loss:2.0595822194667948\n",
      "train loss:2.1573797479020405\n",
      "train loss:2.004783297958847\n",
      "train loss:2.1060902487238127\n",
      "=== epoch:41, train acc:0.2525, test acc:0.17 ===\n",
      "train loss:2.1184130969817905\n",
      "train loss:2.0509879937564413\n",
      "train loss:2.218943191225893\n",
      "train loss:2.0905211515956768\n",
      "=== epoch:42, train acc:0.2525, test acc:0.17 ===\n",
      "train loss:2.1243619161679748\n",
      "train loss:2.0908877977625657\n",
      "train loss:2.1650399934694393\n",
      "train loss:2.0821566420972135\n",
      "=== epoch:43, train acc:0.27, test acc:0.17 ===\n",
      "train loss:2.1198338879282344\n",
      "train loss:2.082601347747053\n",
      "train loss:2.090185151408925\n",
      "train loss:2.0764362147233766\n",
      "=== epoch:44, train acc:0.2625, test acc:0.19 ===\n",
      "train loss:2.05773634840747\n",
      "train loss:2.1206234685146876\n",
      "train loss:2.076731694638796\n",
      "train loss:2.0799670691867664\n",
      "=== epoch:45, train acc:0.275, test acc:0.18 ===\n",
      "train loss:2.0975325072216906\n",
      "train loss:2.0436562514131995\n",
      "train loss:2.070391248878018\n",
      "train loss:2.0077279332023883\n",
      "=== epoch:46, train acc:0.2825, test acc:0.18 ===\n",
      "train loss:2.052805277928037\n",
      "train loss:2.028985177255287\n",
      "train loss:2.1035953442341238\n",
      "train loss:2.1426093435060887\n",
      "=== epoch:47, train acc:0.2875, test acc:0.18 ===\n",
      "train loss:2.079221385977022\n",
      "train loss:2.003388906044971\n",
      "train loss:2.0810826575186607\n",
      "train loss:2.062476783113083\n",
      "=== epoch:48, train acc:0.2975, test acc:0.18 ===\n",
      "train loss:2.1010490038321508\n",
      "train loss:2.0303008087806376\n",
      "train loss:2.066624516073345\n",
      "train loss:2.0447322812789466\n",
      "=== epoch:49, train acc:0.3, test acc:0.2 ===\n",
      "train loss:2.041443999999752\n",
      "train loss:2.098080113561389\n",
      "train loss:2.0830830057664445\n",
      "train loss:1.996305905150462\n",
      "=== epoch:50, train acc:0.305, test acc:0.21 ===\n",
      "train loss:2.0744160118705444\n",
      "train loss:2.091195311934703\n",
      "train loss:2.0330953164021297\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.22\n",
      "val_acc: 0.2100 | lr: 0.0014, weight_decay: 0.0000\n",
      "train loss:2.6498634640136127\n",
      "=== epoch:1, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4693372397945828\n",
      "train loss:2.4966060610615624\n",
      "train loss:2.591565009996169\n",
      "train loss:2.4711816556935915\n",
      "=== epoch:2, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.459029729699881\n",
      "train loss:2.4627224695457444\n",
      "train loss:2.591054183545199\n",
      "train loss:2.5803440310604153\n",
      "=== epoch:3, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5486031327312153\n",
      "train loss:2.3818853882806876\n",
      "train loss:2.451377543998275\n",
      "train loss:2.5169486564385317\n",
      "=== epoch:4, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4454774554869703\n",
      "train loss:2.495407512206919\n",
      "train loss:2.494583412492493\n",
      "train loss:2.522465465271775\n",
      "=== epoch:5, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4652295386711494\n",
      "train loss:2.4308884759949905\n",
      "train loss:2.5013844033870343\n",
      "train loss:2.601848205722944\n",
      "=== epoch:6, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5403147836778857\n",
      "train loss:2.409243741080263\n",
      "train loss:2.382241486810696\n",
      "train loss:2.574602001002101\n",
      "=== epoch:7, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.491836737299692\n",
      "train loss:2.5560329102471635\n",
      "train loss:2.4636770178738714\n",
      "train loss:2.4824923660875937\n",
      "=== epoch:8, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.525168465055314\n",
      "train loss:2.548470404347631\n",
      "train loss:2.531324414372149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3709595947265023\n",
      "=== epoch:9, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4974417083449643\n",
      "train loss:2.5554372923074107\n",
      "train loss:2.495437850586112\n",
      "train loss:2.5374771365320608\n",
      "=== epoch:10, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.611114199072814\n",
      "train loss:2.4503897323159975\n",
      "train loss:2.4042903848051638\n",
      "train loss:2.51563191382682\n",
      "=== epoch:11, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5658413546519387\n",
      "train loss:2.450710774761748\n",
      "train loss:2.4833692177213065\n",
      "train loss:2.5236855422398974\n",
      "=== epoch:12, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.43011581974486\n",
      "train loss:2.564472858526892\n",
      "train loss:2.613261165003814\n",
      "train loss:2.414195112521256\n",
      "=== epoch:13, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4651376709310955\n",
      "train loss:2.561127527219494\n",
      "train loss:2.569118455801278\n",
      "train loss:2.6146328945626673\n",
      "=== epoch:14, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.6453683657411027\n",
      "train loss:2.4745754253792662\n",
      "train loss:2.5984855032941034\n",
      "train loss:2.368835265540347\n",
      "=== epoch:15, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4615253227585057\n",
      "train loss:2.5525016912133776\n",
      "train loss:2.415575266082554\n",
      "train loss:2.5281271094029614\n",
      "=== epoch:16, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5262302175094042\n",
      "train loss:2.437737137845516\n",
      "train loss:2.440857374053067\n",
      "train loss:2.4865107529952435\n",
      "=== epoch:17, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4797865958525933\n",
      "train loss:2.4524753421891665\n",
      "train loss:2.432398094771366\n",
      "train loss:2.4499793804218797\n",
      "=== epoch:18, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4652754493403957\n",
      "train loss:2.4937132908630866\n",
      "train loss:2.3833745063719887\n",
      "train loss:2.513983216405074\n",
      "=== epoch:19, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.480780673912871\n",
      "train loss:2.4943367290336838\n",
      "train loss:2.4410473730016853\n",
      "train loss:2.5260113392878765\n",
      "=== epoch:20, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.436398696209929\n",
      "train loss:2.555008853285441\n",
      "train loss:2.4941812519522264\n",
      "train loss:2.4903389335343005\n",
      "=== epoch:21, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4004719071238614\n",
      "train loss:2.4267340891332605\n",
      "train loss:2.4807794928849036\n",
      "train loss:2.5134172461883395\n",
      "=== epoch:22, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.585271894031517\n",
      "train loss:2.5423586004024026\n",
      "train loss:2.4724589351883832\n",
      "train loss:2.5482916956439343\n",
      "=== epoch:23, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.515168296639404\n",
      "train loss:2.406246716236465\n",
      "train loss:2.5363647203307633\n",
      "train loss:2.4197564240132112\n",
      "=== epoch:24, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3664419973308424\n",
      "train loss:2.5003210735752517\n",
      "train loss:2.5087911897861437\n",
      "train loss:2.4174339547734602\n",
      "=== epoch:25, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5670628115330603\n",
      "train loss:2.508372650620183\n",
      "train loss:2.3863813243844203\n",
      "train loss:2.410639823775867\n",
      "=== epoch:26, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.407151772278482\n",
      "train loss:2.541359128728491\n",
      "train loss:2.4292778879823356\n",
      "train loss:2.5711521253647165\n",
      "=== epoch:27, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.609395338394242\n",
      "train loss:2.4250265118895364\n",
      "train loss:2.543184879573933\n",
      "train loss:2.4019442903774286\n",
      "=== epoch:28, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5260179873205724\n",
      "train loss:2.4880126911223694\n",
      "train loss:2.4407241160997715\n",
      "train loss:2.524038745954584\n",
      "=== epoch:29, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.479253756788587\n",
      "train loss:2.4896605846488256\n",
      "train loss:2.5620206526544913\n",
      "train loss:2.554612095801507\n",
      "=== epoch:30, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.46115048753389\n",
      "train loss:2.4828103838302074\n",
      "train loss:2.61211381107667\n",
      "train loss:2.5828435660646325\n",
      "=== epoch:31, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4193541698642975\n",
      "train loss:2.4379152694224913\n",
      "train loss:2.4590640089347224\n",
      "train loss:2.580756869947177\n",
      "=== epoch:32, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4342708844206977\n",
      "train loss:2.4527787995794683\n",
      "train loss:2.494504818711322\n",
      "train loss:2.445831945350781\n",
      "=== epoch:33, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5047816700182373\n",
      "train loss:2.5153321843967875\n",
      "train loss:2.586047199701235\n",
      "train loss:2.444060056522184\n",
      "=== epoch:34, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.530309552553599\n",
      "train loss:2.5037577573575924\n",
      "train loss:2.5323718499389174\n",
      "train loss:2.578865281501007\n",
      "=== epoch:35, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.424417549754086\n",
      "train loss:2.5000304166367515\n",
      "train loss:2.437558770093637\n",
      "train loss:2.461604312093846\n",
      "=== epoch:36, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5973353566610062\n",
      "train loss:2.430281257172569\n",
      "train loss:2.4660225955348274\n",
      "train loss:2.4313974558677476\n",
      "=== epoch:37, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.442018743883253\n",
      "train loss:2.43485272153285\n",
      "train loss:2.522190865669229\n",
      "train loss:2.4239534404046914\n",
      "=== epoch:38, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.3852195392814255\n",
      "train loss:2.4346023849692195\n",
      "train loss:2.587704624042834\n",
      "train loss:2.400165034743365\n",
      "=== epoch:39, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.500902410610793\n",
      "train loss:2.453629935355324\n",
      "train loss:2.442405165952698\n",
      "train loss:2.488608048503697\n",
      "=== epoch:40, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.45927132179656\n",
      "train loss:2.4677247000081457\n",
      "train loss:2.457947293391516\n",
      "train loss:2.5091660923308456\n",
      "=== epoch:41, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.545646122735757\n",
      "train loss:2.580631717911591\n",
      "train loss:2.4516596879097308\n",
      "train loss:2.634067561477244\n",
      "=== epoch:42, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.511085280007632\n",
      "train loss:2.4070408439876183\n",
      "train loss:2.430990403231466\n",
      "train loss:2.4665230081971288\n",
      "=== epoch:43, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4793246658488446\n",
      "train loss:2.441953904539353\n",
      "train loss:2.532240460260989\n",
      "train loss:2.5276004324546997\n",
      "=== epoch:44, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5928105876288745\n",
      "train loss:2.401375901771982\n",
      "train loss:2.461445731811839\n",
      "train loss:2.472023743546757\n",
      "=== epoch:45, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.513334476554255\n",
      "train loss:2.532420226028893\n",
      "train loss:2.5009197770758105\n",
      "train loss:2.5134098465969275\n",
      "=== epoch:46, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5760818001052908\n",
      "train loss:2.5638385026697708\n",
      "train loss:2.6453361324393745\n",
      "train loss:2.4268792820462894\n",
      "=== epoch:47, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.374292071952601\n",
      "train loss:2.3845453272619404\n",
      "train loss:2.4010510599738395\n",
      "train loss:2.472264898160149\n",
      "=== epoch:48, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4195524146154646\n",
      "train loss:2.5187559908639217\n",
      "train loss:2.525147391755921\n",
      "train loss:2.5379422466776367\n",
      "=== epoch:49, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.4633013445084133\n",
      "train loss:2.4146298938508672\n",
      "train loss:2.457803636838081\n",
      "train loss:2.5169640043761077\n",
      "=== epoch:50, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.5426073787883947\n",
      "train loss:2.4353503348506678\n",
      "train loss:2.523326006839848\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.08\n",
      "val_acc: 0.0800 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3727206550537687\n",
      "=== epoch:1, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3926385027441364\n",
      "train loss:2.430721296913539\n",
      "train loss:2.3962206332948135\n",
      "train loss:2.3996433255983614\n",
      "=== epoch:2, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3557502425208154\n",
      "train loss:2.408702462518661\n",
      "train loss:2.4182331023761137\n",
      "train loss:2.424568532894831\n",
      "=== epoch:3, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3848105659326024\n",
      "train loss:2.395293762041452\n",
      "train loss:2.3939261014012487\n",
      "train loss:2.366327433394495\n",
      "=== epoch:4, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.39628965953141\n",
      "train loss:2.422971666255132\n",
      "train loss:2.425617747876755\n",
      "train loss:2.3933203744480074\n",
      "=== epoch:5, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.369527007903672\n",
      "train loss:2.39653656177345\n",
      "train loss:2.4218384106568602\n",
      "train loss:2.422395301749738\n",
      "=== epoch:6, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.379497859476912\n",
      "train loss:2.426473443341329\n",
      "train loss:2.362869877149392\n",
      "train loss:2.421820132550327\n",
      "=== epoch:7, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4315618961015466\n",
      "train loss:2.4155511014698563\n",
      "train loss:2.378740169841436\n",
      "train loss:2.4241501937181664\n",
      "=== epoch:8, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.36184900925234\n",
      "train loss:2.35761839983505\n",
      "train loss:2.4075019472821215\n",
      "train loss:2.433013488168151\n",
      "=== epoch:9, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3926018543729226\n",
      "train loss:2.364724878810976\n",
      "train loss:2.361060239990499\n",
      "train loss:2.3856198926656065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:10, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3500145709960107\n",
      "train loss:2.4070217439162436\n",
      "train loss:2.395688901996333\n",
      "train loss:2.421674344403509\n",
      "=== epoch:11, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3279571882847794\n",
      "train loss:2.317527374323029\n",
      "train loss:2.4181879640844803\n",
      "train loss:2.3654607374462895\n",
      "=== epoch:12, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.388834164072197\n",
      "train loss:2.3875418265620114\n",
      "train loss:2.405633277550907\n",
      "train loss:2.414517556311715\n",
      "=== epoch:13, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.417435589185269\n",
      "train loss:2.430111347842192\n",
      "train loss:2.4654433143030077\n",
      "train loss:2.351592886024409\n",
      "=== epoch:14, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.556725704063258\n",
      "train loss:2.421677685044388\n",
      "train loss:2.3725886178581432\n",
      "train loss:2.3928159156538378\n",
      "=== epoch:15, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.395455382308387\n",
      "train loss:2.4454792678336137\n",
      "train loss:2.517323795794458\n",
      "train loss:2.352276936929677\n",
      "=== epoch:16, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.357858256638724\n",
      "train loss:2.4127263392544935\n",
      "train loss:2.3644084543786126\n",
      "train loss:2.432341787487194\n",
      "=== epoch:17, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4260892174056305\n",
      "train loss:2.424975238994164\n",
      "train loss:2.3630792295539207\n",
      "train loss:2.4148186625937154\n",
      "=== epoch:18, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.385075319955756\n",
      "train loss:2.4237660648941453\n",
      "train loss:2.3741764903183658\n",
      "train loss:2.4315178237583366\n",
      "=== epoch:19, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.386649090541149\n",
      "train loss:2.398725375523361\n",
      "train loss:2.320528210963079\n",
      "train loss:2.4593643255184996\n",
      "=== epoch:20, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.433754699383791\n",
      "train loss:2.4281128675766195\n",
      "train loss:2.3686040511682496\n",
      "train loss:2.4318139409358333\n",
      "=== epoch:21, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3715764709138583\n",
      "train loss:2.4004391700616092\n",
      "train loss:2.350160709658623\n",
      "train loss:2.443848332115901\n",
      "=== epoch:22, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3663617267780395\n",
      "train loss:2.3905598195108895\n",
      "train loss:2.417426126231903\n",
      "train loss:2.4121442524849535\n",
      "=== epoch:23, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.369265160748257\n",
      "train loss:2.4828312941952535\n",
      "train loss:2.4023873878138065\n",
      "train loss:2.427724305994774\n",
      "=== epoch:24, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4092657740909287\n",
      "train loss:2.405699914135257\n",
      "train loss:2.381741681419152\n",
      "train loss:2.412316377373283\n",
      "=== epoch:25, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4487273283624615\n",
      "train loss:2.4069226725989297\n",
      "train loss:2.389700500238194\n",
      "train loss:2.372313051907033\n",
      "=== epoch:26, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4057953419505567\n",
      "train loss:2.4036916868976315\n",
      "train loss:2.36520409048173\n",
      "train loss:2.4176801339567566\n",
      "=== epoch:27, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4011946638527637\n",
      "train loss:2.3369357979415684\n",
      "train loss:2.4057558251151234\n",
      "train loss:2.432974051410073\n",
      "=== epoch:28, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.420269622514586\n",
      "train loss:2.4457247146722865\n",
      "train loss:2.435445020584634\n",
      "train loss:2.356575756485196\n",
      "=== epoch:29, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4164825500105036\n",
      "train loss:2.4416890559899245\n",
      "train loss:2.3682964502301105\n",
      "train loss:2.4240810322387345\n",
      "=== epoch:30, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3885567635305147\n",
      "train loss:2.4629500810914564\n",
      "train loss:2.4520843539979484\n",
      "train loss:2.394857862288831\n",
      "=== epoch:31, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.439545989614945\n",
      "train loss:2.375715582373444\n",
      "train loss:2.41134845134336\n",
      "train loss:2.4866843675036447\n",
      "=== epoch:32, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.376192291865426\n",
      "train loss:2.3658542316370204\n",
      "train loss:2.4112611211538884\n",
      "train loss:2.4263561195641388\n",
      "=== epoch:33, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4558113300637814\n",
      "train loss:2.4084194440954394\n",
      "train loss:2.4601052531823906\n",
      "train loss:2.3960848590147785\n",
      "=== epoch:34, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4143435505294684\n",
      "train loss:2.4286049270125303\n",
      "train loss:2.4186741017802778\n",
      "train loss:2.3984178157903617\n",
      "=== epoch:35, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4840235325210145\n",
      "train loss:2.432105608620317\n",
      "train loss:2.42571861617111\n",
      "train loss:2.457356319324051\n",
      "=== epoch:36, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.354389189819146\n",
      "train loss:2.361315344654471\n",
      "train loss:2.4061436176620945\n",
      "train loss:2.44053048873001\n",
      "=== epoch:37, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4566560878295487\n",
      "train loss:2.3879104102659987\n",
      "train loss:2.383888360134423\n",
      "train loss:2.508250443400622\n",
      "=== epoch:38, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3925870119648196\n",
      "train loss:2.3363642889969003\n",
      "train loss:2.3492118986039934\n",
      "train loss:2.4398317959055436\n",
      "=== epoch:39, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.413827051927608\n",
      "train loss:2.365053481758365\n",
      "train loss:2.428543162025428\n",
      "train loss:2.4171630298165545\n",
      "=== epoch:40, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.4002962962862084\n",
      "train loss:2.4197021970344075\n",
      "train loss:2.47359491510708\n",
      "train loss:2.423576491084714\n",
      "=== epoch:41, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.375894841666033\n",
      "train loss:2.4225471224718533\n",
      "train loss:2.3785801795500694\n",
      "train loss:2.367095171810956\n",
      "=== epoch:42, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3469017024630636\n",
      "train loss:2.4242365608029153\n",
      "train loss:2.367403264895529\n",
      "train loss:2.419046436788359\n",
      "=== epoch:43, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.338279392439858\n",
      "train loss:2.460483382262413\n",
      "train loss:2.3780496068786565\n",
      "train loss:2.3732862628922655\n",
      "=== epoch:44, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3974567771855586\n",
      "train loss:2.39811368919724\n",
      "train loss:2.4236492061808956\n",
      "train loss:2.3949045079438807\n",
      "=== epoch:45, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3761751738386203\n",
      "train loss:2.340468069184206\n",
      "train loss:2.457498863554382\n",
      "train loss:2.3847635008727033\n",
      "=== epoch:46, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.411899261384484\n",
      "train loss:2.348446580657263\n",
      "train loss:2.4450864980596982\n",
      "train loss:2.3990331866776713\n",
      "=== epoch:47, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.3931669031200755\n",
      "train loss:2.3897532142991347\n",
      "train loss:2.407958301980754\n",
      "train loss:2.4154588450323695\n",
      "=== epoch:48, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.356826895994117\n",
      "train loss:2.3947716566478645\n",
      "train loss:2.3754195614601707\n",
      "train loss:2.3726319936837865\n",
      "=== epoch:49, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.407877614895457\n",
      "train loss:2.419010129948526\n",
      "train loss:2.338036167408741\n",
      "train loss:2.3148622688001628\n",
      "=== epoch:50, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.360322878694045\n",
      "train loss:2.4191783209968465\n",
      "train loss:2.398621953161497\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.414752843216734\n",
      "=== epoch:1, train acc:0.1125, test acc:0.1 ===\n",
      "train loss:2.3831742810294103\n",
      "train loss:2.3566407707181836\n",
      "train loss:2.395565481988315\n",
      "train loss:2.3808491899786826\n",
      "=== epoch:2, train acc:0.11, test acc:0.1 ===\n",
      "train loss:2.294837597081903\n",
      "train loss:2.3623910870479166\n",
      "train loss:2.3559812548637153\n",
      "train loss:2.3703194610823894\n",
      "=== epoch:3, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3629597106479774\n",
      "train loss:2.303523162237547\n",
      "train loss:2.3358239303841404\n",
      "train loss:2.31866104651806\n",
      "=== epoch:4, train acc:0.1325, test acc:0.1 ===\n",
      "train loss:2.303375713558913\n",
      "train loss:2.3147821110822435\n",
      "train loss:2.3336797834091603\n",
      "train loss:2.3460393469616774\n",
      "=== epoch:5, train acc:0.13, test acc:0.1 ===\n",
      "train loss:2.2814860958370495\n",
      "train loss:2.362412229525239\n",
      "train loss:2.3033271857812774\n",
      "train loss:2.283895690506516\n",
      "=== epoch:6, train acc:0.135, test acc:0.1 ===\n",
      "train loss:2.3423380707343324\n",
      "train loss:2.287910228215705\n",
      "train loss:2.3158247925260773\n",
      "train loss:2.3128912923283758\n",
      "=== epoch:7, train acc:0.1425, test acc:0.09 ===\n",
      "train loss:2.3467437249598353\n",
      "train loss:2.3612500932054727\n",
      "train loss:2.336258996320344\n",
      "train loss:2.282058035202914\n",
      "=== epoch:8, train acc:0.145, test acc:0.08 ===\n",
      "train loss:2.2838555088540926\n",
      "train loss:2.2850708279393657\n",
      "train loss:2.4120961745067486\n",
      "train loss:2.3092626539120285\n",
      "=== epoch:9, train acc:0.1625, test acc:0.09 ===\n",
      "train loss:2.3476936107658224\n",
      "train loss:2.2953629084327476\n",
      "train loss:2.2811007975960056\n",
      "train loss:2.2726663062993633\n",
      "=== epoch:10, train acc:0.17, test acc:0.11 ===\n",
      "train loss:2.314832911096181\n",
      "train loss:2.344670070633781\n",
      "train loss:2.355398635982677\n",
      "train loss:2.2542763340213776\n",
      "=== epoch:11, train acc:0.17, test acc:0.11 ===\n",
      "train loss:2.275931952698287\n",
      "train loss:2.263636521614065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.281758221087054\n",
      "train loss:2.2642326896300435\n",
      "=== epoch:12, train acc:0.1725, test acc:0.11 ===\n",
      "train loss:2.294551867216452\n",
      "train loss:2.216964718992003\n",
      "train loss:2.2278687471007155\n",
      "train loss:2.283928070777906\n",
      "=== epoch:13, train acc:0.1825, test acc:0.11 ===\n",
      "train loss:2.2698261094067282\n",
      "train loss:2.2821640646275836\n",
      "train loss:2.22078885066176\n",
      "train loss:2.278653430031137\n",
      "=== epoch:14, train acc:0.19, test acc:0.11 ===\n",
      "train loss:2.2166732792756147\n",
      "train loss:2.303620452147321\n",
      "train loss:2.2405753410439604\n",
      "train loss:2.2492492674030373\n",
      "=== epoch:15, train acc:0.195, test acc:0.11 ===\n",
      "train loss:2.274343340642406\n",
      "train loss:2.285027476836923\n",
      "train loss:2.2437268050135257\n",
      "train loss:2.271474614174359\n",
      "=== epoch:16, train acc:0.2025, test acc:0.11 ===\n",
      "train loss:2.214439057982443\n",
      "train loss:2.2612908494931947\n",
      "train loss:2.2909642103060635\n",
      "train loss:2.192179332127351\n",
      "=== epoch:17, train acc:0.2075, test acc:0.12 ===\n",
      "train loss:2.2702413887728463\n",
      "train loss:2.2412915255832173\n",
      "train loss:2.2765041177199348\n",
      "train loss:2.247376569363776\n",
      "=== epoch:18, train acc:0.21, test acc:0.12 ===\n",
      "train loss:2.2696501822646082\n",
      "train loss:2.19436365828329\n",
      "train loss:2.2688442411764176\n",
      "train loss:2.2529328528848853\n",
      "=== epoch:19, train acc:0.21, test acc:0.12 ===\n",
      "train loss:2.2269785983821\n",
      "train loss:2.2843937307868085\n",
      "train loss:2.2426433387624676\n",
      "train loss:2.2322153921173977\n",
      "=== epoch:20, train acc:0.21, test acc:0.13 ===\n",
      "train loss:2.2164240169014833\n",
      "train loss:2.2911379537313934\n",
      "train loss:2.238178649113101\n",
      "train loss:2.1832776812619468\n",
      "=== epoch:21, train acc:0.215, test acc:0.13 ===\n",
      "train loss:2.2758298485286397\n",
      "train loss:2.208266571425736\n",
      "train loss:2.254127872195099\n",
      "train loss:2.2481037458922506\n",
      "=== epoch:22, train acc:0.2125, test acc:0.13 ===\n",
      "train loss:2.2446962935344748\n",
      "train loss:2.220374708813728\n",
      "train loss:2.1926134609661\n",
      "train loss:2.2661968858493036\n",
      "=== epoch:23, train acc:0.2175, test acc:0.13 ===\n",
      "train loss:2.2791849021631627\n",
      "train loss:2.2126744232903848\n",
      "train loss:2.2329149055452597\n",
      "train loss:2.241909073842752\n",
      "=== epoch:24, train acc:0.2175, test acc:0.15 ===\n",
      "train loss:2.2088665740499627\n",
      "train loss:2.2600382625057986\n",
      "train loss:2.240689630281819\n",
      "train loss:2.1904119365173473\n",
      "=== epoch:25, train acc:0.2225, test acc:0.14 ===\n",
      "train loss:2.2154580755753943\n",
      "train loss:2.2036295677837585\n",
      "train loss:2.229102653089354\n",
      "train loss:2.179790995551372\n",
      "=== epoch:26, train acc:0.2225, test acc:0.14 ===\n",
      "train loss:2.13773911312344\n",
      "train loss:2.17215230995384\n",
      "train loss:2.2410012809868247\n",
      "train loss:2.2048967838855815\n",
      "=== epoch:27, train acc:0.225, test acc:0.14 ===\n",
      "train loss:2.197630076384501\n",
      "train loss:2.1661939021988044\n",
      "train loss:2.229767346796211\n",
      "train loss:2.2114455981525967\n",
      "=== epoch:28, train acc:0.2275, test acc:0.14 ===\n",
      "train loss:2.159257789888322\n",
      "train loss:2.172483197593987\n",
      "train loss:2.207221225235143\n",
      "train loss:2.209332736894712\n",
      "=== epoch:29, train acc:0.2325, test acc:0.14 ===\n",
      "train loss:2.1924361559805523\n",
      "train loss:2.20204074818865\n",
      "train loss:2.1873464424309947\n",
      "train loss:2.2304482743596323\n",
      "=== epoch:30, train acc:0.23, test acc:0.14 ===\n",
      "train loss:2.209819061255265\n",
      "train loss:2.230603712511365\n",
      "train loss:2.1859980689792455\n",
      "train loss:2.2168528083780967\n",
      "=== epoch:31, train acc:0.2425, test acc:0.14 ===\n",
      "train loss:2.2186932217146613\n",
      "train loss:2.1895100996258314\n",
      "train loss:2.1668293265060132\n",
      "train loss:2.1050750524796054\n",
      "=== epoch:32, train acc:0.25, test acc:0.14 ===\n",
      "train loss:2.2018170588036488\n",
      "train loss:2.103983026098145\n",
      "train loss:2.181522615512726\n",
      "train loss:2.144780488117677\n",
      "=== epoch:33, train acc:0.255, test acc:0.15 ===\n",
      "train loss:2.196527050733363\n",
      "train loss:2.196597490490015\n",
      "train loss:2.2193374833985424\n",
      "train loss:2.119032159334594\n",
      "=== epoch:34, train acc:0.255, test acc:0.15 ===\n",
      "train loss:2.1594291270766184\n",
      "train loss:2.1867530055993014\n",
      "train loss:2.126514455932306\n",
      "train loss:2.1413493881184125\n",
      "=== epoch:35, train acc:0.2675, test acc:0.15 ===\n",
      "train loss:2.159159522063825\n",
      "train loss:2.132454368642065\n",
      "train loss:2.1415911008664965\n",
      "train loss:2.1305069063391486\n",
      "=== epoch:36, train acc:0.27, test acc:0.15 ===\n",
      "train loss:2.14134305967717\n",
      "train loss:2.2016886040091164\n",
      "train loss:2.1808842667304646\n",
      "train loss:2.169672958385978\n",
      "=== epoch:37, train acc:0.28, test acc:0.15 ===\n",
      "train loss:2.1908024604670735\n",
      "train loss:2.201649298425636\n",
      "train loss:2.1656668432504014\n",
      "train loss:2.1938424033830537\n",
      "=== epoch:38, train acc:0.2775, test acc:0.16 ===\n",
      "train loss:2.1681435593632634\n",
      "train loss:2.1061848586800913\n",
      "train loss:2.167555734528463\n",
      "train loss:2.138728822125163\n",
      "=== epoch:39, train acc:0.28, test acc:0.17 ===\n",
      "train loss:2.1387194872108974\n",
      "train loss:2.105081207359553\n",
      "train loss:2.191993035825488\n",
      "train loss:2.117679121252088\n",
      "=== epoch:40, train acc:0.285, test acc:0.17 ===\n",
      "train loss:2.153967265522849\n",
      "train loss:2.1767365555481937\n",
      "train loss:2.1221884611445967\n",
      "train loss:2.111935290515686\n",
      "=== epoch:41, train acc:0.2875, test acc:0.18 ===\n",
      "train loss:2.1562125197662243\n",
      "train loss:2.1416003018012546\n",
      "train loss:2.1423605526645244\n",
      "train loss:2.121890571230148\n",
      "=== epoch:42, train acc:0.29, test acc:0.18 ===\n",
      "train loss:2.149738234723886\n",
      "train loss:2.1585606362613468\n",
      "train loss:2.1128374744325105\n",
      "train loss:2.0940788214166863\n",
      "=== epoch:43, train acc:0.2925, test acc:0.19 ===\n",
      "train loss:2.135445190097488\n",
      "train loss:2.1425891195358093\n",
      "train loss:2.0663342289806415\n",
      "train loss:2.130668421045213\n",
      "=== epoch:44, train acc:0.3, test acc:0.2 ===\n",
      "train loss:2.188620493387423\n",
      "train loss:2.0967522054556347\n",
      "train loss:2.111289729599426\n",
      "train loss:2.1219678069989283\n",
      "=== epoch:45, train acc:0.3025, test acc:0.22 ===\n",
      "train loss:2.0802501019178106\n",
      "train loss:2.1102715790510875\n",
      "train loss:2.044926743845964\n",
      "train loss:2.0799203441661547\n",
      "=== epoch:46, train acc:0.305, test acc:0.23 ===\n",
      "train loss:2.1360920292130547\n",
      "train loss:2.0506130561941385\n",
      "train loss:2.091497070193289\n",
      "train loss:2.07881125774487\n",
      "=== epoch:47, train acc:0.305, test acc:0.25 ===\n",
      "train loss:2.0849213052771423\n",
      "train loss:2.0813654226012726\n",
      "train loss:2.122254613775513\n",
      "train loss:2.0971005264209372\n",
      "=== epoch:48, train acc:0.31, test acc:0.25 ===\n",
      "train loss:2.126526996739327\n",
      "train loss:2.091966365655963\n",
      "train loss:2.083635704602186\n",
      "train loss:2.116204495875327\n",
      "=== epoch:49, train acc:0.315, test acc:0.25 ===\n",
      "train loss:2.0991844888768476\n",
      "train loss:2.097953010731182\n",
      "train loss:2.0852923134007755\n",
      "train loss:2.0360206466941766\n",
      "=== epoch:50, train acc:0.3175, test acc:0.26 ===\n",
      "train loss:2.1428664801733235\n",
      "train loss:2.1361397409923133\n",
      "train loss:2.0259832548798755\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.26\n",
      "val_acc: 0.2600 | lr: 0.0015, weight_decay: 0.0000\n",
      "train loss:2.269525592545939\n",
      "=== epoch:1, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.296363672460581\n",
      "train loss:2.3060192946492077\n",
      "train loss:2.259353692449432\n",
      "train loss:2.3107183681694035\n",
      "=== epoch:2, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3437936401015773\n",
      "train loss:2.3054460212719268\n",
      "train loss:2.316608025969714\n",
      "train loss:2.337223026777898\n",
      "=== epoch:3, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.280385423551309\n",
      "train loss:2.3285580394820915\n",
      "train loss:2.286499471296936\n",
      "train loss:2.352303360877193\n",
      "=== epoch:4, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.338539127962826\n",
      "train loss:2.2930113460073938\n",
      "train loss:2.272919531073234\n",
      "train loss:2.3543294140794675\n",
      "=== epoch:5, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.308771849890476\n",
      "train loss:2.324231151393175\n",
      "train loss:2.221253094287074\n",
      "train loss:2.306971205062392\n",
      "=== epoch:6, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3012897969536263\n",
      "train loss:2.3229709804471916\n",
      "train loss:2.3033222294302482\n",
      "train loss:2.301862013614378\n",
      "=== epoch:7, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3075225871028135\n",
      "train loss:2.3240288761606727\n",
      "train loss:2.24870340051642\n",
      "train loss:2.314305187930219\n",
      "=== epoch:8, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.317892037636549\n",
      "train loss:2.2897082939402864\n",
      "train loss:2.341620357947265\n",
      "train loss:2.3522698021419854\n",
      "=== epoch:9, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.324667022977235\n",
      "train loss:2.3296722917335413\n",
      "train loss:2.3067472551074215\n",
      "train loss:2.352880343533704\n",
      "=== epoch:10, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.289185582434992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3304408028882895\n",
      "train loss:2.4029571899713\n",
      "train loss:2.33932792178337\n",
      "=== epoch:11, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3039890990258454\n",
      "train loss:2.2789344876815143\n",
      "train loss:2.338022125761878\n",
      "train loss:2.298127983211237\n",
      "=== epoch:12, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.300403338124548\n",
      "train loss:2.2967698808215102\n",
      "train loss:2.337664879359072\n",
      "train loss:2.312712507520201\n",
      "=== epoch:13, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3088663604553505\n",
      "train loss:2.272822931309444\n",
      "train loss:2.2918151323363225\n",
      "train loss:2.28466711093437\n",
      "=== epoch:14, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2742129925047654\n",
      "train loss:2.2921592350256628\n",
      "train loss:2.276504414828666\n",
      "train loss:2.3307021186059633\n",
      "=== epoch:15, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2761543499782793\n",
      "train loss:2.245146783191182\n",
      "train loss:2.380604505305091\n",
      "train loss:2.2898433281606074\n",
      "=== epoch:16, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.304468247491095\n",
      "train loss:2.327450441514961\n",
      "train loss:2.269715405013007\n",
      "train loss:2.2700760263155653\n",
      "=== epoch:17, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.286064668757073\n",
      "train loss:2.3659062487572076\n",
      "train loss:2.2425067970036596\n",
      "train loss:2.3206518687039335\n",
      "=== epoch:18, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3154534211923052\n",
      "train loss:2.347792415125696\n",
      "train loss:2.2833343608696883\n",
      "train loss:2.3304129467483703\n",
      "=== epoch:19, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3146983237712564\n",
      "train loss:2.3224561100147754\n",
      "train loss:2.3138605901939435\n",
      "train loss:2.359915305082506\n",
      "=== epoch:20, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2820326493741163\n",
      "train loss:2.293977817601711\n",
      "train loss:2.347686459263137\n",
      "train loss:2.290924977734012\n",
      "=== epoch:21, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2314315625411867\n",
      "train loss:2.326850419131909\n",
      "train loss:2.2803111073666407\n",
      "train loss:2.293889281680893\n",
      "=== epoch:22, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2770414617567667\n",
      "train loss:2.332345207876467\n",
      "train loss:2.2617325229816956\n",
      "train loss:2.313608701834978\n",
      "=== epoch:23, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.311732288007914\n",
      "train loss:2.341728019556416\n",
      "train loss:2.31905068375996\n",
      "train loss:2.3429889630513325\n",
      "=== epoch:24, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3207524931365078\n",
      "train loss:2.3225741922537573\n",
      "train loss:2.3103028614467833\n",
      "train loss:2.282725237639021\n",
      "=== epoch:25, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.333745036136681\n",
      "train loss:2.260163238932333\n",
      "train loss:2.308983797866989\n",
      "train loss:2.287314335608047\n",
      "=== epoch:26, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2906557373590704\n",
      "train loss:2.2859048971526073\n",
      "train loss:2.323326921878293\n",
      "train loss:2.2859255198257653\n",
      "=== epoch:27, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3445926470450797\n",
      "train loss:2.3562369193220394\n",
      "train loss:2.2863810838084704\n",
      "train loss:2.2199299025671024\n",
      "=== epoch:28, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2803639775994706\n",
      "train loss:2.2410892109436578\n",
      "train loss:2.339832749154338\n",
      "train loss:2.278466070320559\n",
      "=== epoch:29, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.259336019090035\n",
      "train loss:2.2908818976517726\n",
      "train loss:2.224636365925549\n",
      "train loss:2.2846671619228647\n",
      "=== epoch:30, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.292240582634861\n",
      "train loss:2.321574014655955\n",
      "train loss:2.2772538297989198\n",
      "train loss:2.305052907633666\n",
      "=== epoch:31, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3213653725022225\n",
      "train loss:2.3048847306165627\n",
      "train loss:2.2618994914711394\n",
      "train loss:2.302782309127705\n",
      "=== epoch:32, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3051053404366812\n",
      "train loss:2.280561173603594\n",
      "train loss:2.322811608585585\n",
      "train loss:2.3154571927374077\n",
      "=== epoch:33, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2594334114688963\n",
      "train loss:2.3133439143088226\n",
      "train loss:2.3563168734875544\n",
      "train loss:2.3209583406927967\n",
      "=== epoch:34, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3268618916930786\n",
      "train loss:2.28759395201997\n",
      "train loss:2.3106361899297054\n",
      "train loss:2.3047143144228976\n",
      "=== epoch:35, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2820415594273156\n",
      "train loss:2.289656405013798\n",
      "train loss:2.3021606041282427\n",
      "train loss:2.312280974681339\n",
      "=== epoch:36, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3333090698905714\n",
      "train loss:2.3153670647418663\n",
      "train loss:2.297794434395354\n",
      "train loss:2.327390136952701\n",
      "=== epoch:37, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.290374651297608\n",
      "train loss:2.3197628625260323\n",
      "train loss:2.3445899807504134\n",
      "train loss:2.24972573037762\n",
      "=== epoch:38, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3188871932729853\n",
      "train loss:2.2846823877583535\n",
      "train loss:2.279980620620198\n",
      "train loss:2.2464134255010846\n",
      "=== epoch:39, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3109824126000547\n",
      "train loss:2.365422106720639\n",
      "train loss:2.292981539845319\n",
      "train loss:2.2951435260912496\n",
      "=== epoch:40, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.302618874069528\n",
      "train loss:2.2780036817124465\n",
      "train loss:2.354661137123055\n",
      "train loss:2.3299557143793463\n",
      "=== epoch:41, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3232796477680075\n",
      "train loss:2.3301574537358833\n",
      "train loss:2.2959550298754974\n",
      "train loss:2.2945233583603994\n",
      "=== epoch:42, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3184332366700873\n",
      "train loss:2.284872013618967\n",
      "train loss:2.2936876564286828\n",
      "train loss:2.26822823214339\n",
      "=== epoch:43, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2950163508251955\n",
      "train loss:2.3404162946884823\n",
      "train loss:2.2668283165622998\n",
      "train loss:2.2855253165416016\n",
      "=== epoch:44, train acc:0.12, test acc:0.11 ===\n",
      "train loss:2.2236176281099453\n",
      "train loss:2.2840858385167597\n",
      "train loss:2.2950805750554246\n",
      "train loss:2.287263509069982\n",
      "=== epoch:45, train acc:0.12, test acc:0.11 ===\n",
      "train loss:2.3557418238898724\n",
      "train loss:2.2561774678819186\n",
      "train loss:2.294575022749102\n",
      "train loss:2.2737598810396547\n",
      "=== epoch:46, train acc:0.12, test acc:0.11 ===\n",
      "train loss:2.282349872266917\n",
      "train loss:2.2721956764417377\n",
      "train loss:2.2897301488269637\n",
      "train loss:2.3360323750986582\n",
      "=== epoch:47, train acc:0.12, test acc:0.11 ===\n",
      "train loss:2.314916390995277\n",
      "train loss:2.251407307823468\n",
      "train loss:2.286626588504491\n",
      "train loss:2.3432354035712213\n",
      "=== epoch:48, train acc:0.12, test acc:0.11 ===\n",
      "train loss:2.269512644548025\n",
      "train loss:2.335145396581901\n",
      "train loss:2.3007821538302204\n",
      "train loss:2.2981667010999995\n",
      "=== epoch:49, train acc:0.12, test acc:0.11 ===\n",
      "train loss:2.3729824232950056\n",
      "train loss:2.331407192398285\n",
      "train loss:2.32817616709294\n",
      "train loss:2.307519461873551\n",
      "=== epoch:50, train acc:0.12, test acc:0.11 ===\n",
      "train loss:2.2817454317071992\n",
      "train loss:2.2796646115261643\n",
      "train loss:2.300453262178676\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.11\n",
      "val_acc: 0.1100 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.2922028041393427\n",
      "=== epoch:1, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.3007170370570957\n",
      "train loss:2.3721199061250604\n",
      "train loss:2.2484422581631582\n",
      "train loss:2.3111203663705737\n",
      "=== epoch:2, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.3180420705529556\n",
      "train loss:2.2740986963913614\n",
      "train loss:2.2751398782473005\n",
      "train loss:2.2302248708141574\n",
      "=== epoch:3, train acc:0.135, test acc:0.08 ===\n",
      "train loss:2.2706609477330715\n",
      "train loss:2.260019694262184\n",
      "train loss:2.190452626298944\n",
      "train loss:2.24210763201579\n",
      "=== epoch:4, train acc:0.1525, test acc:0.09 ===\n",
      "train loss:2.249216053428021\n",
      "train loss:2.1632683647262025\n",
      "train loss:2.2332608523375845\n",
      "train loss:2.1968061541880273\n",
      "=== epoch:5, train acc:0.18, test acc:0.1 ===\n",
      "train loss:2.1615737117418856\n",
      "train loss:2.1987182316074834\n",
      "train loss:2.172465200171655\n",
      "train loss:2.183705010333487\n",
      "=== epoch:6, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.148912201997413\n",
      "train loss:2.1747333350733538\n",
      "train loss:2.178884929134488\n",
      "train loss:2.158635701044267\n",
      "=== epoch:7, train acc:0.2775, test acc:0.21 ===\n",
      "train loss:2.146309593233762\n",
      "train loss:2.117122422296291\n",
      "train loss:2.118921181655548\n",
      "train loss:2.16551014222115\n",
      "=== epoch:8, train acc:0.3, test acc:0.24 ===\n",
      "train loss:2.1466379181404562\n",
      "train loss:2.0754194488756106\n",
      "train loss:2.0726119334018525\n",
      "train loss:2.0434151137196306\n",
      "=== epoch:9, train acc:0.3175, test acc:0.24 ===\n",
      "train loss:2.073435016072489\n",
      "train loss:2.066970268133433\n",
      "train loss:2.0193562361429116\n",
      "train loss:1.993229697212251\n",
      "=== epoch:10, train acc:0.35, test acc:0.28 ===\n",
      "train loss:2.083348864616438\n",
      "train loss:2.017686064763353\n",
      "train loss:2.03759959406251\n",
      "train loss:2.0532667440168213\n",
      "=== epoch:11, train acc:0.3725, test acc:0.31 ===\n",
      "train loss:2.039152705304391\n",
      "train loss:1.9746544356110294\n",
      "train loss:2.0032848364900926\n",
      "train loss:2.0734040038589483\n",
      "=== epoch:12, train acc:0.39, test acc:0.33 ===\n",
      "train loss:2.047109850018852\n",
      "train loss:2.052391583418532\n",
      "train loss:1.8698123043916426\n",
      "train loss:1.9711526438197033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:13, train acc:0.4, test acc:0.36 ===\n",
      "train loss:1.8707985985576812\n",
      "train loss:1.975397706659533\n",
      "train loss:1.9325925670143775\n",
      "train loss:1.902106180041775\n",
      "=== epoch:14, train acc:0.42, test acc:0.37 ===\n",
      "train loss:1.9389727157496808\n",
      "train loss:1.850747822614085\n",
      "train loss:1.9463960840747712\n",
      "train loss:1.8420998520493415\n",
      "=== epoch:15, train acc:0.4425, test acc:0.42 ===\n",
      "train loss:1.8641804298598\n",
      "train loss:1.7980039888097614\n",
      "train loss:1.7282141710809957\n",
      "train loss:1.7699713845238831\n",
      "=== epoch:16, train acc:0.4825, test acc:0.43 ===\n",
      "train loss:1.761035965252235\n",
      "train loss:1.7336013606075193\n",
      "train loss:1.8584499003092116\n",
      "train loss:1.8031260187887792\n",
      "=== epoch:17, train acc:0.49, test acc:0.47 ===\n",
      "train loss:1.708632530106682\n",
      "train loss:1.7550047120867625\n",
      "train loss:1.8053537907221782\n",
      "train loss:1.7425797019416425\n",
      "=== epoch:18, train acc:0.5075, test acc:0.5 ===\n",
      "train loss:1.7292410822333435\n",
      "train loss:1.7444943792393381\n",
      "train loss:1.7877401905721235\n",
      "train loss:1.7550989851377843\n",
      "=== epoch:19, train acc:0.5725, test acc:0.56 ===\n",
      "train loss:1.7071868183151238\n",
      "train loss:1.7211453447555\n",
      "train loss:1.581456261664631\n",
      "train loss:1.634422061311112\n",
      "=== epoch:20, train acc:0.595, test acc:0.6 ===\n",
      "train loss:1.6558557555999311\n",
      "train loss:1.6389448063000305\n",
      "train loss:1.5967401669889683\n",
      "train loss:1.6334187971459007\n",
      "=== epoch:21, train acc:0.6475, test acc:0.64 ===\n",
      "train loss:1.6770610415915006\n",
      "train loss:1.5761494781152408\n",
      "train loss:1.5662337690442512\n",
      "train loss:1.4463990954961756\n",
      "=== epoch:22, train acc:0.655, test acc:0.67 ===\n",
      "train loss:1.4029972350396822\n",
      "train loss:1.483678835267363\n",
      "train loss:1.4519340682714148\n",
      "train loss:1.4218933639886748\n",
      "=== epoch:23, train acc:0.66, test acc:0.63 ===\n",
      "train loss:1.4092165214235297\n",
      "train loss:1.4639662679384378\n",
      "train loss:1.4096116968719115\n",
      "train loss:1.4707449228651963\n",
      "=== epoch:24, train acc:0.7025, test acc:0.66 ===\n",
      "train loss:1.4518550945313962\n",
      "train loss:1.4776234764276979\n",
      "train loss:1.328936246996936\n",
      "train loss:1.3549201781474018\n",
      "=== epoch:25, train acc:0.73, test acc:0.7 ===\n",
      "train loss:1.3890269176518764\n",
      "train loss:1.3936562871066285\n",
      "train loss:1.3194621105007325\n",
      "train loss:1.300554939866698\n",
      "=== epoch:26, train acc:0.7325, test acc:0.64 ===\n",
      "train loss:1.2951051265083382\n",
      "train loss:1.2952386959092606\n",
      "train loss:1.243348485962014\n",
      "train loss:1.2429816594055059\n",
      "=== epoch:27, train acc:0.7525, test acc:0.68 ===\n",
      "train loss:1.167500633359557\n",
      "train loss:1.0973547913635289\n",
      "train loss:1.3375126429080808\n",
      "train loss:1.189301730286029\n",
      "=== epoch:28, train acc:0.7725, test acc:0.69 ===\n",
      "train loss:1.1569087684739592\n",
      "train loss:1.0832956364225967\n",
      "train loss:1.1242942619471503\n",
      "train loss:1.1765430380821145\n",
      "=== epoch:29, train acc:0.79, test acc:0.72 ===\n",
      "train loss:1.1180534355077187\n",
      "train loss:1.1263773069095369\n",
      "train loss:1.1423277662421047\n",
      "train loss:1.0878905811681843\n",
      "=== epoch:30, train acc:0.795, test acc:0.7 ===\n",
      "train loss:1.0898541315056929\n",
      "train loss:1.1282774681576793\n",
      "train loss:1.0506304156180468\n",
      "train loss:1.025954991893251\n",
      "=== epoch:31, train acc:0.795, test acc:0.72 ===\n",
      "train loss:0.9799550057467057\n",
      "train loss:0.9249186178732496\n",
      "train loss:1.0197072295023073\n",
      "train loss:1.0022850244477628\n",
      "=== epoch:32, train acc:0.8075, test acc:0.76 ===\n",
      "train loss:0.9332737348997278\n",
      "train loss:0.9590142367123438\n",
      "train loss:0.9894421187453356\n",
      "train loss:0.9142341560357226\n",
      "=== epoch:33, train acc:0.83, test acc:0.75 ===\n",
      "train loss:0.8034383118405168\n",
      "train loss:0.9698595036077685\n",
      "train loss:0.8587690284234089\n",
      "train loss:0.8990505147092146\n",
      "=== epoch:34, train acc:0.8425, test acc:0.78 ===\n",
      "train loss:0.8629606519368445\n",
      "train loss:0.8383789132704371\n",
      "train loss:0.8451138065750122\n",
      "train loss:0.8278376887759057\n",
      "=== epoch:35, train acc:0.835, test acc:0.8 ===\n",
      "train loss:0.8307724141767427\n",
      "train loss:0.8516426929612559\n",
      "train loss:0.8370014867774273\n",
      "train loss:0.7627985862354705\n",
      "=== epoch:36, train acc:0.8425, test acc:0.77 ===\n",
      "train loss:0.85372965390247\n",
      "train loss:0.8448555873991291\n",
      "train loss:0.7803655543787076\n",
      "train loss:0.747691788494745\n",
      "=== epoch:37, train acc:0.845, test acc:0.79 ===\n",
      "train loss:0.8335691739779686\n",
      "train loss:0.8196178598910705\n",
      "train loss:0.6879496355182705\n",
      "train loss:0.709219854808153\n",
      "=== epoch:38, train acc:0.8575, test acc:0.8 ===\n",
      "train loss:0.8425368199997012\n",
      "train loss:0.7280705920416373\n",
      "train loss:0.6269844004373424\n",
      "train loss:0.6350151818802592\n",
      "=== epoch:39, train acc:0.86, test acc:0.77 ===\n",
      "train loss:0.7301601716341188\n",
      "train loss:0.793820954573127\n",
      "train loss:0.6381269125616841\n",
      "train loss:0.7118853599097598\n",
      "=== epoch:40, train acc:0.855, test acc:0.81 ===\n",
      "train loss:0.6278796198188755\n",
      "train loss:0.6868618396857854\n",
      "train loss:0.7532844970755812\n",
      "train loss:0.7065828631827424\n",
      "=== epoch:41, train acc:0.8475, test acc:0.77 ===\n",
      "train loss:0.5850105885295954\n",
      "train loss:0.5926213143757334\n",
      "train loss:0.7374776140883144\n",
      "train loss:0.6551138902999304\n",
      "=== epoch:42, train acc:0.88, test acc:0.82 ===\n",
      "train loss:0.6026600796282859\n",
      "train loss:0.6014015012727868\n",
      "train loss:0.587603588399435\n",
      "train loss:0.5940162903978577\n",
      "=== epoch:43, train acc:0.875, test acc:0.83 ===\n",
      "train loss:0.533355504296156\n",
      "train loss:0.5850861369056376\n",
      "train loss:0.6485331483607369\n",
      "train loss:0.5929226614192934\n",
      "=== epoch:44, train acc:0.8925, test acc:0.84 ===\n",
      "train loss:0.5642379138129322\n",
      "train loss:0.6432971366095074\n",
      "train loss:0.7019682885659966\n",
      "train loss:0.5731005420025771\n",
      "=== epoch:45, train acc:0.8875, test acc:0.83 ===\n",
      "train loss:0.5092276426260293\n",
      "train loss:0.48498992442850913\n",
      "train loss:0.5964055666870643\n",
      "train loss:0.612888122701921\n",
      "=== epoch:46, train acc:0.89, test acc:0.84 ===\n",
      "train loss:0.5252274494965998\n",
      "train loss:0.4557630687751199\n",
      "train loss:0.5126155605129444\n",
      "train loss:0.5733291534962525\n",
      "=== epoch:47, train acc:0.905, test acc:0.84 ===\n",
      "train loss:0.7142786702058085\n",
      "train loss:0.5045907991600729\n",
      "train loss:0.5718531295024195\n",
      "train loss:0.40414362133314585\n",
      "=== epoch:48, train acc:0.905, test acc:0.83 ===\n",
      "train loss:0.4407095727385097\n",
      "train loss:0.5287809693385783\n",
      "train loss:0.4264448368799968\n",
      "train loss:0.5666870682274296\n",
      "=== epoch:49, train acc:0.905, test acc:0.85 ===\n",
      "train loss:0.5307104868511399\n",
      "train loss:0.5507936459490211\n",
      "train loss:0.4389836353753198\n",
      "train loss:0.4067853546397359\n",
      "=== epoch:50, train acc:0.9025, test acc:0.85 ===\n",
      "train loss:0.4687055338314719\n",
      "train loss:0.4858771426921066\n",
      "train loss:0.41272812524651065\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.84\n",
      "val_acc: 0.8500 | lr: 0.0073, weight_decay: 0.0000\n",
      "train loss:2.31991803094585\n",
      "=== epoch:1, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.414757135122808\n",
      "train loss:2.311835947483588\n",
      "train loss:2.3562081620495627\n",
      "train loss:2.418702578834039\n",
      "=== epoch:2, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.354764420556153\n",
      "train loss:2.330628843537395\n",
      "train loss:2.3303951986791547\n",
      "train loss:2.3327927261371113\n",
      "=== epoch:3, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3365146411833284\n",
      "train loss:2.291623538288673\n",
      "train loss:2.3035234433034883\n",
      "train loss:2.3777074028799867\n",
      "=== epoch:4, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.3502308377560026\n",
      "train loss:2.3393277926861415\n",
      "train loss:2.31085678892351\n",
      "train loss:2.3357353180740064\n",
      "=== epoch:5, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.366181813126625\n",
      "train loss:2.276384057252281\n",
      "train loss:2.307670497381501\n",
      "train loss:2.3691446296918137\n",
      "=== epoch:6, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.3575128803929215\n",
      "train loss:2.2849236420155044\n",
      "train loss:2.30387137629402\n",
      "train loss:2.315281825962224\n",
      "=== epoch:7, train acc:0.11, test acc:0.1 ===\n",
      "train loss:2.27091917811989\n",
      "train loss:2.2770461863873024\n",
      "train loss:2.2807566674455417\n",
      "train loss:2.28836193132378\n",
      "=== epoch:8, train acc:0.1125, test acc:0.1 ===\n",
      "train loss:2.2588069888033973\n",
      "train loss:2.247254811254871\n",
      "train loss:2.2821867829866456\n",
      "train loss:2.266393303629912\n",
      "=== epoch:9, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.35152070957886\n",
      "train loss:2.2633475038752184\n",
      "train loss:2.272289211858619\n",
      "train loss:2.312115398789863\n",
      "=== epoch:10, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.245415862504228\n",
      "train loss:2.2528766716206357\n",
      "train loss:2.26151159508438\n",
      "train loss:2.2618768358823274\n",
      "=== epoch:11, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.3150961183872942\n",
      "train loss:2.2850600503157175\n",
      "train loss:2.312820223755454\n",
      "train loss:2.27561512411941\n",
      "=== epoch:12, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.255395649720147\n",
      "train loss:2.2774351848110537\n",
      "train loss:2.3130176335710746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.259398167206915\n",
      "=== epoch:13, train acc:0.1275, test acc:0.11 ===\n",
      "train loss:2.23985942906556\n",
      "train loss:2.281531551495737\n",
      "train loss:2.250208190697655\n",
      "train loss:2.210096514494382\n",
      "=== epoch:14, train acc:0.1325, test acc:0.11 ===\n",
      "train loss:2.267867747416316\n",
      "train loss:2.2805207637821043\n",
      "train loss:2.2161365213385285\n",
      "train loss:2.2562800322790686\n",
      "=== epoch:15, train acc:0.1325, test acc:0.11 ===\n",
      "train loss:2.234081298314652\n",
      "train loss:2.2494584004163456\n",
      "train loss:2.1988783823099216\n",
      "train loss:2.2283093610502367\n",
      "=== epoch:16, train acc:0.1375, test acc:0.12 ===\n",
      "train loss:2.2575439928850103\n",
      "train loss:2.2770818761748033\n",
      "train loss:2.22194875873565\n",
      "train loss:2.212779478937693\n",
      "=== epoch:17, train acc:0.14, test acc:0.12 ===\n",
      "train loss:2.27255172936992\n",
      "train loss:2.2734488205793206\n",
      "train loss:2.280165789629315\n",
      "train loss:2.2505028828790654\n",
      "=== epoch:18, train acc:0.1475, test acc:0.13 ===\n",
      "train loss:2.2540161754323655\n",
      "train loss:2.1553244308488413\n",
      "train loss:2.211526329641534\n",
      "train loss:2.2470209805318477\n",
      "=== epoch:19, train acc:0.1525, test acc:0.14 ===\n",
      "train loss:2.259116292222434\n",
      "train loss:2.20675465577765\n",
      "train loss:2.2455524374278135\n",
      "train loss:2.2577801969625324\n",
      "=== epoch:20, train acc:0.1475, test acc:0.15 ===\n",
      "train loss:2.2046980929651596\n",
      "train loss:2.211459013260807\n",
      "train loss:2.2173385518667508\n",
      "train loss:2.2592150087041394\n",
      "=== epoch:21, train acc:0.145, test acc:0.16 ===\n",
      "train loss:2.191696954776528\n",
      "train loss:2.173136553234825\n",
      "train loss:2.1865707166152757\n",
      "train loss:2.2433201587215277\n",
      "=== epoch:22, train acc:0.155, test acc:0.17 ===\n",
      "train loss:2.2508674073919823\n",
      "train loss:2.2808138726222436\n",
      "train loss:2.170480363165838\n",
      "train loss:2.2505715879610353\n",
      "=== epoch:23, train acc:0.1675, test acc:0.22 ===\n",
      "train loss:2.190632107872096\n",
      "train loss:2.1825842813421645\n",
      "train loss:2.2368426851883667\n",
      "train loss:2.1956217252027797\n",
      "=== epoch:24, train acc:0.175, test acc:0.23 ===\n",
      "train loss:2.18170304928837\n",
      "train loss:2.2202236859000952\n",
      "train loss:2.185512732592584\n",
      "train loss:2.1717437107593094\n",
      "=== epoch:25, train acc:0.185, test acc:0.23 ===\n",
      "train loss:2.2279940188694023\n",
      "train loss:2.2102074511422516\n",
      "train loss:2.1869143669336064\n",
      "train loss:2.160787898771591\n",
      "=== epoch:26, train acc:0.1925, test acc:0.23 ===\n",
      "train loss:2.2018855123926606\n",
      "train loss:2.196392344290598\n",
      "train loss:2.205022239059996\n",
      "train loss:2.158847501982906\n",
      "=== epoch:27, train acc:0.2075, test acc:0.24 ===\n",
      "train loss:2.1601197101692606\n",
      "train loss:2.2170042975477977\n",
      "train loss:2.2037509027268225\n",
      "train loss:2.186838182447375\n",
      "=== epoch:28, train acc:0.2125, test acc:0.24 ===\n",
      "train loss:2.155295714647102\n",
      "train loss:2.1904131133402376\n",
      "train loss:2.1790026548186123\n",
      "train loss:2.1687152113679677\n",
      "=== epoch:29, train acc:0.2275, test acc:0.25 ===\n",
      "train loss:2.174810983279748\n",
      "train loss:2.1902816960129003\n",
      "train loss:2.211438097291636\n",
      "train loss:2.193197561455949\n",
      "=== epoch:30, train acc:0.2475, test acc:0.25 ===\n",
      "train loss:2.156515369591028\n",
      "train loss:2.198685410152832\n",
      "train loss:2.1990115218332975\n",
      "train loss:2.1634572260641227\n",
      "=== epoch:31, train acc:0.26, test acc:0.27 ===\n",
      "train loss:2.200107201220418\n",
      "train loss:2.1657603199499618\n",
      "train loss:2.1538315188494237\n",
      "train loss:2.1204723514627526\n",
      "=== epoch:32, train acc:0.2625, test acc:0.29 ===\n",
      "train loss:2.1751294517777358\n",
      "train loss:2.2099743706203268\n",
      "train loss:2.0943852287273046\n",
      "train loss:2.168734562971438\n",
      "=== epoch:33, train acc:0.27, test acc:0.29 ===\n",
      "train loss:2.1670513058356113\n",
      "train loss:2.1791459130486253\n",
      "train loss:2.1343410738235384\n",
      "train loss:2.1716708033826224\n",
      "=== epoch:34, train acc:0.275, test acc:0.3 ===\n",
      "train loss:2.1068519612078584\n",
      "train loss:2.1659113661449245\n",
      "train loss:2.092489297273756\n",
      "train loss:2.147620344471406\n",
      "=== epoch:35, train acc:0.285, test acc:0.3 ===\n",
      "train loss:2.158862182523041\n",
      "train loss:2.1238072281696345\n",
      "train loss:2.147420635887212\n",
      "train loss:2.1488705009690334\n",
      "=== epoch:36, train acc:0.29, test acc:0.32 ===\n",
      "train loss:2.0981461753659976\n",
      "train loss:2.179981164741498\n",
      "train loss:2.120252916705728\n",
      "train loss:2.1239675276286603\n",
      "=== epoch:37, train acc:0.295, test acc:0.33 ===\n",
      "train loss:2.0946257394417067\n",
      "train loss:2.134280674763227\n",
      "train loss:2.0929482001057274\n",
      "train loss:2.1323645874449175\n",
      "=== epoch:38, train acc:0.2925, test acc:0.33 ===\n",
      "train loss:2.1466596126856805\n",
      "train loss:2.1022511639193158\n",
      "train loss:2.1014263765845262\n",
      "train loss:2.0786576668227\n",
      "=== epoch:39, train acc:0.295, test acc:0.34 ===\n",
      "train loss:2.1085716520371194\n",
      "train loss:2.0974888837020327\n",
      "train loss:2.119679314751075\n",
      "train loss:2.0942483649424335\n",
      "=== epoch:40, train acc:0.295, test acc:0.35 ===\n",
      "train loss:2.151814485157087\n",
      "train loss:2.128018768672624\n",
      "train loss:2.104841796050929\n",
      "train loss:2.118442250407865\n",
      "=== epoch:41, train acc:0.3025, test acc:0.35 ===\n",
      "train loss:2.0941403522407884\n",
      "train loss:2.1424111186322627\n",
      "train loss:2.1804653888785146\n",
      "train loss:2.086423455510932\n",
      "=== epoch:42, train acc:0.32, test acc:0.36 ===\n",
      "train loss:2.143874201721844\n",
      "train loss:2.1318795550458662\n",
      "train loss:2.082670107421846\n",
      "train loss:2.117271315418552\n",
      "=== epoch:43, train acc:0.325, test acc:0.35 ===\n",
      "train loss:2.11433993122839\n",
      "train loss:2.1443878637750924\n",
      "train loss:2.110973478394539\n",
      "train loss:2.1362763023724756\n",
      "=== epoch:44, train acc:0.3225, test acc:0.36 ===\n",
      "train loss:2.1038248566240445\n",
      "train loss:2.113276878127603\n",
      "train loss:2.1092146008099983\n",
      "train loss:2.0817714826411113\n",
      "=== epoch:45, train acc:0.3275, test acc:0.36 ===\n",
      "train loss:2.075959485117171\n",
      "train loss:2.12355070928996\n",
      "train loss:2.0676884737596697\n",
      "train loss:2.078859330731544\n",
      "=== epoch:46, train acc:0.33, test acc:0.37 ===\n",
      "train loss:2.0861346135056555\n",
      "train loss:2.045586130488492\n",
      "train loss:2.0660775469435926\n",
      "train loss:2.0461149130732714\n",
      "=== epoch:47, train acc:0.3375, test acc:0.37 ===\n",
      "train loss:2.026347234242546\n",
      "train loss:2.0778174001975622\n",
      "train loss:2.0968200691040675\n",
      "train loss:2.082404746655164\n",
      "=== epoch:48, train acc:0.3475, test acc:0.36 ===\n",
      "train loss:2.1027645529806818\n",
      "train loss:2.145070820869765\n",
      "train loss:2.0052167924038824\n",
      "train loss:2.008659449832792\n",
      "=== epoch:49, train acc:0.3625, test acc:0.38 ===\n",
      "train loss:1.9982785964826124\n",
      "train loss:2.040426567346019\n",
      "train loss:2.0424056188813116\n",
      "train loss:1.9969752421652929\n",
      "=== epoch:50, train acc:0.3675, test acc:0.37 ===\n",
      "train loss:2.0541906156120167\n",
      "train loss:2.05340274907967\n",
      "train loss:2.0763652930503604\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.38\n",
      "val_acc: 0.3700 | lr: 0.0019, weight_decay: 0.0000\n",
      "train loss:2.3247271796400413\n",
      "=== epoch:1, train acc:0.095, test acc:0.11 ===\n",
      "train loss:2.378436786245455\n",
      "train loss:2.2701272689808443\n",
      "train loss:2.370469445241655\n",
      "train loss:2.322085265663807\n",
      "=== epoch:2, train acc:0.095, test acc:0.11 ===\n",
      "train loss:2.336587215979826\n",
      "train loss:2.3689001163107863\n",
      "train loss:2.3650195124449254\n",
      "train loss:2.3017423999575075\n",
      "=== epoch:3, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.3906765943305457\n",
      "train loss:2.3227446284646556\n",
      "train loss:2.277372743067459\n",
      "train loss:2.352717387875971\n",
      "=== epoch:4, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.392079091516909\n",
      "train loss:2.3473014153298197\n",
      "train loss:2.3922880985340136\n",
      "train loss:2.375137742061075\n",
      "=== epoch:5, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.315504707600968\n",
      "train loss:2.373228857567351\n",
      "train loss:2.4230233938732058\n",
      "train loss:2.281498840804212\n",
      "=== epoch:6, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.411922626481523\n",
      "train loss:2.3011695017185416\n",
      "train loss:2.354018588915484\n",
      "train loss:2.3288044097922036\n",
      "=== epoch:7, train acc:0.0975, test acc:0.11 ===\n",
      "train loss:2.289440059938223\n",
      "train loss:2.3673212475682917\n",
      "train loss:2.358035689624273\n",
      "train loss:2.322339680587757\n",
      "=== epoch:8, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.320137654420554\n",
      "train loss:2.331436286821068\n",
      "train loss:2.3467210176009066\n",
      "train loss:2.4565385840432925\n",
      "=== epoch:9, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.363489692559808\n",
      "train loss:2.3214725676779953\n",
      "train loss:2.3600384971898825\n",
      "train loss:2.3963124098401374\n",
      "=== epoch:10, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.270528015415993\n",
      "train loss:2.328730819763348\n",
      "train loss:2.338452575501653\n",
      "train loss:2.368611740852644\n",
      "=== epoch:11, train acc:0.1025, test acc:0.12 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3642227817717596\n",
      "train loss:2.2103453056062445\n",
      "train loss:2.399749758160512\n",
      "train loss:2.344852129638858\n",
      "=== epoch:12, train acc:0.11, test acc:0.12 ===\n",
      "train loss:2.3548976651768503\n",
      "train loss:2.237575309178991\n",
      "train loss:2.327178190378724\n",
      "train loss:2.354562124048573\n",
      "=== epoch:13, train acc:0.11, test acc:0.12 ===\n",
      "train loss:2.299810202421917\n",
      "train loss:2.3376628294184485\n",
      "train loss:2.4006567897606947\n",
      "train loss:2.2900938335199985\n",
      "=== epoch:14, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.3908311399725752\n",
      "train loss:2.326282234059729\n",
      "train loss:2.386508234803516\n",
      "train loss:2.353657958223464\n",
      "=== epoch:15, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.2506046689321426\n",
      "train loss:2.3401898399662\n",
      "train loss:2.3590795031038305\n",
      "train loss:2.2813297050554793\n",
      "=== epoch:16, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.307012595469476\n",
      "train loss:2.2916472901505216\n",
      "train loss:2.276767380860936\n",
      "train loss:2.3530007009785763\n",
      "=== epoch:17, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.2874708048766523\n",
      "train loss:2.4098528736141787\n",
      "train loss:2.336417068779694\n",
      "train loss:2.377933882750765\n",
      "=== epoch:18, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.3148420404284638\n",
      "train loss:2.311293918444012\n",
      "train loss:2.4078680199585074\n",
      "train loss:2.288683085201433\n",
      "=== epoch:19, train acc:0.12, test acc:0.13 ===\n",
      "train loss:2.2963998364050995\n",
      "train loss:2.3054331179448093\n",
      "train loss:2.319891083196084\n",
      "train loss:2.32370519667907\n",
      "=== epoch:20, train acc:0.1225, test acc:0.13 ===\n",
      "train loss:2.4067739204767133\n",
      "train loss:2.2958778761805765\n",
      "train loss:2.367133313191604\n",
      "train loss:2.2812455823236584\n",
      "=== epoch:21, train acc:0.125, test acc:0.13 ===\n",
      "train loss:2.2792783268745924\n",
      "train loss:2.308705395653278\n",
      "train loss:2.326665363450411\n",
      "train loss:2.288878542687523\n",
      "=== epoch:22, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3289684024761614\n",
      "train loss:2.267370109008122\n",
      "train loss:2.3301424171246508\n",
      "train loss:2.240493763352259\n",
      "=== epoch:23, train acc:0.1325, test acc:0.13 ===\n",
      "train loss:2.369744423096398\n",
      "train loss:2.3674282556518125\n",
      "train loss:2.348386147604046\n",
      "train loss:2.36056298860304\n",
      "=== epoch:24, train acc:0.135, test acc:0.13 ===\n",
      "train loss:2.2555365794285525\n",
      "train loss:2.3111216050390118\n",
      "train loss:2.2998706642411006\n",
      "train loss:2.3196634520585655\n",
      "=== epoch:25, train acc:0.1375, test acc:0.13 ===\n",
      "train loss:2.2630510028333317\n",
      "train loss:2.2906181854295533\n",
      "train loss:2.2302623579310636\n",
      "train loss:2.328711319606022\n",
      "=== epoch:26, train acc:0.14, test acc:0.13 ===\n",
      "train loss:2.323212031420988\n",
      "train loss:2.3006449135944034\n",
      "train loss:2.294870326503946\n",
      "train loss:2.329209885445517\n",
      "=== epoch:27, train acc:0.1425, test acc:0.13 ===\n",
      "train loss:2.2222154872928495\n",
      "train loss:2.2679549395607426\n",
      "train loss:2.1864113226970217\n",
      "train loss:2.37931210701817\n",
      "=== epoch:28, train acc:0.15, test acc:0.13 ===\n",
      "train loss:2.326142530899386\n",
      "train loss:2.28409581073091\n",
      "train loss:2.2785308848412433\n",
      "train loss:2.3132522092876746\n",
      "=== epoch:29, train acc:0.15, test acc:0.13 ===\n",
      "train loss:2.2668783224800855\n",
      "train loss:2.283466903851868\n",
      "train loss:2.2752614215077873\n",
      "train loss:2.300513723009303\n",
      "=== epoch:30, train acc:0.15, test acc:0.13 ===\n",
      "train loss:2.2709954948465105\n",
      "train loss:2.351644792114519\n",
      "train loss:2.275907571604015\n",
      "train loss:2.300565847306972\n",
      "=== epoch:31, train acc:0.15, test acc:0.13 ===\n",
      "train loss:2.2418854325068986\n",
      "train loss:2.2999334035707637\n",
      "train loss:2.2338226277046225\n",
      "train loss:2.2319102984726893\n",
      "=== epoch:32, train acc:0.15, test acc:0.13 ===\n",
      "train loss:2.2787629976956296\n",
      "train loss:2.310480370224988\n",
      "train loss:2.3539242506202274\n",
      "train loss:2.3029974101630457\n",
      "=== epoch:33, train acc:0.1525, test acc:0.13 ===\n",
      "train loss:2.3330461935590443\n",
      "train loss:2.217822624342789\n",
      "train loss:2.267083157490082\n",
      "train loss:2.3140228581430526\n",
      "=== epoch:34, train acc:0.1525, test acc:0.13 ===\n",
      "train loss:2.257275089694323\n",
      "train loss:2.316797685014272\n",
      "train loss:2.2780896845501317\n",
      "train loss:2.3022351862218646\n",
      "=== epoch:35, train acc:0.1525, test acc:0.13 ===\n",
      "train loss:2.331054510082359\n",
      "train loss:2.2424817222616222\n",
      "train loss:2.246903595185348\n",
      "train loss:2.263304781721719\n",
      "=== epoch:36, train acc:0.155, test acc:0.13 ===\n",
      "train loss:2.3362662960985876\n",
      "train loss:2.2681553312601155\n",
      "train loss:2.2673662208845604\n",
      "train loss:2.3227553077308416\n",
      "=== epoch:37, train acc:0.155, test acc:0.13 ===\n",
      "train loss:2.294441026525504\n",
      "train loss:2.3301643670231265\n",
      "train loss:2.2437791116892365\n",
      "train loss:2.215864399370761\n",
      "=== epoch:38, train acc:0.155, test acc:0.13 ===\n",
      "train loss:2.319395104552889\n",
      "train loss:2.257668699025875\n",
      "train loss:2.336085471257741\n",
      "train loss:2.274337042184541\n",
      "=== epoch:39, train acc:0.1575, test acc:0.13 ===\n",
      "train loss:2.2641799774526272\n",
      "train loss:2.269529135724914\n",
      "train loss:2.3177797443986377\n",
      "train loss:2.2337453566309717\n",
      "=== epoch:40, train acc:0.16, test acc:0.13 ===\n",
      "train loss:2.335807037166423\n",
      "train loss:2.3551250974263627\n",
      "train loss:2.283109945743887\n",
      "train loss:2.257276162772853\n",
      "=== epoch:41, train acc:0.16, test acc:0.13 ===\n",
      "train loss:2.297777081617057\n",
      "train loss:2.2574429634077595\n",
      "train loss:2.3142408198565163\n",
      "train loss:2.2670251550861136\n",
      "=== epoch:42, train acc:0.16, test acc:0.13 ===\n",
      "train loss:2.1743743006506904\n",
      "train loss:2.2710597282766103\n",
      "train loss:2.2637345787481715\n",
      "train loss:2.1948182374566003\n",
      "=== epoch:43, train acc:0.16, test acc:0.13 ===\n",
      "train loss:2.407017299604171\n",
      "train loss:2.2825575337289155\n",
      "train loss:2.2563453669803337\n",
      "train loss:2.253071430542359\n",
      "=== epoch:44, train acc:0.16, test acc:0.13 ===\n",
      "train loss:2.236799772664125\n",
      "train loss:2.2642165044853884\n",
      "train loss:2.222016248953964\n",
      "train loss:2.2307452383005657\n",
      "=== epoch:45, train acc:0.165, test acc:0.13 ===\n",
      "train loss:2.265121454176326\n",
      "train loss:2.2745366452262052\n",
      "train loss:2.2610355074646855\n",
      "train loss:2.3041154743279213\n",
      "=== epoch:46, train acc:0.1675, test acc:0.13 ===\n",
      "train loss:2.2529576079982307\n",
      "train loss:2.217600085918003\n",
      "train loss:2.2623126297945495\n",
      "train loss:2.2513884818238834\n",
      "=== epoch:47, train acc:0.17, test acc:0.13 ===\n",
      "train loss:2.230275905144027\n",
      "train loss:2.3155529167152706\n",
      "train loss:2.246632000954151\n",
      "train loss:2.2226876660200348\n",
      "=== epoch:48, train acc:0.17, test acc:0.13 ===\n",
      "train loss:2.1463295869840504\n",
      "train loss:2.272918070685996\n",
      "train loss:2.208485081792736\n",
      "train loss:2.222451332721665\n",
      "=== epoch:49, train acc:0.1725, test acc:0.13 ===\n",
      "train loss:2.2967877429422177\n",
      "train loss:2.2430658647587993\n",
      "train loss:2.2714282747277137\n",
      "train loss:2.24391748305506\n",
      "=== epoch:50, train acc:0.1725, test acc:0.13 ===\n",
      "train loss:2.1418215799683695\n",
      "train loss:2.2014604829327924\n",
      "train loss:2.2123527461419035\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.13\n",
      "val_acc: 0.1300 | lr: 0.0003, weight_decay: 0.0000\n",
      "train loss:2.368207040522736\n",
      "=== epoch:1, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3513514129016597\n",
      "train loss:2.398739383047166\n",
      "train loss:2.3813108762046706\n",
      "train loss:2.357397938344418\n",
      "=== epoch:2, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.4063467837256054\n",
      "train loss:2.4115255861697573\n",
      "train loss:2.325470625244924\n",
      "train loss:2.3742041526556417\n",
      "=== epoch:3, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.409875423728749\n",
      "train loss:2.4047035941200057\n",
      "train loss:2.3797539136110597\n",
      "train loss:2.4155495240750846\n",
      "=== epoch:4, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3995887651226284\n",
      "train loss:2.433296626219897\n",
      "train loss:2.33430977921293\n",
      "train loss:2.3535556964705635\n",
      "=== epoch:5, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3700987055390152\n",
      "train loss:2.371053123194458\n",
      "train loss:2.349007192147754\n",
      "train loss:2.406099772863497\n",
      "=== epoch:6, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3575219985662654\n",
      "train loss:2.4006735210541748\n",
      "train loss:2.363098964606981\n",
      "train loss:2.277999149030503\n",
      "=== epoch:7, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.30961928487038\n",
      "train loss:2.318476408738478\n",
      "train loss:2.4049959187857777\n",
      "train loss:2.3405274924250783\n",
      "=== epoch:8, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3667125384802166\n",
      "train loss:2.3916598912653813\n",
      "train loss:2.4040914469679358\n",
      "train loss:2.4202619110829904\n",
      "=== epoch:9, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3845748358471086\n",
      "train loss:2.3757806252464535\n",
      "train loss:2.3393384189879143\n",
      "train loss:2.4187922603137886\n",
      "=== epoch:10, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.432752815531508\n",
      "train loss:2.3569423800839995\n",
      "train loss:2.3514634379139805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3655330710832496\n",
      "=== epoch:11, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.438117459966152\n",
      "train loss:2.3688091380116774\n",
      "train loss:2.3314780299418607\n",
      "train loss:2.324580442057852\n",
      "=== epoch:12, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3561562848955173\n",
      "train loss:2.368415066033969\n",
      "train loss:2.3823416185331325\n",
      "train loss:2.348730120990564\n",
      "=== epoch:13, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3729267565210184\n",
      "train loss:2.3648970971374403\n",
      "train loss:2.4026501680750076\n",
      "train loss:2.3396922756470215\n",
      "=== epoch:14, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.4589189315243094\n",
      "train loss:2.3862235639446534\n",
      "train loss:2.407795704952084\n",
      "train loss:2.368883025341968\n",
      "=== epoch:15, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3649490558276236\n",
      "train loss:2.360091793656424\n",
      "train loss:2.3417455899062047\n",
      "train loss:2.2960425416404164\n",
      "=== epoch:16, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.393422318215226\n",
      "train loss:2.3741860505905854\n",
      "train loss:2.2568068462087942\n",
      "train loss:2.366146801695356\n",
      "=== epoch:17, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3984215536275566\n",
      "train loss:2.3648555919636256\n",
      "train loss:2.344974403290321\n",
      "train loss:2.368872257581504\n",
      "=== epoch:18, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3235602269111233\n",
      "train loss:2.4283932063658495\n",
      "train loss:2.363753664310487\n",
      "train loss:2.3388833791908357\n",
      "=== epoch:19, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.377045089505435\n",
      "train loss:2.3726040944612157\n",
      "train loss:2.4092032801378953\n",
      "train loss:2.393199305426096\n",
      "=== epoch:20, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.354340223361344\n",
      "train loss:2.397198732643705\n",
      "train loss:2.360977432059855\n",
      "train loss:2.3922809347978693\n",
      "=== epoch:21, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3805119593346755\n",
      "train loss:2.3575677097998304\n",
      "train loss:2.4248230247280937\n",
      "train loss:2.2935490535584058\n",
      "=== epoch:22, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.387202194905595\n",
      "train loss:2.3814787814547405\n",
      "train loss:2.375676020975735\n",
      "train loss:2.3799596622568875\n",
      "=== epoch:23, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3201437097704383\n",
      "train loss:2.3523834409055326\n",
      "train loss:2.341537642187779\n",
      "train loss:2.3798840975062427\n",
      "=== epoch:24, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3966058382186826\n",
      "train loss:2.3028424895055446\n",
      "train loss:2.3738302434197127\n",
      "train loss:2.3931665281428995\n",
      "=== epoch:25, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3762986339108503\n",
      "train loss:2.3432196908340144\n",
      "train loss:2.3456644674690432\n",
      "train loss:2.3490019592429543\n",
      "=== epoch:26, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.346233360835837\n",
      "train loss:2.383725647630392\n",
      "train loss:2.3614348741235376\n",
      "train loss:2.4461964107338803\n",
      "=== epoch:27, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3480822393119722\n",
      "train loss:2.355931516397529\n",
      "train loss:2.356756695347474\n",
      "train loss:2.3412411815255023\n",
      "=== epoch:28, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3866321086889597\n",
      "train loss:2.4062269231621976\n",
      "train loss:2.3504664746939836\n",
      "train loss:2.4015337872060534\n",
      "=== epoch:29, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3103811693624725\n",
      "train loss:2.3647699712168144\n",
      "train loss:2.403192765908496\n",
      "train loss:2.3325122270220358\n",
      "=== epoch:30, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.4179287978611232\n",
      "train loss:2.3644761900186815\n",
      "train loss:2.33543696222064\n",
      "train loss:2.3944749518192014\n",
      "=== epoch:31, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3794365990414157\n",
      "train loss:2.4356037143271956\n",
      "train loss:2.3941895967139466\n",
      "train loss:2.350762672223772\n",
      "=== epoch:32, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3528851907683626\n",
      "train loss:2.4183788981545447\n",
      "train loss:2.353983267488343\n",
      "train loss:2.382154625153415\n",
      "=== epoch:33, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3226282740783475\n",
      "train loss:2.360343945359657\n",
      "train loss:2.3334414222986264\n",
      "train loss:2.445213109176454\n",
      "=== epoch:34, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3777173829155807\n",
      "train loss:2.381041660436282\n",
      "train loss:2.4400394980732383\n",
      "train loss:2.3448383881680543\n",
      "=== epoch:35, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.312516202854079\n",
      "train loss:2.3431096019092683\n",
      "train loss:2.399157940776229\n",
      "train loss:2.410048584213555\n",
      "=== epoch:36, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3655674625591336\n",
      "train loss:2.3896937081059715\n",
      "train loss:2.306791069926858\n",
      "train loss:2.3418051289449084\n",
      "=== epoch:37, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3152790345977685\n",
      "train loss:2.399534913453657\n",
      "train loss:2.3859967577615087\n",
      "train loss:2.3843400807754946\n",
      "=== epoch:38, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.347734243591319\n",
      "train loss:2.362322293608963\n",
      "train loss:2.353779073216422\n",
      "train loss:2.363320707008419\n",
      "=== epoch:39, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.358814891373914\n",
      "train loss:2.3665370006798727\n",
      "train loss:2.3461889849605817\n",
      "train loss:2.3351498486401905\n",
      "=== epoch:40, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3245213111073117\n",
      "train loss:2.3612774231737292\n",
      "train loss:2.3370048476302587\n",
      "train loss:2.397329832808258\n",
      "=== epoch:41, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.38605313937625\n",
      "train loss:2.4044922207160018\n",
      "train loss:2.350109868496341\n",
      "train loss:2.3792971358203814\n",
      "=== epoch:42, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3755188687576547\n",
      "train loss:2.3780607407278946\n",
      "train loss:2.4682948996570913\n",
      "train loss:2.3840695776363545\n",
      "=== epoch:43, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3517798048981566\n",
      "train loss:2.342519992982615\n",
      "train loss:2.333841642989195\n",
      "train loss:2.362949368344825\n",
      "=== epoch:44, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.370003658336696\n",
      "train loss:2.3662022277152026\n",
      "train loss:2.399874238676457\n",
      "train loss:2.4032697423860383\n",
      "=== epoch:45, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.4226115554457888\n",
      "train loss:2.340505001187881\n",
      "train loss:2.364254302473288\n",
      "train loss:2.338011311248175\n",
      "=== epoch:46, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.4257278409230185\n",
      "train loss:2.4006697105228634\n",
      "train loss:2.4445637571303798\n",
      "train loss:2.4201015699976476\n",
      "=== epoch:47, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.434743848521913\n",
      "train loss:2.3880904935550498\n",
      "train loss:2.3087514978485357\n",
      "train loss:2.3118928311709817\n",
      "=== epoch:48, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3652400391687536\n",
      "train loss:2.3879447782838565\n",
      "train loss:2.394083258793974\n",
      "train loss:2.4198987292560368\n",
      "=== epoch:49, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3473675230229714\n",
      "train loss:2.390415456742546\n",
      "train loss:2.3433694777561858\n",
      "train loss:2.396184462591488\n",
      "=== epoch:50, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.3628159895968786\n",
      "train loss:2.414276488669475\n",
      "train loss:2.2814811439404545\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.06\n",
      "val_acc: 0.0600 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3988326773558923\n",
      "=== epoch:1, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.472204873257432\n",
      "train loss:2.523590537177298\n",
      "train loss:2.4377905295087428\n",
      "train loss:2.4173308913473512\n",
      "=== epoch:2, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.498769184660619\n",
      "train loss:2.5058650531277062\n",
      "train loss:2.470322000518044\n",
      "train loss:2.5159351621563975\n",
      "=== epoch:3, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.5844914328998394\n",
      "train loss:2.430668831195325\n",
      "train loss:2.454275212175331\n",
      "train loss:2.4874232703978922\n",
      "=== epoch:4, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4703994939841603\n",
      "train loss:2.4674122777597916\n",
      "train loss:2.402447824646731\n",
      "train loss:2.444776596348015\n",
      "=== epoch:5, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.499537467587286\n",
      "train loss:2.396498850579047\n",
      "train loss:2.3918718001016197\n",
      "train loss:2.4774952421823384\n",
      "=== epoch:6, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.44781496748677\n",
      "train loss:2.570646480358872\n",
      "train loss:2.4919963171839856\n",
      "train loss:2.4546349311733184\n",
      "=== epoch:7, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4166874177825473\n",
      "train loss:2.380358504196976\n",
      "train loss:2.4955716176676046\n",
      "train loss:2.461031894516387\n",
      "=== epoch:8, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.481892044154936\n",
      "train loss:2.4657551974057594\n",
      "train loss:2.392257742466729\n",
      "train loss:2.4857692096142823\n",
      "=== epoch:9, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.515407725970058\n",
      "train loss:2.4439889690183425\n",
      "train loss:2.523287592216594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.467573141464634\n",
      "=== epoch:10, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.465922545301979\n",
      "train loss:2.523497999394753\n",
      "train loss:2.448381901619695\n",
      "train loss:2.5048120735225567\n",
      "=== epoch:11, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4334426205558355\n",
      "train loss:2.438228451822954\n",
      "train loss:2.464611942789768\n",
      "train loss:2.48554551872062\n",
      "=== epoch:12, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4625985269780433\n",
      "train loss:2.4212986782106656\n",
      "train loss:2.5061284240688946\n",
      "train loss:2.3886189925281394\n",
      "=== epoch:13, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.459019567565227\n",
      "train loss:2.4625592942264305\n",
      "train loss:2.39653283381646\n",
      "train loss:2.5069661949513247\n",
      "=== epoch:14, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4838963120274786\n",
      "train loss:2.507580770449272\n",
      "train loss:2.501737553370632\n",
      "train loss:2.4687326560410385\n",
      "=== epoch:15, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.513586499942938\n",
      "train loss:2.338076250352325\n",
      "train loss:2.519687867141951\n",
      "train loss:2.460086861236513\n",
      "=== epoch:16, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.456860154828888\n",
      "train loss:2.41596215400361\n",
      "train loss:2.3971233459186916\n",
      "train loss:2.46881021586793\n",
      "=== epoch:17, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4585169643702525\n",
      "train loss:2.5131023616467334\n",
      "train loss:2.4652060210227553\n",
      "train loss:2.4958327432466336\n",
      "=== epoch:18, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4889628844240055\n",
      "train loss:2.493645941638034\n",
      "train loss:2.5741335029635763\n",
      "train loss:2.369766001183266\n",
      "=== epoch:19, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.489170114810907\n",
      "train loss:2.4598898919655854\n",
      "train loss:2.4493702006803386\n",
      "train loss:2.430378707958873\n",
      "=== epoch:20, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.601105321940591\n",
      "train loss:2.476869475594752\n",
      "train loss:2.5315002817479986\n",
      "train loss:2.429035528687401\n",
      "=== epoch:21, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4780400555448305\n",
      "train loss:2.5014429569817684\n",
      "train loss:2.4181066592298213\n",
      "train loss:2.4490940172122517\n",
      "=== epoch:22, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.5206112010187023\n",
      "train loss:2.4793536352415804\n",
      "train loss:2.495708838898918\n",
      "train loss:2.4133798296921607\n",
      "=== epoch:23, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4106089329903067\n",
      "train loss:2.396053218899753\n",
      "train loss:2.3991630195674936\n",
      "train loss:2.5346840722562742\n",
      "=== epoch:24, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.509364778971186\n",
      "train loss:2.4979370592993404\n",
      "train loss:2.464748664709412\n",
      "train loss:2.495456348731145\n",
      "=== epoch:25, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4449888935109594\n",
      "train loss:2.4345644839575464\n",
      "train loss:2.4649130909430794\n",
      "train loss:2.312910607255879\n",
      "=== epoch:26, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.43501935310433\n",
      "train loss:2.464703890706793\n",
      "train loss:2.420035152122602\n",
      "train loss:2.516447291862044\n",
      "=== epoch:27, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.36865175227493\n",
      "train loss:2.3951394766774685\n",
      "train loss:2.4499528283634144\n",
      "train loss:2.4788835839824648\n",
      "=== epoch:28, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4869402673595515\n",
      "train loss:2.524133391450647\n",
      "train loss:2.43190128784972\n",
      "train loss:2.471790303371614\n",
      "=== epoch:29, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.3977822188650206\n",
      "train loss:2.479162924227264\n",
      "train loss:2.4507633795771313\n",
      "train loss:2.4929969352981654\n",
      "=== epoch:30, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.4553936746650504\n",
      "train loss:2.431596491112558\n",
      "train loss:2.4735146568737396\n",
      "train loss:2.5143092016701925\n",
      "=== epoch:31, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.462701241430885\n",
      "train loss:2.543828574118221\n",
      "train loss:2.503957233951555\n",
      "train loss:2.5085112209476685\n",
      "=== epoch:32, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.459945070341564\n",
      "train loss:2.5433132956194417\n",
      "train loss:2.453982294597215\n",
      "train loss:2.5009832271369383\n",
      "=== epoch:33, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.448479367705566\n",
      "train loss:2.5436928662281595\n",
      "train loss:2.4218729290396337\n",
      "train loss:2.3798757984726673\n",
      "=== epoch:34, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4637674823100006\n",
      "train loss:2.479543924198286\n",
      "train loss:2.4605252874912886\n",
      "train loss:2.509696987895769\n",
      "=== epoch:35, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4064199870907177\n",
      "train loss:2.6101436333140935\n",
      "train loss:2.509634263343597\n",
      "train loss:2.540722005104693\n",
      "=== epoch:36, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.386340485397695\n",
      "train loss:2.3928582660409927\n",
      "train loss:2.3186152783890965\n",
      "train loss:2.377038483781427\n",
      "=== epoch:37, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.5042679080431443\n",
      "train loss:2.375051632634153\n",
      "train loss:2.444095931445477\n",
      "train loss:2.3884025169078886\n",
      "=== epoch:38, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.508118490353174\n",
      "train loss:2.4901875533842865\n",
      "train loss:2.495596361648057\n",
      "train loss:2.4753139270785125\n",
      "=== epoch:39, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4136262863668803\n",
      "train loss:2.418509738947153\n",
      "train loss:2.4822992837813294\n",
      "train loss:2.5007539305429014\n",
      "=== epoch:40, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.420452737366256\n",
      "train loss:2.410586242897382\n",
      "train loss:2.5939685434584936\n",
      "train loss:2.42166575935065\n",
      "=== epoch:41, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.5185589538394915\n",
      "train loss:2.4288616576865047\n",
      "train loss:2.4358319912966016\n",
      "train loss:2.397027191543884\n",
      "=== epoch:42, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.402072141181453\n",
      "train loss:2.472515259845541\n",
      "train loss:2.458807673267819\n",
      "train loss:2.3909031305215724\n",
      "=== epoch:43, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4223883524589804\n",
      "train loss:2.3808184389200386\n",
      "train loss:2.5206915909420724\n",
      "train loss:2.542923186045785\n",
      "=== epoch:44, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4336720559806584\n",
      "train loss:2.4444682322931897\n",
      "train loss:2.431934125962349\n",
      "train loss:2.4132703839778857\n",
      "=== epoch:45, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.458974878433777\n",
      "train loss:2.4468212552798323\n",
      "train loss:2.4107828804568725\n",
      "train loss:2.4986125638299646\n",
      "=== epoch:46, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.37405086151719\n",
      "train loss:2.4156043616636316\n",
      "train loss:2.4351453656272932\n",
      "train loss:2.501835712291663\n",
      "=== epoch:47, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.501200916045265\n",
      "train loss:2.3222314929540917\n",
      "train loss:2.4606551218389567\n",
      "train loss:2.5935664399087144\n",
      "=== epoch:48, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.576253473914462\n",
      "train loss:2.502934348162567\n",
      "train loss:2.4549544581788028\n",
      "train loss:2.420851290071886\n",
      "=== epoch:49, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4534723630472355\n",
      "train loss:2.5015797052109776\n",
      "train loss:2.4694140035843866\n",
      "train loss:2.540580773550104\n",
      "=== epoch:50, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4740253392147946\n",
      "train loss:2.4953887177362013\n",
      "train loss:2.422248773221492\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.15\n",
      "val_acc: 0.1500 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3067249822959393\n",
      "=== epoch:1, train acc:0.105, test acc:0.06 ===\n",
      "train loss:2.278737284255528\n",
      "train loss:2.272647001318992\n",
      "train loss:2.330705990033281\n",
      "train loss:2.3003951381057224\n",
      "=== epoch:2, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.3185895343721885\n",
      "train loss:2.3222752828350792\n",
      "train loss:2.3204671181130343\n",
      "train loss:2.3334917811034073\n",
      "=== epoch:3, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.3132046460875864\n",
      "train loss:2.3136361411051842\n",
      "train loss:2.309333376409576\n",
      "train loss:2.31230404816782\n",
      "=== epoch:4, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.2994285641992733\n",
      "train loss:2.271586332250918\n",
      "train loss:2.3047050138060254\n",
      "train loss:2.299697765027768\n",
      "=== epoch:5, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.3463945216464066\n",
      "train loss:2.354954591888919\n",
      "train loss:2.2654215073881088\n",
      "train loss:2.314259675364563\n",
      "=== epoch:6, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.3163457500350844\n",
      "train loss:2.290421816708046\n",
      "train loss:2.282130299307225\n",
      "train loss:2.284361613349022\n",
      "=== epoch:7, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.352201733015064\n",
      "train loss:2.3191303468449833\n",
      "train loss:2.30159957590066\n",
      "train loss:2.351083518866009\n",
      "=== epoch:8, train acc:0.11, test acc:0.06 ===\n",
      "train loss:2.2585139039160875\n",
      "train loss:2.3332245121989126\n",
      "train loss:2.290647886624534\n",
      "train loss:2.326431529217202\n",
      "=== epoch:9, train acc:0.115, test acc:0.06 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.275576213275777\n",
      "train loss:2.2995707588248058\n",
      "train loss:2.29512740822596\n",
      "train loss:2.326646859869303\n",
      "=== epoch:10, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.281097261000624\n",
      "train loss:2.2402292917190585\n",
      "train loss:2.3141149315762903\n",
      "train loss:2.305079277394638\n",
      "=== epoch:11, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.30887983725004\n",
      "train loss:2.2844431830636696\n",
      "train loss:2.3687782675154505\n",
      "train loss:2.2390506798282743\n",
      "=== epoch:12, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3051654458775275\n",
      "train loss:2.3279834641732617\n",
      "train loss:2.3477664039256707\n",
      "train loss:2.294933087697528\n",
      "=== epoch:13, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.2969315117022218\n",
      "train loss:2.3062737399029754\n",
      "train loss:2.295172747654717\n",
      "train loss:2.234605644586878\n",
      "=== epoch:14, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3152155559643592\n",
      "train loss:2.318484082598269\n",
      "train loss:2.301032205540399\n",
      "train loss:2.2780476270029903\n",
      "=== epoch:15, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3174896449532416\n",
      "train loss:2.2743891833770227\n",
      "train loss:2.3095259604236147\n",
      "train loss:2.263722193306353\n",
      "=== epoch:16, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.2816770995851066\n",
      "train loss:2.2796094012294663\n",
      "train loss:2.273126339194521\n",
      "train loss:2.296127170184604\n",
      "=== epoch:17, train acc:0.12, test acc:0.06 ===\n",
      "train loss:2.306605180363532\n",
      "train loss:2.256508282209949\n",
      "train loss:2.2810007733679254\n",
      "train loss:2.282793017855755\n",
      "=== epoch:18, train acc:0.12, test acc:0.06 ===\n",
      "train loss:2.326010371263646\n",
      "train loss:2.3189284017245173\n",
      "train loss:2.3337925383115783\n",
      "train loss:2.2550850960734854\n",
      "=== epoch:19, train acc:0.1225, test acc:0.06 ===\n",
      "train loss:2.3177935293705585\n",
      "train loss:2.309747460612315\n",
      "train loss:2.304919773264159\n",
      "train loss:2.2852387387649458\n",
      "=== epoch:20, train acc:0.1225, test acc:0.06 ===\n",
      "train loss:2.259114878986286\n",
      "train loss:2.307823432714984\n",
      "train loss:2.279651694214546\n",
      "train loss:2.314846835584057\n",
      "=== epoch:21, train acc:0.1225, test acc:0.06 ===\n",
      "train loss:2.274743059479999\n",
      "train loss:2.3501022086636962\n",
      "train loss:2.2610631937394197\n",
      "train loss:2.3160429023765823\n",
      "=== epoch:22, train acc:0.1225, test acc:0.06 ===\n",
      "train loss:2.2760011101569324\n",
      "train loss:2.291028973766867\n",
      "train loss:2.2601696970522904\n",
      "train loss:2.3395005886302354\n",
      "=== epoch:23, train acc:0.1225, test acc:0.06 ===\n",
      "train loss:2.314162107382089\n",
      "train loss:2.2949153628416505\n",
      "train loss:2.318081717732876\n",
      "train loss:2.3263167100771844\n",
      "=== epoch:24, train acc:0.1225, test acc:0.06 ===\n",
      "train loss:2.320597691045075\n",
      "train loss:2.2792148151216933\n",
      "train loss:2.295857902306568\n",
      "train loss:2.281790145256303\n",
      "=== epoch:25, train acc:0.1225, test acc:0.06 ===\n",
      "train loss:2.3193147927077415\n",
      "train loss:2.2984121477863573\n",
      "train loss:2.3178856550239515\n",
      "train loss:2.3140198604249873\n",
      "=== epoch:26, train acc:0.1225, test acc:0.06 ===\n",
      "train loss:2.3345394230165972\n",
      "train loss:2.2904849232147795\n",
      "train loss:2.297323539424845\n",
      "train loss:2.285949005857698\n",
      "=== epoch:27, train acc:0.1225, test acc:0.07 ===\n",
      "train loss:2.263950118788436\n",
      "train loss:2.297907161897751\n",
      "train loss:2.2706190008097606\n",
      "train loss:2.3283947266734466\n",
      "=== epoch:28, train acc:0.1225, test acc:0.07 ===\n",
      "train loss:2.2992008252723783\n",
      "train loss:2.2949060678560156\n",
      "train loss:2.3065098160887\n",
      "train loss:2.30470235123792\n",
      "=== epoch:29, train acc:0.1225, test acc:0.07 ===\n",
      "train loss:2.309141133603097\n",
      "train loss:2.225537895264365\n",
      "train loss:2.3207136614545547\n",
      "train loss:2.27756783676066\n",
      "=== epoch:30, train acc:0.1225, test acc:0.07 ===\n",
      "train loss:2.2526407618611497\n",
      "train loss:2.3260423419322005\n",
      "train loss:2.3373980400520513\n",
      "train loss:2.314748225561285\n",
      "=== epoch:31, train acc:0.1225, test acc:0.07 ===\n",
      "train loss:2.3226352979053986\n",
      "train loss:2.2748160382720854\n",
      "train loss:2.3083085495726663\n",
      "train loss:2.244080971645405\n",
      "=== epoch:32, train acc:0.1225, test acc:0.07 ===\n",
      "train loss:2.282648592387627\n",
      "train loss:2.249142985121188\n",
      "train loss:2.2826042045093913\n",
      "train loss:2.293348512518393\n",
      "=== epoch:33, train acc:0.1275, test acc:0.07 ===\n",
      "train loss:2.2694501305996604\n",
      "train loss:2.2935492105536395\n",
      "train loss:2.267678985256273\n",
      "train loss:2.249019289651794\n",
      "=== epoch:34, train acc:0.1275, test acc:0.07 ===\n",
      "train loss:2.2530955591223303\n",
      "train loss:2.307582919427395\n",
      "train loss:2.309576458032249\n",
      "train loss:2.2960650830423392\n",
      "=== epoch:35, train acc:0.1275, test acc:0.07 ===\n",
      "train loss:2.2780433702898044\n",
      "train loss:2.2703748361339082\n",
      "train loss:2.286804352258301\n",
      "train loss:2.3273828300291943\n",
      "=== epoch:36, train acc:0.13, test acc:0.07 ===\n",
      "train loss:2.3500083987727174\n",
      "train loss:2.292947552285583\n",
      "train loss:2.263607051773443\n",
      "train loss:2.24093438921292\n",
      "=== epoch:37, train acc:0.13, test acc:0.08 ===\n",
      "train loss:2.313733210994888\n",
      "train loss:2.290055086914824\n",
      "train loss:2.2271800396508876\n",
      "train loss:2.3178915765948807\n",
      "=== epoch:38, train acc:0.13, test acc:0.08 ===\n",
      "train loss:2.3092991511445193\n",
      "train loss:2.3270897289675814\n",
      "train loss:2.252907084844038\n",
      "train loss:2.334548500947347\n",
      "=== epoch:39, train acc:0.13, test acc:0.08 ===\n",
      "train loss:2.2720526844177624\n",
      "train loss:2.3154078006811267\n",
      "train loss:2.2576085758378253\n",
      "train loss:2.284664146248005\n",
      "=== epoch:40, train acc:0.13, test acc:0.08 ===\n",
      "train loss:2.2712586040871\n",
      "train loss:2.278594652560047\n",
      "train loss:2.2853240288885592\n",
      "train loss:2.249967686333148\n",
      "=== epoch:41, train acc:0.135, test acc:0.08 ===\n",
      "train loss:2.319226480179455\n",
      "train loss:2.301806218729945\n",
      "train loss:2.2338838965897807\n",
      "train loss:2.2662029281532106\n",
      "=== epoch:42, train acc:0.135, test acc:0.08 ===\n",
      "train loss:2.27176269036474\n",
      "train loss:2.30225473908646\n",
      "train loss:2.3035549829926087\n",
      "train loss:2.2535627911455003\n",
      "=== epoch:43, train acc:0.135, test acc:0.08 ===\n",
      "train loss:2.2938871968279986\n",
      "train loss:2.3053192094992085\n",
      "train loss:2.250992080379335\n",
      "train loss:2.3000874632925394\n",
      "=== epoch:44, train acc:0.1375, test acc:0.08 ===\n",
      "train loss:2.270213971343934\n",
      "train loss:2.262074012846301\n",
      "train loss:2.282645476132648\n",
      "train loss:2.323087342687025\n",
      "=== epoch:45, train acc:0.1375, test acc:0.08 ===\n",
      "train loss:2.254200076708605\n",
      "train loss:2.288904236382468\n",
      "train loss:2.318999615725622\n",
      "train loss:2.29476328073245\n",
      "=== epoch:46, train acc:0.1375, test acc:0.08 ===\n",
      "train loss:2.2499369752383123\n",
      "train loss:2.290182670998716\n",
      "train loss:2.2694655949349363\n",
      "train loss:2.2635568300138127\n",
      "=== epoch:47, train acc:0.1375, test acc:0.08 ===\n",
      "train loss:2.2348552093625615\n",
      "train loss:2.2868516998545894\n",
      "train loss:2.303937038419814\n",
      "train loss:2.2593375334500014\n",
      "=== epoch:48, train acc:0.1375, test acc:0.08 ===\n",
      "train loss:2.2654446427172683\n",
      "train loss:2.2655046970376325\n",
      "train loss:2.2558924626437866\n",
      "train loss:2.2943105929903167\n",
      "=== epoch:49, train acc:0.1375, test acc:0.08 ===\n",
      "train loss:2.316330417213787\n",
      "train loss:2.2873324242183606\n",
      "train loss:2.227936301919303\n",
      "train loss:2.2612254231647864\n",
      "=== epoch:50, train acc:0.1425, test acc:0.08 ===\n",
      "train loss:2.2454516790290717\n",
      "train loss:2.2343920907752537\n",
      "train loss:2.350526207756733\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.08\n",
      "val_acc: 0.0800 | lr: 0.0002, weight_decay: 0.0000\n",
      "train loss:2.3710910380453716\n",
      "=== epoch:1, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.378436949470986\n",
      "train loss:2.455728228784621\n",
      "train loss:2.436255155122334\n",
      "train loss:2.3616151190294588\n",
      "=== epoch:2, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3679456380171833\n",
      "train loss:2.393393095159014\n",
      "train loss:2.363366349646881\n",
      "train loss:2.42094934201829\n",
      "=== epoch:3, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.4148433068015995\n",
      "train loss:2.4159712856737126\n",
      "train loss:2.5009361163292265\n",
      "train loss:2.386111789926612\n",
      "=== epoch:4, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.4093310676125617\n",
      "train loss:2.3682605585624694\n",
      "train loss:2.3838462991390568\n",
      "train loss:2.346462208706726\n",
      "=== epoch:5, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.425304344110623\n",
      "train loss:2.4572610692287373\n",
      "train loss:2.480118258169913\n",
      "train loss:2.3223110202150186\n",
      "=== epoch:6, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.304680804892667\n",
      "train loss:2.3133782314441556\n",
      "train loss:2.3331356141082313\n",
      "train loss:2.434577724185672\n",
      "=== epoch:7, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.340326473077596\n",
      "train loss:2.3510593805434827\n",
      "train loss:2.419136681301187\n",
      "train loss:2.3673416356813766\n",
      "=== epoch:8, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.4291657492099628\n",
      "train loss:2.3904960085629323\n",
      "train loss:2.3547082935491073\n",
      "train loss:2.3799569232233173\n",
      "=== epoch:9, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3624314220217353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.409080829339401\n",
      "train loss:2.404656223035535\n",
      "train loss:2.384833818610507\n",
      "=== epoch:10, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4431639624881\n",
      "train loss:2.3650595164360606\n",
      "train loss:2.3527149620678354\n",
      "train loss:2.357456542752758\n",
      "=== epoch:11, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3999863509078763\n",
      "train loss:2.3682315547017168\n",
      "train loss:2.3604075292177917\n",
      "train loss:2.38841221702034\n",
      "=== epoch:12, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3509427643500986\n",
      "train loss:2.3729527884500983\n",
      "train loss:2.3370672359215248\n",
      "train loss:2.362881059619374\n",
      "=== epoch:13, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.4360841594762364\n",
      "train loss:2.3597475061230613\n",
      "train loss:2.376909181769128\n",
      "train loss:2.366041521570214\n",
      "=== epoch:14, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.445187936431079\n",
      "train loss:2.377189842178983\n",
      "train loss:2.411409430541835\n",
      "train loss:2.3924899572935385\n",
      "=== epoch:15, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3433113364378073\n",
      "train loss:2.3972355753082972\n",
      "train loss:2.3794346414217022\n",
      "train loss:2.344364067224807\n",
      "=== epoch:16, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.442666238485393\n",
      "train loss:2.3370085902692472\n",
      "train loss:2.4283560685332186\n",
      "train loss:2.350649059239583\n",
      "=== epoch:17, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3183523438942957\n",
      "train loss:2.3590241786033594\n",
      "train loss:2.367517622096981\n",
      "train loss:2.2898842905784713\n",
      "=== epoch:18, train acc:0.095, test acc:0.12 ===\n",
      "train loss:2.3580213174925095\n",
      "train loss:2.3901337724741363\n",
      "train loss:2.33102592680773\n",
      "train loss:2.3492870517139948\n",
      "=== epoch:19, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.3371772104516646\n",
      "train loss:2.3988237492827214\n",
      "train loss:2.395002925152534\n",
      "train loss:2.3340423665944896\n",
      "=== epoch:20, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.360268504324339\n",
      "train loss:2.380414071736479\n",
      "train loss:2.366818482391997\n",
      "train loss:2.31800002582427\n",
      "=== epoch:21, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.4064623447398312\n",
      "train loss:2.367094319900102\n",
      "train loss:2.3880764784676805\n",
      "train loss:2.3505313635658034\n",
      "=== epoch:22, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.31529737748583\n",
      "train loss:2.344329811175154\n",
      "train loss:2.3892446913867222\n",
      "train loss:2.438801505487126\n",
      "=== epoch:23, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.3873082673918438\n",
      "train loss:2.2963928189844465\n",
      "train loss:2.3566689107132563\n",
      "train loss:2.3702971678096154\n",
      "=== epoch:24, train acc:0.1, test acc:0.12 ===\n",
      "train loss:2.361840877929826\n",
      "train loss:2.3956879145514693\n",
      "train loss:2.309735712733944\n",
      "train loss:2.369679125293481\n",
      "=== epoch:25, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.3717426899540763\n",
      "train loss:2.335531001816316\n",
      "train loss:2.419278697069349\n",
      "train loss:2.3557369430255815\n",
      "=== epoch:26, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.3624387027725624\n",
      "train loss:2.3144349886232827\n",
      "train loss:2.3624173991853326\n",
      "train loss:2.3739012774798973\n",
      "=== epoch:27, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.3771421341969847\n",
      "train loss:2.3596655014637062\n",
      "train loss:2.3509059532767886\n",
      "train loss:2.417160124719724\n",
      "=== epoch:28, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.405637397930497\n",
      "train loss:2.3559889962116634\n",
      "train loss:2.331447122347703\n",
      "train loss:2.381819765191017\n",
      "=== epoch:29, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.3739163838291772\n",
      "train loss:2.3191610472315487\n",
      "train loss:2.361132209097491\n",
      "train loss:2.368087476494024\n",
      "=== epoch:30, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.3364195862874553\n",
      "train loss:2.3188919310254614\n",
      "train loss:2.302017591998962\n",
      "train loss:2.333980598717253\n",
      "=== epoch:31, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.4299877693285823\n",
      "train loss:2.3969416927426113\n",
      "train loss:2.3290768269607405\n",
      "train loss:2.379879229204118\n",
      "=== epoch:32, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.3876201306200633\n",
      "train loss:2.362410694629994\n",
      "train loss:2.3353763602354127\n",
      "train loss:2.3707743815197615\n",
      "=== epoch:33, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.4262201430223973\n",
      "train loss:2.3366952289189946\n",
      "train loss:2.3492061103981765\n",
      "train loss:2.3849756173619667\n",
      "=== epoch:34, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.3847744518321754\n",
      "train loss:2.268155639199283\n",
      "train loss:2.3139156124779903\n",
      "train loss:2.4245929668229227\n",
      "=== epoch:35, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.3386859950729146\n",
      "train loss:2.3694283478791682\n",
      "train loss:2.4316258119651115\n",
      "train loss:2.368555380819385\n",
      "=== epoch:36, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.3235836411631943\n",
      "train loss:2.413337692852599\n",
      "train loss:2.3680366481886455\n",
      "train loss:2.3762383222372954\n",
      "=== epoch:37, train acc:0.105, test acc:0.12 ===\n",
      "train loss:2.405582979417983\n",
      "train loss:2.3682448658269544\n",
      "train loss:2.393613395882258\n",
      "train loss:2.3376963881351616\n",
      "=== epoch:38, train acc:0.1075, test acc:0.12 ===\n",
      "train loss:2.3929754194176467\n",
      "train loss:2.3252181521966584\n",
      "train loss:2.324868879659121\n",
      "train loss:2.322316823180114\n",
      "=== epoch:39, train acc:0.1075, test acc:0.12 ===\n",
      "train loss:2.382761165775488\n",
      "train loss:2.355873889498019\n",
      "train loss:2.360235874866447\n",
      "train loss:2.297706237237893\n",
      "=== epoch:40, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.366155445013667\n",
      "train loss:2.4138897737428087\n",
      "train loss:2.3194537593978435\n",
      "train loss:2.454917735519061\n",
      "=== epoch:41, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.319949873120534\n",
      "train loss:2.405513617539554\n",
      "train loss:2.329575203469316\n",
      "train loss:2.3453310303556183\n",
      "=== epoch:42, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.371544417474777\n",
      "train loss:2.304741017108077\n",
      "train loss:2.3706817885583007\n",
      "train loss:2.35638568038489\n",
      "=== epoch:43, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.431326021560709\n",
      "train loss:2.3548488248243946\n",
      "train loss:2.342588441039037\n",
      "train loss:2.3828007265016677\n",
      "=== epoch:44, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.4076547518873417\n",
      "train loss:2.357695334745717\n",
      "train loss:2.359417081005292\n",
      "train loss:2.3810006094792\n",
      "=== epoch:45, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3981226131210978\n",
      "train loss:2.318886987170518\n",
      "train loss:2.3157751682375354\n",
      "train loss:2.3601771204406905\n",
      "=== epoch:46, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3844871507094316\n",
      "train loss:2.3553887276045273\n",
      "train loss:2.3674503201305193\n",
      "train loss:2.3936632781325065\n",
      "=== epoch:47, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3337259554333576\n",
      "train loss:2.345031066897973\n",
      "train loss:2.351333876686178\n",
      "train loss:2.367952348462566\n",
      "=== epoch:48, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3581226717090717\n",
      "train loss:2.3137210734099423\n",
      "train loss:2.358715087734606\n",
      "train loss:2.3632886949551244\n",
      "=== epoch:49, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.360587724014893\n",
      "train loss:2.338717524977939\n",
      "train loss:2.3814164510314786\n",
      "train loss:2.3356090293242806\n",
      "=== epoch:50, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.4122963850519414\n",
      "train loss:2.3242807387415003\n",
      "train loss:2.3154577826748906\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.3968006725467115\n",
      "=== epoch:1, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4151891648252293\n",
      "train loss:2.439986279864163\n",
      "train loss:2.4826335166174895\n",
      "train loss:2.431804191617509\n",
      "=== epoch:2, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.347205976035976\n",
      "train loss:2.3778106114105655\n",
      "train loss:2.4553370186935655\n",
      "train loss:2.3936925353994654\n",
      "=== epoch:3, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.440832286837438\n",
      "train loss:2.502924868861619\n",
      "train loss:2.4752841292471115\n",
      "train loss:2.431575077260733\n",
      "=== epoch:4, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.46858767634627\n",
      "train loss:2.370553072367066\n",
      "train loss:2.377150281298141\n",
      "train loss:2.3967655603372067\n",
      "=== epoch:5, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.455613861000791\n",
      "train loss:2.4139643722339326\n",
      "train loss:2.365358982958757\n",
      "train loss:2.3894651337440598\n",
      "=== epoch:6, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.447990500116333\n",
      "train loss:2.4395928406788303\n",
      "train loss:2.3944208491041428\n",
      "train loss:2.4311623302302823\n",
      "=== epoch:7, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.448199488933748\n",
      "train loss:2.3888742286689353\n",
      "train loss:2.4144187358496736\n",
      "train loss:2.424896580141527\n",
      "=== epoch:8, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.420764104377089\n",
      "train loss:2.387016383501183\n",
      "train loss:2.4814149393152363\n",
      "train loss:2.395720394792935\n",
      "=== epoch:9, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.443910935355783\n",
      "train loss:2.4442144954609666\n",
      "train loss:2.4131162695128445\n",
      "train loss:2.4459323918589013\n",
      "=== epoch:10, train acc:0.075, test acc:0.06 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4579700550348824\n",
      "train loss:2.418965144018014\n",
      "train loss:2.397820116118515\n",
      "train loss:2.4153146534106624\n",
      "=== epoch:11, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.35981503633095\n",
      "train loss:2.498807136254576\n",
      "train loss:2.490088282465439\n",
      "train loss:2.465720728965997\n",
      "=== epoch:12, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4818718424644377\n",
      "train loss:2.4809723352043958\n",
      "train loss:2.4452695063093035\n",
      "train loss:2.448419997327797\n",
      "=== epoch:13, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.453665934775622\n",
      "train loss:2.466587593956788\n",
      "train loss:2.4302653156584215\n",
      "train loss:2.4696135936124266\n",
      "=== epoch:14, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.42892377135596\n",
      "train loss:2.448443999756178\n",
      "train loss:2.45441417030709\n",
      "train loss:2.302999276181578\n",
      "=== epoch:15, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.376447853951593\n",
      "train loss:2.425490609355297\n",
      "train loss:2.474161743840517\n",
      "train loss:2.4609892229201873\n",
      "=== epoch:16, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.393220530112635\n",
      "train loss:2.4080789871766206\n",
      "train loss:2.4171471975243435\n",
      "train loss:2.4403562947091695\n",
      "=== epoch:17, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.37456827061839\n",
      "train loss:2.3693445294990227\n",
      "train loss:2.4696920837136314\n",
      "train loss:2.4247253768014927\n",
      "=== epoch:18, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.3545767010150653\n",
      "train loss:2.4421203784516137\n",
      "train loss:2.3943640406192057\n",
      "train loss:2.425196339926147\n",
      "=== epoch:19, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.407448874564059\n",
      "train loss:2.439770137481157\n",
      "train loss:2.459007361621839\n",
      "train loss:2.4448475757440487\n",
      "=== epoch:20, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.371390425371475\n",
      "train loss:2.3610667689739486\n",
      "train loss:2.4170207850271734\n",
      "train loss:2.406652832958147\n",
      "=== epoch:21, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.3710818660778354\n",
      "train loss:2.402681281451895\n",
      "train loss:2.3652136827053463\n",
      "train loss:2.4700456395219956\n",
      "=== epoch:22, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.449130313608535\n",
      "train loss:2.4321452305713973\n",
      "train loss:2.4253759265731554\n",
      "train loss:2.396315865517758\n",
      "=== epoch:23, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4373342297668836\n",
      "train loss:2.3851420033797717\n",
      "train loss:2.4644324271082043\n",
      "train loss:2.3858728561288127\n",
      "=== epoch:24, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.440157506938984\n",
      "train loss:2.3680133381626476\n",
      "train loss:2.417325920305429\n",
      "train loss:2.4740571610369746\n",
      "=== epoch:25, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.441704267263636\n",
      "train loss:2.5105594068440107\n",
      "train loss:2.414761986953271\n",
      "train loss:2.4835581321094944\n",
      "=== epoch:26, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.3503241542721627\n",
      "train loss:2.371554404645735\n",
      "train loss:2.4269427753476522\n",
      "train loss:2.4407743381099585\n",
      "=== epoch:27, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.43541073704752\n",
      "train loss:2.396906164017809\n",
      "train loss:2.4191983707021114\n",
      "train loss:2.4274567446291178\n",
      "=== epoch:28, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.3336670286126218\n",
      "train loss:2.320079116439982\n",
      "train loss:2.370764155425398\n",
      "train loss:2.482439803083401\n",
      "=== epoch:29, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.38522674225527\n",
      "train loss:2.4402732100830637\n",
      "train loss:2.377252133942964\n",
      "train loss:2.4032746731078074\n",
      "=== epoch:30, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4155750842745207\n",
      "train loss:2.3501916498395024\n",
      "train loss:2.3826601664026614\n",
      "train loss:2.45306043891653\n",
      "=== epoch:31, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.3741851041768522\n",
      "train loss:2.499120140214649\n",
      "train loss:2.4065064648810086\n",
      "train loss:2.4255827679465067\n",
      "=== epoch:32, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.428980506541255\n",
      "train loss:2.380688672808233\n",
      "train loss:2.50752452997315\n",
      "train loss:2.4925636803169993\n",
      "=== epoch:33, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4221795147840184\n",
      "train loss:2.4085743362460237\n",
      "train loss:2.4158498432210904\n",
      "train loss:2.3976357968057167\n",
      "=== epoch:34, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.456992257732862\n",
      "train loss:2.3911571477312843\n",
      "train loss:2.4540609022454727\n",
      "train loss:2.429411431419928\n",
      "=== epoch:35, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.3937208436407564\n",
      "train loss:2.3551333688264737\n",
      "train loss:2.407895515289896\n",
      "train loss:2.53072737515963\n",
      "=== epoch:36, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4579379533743175\n",
      "train loss:2.455800900647934\n",
      "train loss:2.400482458275111\n",
      "train loss:2.4274700411718486\n",
      "=== epoch:37, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.404215810630635\n",
      "train loss:2.42026253587062\n",
      "train loss:2.5421041462221394\n",
      "train loss:2.525660631451093\n",
      "=== epoch:38, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4940813930321117\n",
      "train loss:2.443158161477834\n",
      "train loss:2.4347685024730987\n",
      "train loss:2.412967801890683\n",
      "=== epoch:39, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4850640846412353\n",
      "train loss:2.4473413996684266\n",
      "train loss:2.470369318900203\n",
      "train loss:2.4561130751966815\n",
      "=== epoch:40, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.410948664627936\n",
      "train loss:2.4440231348972876\n",
      "train loss:2.3899112334384363\n",
      "train loss:2.3739586322866693\n",
      "=== epoch:41, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.395279120487329\n",
      "train loss:2.4330441614382914\n",
      "train loss:2.401160228606742\n",
      "train loss:2.4860988734666183\n",
      "=== epoch:42, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.416793386283764\n",
      "train loss:2.4413586279215442\n",
      "train loss:2.4417618266471313\n",
      "train loss:2.3735579139235834\n",
      "=== epoch:43, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4533692869941186\n",
      "train loss:2.4799157823143716\n",
      "train loss:2.48310264331524\n",
      "train loss:2.412951631603164\n",
      "=== epoch:44, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.3947761446103795\n",
      "train loss:2.46474212462217\n",
      "train loss:2.4435698250252753\n",
      "train loss:2.448879635228695\n",
      "=== epoch:45, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4639219646986374\n",
      "train loss:2.418095606304305\n",
      "train loss:2.3915809308615263\n",
      "train loss:2.43833076397991\n",
      "=== epoch:46, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.486882791742873\n",
      "train loss:2.4142548015856757\n",
      "train loss:2.401882286235731\n",
      "train loss:2.48254520378021\n",
      "=== epoch:47, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4219998164304575\n",
      "train loss:2.3912331144021794\n",
      "train loss:2.418023275546263\n",
      "train loss:2.4745408571486496\n",
      "=== epoch:48, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.438432455999494\n",
      "train loss:2.382912509632245\n",
      "train loss:2.4414766419167133\n",
      "train loss:2.480202409443206\n",
      "=== epoch:49, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.4792012492090127\n",
      "train loss:2.391134768942854\n",
      "train loss:2.4941307014830865\n",
      "train loss:2.4088280795305845\n",
      "=== epoch:50, train acc:0.075, test acc:0.06 ===\n",
      "train loss:2.52169502809839\n",
      "train loss:2.44229088698591\n",
      "train loss:2.4545855549177267\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.06\n",
      "val_acc: 0.0600 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.366103541692417\n",
      "=== epoch:1, train acc:0.11, test acc:0.09 ===\n",
      "train loss:2.4322003762381024\n",
      "train loss:2.3778875747686072\n",
      "train loss:2.4139323074150716\n",
      "train loss:2.384380635629545\n",
      "=== epoch:2, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3433619867652378\n",
      "train loss:2.3089786162276376\n",
      "train loss:2.299202214891429\n",
      "train loss:2.347946101552312\n",
      "=== epoch:3, train acc:0.1325, test acc:0.1 ===\n",
      "train loss:2.3392194545415155\n",
      "train loss:2.3274418357515128\n",
      "train loss:2.2548169948778347\n",
      "train loss:2.305780340553141\n",
      "=== epoch:4, train acc:0.155, test acc:0.11 ===\n",
      "train loss:2.3711404670269927\n",
      "train loss:2.3770397013617313\n",
      "train loss:2.2756481026155746\n",
      "train loss:2.3188361948535965\n",
      "=== epoch:5, train acc:0.165, test acc:0.12 ===\n",
      "train loss:2.255823336523431\n",
      "train loss:2.3267050719517743\n",
      "train loss:2.2847105223155273\n",
      "train loss:2.3353167016405094\n",
      "=== epoch:6, train acc:0.1775, test acc:0.13 ===\n",
      "train loss:2.250855417598574\n",
      "train loss:2.2523204752433146\n",
      "train loss:2.231229843451695\n",
      "train loss:2.2567470918088834\n",
      "=== epoch:7, train acc:0.1875, test acc:0.14 ===\n",
      "train loss:2.2634618611928987\n",
      "train loss:2.2205751298490295\n",
      "train loss:2.2698276202536958\n",
      "train loss:2.244106474364875\n",
      "=== epoch:8, train acc:0.2025, test acc:0.15 ===\n",
      "train loss:2.243370002156061\n",
      "train loss:2.210156803010228\n",
      "train loss:2.281318900081099\n",
      "train loss:2.3108439669433047\n",
      "=== epoch:9, train acc:0.215, test acc:0.17 ===\n",
      "train loss:2.2582821199462937\n",
      "train loss:2.243854149076976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.222581698717487\n",
      "train loss:2.152386923921761\n",
      "=== epoch:10, train acc:0.22, test acc:0.17 ===\n",
      "train loss:2.1462640798246246\n",
      "train loss:2.177129922311693\n",
      "train loss:2.204280129221161\n",
      "train loss:2.2406499761876213\n",
      "=== epoch:11, train acc:0.225, test acc:0.17 ===\n",
      "train loss:2.2158647916033236\n",
      "train loss:2.203752864170837\n",
      "train loss:2.1320305686524232\n",
      "train loss:2.229894851655743\n",
      "=== epoch:12, train acc:0.2375, test acc:0.18 ===\n",
      "train loss:2.2075997182028964\n",
      "train loss:2.1131609307298715\n",
      "train loss:2.2559508028261837\n",
      "train loss:2.196408163395253\n",
      "=== epoch:13, train acc:0.2375, test acc:0.18 ===\n",
      "train loss:2.19871184127696\n",
      "train loss:2.084780400164815\n",
      "train loss:2.217214854028768\n",
      "train loss:2.1534727945453085\n",
      "=== epoch:14, train acc:0.2475, test acc:0.16 ===\n",
      "train loss:2.170526412937269\n",
      "train loss:2.172419670609888\n",
      "train loss:2.1577243899428833\n",
      "train loss:2.184331336796706\n",
      "=== epoch:15, train acc:0.25, test acc:0.18 ===\n",
      "train loss:2.142203639199541\n",
      "train loss:2.128915879768536\n",
      "train loss:2.139581087568472\n",
      "train loss:2.1522979076388506\n",
      "=== epoch:16, train acc:0.25, test acc:0.19 ===\n",
      "train loss:2.1688460398798712\n",
      "train loss:2.0659689802542966\n",
      "train loss:2.0691650709433036\n",
      "train loss:2.0988852199165446\n",
      "=== epoch:17, train acc:0.265, test acc:0.19 ===\n",
      "train loss:2.0859522561695623\n",
      "train loss:2.0676984179512288\n",
      "train loss:2.052080573190496\n",
      "train loss:2.0874511218126948\n",
      "=== epoch:18, train acc:0.2775, test acc:0.18 ===\n",
      "train loss:2.051234320224843\n",
      "train loss:2.142501655634987\n",
      "train loss:2.0741659449766088\n",
      "train loss:2.125521378875743\n",
      "=== epoch:19, train acc:0.2775, test acc:0.18 ===\n",
      "train loss:2.025059080313725\n",
      "train loss:2.050936450811184\n",
      "train loss:2.000513870774209\n",
      "train loss:2.030700023617749\n",
      "=== epoch:20, train acc:0.295, test acc:0.18 ===\n",
      "train loss:2.0400812144227025\n",
      "train loss:2.0439587254358726\n",
      "train loss:2.0311884888089393\n",
      "train loss:2.0748432494376345\n",
      "=== epoch:21, train acc:0.3, test acc:0.18 ===\n",
      "train loss:1.9650822457651052\n",
      "train loss:1.9840995448105048\n",
      "train loss:2.0072936925884726\n",
      "train loss:1.995575684254566\n",
      "=== epoch:22, train acc:0.3, test acc:0.2 ===\n",
      "train loss:2.0569128211525656\n",
      "train loss:2.0111687259347564\n",
      "train loss:1.9967341904737266\n",
      "train loss:1.9108127018358367\n",
      "=== epoch:23, train acc:0.3125, test acc:0.19 ===\n",
      "train loss:2.0048662525777465\n",
      "train loss:2.0099400219429673\n",
      "train loss:2.0327096936090667\n",
      "train loss:1.995323290844548\n",
      "=== epoch:24, train acc:0.3375, test acc:0.2 ===\n",
      "train loss:1.9715126489711627\n",
      "train loss:1.9942566797511767\n",
      "train loss:1.9035637152388363\n",
      "train loss:2.0482743693208136\n",
      "=== epoch:25, train acc:0.3575, test acc:0.21 ===\n",
      "train loss:1.8733485294139827\n",
      "train loss:1.9549220933315095\n",
      "train loss:2.011541604601436\n",
      "train loss:1.9828774651069563\n",
      "=== epoch:26, train acc:0.38, test acc:0.24 ===\n",
      "train loss:1.9315615266333246\n",
      "train loss:1.9257130925740369\n",
      "train loss:2.0331542928255923\n",
      "train loss:1.9061745168886342\n",
      "=== epoch:27, train acc:0.395, test acc:0.27 ===\n",
      "train loss:1.9522351724212923\n",
      "train loss:2.003085494728951\n",
      "train loss:1.945354473979543\n",
      "train loss:1.960123172807271\n",
      "=== epoch:28, train acc:0.4075, test acc:0.27 ===\n",
      "train loss:1.8951078799684333\n",
      "train loss:1.950373515576045\n",
      "train loss:1.9376151563422104\n",
      "train loss:1.9148183266286376\n",
      "=== epoch:29, train acc:0.4225, test acc:0.27 ===\n",
      "train loss:1.9308090141504515\n",
      "train loss:1.8991739959528164\n",
      "train loss:1.964746696000103\n",
      "train loss:1.9162076142576616\n",
      "=== epoch:30, train acc:0.435, test acc:0.29 ===\n",
      "train loss:1.9737190179118378\n",
      "train loss:1.8146431893841553\n",
      "train loss:1.898181782140187\n",
      "train loss:1.8453445556263357\n",
      "=== epoch:31, train acc:0.44, test acc:0.28 ===\n",
      "train loss:1.9595885214206628\n",
      "train loss:1.8658127141075866\n",
      "train loss:1.890606570086045\n",
      "train loss:1.911912864097209\n",
      "=== epoch:32, train acc:0.455, test acc:0.32 ===\n",
      "train loss:1.9027757692844194\n",
      "train loss:1.822522350660894\n",
      "train loss:1.961051153721798\n",
      "train loss:1.8994995642442398\n",
      "=== epoch:33, train acc:0.4725, test acc:0.34 ===\n",
      "train loss:1.8660219239917755\n",
      "train loss:1.8757108981988933\n",
      "train loss:1.760664303386962\n",
      "train loss:1.8609647894786272\n",
      "=== epoch:34, train acc:0.4875, test acc:0.35 ===\n",
      "train loss:1.996954412158612\n",
      "train loss:1.8456524279223057\n",
      "train loss:1.8550527029747117\n",
      "train loss:1.794452885901874\n",
      "=== epoch:35, train acc:0.5025, test acc:0.36 ===\n",
      "train loss:1.8420863796429523\n",
      "train loss:1.7530943018800778\n",
      "train loss:1.8287239394741304\n",
      "train loss:1.7777163358211179\n",
      "=== epoch:36, train acc:0.5275, test acc:0.36 ===\n",
      "train loss:1.8807468994588121\n",
      "train loss:1.825019661303985\n",
      "train loss:1.8778790782053294\n",
      "train loss:1.7553670293547474\n",
      "=== epoch:37, train acc:0.545, test acc:0.37 ===\n",
      "train loss:1.818798394000353\n",
      "train loss:1.8249585622502869\n",
      "train loss:1.7465020614413078\n",
      "train loss:1.777993028690496\n",
      "=== epoch:38, train acc:0.565, test acc:0.41 ===\n",
      "train loss:1.7111688804354843\n",
      "train loss:1.7228654268290686\n",
      "train loss:1.734048622519556\n",
      "train loss:1.775927085251577\n",
      "=== epoch:39, train acc:0.58, test acc:0.46 ===\n",
      "train loss:1.7925332265812743\n",
      "train loss:1.722232262506187\n",
      "train loss:1.8089793744208829\n",
      "train loss:1.6869878062119645\n",
      "=== epoch:40, train acc:0.6, test acc:0.46 ===\n",
      "train loss:1.7025091151031577\n",
      "train loss:1.7112450584645014\n",
      "train loss:1.8097099811216069\n",
      "train loss:1.7331315992391316\n",
      "=== epoch:41, train acc:0.6175, test acc:0.5 ===\n",
      "train loss:1.7603535746730812\n",
      "train loss:1.7264507434228096\n",
      "train loss:1.7456018607817048\n",
      "train loss:1.7298056236462944\n",
      "=== epoch:42, train acc:0.62, test acc:0.51 ===\n",
      "train loss:1.7115529122621356\n",
      "train loss:1.7694014076837847\n",
      "train loss:1.8283850075118853\n",
      "train loss:1.798610060233501\n",
      "=== epoch:43, train acc:0.635, test acc:0.52 ===\n",
      "train loss:1.5862020219221447\n",
      "train loss:1.6866127928228714\n",
      "train loss:1.754093628332775\n",
      "train loss:1.5743320222939272\n",
      "=== epoch:44, train acc:0.64, test acc:0.52 ===\n",
      "train loss:1.6806690071718136\n",
      "train loss:1.6352391886833508\n",
      "train loss:1.6463076059380295\n",
      "train loss:1.6042497935035842\n",
      "=== epoch:45, train acc:0.6325, test acc:0.54 ===\n",
      "train loss:1.6405281140611208\n",
      "train loss:1.7016332462072457\n",
      "train loss:1.603166518304869\n",
      "train loss:1.5472011109580457\n",
      "=== epoch:46, train acc:0.6425, test acc:0.57 ===\n",
      "train loss:1.6428759862497222\n",
      "train loss:1.5856328810855014\n",
      "train loss:1.4780574772752793\n",
      "train loss:1.5802736361889462\n",
      "=== epoch:47, train acc:0.6625, test acc:0.57 ===\n",
      "train loss:1.5846486722362985\n",
      "train loss:1.6093298047528688\n",
      "train loss:1.6288995586015562\n",
      "train loss:1.5546109730070485\n",
      "=== epoch:48, train acc:0.68, test acc:0.57 ===\n",
      "train loss:1.539325868379008\n",
      "train loss:1.5013606058454703\n",
      "train loss:1.5840904452358098\n",
      "train loss:1.5121184932728922\n",
      "=== epoch:49, train acc:0.6725, test acc:0.56 ===\n",
      "train loss:1.4400983894368433\n",
      "train loss:1.5187821885390949\n",
      "train loss:1.542621102017243\n",
      "train loss:1.5872341390086946\n",
      "=== epoch:50, train acc:0.6625, test acc:0.6 ===\n",
      "train loss:1.539142175410202\n",
      "train loss:1.5405863025584254\n",
      "train loss:1.4729098121528925\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.58\n",
      "val_acc: 0.6000 | lr: 0.0033, weight_decay: 0.0000\n",
      "train loss:2.401468222092941\n",
      "=== epoch:1, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.4103648677715555\n",
      "train loss:2.299424688790035\n",
      "train loss:2.3452745521582896\n",
      "train loss:2.393109770110531\n",
      "=== epoch:2, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.311788059682077\n",
      "train loss:2.2823606582772933\n",
      "train loss:2.338830411364815\n",
      "train loss:2.33508890275234\n",
      "=== epoch:3, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.2794193088629666\n",
      "train loss:2.438390357043543\n",
      "train loss:2.4150000601020474\n",
      "train loss:2.321238286702039\n",
      "=== epoch:4, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.440168508290229\n",
      "train loss:2.384917911102157\n",
      "train loss:2.434400016453543\n",
      "train loss:2.3942262009649804\n",
      "=== epoch:5, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.4085257480138926\n",
      "train loss:2.350623759234724\n",
      "train loss:2.342662333849005\n",
      "train loss:2.4147140638563642\n",
      "=== epoch:6, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.483962802238811\n",
      "train loss:2.415100944535286\n",
      "train loss:2.2966435125486053\n",
      "train loss:2.2588260558678996\n",
      "=== epoch:7, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3509912776010915\n",
      "train loss:2.40647620093532\n",
      "train loss:2.318972353202217\n",
      "train loss:2.3809604272946023\n",
      "=== epoch:8, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3299746721817116\n",
      "train loss:2.4034637389572184\n",
      "train loss:2.3686002555357843\n",
      "train loss:2.369967328073985\n",
      "=== epoch:9, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3592002469268794\n",
      "train loss:2.3892426492986276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4778810449453745\n",
      "train loss:2.385237428424307\n",
      "=== epoch:10, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3857099232965226\n",
      "train loss:2.3412997840053\n",
      "train loss:2.369945184508634\n",
      "train loss:2.4478324665420637\n",
      "=== epoch:11, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.399153044060499\n",
      "train loss:2.408983515598033\n",
      "train loss:2.2961731723433942\n",
      "train loss:2.3734753827778325\n",
      "=== epoch:12, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3817179280173497\n",
      "train loss:2.2587498867325713\n",
      "train loss:2.4061014266585987\n",
      "train loss:2.3189033684691123\n",
      "=== epoch:13, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.4305589377049768\n",
      "train loss:2.3937718915896977\n",
      "train loss:2.329614028794413\n",
      "train loss:2.3727455027903455\n",
      "=== epoch:14, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3806248223820083\n",
      "train loss:2.3949036277539033\n",
      "train loss:2.3544888354833327\n",
      "train loss:2.346177235643265\n",
      "=== epoch:15, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.312177778138255\n",
      "train loss:2.3616762093340875\n",
      "train loss:2.34077867474732\n",
      "train loss:2.366833349112259\n",
      "=== epoch:16, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.405723238401588\n",
      "train loss:2.355419274928086\n",
      "train loss:2.3807029003356974\n",
      "train loss:2.38313316221569\n",
      "=== epoch:17, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.39677756743539\n",
      "train loss:2.388463292896784\n",
      "train loss:2.3604811882011547\n",
      "train loss:2.3315776904544077\n",
      "=== epoch:18, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.4386515823860493\n",
      "train loss:2.365255559608519\n",
      "train loss:2.4152286094019675\n",
      "train loss:2.371130031897719\n",
      "=== epoch:19, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.2723965249249636\n",
      "train loss:2.4084451084107714\n",
      "train loss:2.342380003743392\n",
      "train loss:2.446172762184988\n",
      "=== epoch:20, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.371217005949649\n",
      "train loss:2.3506600902276973\n",
      "train loss:2.348439602957325\n",
      "train loss:2.3357338702202117\n",
      "=== epoch:21, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.354860520103712\n",
      "train loss:2.3361191582525063\n",
      "train loss:2.328855700121399\n",
      "train loss:2.344566784203508\n",
      "=== epoch:22, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.2899969206589366\n",
      "train loss:2.336226901866842\n",
      "train loss:2.3982097844563306\n",
      "train loss:2.341640058557678\n",
      "=== epoch:23, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.247059692801197\n",
      "train loss:2.2819453504805463\n",
      "train loss:2.4100437049167676\n",
      "train loss:2.331388712559123\n",
      "=== epoch:24, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.378228183293165\n",
      "train loss:2.3576948514332305\n",
      "train loss:2.34333535893\n",
      "train loss:2.3551643965626496\n",
      "=== epoch:25, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.3291280907551735\n",
      "train loss:2.38502118756184\n",
      "train loss:2.4084376961702065\n",
      "train loss:2.380758429814899\n",
      "=== epoch:26, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.3585038286456355\n",
      "train loss:2.323268898241635\n",
      "train loss:2.3513685753551874\n",
      "train loss:2.308246133913382\n",
      "=== epoch:27, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.4131421165525686\n",
      "train loss:2.381607641836535\n",
      "train loss:2.3244041981516657\n",
      "train loss:2.375398788769869\n",
      "=== epoch:28, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.3266531535780395\n",
      "train loss:2.3596059794265076\n",
      "train loss:2.3752788240094276\n",
      "train loss:2.356700875009743\n",
      "=== epoch:29, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.318067811722322\n",
      "train loss:2.401056876785653\n",
      "train loss:2.3258246028037233\n",
      "train loss:2.3249568997097345\n",
      "=== epoch:30, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.3277392961518766\n",
      "train loss:2.332536103242639\n",
      "train loss:2.376048292535783\n",
      "train loss:2.3596794752071153\n",
      "=== epoch:31, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.323229846339757\n",
      "train loss:2.2746414251451283\n",
      "train loss:2.3575752854448564\n",
      "train loss:2.3959527041645763\n",
      "=== epoch:32, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.321500589194886\n",
      "train loss:2.378107149710254\n",
      "train loss:2.321914128290008\n",
      "train loss:2.398922919661545\n",
      "=== epoch:33, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.384675864862049\n",
      "train loss:2.358635473980033\n",
      "train loss:2.3660008117186853\n",
      "train loss:2.285918160051283\n",
      "=== epoch:34, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.3715331322258786\n",
      "train loss:2.346438660870819\n",
      "train loss:2.3784454391803345\n",
      "train loss:2.277688386537242\n",
      "=== epoch:35, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.3349586385252663\n",
      "train loss:2.3629165123362954\n",
      "train loss:2.4033344209769583\n",
      "train loss:2.3521533397977987\n",
      "=== epoch:36, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.3463039625030624\n",
      "train loss:2.380565461332634\n",
      "train loss:2.368004632904678\n",
      "train loss:2.3780235683098274\n",
      "=== epoch:37, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.343658748752842\n",
      "train loss:2.2725442134969445\n",
      "train loss:2.3453003603529248\n",
      "train loss:2.343163308519118\n",
      "=== epoch:38, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.321028482225716\n",
      "train loss:2.4116163214627995\n",
      "train loss:2.3592195183747786\n",
      "train loss:2.3884714051133193\n",
      "=== epoch:39, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.3520319694002128\n",
      "train loss:2.306273102731389\n",
      "train loss:2.3229222718325566\n",
      "train loss:2.3386107474729756\n",
      "=== epoch:40, train acc:0.1175, test acc:0.12 ===\n",
      "train loss:2.328638542572283\n",
      "train loss:2.3612481335274453\n",
      "train loss:2.3270308577255956\n",
      "train loss:2.39964445410851\n",
      "=== epoch:41, train acc:0.1175, test acc:0.12 ===\n",
      "train loss:2.369458648659084\n",
      "train loss:2.2954819878814607\n",
      "train loss:2.3429838674126664\n",
      "train loss:2.379157476566648\n",
      "=== epoch:42, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.336792780383251\n",
      "train loss:2.3474134449451634\n",
      "train loss:2.2689832431150827\n",
      "train loss:2.3101839635174772\n",
      "=== epoch:43, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3091673897892755\n",
      "train loss:2.3410144736105107\n",
      "train loss:2.335512532000766\n",
      "train loss:2.371154642162277\n",
      "=== epoch:44, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3534560785870466\n",
      "train loss:2.351912488495103\n",
      "train loss:2.323183763142063\n",
      "train loss:2.291727905136101\n",
      "=== epoch:45, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3225336379081263\n",
      "train loss:2.381153050247735\n",
      "train loss:2.347350699654717\n",
      "train loss:2.344735695026888\n",
      "=== epoch:46, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3928280963662614\n",
      "train loss:2.3650290761323363\n",
      "train loss:2.3266792984568627\n",
      "train loss:2.4116585082320694\n",
      "=== epoch:47, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.309529855605866\n",
      "train loss:2.3677765107489326\n",
      "train loss:2.321821049116993\n",
      "train loss:2.3674011010904015\n",
      "=== epoch:48, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.3573553881605678\n",
      "train loss:2.3296342761432824\n",
      "train loss:2.328762101249945\n",
      "train loss:2.339449701162446\n",
      "=== epoch:49, train acc:0.1175, test acc:0.12 ===\n",
      "train loss:2.299085177988437\n",
      "train loss:2.3407764762967154\n",
      "train loss:2.323852800013369\n",
      "train loss:2.2877349414960815\n",
      "=== epoch:50, train acc:0.1175, test acc:0.12 ===\n",
      "train loss:2.3069231969102915\n",
      "train loss:2.354821149519086\n",
      "train loss:2.319323676516441\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0002, weight_decay: 0.0000\n",
      "train loss:2.3453764257621508\n",
      "=== epoch:1, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.312308744851217\n",
      "train loss:2.3229660584403926\n",
      "train loss:2.360243867385856\n",
      "train loss:2.3225913273410623\n",
      "=== epoch:2, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.311796389667734\n",
      "train loss:2.336266098742763\n",
      "train loss:2.317281389226374\n",
      "train loss:2.295280994218031\n",
      "=== epoch:3, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.3679514146631604\n",
      "train loss:2.359199932849225\n",
      "train loss:2.317704559666147\n",
      "train loss:2.306930560068329\n",
      "=== epoch:4, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.332489182798694\n",
      "train loss:2.32541410996011\n",
      "train loss:2.311646982876472\n",
      "train loss:2.3127463224773663\n",
      "=== epoch:5, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.376733755136972\n",
      "train loss:2.3222353804552602\n",
      "train loss:2.3519493430165856\n",
      "train loss:2.2968188004672836\n",
      "=== epoch:6, train acc:0.105, test acc:0.06 ===\n",
      "train loss:2.335279162484109\n",
      "train loss:2.33374474092435\n",
      "train loss:2.3232158227147837\n",
      "train loss:2.298438447570964\n",
      "=== epoch:7, train acc:0.105, test acc:0.06 ===\n",
      "train loss:2.34757442570143\n",
      "train loss:2.3530276001810946\n",
      "train loss:2.3212561198185893\n",
      "train loss:2.379275812447335\n",
      "=== epoch:8, train acc:0.105, test acc:0.06 ===\n",
      "train loss:2.3544261255095495\n",
      "train loss:2.311961876441563\n",
      "train loss:2.3731323170007737\n",
      "train loss:2.3395322761376893\n",
      "=== epoch:9, train acc:0.105, test acc:0.06 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.296792750566866\n",
      "train loss:2.332086871962623\n",
      "train loss:2.325840616539797\n",
      "train loss:2.3237112741882924\n",
      "=== epoch:10, train acc:0.1075, test acc:0.06 ===\n",
      "train loss:2.2490192870461536\n",
      "train loss:2.2988350301271545\n",
      "train loss:2.366746777156823\n",
      "train loss:2.3270166979530837\n",
      "=== epoch:11, train acc:0.105, test acc:0.06 ===\n",
      "train loss:2.3507188516765303\n",
      "train loss:2.2738964884269124\n",
      "train loss:2.2636279375408987\n",
      "train loss:2.3025145471707917\n",
      "=== epoch:12, train acc:0.1075, test acc:0.07 ===\n",
      "train loss:2.3520122500773954\n",
      "train loss:2.214563280603911\n",
      "train loss:2.3578587942893776\n",
      "train loss:2.2987119689354967\n",
      "=== epoch:13, train acc:0.11, test acc:0.07 ===\n",
      "train loss:2.3302738653247794\n",
      "train loss:2.3144870099565353\n",
      "train loss:2.3498555949619377\n",
      "train loss:2.2908126306689462\n",
      "=== epoch:14, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.2511526022008703\n",
      "train loss:2.367481632970972\n",
      "train loss:2.30095581972813\n",
      "train loss:2.2451943287885263\n",
      "=== epoch:15, train acc:0.1125, test acc:0.08 ===\n",
      "train loss:2.2686018155752223\n",
      "train loss:2.3252835053496526\n",
      "train loss:2.304047667248619\n",
      "train loss:2.3282812587714448\n",
      "=== epoch:16, train acc:0.1125, test acc:0.08 ===\n",
      "train loss:2.2324524442786533\n",
      "train loss:2.3268411079951186\n",
      "train loss:2.303623062964739\n",
      "train loss:2.2571693746074777\n",
      "=== epoch:17, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.30294854892703\n",
      "train loss:2.326499380309575\n",
      "train loss:2.2570949313288344\n",
      "train loss:2.29089505371424\n",
      "=== epoch:18, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.3198026464100305\n",
      "train loss:2.252209130424627\n",
      "train loss:2.3378944229783096\n",
      "train loss:2.294686933483644\n",
      "=== epoch:19, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.241205706409448\n",
      "train loss:2.3283145302246426\n",
      "train loss:2.295410666123389\n",
      "train loss:2.228762923092882\n",
      "=== epoch:20, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.281530662102314\n",
      "train loss:2.265190099455862\n",
      "train loss:2.3281387093953203\n",
      "train loss:2.313807774731635\n",
      "=== epoch:21, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3211146956683253\n",
      "train loss:2.2050625596580353\n",
      "train loss:2.32651803661283\n",
      "train loss:2.2641642136643174\n",
      "=== epoch:22, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.2385293612340096\n",
      "train loss:2.2658024182439487\n",
      "train loss:2.310890939853052\n",
      "train loss:2.2431648722236566\n",
      "=== epoch:23, train acc:0.11, test acc:0.09 ===\n",
      "train loss:2.297956477563327\n",
      "train loss:2.2312986456100083\n",
      "train loss:2.286373321072233\n",
      "train loss:2.339191732974899\n",
      "=== epoch:24, train acc:0.11, test acc:0.09 ===\n",
      "train loss:2.348927619090896\n",
      "train loss:2.2682991021329846\n",
      "train loss:2.325284118985756\n",
      "train loss:2.315890680494615\n",
      "=== epoch:25, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.2876382223507155\n",
      "train loss:2.265925716462641\n",
      "train loss:2.2950414543900464\n",
      "train loss:2.3158928308844238\n",
      "=== epoch:26, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.230262321396059\n",
      "train loss:2.2382924592681785\n",
      "train loss:2.285719904842765\n",
      "train loss:2.2646636614082376\n",
      "=== epoch:27, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.3117643756606996\n",
      "train loss:2.3203090690002734\n",
      "train loss:2.307619713278122\n",
      "train loss:2.273115628361694\n",
      "=== epoch:28, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.241533079742048\n",
      "train loss:2.306021279791895\n",
      "train loss:2.2879509875591593\n",
      "train loss:2.2612173760227505\n",
      "=== epoch:29, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.31433318539161\n",
      "train loss:2.2427979103898337\n",
      "train loss:2.31249091012249\n",
      "train loss:2.28185140258034\n",
      "=== epoch:30, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.3230449684467387\n",
      "train loss:2.2381849597901953\n",
      "train loss:2.2610026965425987\n",
      "train loss:2.286006145538314\n",
      "=== epoch:31, train acc:0.12, test acc:0.09 ===\n",
      "train loss:2.2761597716112294\n",
      "train loss:2.2387475786325157\n",
      "train loss:2.2352855963349367\n",
      "train loss:2.2973599737735166\n",
      "=== epoch:32, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.278341388597858\n",
      "train loss:2.235070689083594\n",
      "train loss:2.270566929255422\n",
      "train loss:2.2308681057740944\n",
      "=== epoch:33, train acc:0.1225, test acc:0.1 ===\n",
      "train loss:2.253677523640511\n",
      "train loss:2.2689781130197484\n",
      "train loss:2.25891813490371\n",
      "train loss:2.2993359012177126\n",
      "=== epoch:34, train acc:0.1275, test acc:0.1 ===\n",
      "train loss:2.3022905726078973\n",
      "train loss:2.2591993859196973\n",
      "train loss:2.2690174927520537\n",
      "train loss:2.2649058388817997\n",
      "=== epoch:35, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.2842290354075643\n",
      "train loss:2.2410919580652413\n",
      "train loss:2.2649918304439587\n",
      "train loss:2.290599331527338\n",
      "=== epoch:36, train acc:0.1375, test acc:0.09 ===\n",
      "train loss:2.241763538020984\n",
      "train loss:2.2717820551831482\n",
      "train loss:2.2524763873969516\n",
      "train loss:2.258199381551875\n",
      "=== epoch:37, train acc:0.14, test acc:0.09 ===\n",
      "train loss:2.272202468419211\n",
      "train loss:2.302490690199644\n",
      "train loss:2.2170464661542475\n",
      "train loss:2.2344409610811615\n",
      "=== epoch:38, train acc:0.1375, test acc:0.09 ===\n",
      "train loss:2.25385661827314\n",
      "train loss:2.2405847744271745\n",
      "train loss:2.3336192073537947\n",
      "train loss:2.266589296966246\n",
      "=== epoch:39, train acc:0.14, test acc:0.09 ===\n",
      "train loss:2.2126903680777783\n",
      "train loss:2.2178117288096084\n",
      "train loss:2.284036277885487\n",
      "train loss:2.2701724417649016\n",
      "=== epoch:40, train acc:0.145, test acc:0.09 ===\n",
      "train loss:2.2695860208252494\n",
      "train loss:2.24718451522539\n",
      "train loss:2.2815673438826303\n",
      "train loss:2.215648149710734\n",
      "=== epoch:41, train acc:0.145, test acc:0.09 ===\n",
      "train loss:2.248983914497412\n",
      "train loss:2.241064868775517\n",
      "train loss:2.2622990040054276\n",
      "train loss:2.2411854696367053\n",
      "=== epoch:42, train acc:0.1475, test acc:0.09 ===\n",
      "train loss:2.2677936420765663\n",
      "train loss:2.2222467251144162\n",
      "train loss:2.2126343544058016\n",
      "train loss:2.2277329738709\n",
      "=== epoch:43, train acc:0.15, test acc:0.11 ===\n",
      "train loss:2.3023266171130987\n",
      "train loss:2.2285377842896503\n",
      "train loss:2.21060496445996\n",
      "train loss:2.257527023056977\n",
      "=== epoch:44, train acc:0.1525, test acc:0.11 ===\n",
      "train loss:2.1964306665544373\n",
      "train loss:2.241538582001697\n",
      "train loss:2.2652324875921086\n",
      "train loss:2.2385139913236327\n",
      "=== epoch:45, train acc:0.15, test acc:0.11 ===\n",
      "train loss:2.2273309399068264\n",
      "train loss:2.2945170874408833\n",
      "train loss:2.2158450285775317\n",
      "train loss:2.2912288598898214\n",
      "=== epoch:46, train acc:0.1575, test acc:0.11 ===\n",
      "train loss:2.2290235417965203\n",
      "train loss:2.2755703179004363\n",
      "train loss:2.2422025008112616\n",
      "train loss:2.293940037301373\n",
      "=== epoch:47, train acc:0.1575, test acc:0.11 ===\n",
      "train loss:2.2455522971541146\n",
      "train loss:2.2122590472157353\n",
      "train loss:2.280890053027226\n",
      "train loss:2.2638567215774796\n",
      "=== epoch:48, train acc:0.16, test acc:0.12 ===\n",
      "train loss:2.256660127475703\n",
      "train loss:2.254292654446848\n",
      "train loss:2.2600390885538353\n",
      "train loss:2.2127330723494625\n",
      "=== epoch:49, train acc:0.1625, test acc:0.12 ===\n",
      "train loss:2.2048133916482895\n",
      "train loss:2.2073048061476306\n",
      "train loss:2.2529520138001065\n",
      "train loss:2.270556048939678\n",
      "=== epoch:50, train acc:0.16, test acc:0.13 ===\n",
      "train loss:2.2505185575190336\n",
      "train loss:2.231269947362857\n",
      "train loss:2.2196829834926635\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.14\n",
      "val_acc: 0.1300 | lr: 0.0006, weight_decay: 0.0000\n",
      "train loss:2.2747440297184025\n",
      "=== epoch:1, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.3617312637019006\n",
      "train loss:2.380570305024938\n",
      "train loss:2.327666861458414\n",
      "train loss:2.382392586638069\n",
      "=== epoch:2, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.3703523192400238\n",
      "train loss:2.2733973761809065\n",
      "train loss:2.335081197043273\n",
      "train loss:2.3436090550092703\n",
      "=== epoch:3, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.308268421381803\n",
      "train loss:2.2909515197872246\n",
      "train loss:2.3513416223655934\n",
      "train loss:2.297641986306208\n",
      "=== epoch:4, train acc:0.125, test acc:0.21 ===\n",
      "train loss:2.343654752305027\n",
      "train loss:2.3131783062285285\n",
      "train loss:2.2553409137134297\n",
      "train loss:2.3059908015255286\n",
      "=== epoch:5, train acc:0.13, test acc:0.21 ===\n",
      "train loss:2.34682965601114\n",
      "train loss:2.3087114105863527\n",
      "train loss:2.3368753157428834\n",
      "train loss:2.3197451192217673\n",
      "=== epoch:6, train acc:0.1325, test acc:0.22 ===\n",
      "train loss:2.2469318299312913\n",
      "train loss:2.2722877410239315\n",
      "train loss:2.293113611255655\n",
      "train loss:2.3278686679830534\n",
      "=== epoch:7, train acc:0.1375, test acc:0.22 ===\n",
      "train loss:2.2847552650715084\n",
      "train loss:2.3093743476878914\n",
      "train loss:2.2676082956673334\n",
      "train loss:2.2893444233855016\n",
      "=== epoch:8, train acc:0.1425, test acc:0.23 ===\n",
      "train loss:2.277966479173409\n",
      "train loss:2.3176095936455923\n",
      "train loss:2.27307382741636\n",
      "train loss:2.245916958620338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:9, train acc:0.145, test acc:0.25 ===\n",
      "train loss:2.237423152468528\n",
      "train loss:2.2639383352099522\n",
      "train loss:2.2449772505798222\n",
      "train loss:2.240201843575081\n",
      "=== epoch:10, train acc:0.1475, test acc:0.27 ===\n",
      "train loss:2.256313517387439\n",
      "train loss:2.2597830154953686\n",
      "train loss:2.2187870022926313\n",
      "train loss:2.21021139131445\n",
      "=== epoch:11, train acc:0.155, test acc:0.27 ===\n",
      "train loss:2.2066416269765936\n",
      "train loss:2.2295603843759912\n",
      "train loss:2.2498770671387196\n",
      "train loss:2.247282420919591\n",
      "=== epoch:12, train acc:0.1625, test acc:0.27 ===\n",
      "train loss:2.2273024946938964\n",
      "train loss:2.228201079255487\n",
      "train loss:2.205293653731993\n",
      "train loss:2.224058255415165\n",
      "=== epoch:13, train acc:0.175, test acc:0.27 ===\n",
      "train loss:2.2035880544735114\n",
      "train loss:2.2257644955902167\n",
      "train loss:2.2382963528163877\n",
      "train loss:2.2386161351022085\n",
      "=== epoch:14, train acc:0.1825, test acc:0.26 ===\n",
      "train loss:2.2606842634033573\n",
      "train loss:2.2133550660593566\n",
      "train loss:2.1953299894268707\n",
      "train loss:2.193480614914768\n",
      "=== epoch:15, train acc:0.1925, test acc:0.26 ===\n",
      "train loss:2.1780391939788215\n",
      "train loss:2.2270665025239604\n",
      "train loss:2.172056873421847\n",
      "train loss:2.1829872540168074\n",
      "=== epoch:16, train acc:0.2, test acc:0.28 ===\n",
      "train loss:2.2130617584012953\n",
      "train loss:2.2289758419296577\n",
      "train loss:2.1569919806299627\n",
      "train loss:2.134737013227965\n",
      "=== epoch:17, train acc:0.2025, test acc:0.28 ===\n",
      "train loss:2.189549223055143\n",
      "train loss:2.1928097839834066\n",
      "train loss:2.196953764270325\n",
      "train loss:2.1590015826838727\n",
      "=== epoch:18, train acc:0.2125, test acc:0.28 ===\n",
      "train loss:2.151610760278258\n",
      "train loss:2.2385674051167515\n",
      "train loss:2.2289391819324638\n",
      "train loss:2.220096087642627\n",
      "=== epoch:19, train acc:0.22, test acc:0.29 ===\n",
      "train loss:2.1656571261236173\n",
      "train loss:2.191569632627587\n",
      "train loss:2.1606274124755345\n",
      "train loss:2.1794671936541\n",
      "=== epoch:20, train acc:0.235, test acc:0.3 ===\n",
      "train loss:2.1531190119540735\n",
      "train loss:2.167305209990839\n",
      "train loss:2.1983636976476095\n",
      "train loss:2.1770890026812717\n",
      "=== epoch:21, train acc:0.2425, test acc:0.3 ===\n",
      "train loss:2.1451678603767954\n",
      "train loss:2.1480054621835567\n",
      "train loss:2.118586718330497\n",
      "train loss:2.1620071786495503\n",
      "=== epoch:22, train acc:0.2425, test acc:0.3 ===\n",
      "train loss:2.1820842539741676\n",
      "train loss:2.16383040976843\n",
      "train loss:2.2089282726648602\n",
      "train loss:2.164747890574951\n",
      "=== epoch:23, train acc:0.26, test acc:0.3 ===\n",
      "train loss:2.154970713511614\n",
      "train loss:2.1576543015792535\n",
      "train loss:2.106585309039733\n",
      "train loss:2.096587966029657\n",
      "=== epoch:24, train acc:0.2675, test acc:0.31 ===\n",
      "train loss:2.1688306491348524\n",
      "train loss:2.1610454184104557\n",
      "train loss:2.146249657002897\n",
      "train loss:2.166522822080144\n",
      "=== epoch:25, train acc:0.2675, test acc:0.32 ===\n",
      "train loss:2.168867354088721\n",
      "train loss:2.106220486585319\n",
      "train loss:2.1381583074164148\n",
      "train loss:2.1151679669128\n",
      "=== epoch:26, train acc:0.27, test acc:0.33 ===\n",
      "train loss:2.2001779413211398\n",
      "train loss:2.1011073691876305\n",
      "train loss:2.1116237142371133\n",
      "train loss:2.1274998285911453\n",
      "=== epoch:27, train acc:0.2725, test acc:0.33 ===\n",
      "train loss:2.080336141119235\n",
      "train loss:2.10282985315724\n",
      "train loss:2.140892451733752\n",
      "train loss:2.188967672970131\n",
      "=== epoch:28, train acc:0.275, test acc:0.34 ===\n",
      "train loss:2.1109443145667983\n",
      "train loss:2.1831097570537747\n",
      "train loss:2.202094782381818\n",
      "train loss:2.144726937395739\n",
      "=== epoch:29, train acc:0.28, test acc:0.34 ===\n",
      "train loss:2.141216712501952\n",
      "train loss:2.1105328121639872\n",
      "train loss:2.121056403885781\n",
      "train loss:2.1064664885415634\n",
      "=== epoch:30, train acc:0.295, test acc:0.35 ===\n",
      "train loss:2.0853607253223014\n",
      "train loss:2.113121868776541\n",
      "train loss:2.1490983766217004\n",
      "train loss:2.0931054404183578\n",
      "=== epoch:31, train acc:0.3, test acc:0.35 ===\n",
      "train loss:2.045282870566108\n",
      "train loss:2.1079601118813334\n",
      "train loss:2.1431264780889783\n",
      "train loss:2.1054472345831714\n",
      "=== epoch:32, train acc:0.3075, test acc:0.36 ===\n",
      "train loss:2.136297129467615\n",
      "train loss:2.0775332451568085\n",
      "train loss:2.0383664840941593\n",
      "train loss:2.092304662772118\n",
      "=== epoch:33, train acc:0.3125, test acc:0.36 ===\n",
      "train loss:2.087919753635835\n",
      "train loss:2.090526037523206\n",
      "train loss:2.144848572458432\n",
      "train loss:2.097226398621889\n",
      "=== epoch:34, train acc:0.32, test acc:0.37 ===\n",
      "train loss:2.112444712535222\n",
      "train loss:2.1129910184764875\n",
      "train loss:2.1037202837014584\n",
      "train loss:2.069479635570382\n",
      "=== epoch:35, train acc:0.33, test acc:0.39 ===\n",
      "train loss:2.0430998807552943\n",
      "train loss:2.108534741235935\n",
      "train loss:2.1004286692852046\n",
      "train loss:2.073099611130892\n",
      "=== epoch:36, train acc:0.34, test acc:0.4 ===\n",
      "train loss:2.0690536682922906\n",
      "train loss:2.126139836305567\n",
      "train loss:2.100852208919436\n",
      "train loss:2.0983381338089715\n",
      "=== epoch:37, train acc:0.355, test acc:0.4 ===\n",
      "train loss:2.0818724174797665\n",
      "train loss:2.028396377792458\n",
      "train loss:2.073721969959205\n",
      "train loss:2.093803682813953\n",
      "=== epoch:38, train acc:0.36, test acc:0.4 ===\n",
      "train loss:2.0471960944013263\n",
      "train loss:2.03360895391278\n",
      "train loss:2.1061842605818346\n",
      "train loss:2.064238410343351\n",
      "=== epoch:39, train acc:0.3675, test acc:0.4 ===\n",
      "train loss:2.065755476457735\n",
      "train loss:2.0590088546802767\n",
      "train loss:2.0595010526785082\n",
      "train loss:2.063582574242659\n",
      "=== epoch:40, train acc:0.3825, test acc:0.41 ===\n",
      "train loss:2.0655577649460053\n",
      "train loss:2.065524493977185\n",
      "train loss:2.068587754181542\n",
      "train loss:2.1011990640458706\n",
      "=== epoch:41, train acc:0.38, test acc:0.41 ===\n",
      "train loss:1.974991139000347\n",
      "train loss:2.000707643672116\n",
      "train loss:2.0585549520888504\n",
      "train loss:2.1002717568512224\n",
      "=== epoch:42, train acc:0.385, test acc:0.41 ===\n",
      "train loss:1.9845759397147127\n",
      "train loss:2.10742041833552\n",
      "train loss:2.0472538753001164\n",
      "train loss:2.0986982142750903\n",
      "=== epoch:43, train acc:0.3975, test acc:0.4 ===\n",
      "train loss:2.0415406066210604\n",
      "train loss:2.0641427146531544\n",
      "train loss:2.038166472901484\n",
      "train loss:1.9805669956785972\n",
      "=== epoch:44, train acc:0.395, test acc:0.41 ===\n",
      "train loss:1.9724969481009624\n",
      "train loss:2.0127402608217584\n",
      "train loss:1.982157681926523\n",
      "train loss:2.001201993922777\n",
      "=== epoch:45, train acc:0.4, test acc:0.41 ===\n",
      "train loss:2.016113690118981\n",
      "train loss:2.0231326256315865\n",
      "train loss:2.0084436300787414\n",
      "train loss:1.9837342679415464\n",
      "=== epoch:46, train acc:0.4075, test acc:0.4 ===\n",
      "train loss:2.019369355715379\n",
      "train loss:2.010365928339469\n",
      "train loss:2.0441562342854884\n",
      "train loss:2.039931170412499\n",
      "=== epoch:47, train acc:0.41, test acc:0.38 ===\n",
      "train loss:1.9754245511177413\n",
      "train loss:1.958815154707926\n",
      "train loss:2.017586925691325\n",
      "train loss:1.973133688050573\n",
      "=== epoch:48, train acc:0.415, test acc:0.38 ===\n",
      "train loss:1.9024311209156521\n",
      "train loss:2.0427398519762825\n",
      "train loss:2.0127845498653\n",
      "train loss:1.9768170986174762\n",
      "=== epoch:49, train acc:0.42, test acc:0.39 ===\n",
      "train loss:1.988043469072501\n",
      "train loss:1.9512588192192957\n",
      "train loss:1.9819188490499542\n",
      "train loss:1.9822375664250411\n",
      "=== epoch:50, train acc:0.425, test acc:0.4 ===\n",
      "train loss:1.9742842815510437\n",
      "train loss:1.9042342211793772\n",
      "train loss:1.962537389363902\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.4\n",
      "val_acc: 0.4000 | lr: 0.0024, weight_decay: 0.0000\n",
      "train loss:2.379011686794925\n",
      "=== epoch:1, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.33106764218307\n",
      "train loss:2.306607687437323\n",
      "train loss:2.378876340733978\n",
      "train loss:2.404575899585185\n",
      "=== epoch:2, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.434078703105722\n",
      "train loss:2.4138548959622557\n",
      "train loss:2.308753967170718\n",
      "train loss:2.39146484331017\n",
      "=== epoch:3, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.291136169997087\n",
      "train loss:2.336724799357465\n",
      "train loss:2.389064964163968\n",
      "train loss:2.364556115278364\n",
      "=== epoch:4, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.3114880127078155\n",
      "train loss:2.3255095102613494\n",
      "train loss:2.316582365121631\n",
      "train loss:2.3833889829277237\n",
      "=== epoch:5, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.318162941688221\n",
      "train loss:2.334352959819679\n",
      "train loss:2.325978156958346\n",
      "train loss:2.354990307058888\n",
      "=== epoch:6, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.3528907578516427\n",
      "train loss:2.3229096006076118\n",
      "train loss:2.313937109349871\n",
      "train loss:2.2944704673519087\n",
      "=== epoch:7, train acc:0.1275, test acc:0.09 ===\n",
      "train loss:2.408163481519754\n",
      "train loss:2.427644245765407\n",
      "train loss:2.3222487406595476\n",
      "train loss:2.38203570385569\n",
      "=== epoch:8, train acc:0.1275, test acc:0.09 ===\n",
      "train loss:2.3492623487358033\n",
      "train loss:2.4073555321065374\n",
      "train loss:2.310114694626463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4509702990595996\n",
      "=== epoch:9, train acc:0.1275, test acc:0.09 ===\n",
      "train loss:2.3944371152781923\n",
      "train loss:2.332409388480102\n",
      "train loss:2.4368249432197966\n",
      "train loss:2.4584507508370317\n",
      "=== epoch:10, train acc:0.1275, test acc:0.09 ===\n",
      "train loss:2.3479409964122517\n",
      "train loss:2.3394000628776257\n",
      "train loss:2.3582391434895427\n",
      "train loss:2.3894238790944224\n",
      "=== epoch:11, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.377300843928915\n",
      "train loss:2.362008785755569\n",
      "train loss:2.3384740263205743\n",
      "train loss:2.3823950443679682\n",
      "=== epoch:12, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.4455113591426665\n",
      "train loss:2.3622874872580377\n",
      "train loss:2.3902967520430543\n",
      "train loss:2.3412844434156113\n",
      "=== epoch:13, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.321369239868904\n",
      "train loss:2.376121942866079\n",
      "train loss:2.3475233055478295\n",
      "train loss:2.384099409371293\n",
      "=== epoch:14, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.3454455021550427\n",
      "train loss:2.342783380878349\n",
      "train loss:2.388675625602951\n",
      "train loss:2.3286172184432385\n",
      "=== epoch:15, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.2930582128892163\n",
      "train loss:2.3434700028242803\n",
      "train loss:2.4048246514509013\n",
      "train loss:2.4214860843047834\n",
      "=== epoch:16, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.347760847623758\n",
      "train loss:2.3551498854013837\n",
      "train loss:2.341670167320702\n",
      "train loss:2.3418606077177135\n",
      "=== epoch:17, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.347282565614001\n",
      "train loss:2.3884169334730747\n",
      "train loss:2.3752343891499996\n",
      "train loss:2.3978311247775697\n",
      "=== epoch:18, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.3446839100450116\n",
      "train loss:2.297667722983393\n",
      "train loss:2.357354578546559\n",
      "train loss:2.3713222163505545\n",
      "=== epoch:19, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.3345737131396325\n",
      "train loss:2.3608861227655735\n",
      "train loss:2.3518193615703846\n",
      "train loss:2.4143676303139094\n",
      "=== epoch:20, train acc:0.1275, test acc:0.08 ===\n",
      "train loss:2.3312405486022985\n",
      "train loss:2.3448945927493576\n",
      "train loss:2.3514754658396835\n",
      "train loss:2.3166031561238287\n",
      "=== epoch:21, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.390812638775287\n",
      "train loss:2.3891847628278704\n",
      "train loss:2.3411873774715453\n",
      "train loss:2.303341527321116\n",
      "=== epoch:22, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.330174841654742\n",
      "train loss:2.3388613521092902\n",
      "train loss:2.3588898947455244\n",
      "train loss:2.355815640426785\n",
      "=== epoch:23, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.3547343704154873\n",
      "train loss:2.329186440553852\n",
      "train loss:2.351423004560186\n",
      "train loss:2.4597514997841947\n",
      "=== epoch:24, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.399401304837826\n",
      "train loss:2.3777915703084016\n",
      "train loss:2.3514556590961306\n",
      "train loss:2.3536175569777806\n",
      "=== epoch:25, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.3344875482426755\n",
      "train loss:2.383670929913271\n",
      "train loss:2.3878669881347494\n",
      "train loss:2.368050691412564\n",
      "=== epoch:26, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.341924077986133\n",
      "train loss:2.4298448408017994\n",
      "train loss:2.3580332153305883\n",
      "train loss:2.354499489739931\n",
      "=== epoch:27, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.359672851344657\n",
      "train loss:2.352819261833654\n",
      "train loss:2.3963908243062884\n",
      "train loss:2.3908459788854883\n",
      "=== epoch:28, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3678276337255073\n",
      "train loss:2.305210198510906\n",
      "train loss:2.3290582453551956\n",
      "train loss:2.3469485679292523\n",
      "=== epoch:29, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.362356945569323\n",
      "train loss:2.31477573928081\n",
      "train loss:2.3220938371411406\n",
      "train loss:2.3426292237459694\n",
      "=== epoch:30, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.2741807371452945\n",
      "train loss:2.4205098186759555\n",
      "train loss:2.4265278266303625\n",
      "train loss:2.3178508422229323\n",
      "=== epoch:31, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.26039905081431\n",
      "train loss:2.358165245958794\n",
      "train loss:2.305841760677493\n",
      "train loss:2.400864693960926\n",
      "=== epoch:32, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3902024408441798\n",
      "train loss:2.3372379804346277\n",
      "train loss:2.374272593189707\n",
      "train loss:2.361642854840526\n",
      "=== epoch:33, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.373258778843768\n",
      "train loss:2.3477735227103294\n",
      "train loss:2.2902443205866096\n",
      "train loss:2.3511908829596075\n",
      "=== epoch:34, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3666091367293616\n",
      "train loss:2.358108545162707\n",
      "train loss:2.324575555329566\n",
      "train loss:2.3097378937819966\n",
      "=== epoch:35, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.342875858843182\n",
      "train loss:2.388703075362206\n",
      "train loss:2.407834971781137\n",
      "train loss:2.2985976379335065\n",
      "=== epoch:36, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.429786872353848\n",
      "train loss:2.323548982289747\n",
      "train loss:2.4068918268290456\n",
      "train loss:2.369417061653183\n",
      "=== epoch:37, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.2660554143393536\n",
      "train loss:2.422577765221411\n",
      "train loss:2.3652933662230904\n",
      "train loss:2.324480103715004\n",
      "=== epoch:38, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.343828645857339\n",
      "train loss:2.336374338260133\n",
      "train loss:2.4072404253444804\n",
      "train loss:2.414462965825968\n",
      "=== epoch:39, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.428374357536398\n",
      "train loss:2.2933375756580276\n",
      "train loss:2.26876963502049\n",
      "train loss:2.336510328393872\n",
      "=== epoch:40, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.284338901798926\n",
      "train loss:2.3475398216097565\n",
      "train loss:2.332829484350718\n",
      "train loss:2.2980368413810472\n",
      "=== epoch:41, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.3454654947083022\n",
      "train loss:2.3496574404870323\n",
      "train loss:2.2811948559661452\n",
      "train loss:2.293053905443939\n",
      "=== epoch:42, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.34824501472259\n",
      "train loss:2.2986367541629655\n",
      "train loss:2.3544587692795043\n",
      "train loss:2.343298545146815\n",
      "=== epoch:43, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.4038660100282145\n",
      "train loss:2.3755172347048537\n",
      "train loss:2.240214522098691\n",
      "train loss:2.255876678040716\n",
      "=== epoch:44, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.387802891053416\n",
      "train loss:2.2911355797789814\n",
      "train loss:2.319483193249143\n",
      "train loss:2.406651153756079\n",
      "=== epoch:45, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3979188793409265\n",
      "train loss:2.3486892019837997\n",
      "train loss:2.4268855729678775\n",
      "train loss:2.2806276561095276\n",
      "=== epoch:46, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.34385243597933\n",
      "train loss:2.2890894053852664\n",
      "train loss:2.349167638318238\n",
      "train loss:2.3855506415455103\n",
      "=== epoch:47, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3450535824076653\n",
      "train loss:2.3630716940747667\n",
      "train loss:2.2754720623640896\n",
      "train loss:2.3336268648773713\n",
      "=== epoch:48, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.361243798110937\n",
      "train loss:2.296916224953092\n",
      "train loss:2.3270165164292633\n",
      "train loss:2.288209208802686\n",
      "=== epoch:49, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.274606410888859\n",
      "train loss:2.3477167430409356\n",
      "train loss:2.4086713361849483\n",
      "train loss:2.288224590002985\n",
      "=== epoch:50, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3060269634147312\n",
      "train loss:2.3893906424452207\n",
      "train loss:2.311646488128679\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.412073936939122\n",
      "=== epoch:1, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.412895790484062\n",
      "train loss:2.3824622734238745\n",
      "train loss:2.350587164257972\n",
      "train loss:2.340268027163848\n",
      "=== epoch:2, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4107553164682534\n",
      "train loss:2.39730830378345\n",
      "train loss:2.3927689697719257\n",
      "train loss:2.3549340103233996\n",
      "=== epoch:3, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.397990659820328\n",
      "train loss:2.444007718385279\n",
      "train loss:2.405857901395969\n",
      "train loss:2.4451426174340365\n",
      "=== epoch:4, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.419378705369711\n",
      "train loss:2.385842600510594\n",
      "train loss:2.353807812511377\n",
      "train loss:2.422830335742498\n",
      "=== epoch:5, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4090879594555847\n",
      "train loss:2.4388352410028094\n",
      "train loss:2.3276668919110364\n",
      "train loss:2.3608817036544925\n",
      "=== epoch:6, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.36091786959895\n",
      "train loss:2.2847505707099383\n",
      "train loss:2.305554993981272\n",
      "train loss:2.324647591642378\n",
      "=== epoch:7, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.34431031731759\n",
      "train loss:2.3657159600218067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.349220387662653\n",
      "train loss:2.362837293780658\n",
      "=== epoch:8, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.408511991333246\n",
      "train loss:2.376513617119029\n",
      "train loss:2.374839279112973\n",
      "train loss:2.416170876465534\n",
      "=== epoch:9, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.2917935761236916\n",
      "train loss:2.4110972327748437\n",
      "train loss:2.4055269442659903\n",
      "train loss:2.365206866577499\n",
      "=== epoch:10, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3558968080054563\n",
      "train loss:2.44531725943114\n",
      "train loss:2.354315273828098\n",
      "train loss:2.3068846306615445\n",
      "=== epoch:11, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.420853935149943\n",
      "train loss:2.402010414881868\n",
      "train loss:2.3073571812265303\n",
      "train loss:2.384422118775578\n",
      "=== epoch:12, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.2835759782619394\n",
      "train loss:2.363884221153325\n",
      "train loss:2.3328927862751834\n",
      "train loss:2.401744063322882\n",
      "=== epoch:13, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.358564215811912\n",
      "train loss:2.3825515243902053\n",
      "train loss:2.3594778877472975\n",
      "train loss:2.4127027905852065\n",
      "=== epoch:14, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4730306838302356\n",
      "train loss:2.3703925862342885\n",
      "train loss:2.4131368503326143\n",
      "train loss:2.423771050505336\n",
      "=== epoch:15, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.2873930009177745\n",
      "train loss:2.351667814883053\n",
      "train loss:2.401007310392403\n",
      "train loss:2.394654166984458\n",
      "=== epoch:16, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4131946022509845\n",
      "train loss:2.409162539997737\n",
      "train loss:2.4247769792420315\n",
      "train loss:2.358230145147752\n",
      "=== epoch:17, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3025132058571414\n",
      "train loss:2.349410845292965\n",
      "train loss:2.291816993839898\n",
      "train loss:2.4091935838780802\n",
      "=== epoch:18, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.398780011128737\n",
      "train loss:2.3079432155901407\n",
      "train loss:2.435280792558514\n",
      "train loss:2.300307998206976\n",
      "=== epoch:19, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4898046312936435\n",
      "train loss:2.3679203020135353\n",
      "train loss:2.2567198151455328\n",
      "train loss:2.352009102135157\n",
      "=== epoch:20, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.293787974108947\n",
      "train loss:2.3625108785576012\n",
      "train loss:2.3523232230358575\n",
      "train loss:2.311549168907451\n",
      "=== epoch:21, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3443348956173513\n",
      "train loss:2.3505948815464563\n",
      "train loss:2.4476090396321797\n",
      "train loss:2.348415687021023\n",
      "=== epoch:22, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3693585875235113\n",
      "train loss:2.418871839149404\n",
      "train loss:2.3594844108808735\n",
      "train loss:2.3463297884674095\n",
      "=== epoch:23, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.394096040074855\n",
      "train loss:2.3811726991265343\n",
      "train loss:2.3517395631269804\n",
      "train loss:2.3790275754766466\n",
      "=== epoch:24, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.388216834396789\n",
      "train loss:2.369512414246555\n",
      "train loss:2.3847250251633443\n",
      "train loss:2.2763361491615552\n",
      "=== epoch:25, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.369783233978018\n",
      "train loss:2.3779755054461935\n",
      "train loss:2.3266405108291672\n",
      "train loss:2.447143963288005\n",
      "=== epoch:26, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3869175238624636\n",
      "train loss:2.3779163288040066\n",
      "train loss:2.411871905821119\n",
      "train loss:2.4159747412859\n",
      "=== epoch:27, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4145244175934315\n",
      "train loss:2.436846037403633\n",
      "train loss:2.38291357391012\n",
      "train loss:2.304353408624479\n",
      "=== epoch:28, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.400641773147877\n",
      "train loss:2.2643253133389822\n",
      "train loss:2.4605823986149624\n",
      "train loss:2.3729174983334125\n",
      "=== epoch:29, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3913505826469543\n",
      "train loss:2.2620369011249664\n",
      "train loss:2.3629633212109753\n",
      "train loss:2.378821054836949\n",
      "=== epoch:30, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4643481624842605\n",
      "train loss:2.3137900577072075\n",
      "train loss:2.3424799470489837\n",
      "train loss:2.4392482243545603\n",
      "=== epoch:31, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3771732822609817\n",
      "train loss:2.3987167416147526\n",
      "train loss:2.302725384378034\n",
      "train loss:2.441576492749457\n",
      "=== epoch:32, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3277873135518417\n",
      "train loss:2.327995783784577\n",
      "train loss:2.3986504911104087\n",
      "train loss:2.327339543166557\n",
      "=== epoch:33, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3030763870568722\n",
      "train loss:2.3676299699543417\n",
      "train loss:2.381670396223114\n",
      "train loss:2.388136434801697\n",
      "=== epoch:34, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3552496454853897\n",
      "train loss:2.2990327965430395\n",
      "train loss:2.4150618538062942\n",
      "train loss:2.396391678047463\n",
      "=== epoch:35, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3526427847143303\n",
      "train loss:2.455586068494713\n",
      "train loss:2.406289868911066\n",
      "train loss:2.302952166628334\n",
      "=== epoch:36, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.359812304067046\n",
      "train loss:2.3795452500725736\n",
      "train loss:2.322530919115594\n",
      "train loss:2.3142533075395457\n",
      "=== epoch:37, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4014213410995064\n",
      "train loss:2.3099966274502797\n",
      "train loss:2.307220809973034\n",
      "train loss:2.396448515408518\n",
      "=== epoch:38, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.40267576431278\n",
      "train loss:2.319201084944697\n",
      "train loss:2.322963296034769\n",
      "train loss:2.4007586716388962\n",
      "=== epoch:39, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3660709521434606\n",
      "train loss:2.382322096686217\n",
      "train loss:2.3792367926582076\n",
      "train loss:2.2728498667758377\n",
      "=== epoch:40, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3863497517704726\n",
      "train loss:2.339104227820768\n",
      "train loss:2.335963718731315\n",
      "train loss:2.4005647021309207\n",
      "=== epoch:41, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3810186457258617\n",
      "train loss:2.396634795183783\n",
      "train loss:2.3535607598043677\n",
      "train loss:2.317708845281996\n",
      "=== epoch:42, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3998786477766307\n",
      "train loss:2.353813597035693\n",
      "train loss:2.3993612348001276\n",
      "train loss:2.299422937615441\n",
      "=== epoch:43, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4185536913932277\n",
      "train loss:2.351446425379114\n",
      "train loss:2.4125336130102553\n",
      "train loss:2.396349981611869\n",
      "=== epoch:44, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3697294059151632\n",
      "train loss:2.3493610907955316\n",
      "train loss:2.302821309432385\n",
      "train loss:2.4302507858178553\n",
      "=== epoch:45, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.377402929310844\n",
      "train loss:2.3480713019979746\n",
      "train loss:2.385531739935555\n",
      "train loss:2.27861704196168\n",
      "=== epoch:46, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.326265569786333\n",
      "train loss:2.3890681455965557\n",
      "train loss:2.351040803491979\n",
      "train loss:2.3897168284237598\n",
      "=== epoch:47, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.4080750290921955\n",
      "train loss:2.4317289920005556\n",
      "train loss:2.2140437017766073\n",
      "train loss:2.335782665660206\n",
      "=== epoch:48, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.3475799386651954\n",
      "train loss:2.349197192960071\n",
      "train loss:2.3252008409990954\n",
      "train loss:2.3455124488423666\n",
      "=== epoch:49, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.404145438103308\n",
      "train loss:2.4496695406685483\n",
      "train loss:2.369198168534774\n",
      "train loss:2.3213822944208657\n",
      "=== epoch:50, train acc:0.1425, test acc:0.15 ===\n",
      "train loss:2.367947046630695\n",
      "train loss:2.3369298933360882\n",
      "train loss:2.4218412991344263\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.15\n",
      "val_acc: 0.1500 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3871656838954864\n",
      "=== epoch:1, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3857351208880613\n",
      "train loss:2.3535274413224765\n",
      "train loss:2.42131627388534\n",
      "train loss:2.4007576934939845\n",
      "=== epoch:2, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.367455435570688\n",
      "train loss:2.3633242958404024\n",
      "train loss:2.4066559510626537\n",
      "train loss:2.3862637173174575\n",
      "=== epoch:3, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3266584468378566\n",
      "train loss:2.368528402148654\n",
      "train loss:2.4198291979127116\n",
      "train loss:2.3862633938289934\n",
      "=== epoch:4, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3595634166024717\n",
      "train loss:2.391547537614123\n",
      "train loss:2.405801759531464\n",
      "train loss:2.3300236477534795\n",
      "=== epoch:5, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3129873875192293\n",
      "train loss:2.4054180862202403\n",
      "train loss:2.339056812002975\n",
      "train loss:2.3751396190463803\n",
      "=== epoch:6, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.425648967710328\n",
      "train loss:2.352618536071028\n",
      "train loss:2.3008312051983553\n",
      "train loss:2.3851973874288297\n",
      "=== epoch:7, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.358096819783517\n",
      "train loss:2.347147703511094\n",
      "train loss:2.4122540638448524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3987110114579084\n",
      "=== epoch:8, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.351854990183121\n",
      "train loss:2.3093813697946532\n",
      "train loss:2.3103927359096987\n",
      "train loss:2.408069249262665\n",
      "=== epoch:9, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.422503976306323\n",
      "train loss:2.3720355421843333\n",
      "train loss:2.4195811435814383\n",
      "train loss:2.3648143324576663\n",
      "=== epoch:10, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.403573352966388\n",
      "train loss:2.4679302870368516\n",
      "train loss:2.3253576968069147\n",
      "train loss:2.4299655058298586\n",
      "=== epoch:11, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.352929568509325\n",
      "train loss:2.39821843351515\n",
      "train loss:2.4113577311337213\n",
      "train loss:2.3603367949214715\n",
      "=== epoch:12, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3859068597422364\n",
      "train loss:2.3587430417343076\n",
      "train loss:2.4268176736265437\n",
      "train loss:2.373263165390028\n",
      "=== epoch:13, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.4120398348904715\n",
      "train loss:2.4038591051729283\n",
      "train loss:2.3635575810720506\n",
      "train loss:2.4027270508972864\n",
      "=== epoch:14, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3756271035492547\n",
      "train loss:2.3656692214493407\n",
      "train loss:2.4203467244964583\n",
      "train loss:2.3537155822008415\n",
      "=== epoch:15, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.2877062962743153\n",
      "train loss:2.3766206841127104\n",
      "train loss:2.4279875062596714\n",
      "train loss:2.4233034383261978\n",
      "=== epoch:16, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.284372430841579\n",
      "train loss:2.3540110882980816\n",
      "train loss:2.3866738904388267\n",
      "train loss:2.403146988952485\n",
      "=== epoch:17, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.321309637869431\n",
      "train loss:2.4269559461130608\n",
      "train loss:2.372222485552427\n",
      "train loss:2.3972076487422336\n",
      "=== epoch:18, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.350518101108741\n",
      "train loss:2.3602531624067438\n",
      "train loss:2.293084694073914\n",
      "train loss:2.372899703083365\n",
      "=== epoch:19, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3125096601347086\n",
      "train loss:2.387180551750634\n",
      "train loss:2.4092360356229148\n",
      "train loss:2.3938711940847575\n",
      "=== epoch:20, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3266087623474894\n",
      "train loss:2.426336195620701\n",
      "train loss:2.432634386675257\n",
      "train loss:2.3240152188448095\n",
      "=== epoch:21, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3812825257898296\n",
      "train loss:2.382779495220296\n",
      "train loss:2.438396585087409\n",
      "train loss:2.4319677166245413\n",
      "=== epoch:22, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.377087419762272\n",
      "train loss:2.4021769184065778\n",
      "train loss:2.362446099673076\n",
      "train loss:2.3858888673655008\n",
      "=== epoch:23, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3966634452961437\n",
      "train loss:2.290071989675682\n",
      "train loss:2.360122894009544\n",
      "train loss:2.3848224593351603\n",
      "=== epoch:24, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.4085314969059652\n",
      "train loss:2.3112822738164738\n",
      "train loss:2.355021835826167\n",
      "train loss:2.3328488941862666\n",
      "=== epoch:25, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.411607131190573\n",
      "train loss:2.371401902764996\n",
      "train loss:2.3540363691044637\n",
      "train loss:2.377776079074328\n",
      "=== epoch:26, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.440975301628149\n",
      "train loss:2.326473470481434\n",
      "train loss:2.401147970865392\n",
      "train loss:2.3963105787299956\n",
      "=== epoch:27, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3467406755033413\n",
      "train loss:2.3685659164631883\n",
      "train loss:2.3335358275016502\n",
      "train loss:2.3610839474937393\n",
      "=== epoch:28, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.37395666051804\n",
      "train loss:2.354425520934425\n",
      "train loss:2.342899638204502\n",
      "train loss:2.441899101339985\n",
      "=== epoch:29, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3632678165367955\n",
      "train loss:2.4157538878624627\n",
      "train loss:2.377269507943923\n",
      "train loss:2.3703209758946246\n",
      "=== epoch:30, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.372766623990396\n",
      "train loss:2.3473650039466434\n",
      "train loss:2.408295788389696\n",
      "train loss:2.4362039053015616\n",
      "=== epoch:31, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3759225518519522\n",
      "train loss:2.3607266653923134\n",
      "train loss:2.3937172720871334\n",
      "train loss:2.3700263719658388\n",
      "=== epoch:32, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.389278051604187\n",
      "train loss:2.314361038423762\n",
      "train loss:2.33539384529237\n",
      "train loss:2.3940346740254603\n",
      "=== epoch:33, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.384373294387655\n",
      "train loss:2.428596449721463\n",
      "train loss:2.324083244532044\n",
      "train loss:2.3971351805550336\n",
      "=== epoch:34, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.4184581656082385\n",
      "train loss:2.387671298614812\n",
      "train loss:2.3993543562678186\n",
      "train loss:2.317553206838098\n",
      "=== epoch:35, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.390434990781121\n",
      "train loss:2.399214006663925\n",
      "train loss:2.327750751315259\n",
      "train loss:2.324011735280185\n",
      "=== epoch:36, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.327446874440956\n",
      "train loss:2.410718033688514\n",
      "train loss:2.335502474180726\n",
      "train loss:2.3570693992400926\n",
      "=== epoch:37, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.330988340473346\n",
      "train loss:2.3149261430900756\n",
      "train loss:2.3672888738914346\n",
      "train loss:2.4048975698155144\n",
      "=== epoch:38, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.333187069783964\n",
      "train loss:2.4330254337395423\n",
      "train loss:2.3939189662934828\n",
      "train loss:2.344362172089182\n",
      "=== epoch:39, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.357070727791704\n",
      "train loss:2.352973427884219\n",
      "train loss:2.3445712797107676\n",
      "train loss:2.39179899802806\n",
      "=== epoch:40, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3601151432053435\n",
      "train loss:2.3638495596525155\n",
      "train loss:2.3071069396154327\n",
      "train loss:2.405009205958501\n",
      "=== epoch:41, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.390710607691035\n",
      "train loss:2.3601602274661073\n",
      "train loss:2.344068330465409\n",
      "train loss:2.309398877518154\n",
      "=== epoch:42, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.345501349641936\n",
      "train loss:2.3334108855718028\n",
      "train loss:2.353676779229779\n",
      "train loss:2.38842381541688\n",
      "=== epoch:43, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.423073965670118\n",
      "train loss:2.3431200245235644\n",
      "train loss:2.3970038836248717\n",
      "train loss:2.4171608886956797\n",
      "=== epoch:44, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.405856284947359\n",
      "train loss:2.3531809245238517\n",
      "train loss:2.3575779264277816\n",
      "train loss:2.414874926277681\n",
      "=== epoch:45, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.386606093316313\n",
      "train loss:2.338838560612719\n",
      "train loss:2.345770949746787\n",
      "train loss:2.3494799898449297\n",
      "=== epoch:46, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3813832080296877\n",
      "train loss:2.4004557745666455\n",
      "train loss:2.314639210100403\n",
      "train loss:2.3406373168159553\n",
      "=== epoch:47, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3975463649591577\n",
      "train loss:2.3886637493887592\n",
      "train loss:2.384369409056679\n",
      "train loss:2.3824184915133153\n",
      "=== epoch:48, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3257198490259863\n",
      "train loss:2.3667457856485177\n",
      "train loss:2.395583135129347\n",
      "train loss:2.3505212662447352\n",
      "=== epoch:49, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3749955742360873\n",
      "train loss:2.3998277985108327\n",
      "train loss:2.4130370100975407\n",
      "train loss:2.346012235875083\n",
      "=== epoch:50, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.3914229659140886\n",
      "train loss:2.4402605051746606\n",
      "train loss:2.351990708023394\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3657515132793177\n",
      "=== epoch:1, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.4530077395751277\n",
      "train loss:2.3797729444436646\n",
      "train loss:2.3930972999340376\n",
      "train loss:2.3379075597691386\n",
      "=== epoch:2, train acc:0.14, test acc:0.15 ===\n",
      "train loss:2.3937949802390865\n",
      "train loss:2.261784711894337\n",
      "train loss:2.2848953951574167\n",
      "train loss:2.2622420444333224\n",
      "=== epoch:3, train acc:0.1825, test acc:0.22 ===\n",
      "train loss:2.2763192338059195\n",
      "train loss:2.31118777346058\n",
      "train loss:2.2498806436616547\n",
      "train loss:2.205200070928193\n",
      "=== epoch:4, train acc:0.215, test acc:0.24 ===\n",
      "train loss:2.213968187157388\n",
      "train loss:2.2254767944750533\n",
      "train loss:2.1817467457740145\n",
      "train loss:2.2238620768551636\n",
      "=== epoch:5, train acc:0.235, test acc:0.26 ===\n",
      "train loss:2.20540876273533\n",
      "train loss:2.16927640307382\n",
      "train loss:2.1683849366100763\n",
      "train loss:2.1013372648238122\n",
      "=== epoch:6, train acc:0.2625, test acc:0.3 ===\n",
      "train loss:2.1625360705403747\n",
      "train loss:2.181007490034172\n",
      "train loss:2.15337676772126\n",
      "train loss:2.100655559321213\n",
      "=== epoch:7, train acc:0.285, test acc:0.28 ===\n",
      "train loss:2.175040212273052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.094258957519064\n",
      "train loss:2.1256162037289474\n",
      "train loss:2.0614933363684402\n",
      "=== epoch:8, train acc:0.3125, test acc:0.29 ===\n",
      "train loss:2.069802215177349\n",
      "train loss:2.0549224370112773\n",
      "train loss:2.0655010081386225\n",
      "train loss:2.0470677428196224\n",
      "=== epoch:9, train acc:0.345, test acc:0.31 ===\n",
      "train loss:2.0428033899870703\n",
      "train loss:2.0276327828808065\n",
      "train loss:1.9840837097898762\n",
      "train loss:2.036628039986888\n",
      "=== epoch:10, train acc:0.355, test acc:0.33 ===\n",
      "train loss:2.0119973273006226\n",
      "train loss:1.9871172545686986\n",
      "train loss:2.009242968741268\n",
      "train loss:1.9465006262093374\n",
      "=== epoch:11, train acc:0.3825, test acc:0.37 ===\n",
      "train loss:1.9678476912906449\n",
      "train loss:1.9456187758504888\n",
      "train loss:1.9243479907683883\n",
      "train loss:1.9224252699188296\n",
      "=== epoch:12, train acc:0.425, test acc:0.37 ===\n",
      "train loss:1.960858250369716\n",
      "train loss:1.9035591299470027\n",
      "train loss:1.9191299597363363\n",
      "train loss:1.869945671498863\n",
      "=== epoch:13, train acc:0.44, test acc:0.38 ===\n",
      "train loss:1.9293314867941995\n",
      "train loss:1.855940980929464\n",
      "train loss:1.882559157357303\n",
      "train loss:1.8206323125446424\n",
      "=== epoch:14, train acc:0.4675, test acc:0.42 ===\n",
      "train loss:1.822472927168482\n",
      "train loss:1.8067558139495028\n",
      "train loss:1.876628704107355\n",
      "train loss:1.8219401964524222\n",
      "=== epoch:15, train acc:0.51, test acc:0.48 ===\n",
      "train loss:1.749781057272592\n",
      "train loss:1.7927243001178743\n",
      "train loss:1.7822145879625468\n",
      "train loss:1.7838658133322292\n",
      "=== epoch:16, train acc:0.5575, test acc:0.54 ===\n",
      "train loss:1.7146277234440315\n",
      "train loss:1.6797485857272547\n",
      "train loss:1.7648486855380612\n",
      "train loss:1.7591270502907659\n",
      "=== epoch:17, train acc:0.58, test acc:0.56 ===\n",
      "train loss:1.62631595754182\n",
      "train loss:1.680012237113442\n",
      "train loss:1.6089907323634576\n",
      "train loss:1.634292163134959\n",
      "=== epoch:18, train acc:0.5925, test acc:0.56 ===\n",
      "train loss:1.575773897663556\n",
      "train loss:1.6051501368387948\n",
      "train loss:1.5027548936908435\n",
      "train loss:1.6045752240149953\n",
      "=== epoch:19, train acc:0.635, test acc:0.56 ===\n",
      "train loss:1.5123183048822961\n",
      "train loss:1.5080075808540419\n",
      "train loss:1.4665954163446018\n",
      "train loss:1.410928729746291\n",
      "=== epoch:20, train acc:0.6675, test acc:0.61 ===\n",
      "train loss:1.4528018261390094\n",
      "train loss:1.479699269858356\n",
      "train loss:1.4384491376138187\n",
      "train loss:1.435936354182078\n",
      "=== epoch:21, train acc:0.695, test acc:0.65 ===\n",
      "train loss:1.3434276630588182\n",
      "train loss:1.3325921988953586\n",
      "train loss:1.359791196171209\n",
      "train loss:1.3529505423818133\n",
      "=== epoch:22, train acc:0.675, test acc:0.66 ===\n",
      "train loss:1.3100904332351502\n",
      "train loss:1.3380078124811217\n",
      "train loss:1.2616953568730256\n",
      "train loss:1.3708592832961028\n",
      "=== epoch:23, train acc:0.7025, test acc:0.66 ===\n",
      "train loss:1.373427718631728\n",
      "train loss:1.29205293498219\n",
      "train loss:1.2754098244716459\n",
      "train loss:1.1989994741582064\n",
      "=== epoch:24, train acc:0.76, test acc:0.7 ===\n",
      "train loss:1.3047715347988644\n",
      "train loss:1.2685760628740879\n",
      "train loss:1.2306813667155816\n",
      "train loss:1.2496438770852456\n",
      "=== epoch:25, train acc:0.78, test acc:0.73 ===\n",
      "train loss:1.251273877419563\n",
      "train loss:1.0990143602831244\n",
      "train loss:1.0269744260513645\n",
      "train loss:1.0859250325891836\n",
      "=== epoch:26, train acc:0.77, test acc:0.73 ===\n",
      "train loss:1.1086589841584757\n",
      "train loss:1.0356092735773292\n",
      "train loss:0.9251575769792121\n",
      "train loss:0.9968303087289055\n",
      "=== epoch:27, train acc:0.8, test acc:0.73 ===\n",
      "train loss:1.00452513959153\n",
      "train loss:0.9870212851087738\n",
      "train loss:1.0300922096091825\n",
      "train loss:1.0009240795104257\n",
      "=== epoch:28, train acc:0.8175, test acc:0.75 ===\n",
      "train loss:0.9593317594063363\n",
      "train loss:1.081782374757474\n",
      "train loss:0.9544833602429659\n",
      "train loss:0.9190657977586744\n",
      "=== epoch:29, train acc:0.8375, test acc:0.74 ===\n",
      "train loss:0.9441420373633487\n",
      "train loss:0.9536132386423837\n",
      "train loss:0.8958783737820915\n",
      "train loss:0.8521623046199325\n",
      "=== epoch:30, train acc:0.85, test acc:0.75 ===\n",
      "train loss:0.7167200335554408\n",
      "train loss:0.8617203570191632\n",
      "train loss:0.8067094819478302\n",
      "train loss:0.8411150961475456\n",
      "=== epoch:31, train acc:0.835, test acc:0.76 ===\n",
      "train loss:0.6614889565904588\n",
      "train loss:0.7156182949897052\n",
      "train loss:0.6763275905785651\n",
      "train loss:0.8573031555168602\n",
      "=== epoch:32, train acc:0.8625, test acc:0.78 ===\n",
      "train loss:0.7503485517097355\n",
      "train loss:0.7428834391549353\n",
      "train loss:0.7854893011354767\n",
      "train loss:0.7182805210594742\n",
      "=== epoch:33, train acc:0.87, test acc:0.81 ===\n",
      "train loss:0.6722376335778245\n",
      "train loss:0.6342316022005052\n",
      "train loss:0.7129574382997478\n",
      "train loss:0.7490063135522976\n",
      "=== epoch:34, train acc:0.86, test acc:0.8 ===\n",
      "train loss:0.7225607241445567\n",
      "train loss:0.6516690155282244\n",
      "train loss:0.5585589127381189\n",
      "train loss:0.5770024931866717\n",
      "=== epoch:35, train acc:0.885, test acc:0.79 ===\n",
      "train loss:0.6097257357050485\n",
      "train loss:0.6719570829160944\n",
      "train loss:0.6348414368211439\n",
      "train loss:0.5768493253874369\n",
      "=== epoch:36, train acc:0.875, test acc:0.81 ===\n",
      "train loss:0.7629417887404668\n",
      "train loss:0.5876754093672462\n",
      "train loss:0.661510856289112\n",
      "train loss:0.5994971171060681\n",
      "=== epoch:37, train acc:0.885, test acc:0.83 ===\n",
      "train loss:0.6236782695251141\n",
      "train loss:0.5175296827892442\n",
      "train loss:0.48028401460562636\n",
      "train loss:0.47874927735526185\n",
      "=== epoch:38, train acc:0.8975, test acc:0.83 ===\n",
      "train loss:0.5615250478349656\n",
      "train loss:0.37971478309563095\n",
      "train loss:0.5832947428767669\n",
      "train loss:0.4166578283372336\n",
      "=== epoch:39, train acc:0.895, test acc:0.84 ===\n",
      "train loss:0.5264573043484349\n",
      "train loss:0.5532748237824655\n",
      "train loss:0.3868559586942876\n",
      "train loss:0.451600463056805\n",
      "=== epoch:40, train acc:0.9075, test acc:0.82 ===\n",
      "train loss:0.34739542210798147\n",
      "train loss:0.44032321078351977\n",
      "train loss:0.43217566649794215\n",
      "train loss:0.4906677429655031\n",
      "=== epoch:41, train acc:0.8975, test acc:0.82 ===\n",
      "train loss:0.4597541877324021\n",
      "train loss:0.40121947339383157\n",
      "train loss:0.45592340854037483\n",
      "train loss:0.35415333723037984\n",
      "=== epoch:42, train acc:0.91, test acc:0.82 ===\n",
      "train loss:0.4634679040359985\n",
      "train loss:0.4291298089353293\n",
      "train loss:0.46583582496520864\n",
      "train loss:0.38886443917100655\n",
      "=== epoch:43, train acc:0.92, test acc:0.8 ===\n",
      "train loss:0.3852262967090064\n",
      "train loss:0.37159976028717356\n",
      "train loss:0.40321019250373447\n",
      "train loss:0.44972266850935105\n",
      "=== epoch:44, train acc:0.925, test acc:0.81 ===\n",
      "train loss:0.45309678086736027\n",
      "train loss:0.3456111223128648\n",
      "train loss:0.375958399890045\n",
      "train loss:0.31250238738116165\n",
      "=== epoch:45, train acc:0.925, test acc:0.84 ===\n",
      "train loss:0.2733084412648813\n",
      "train loss:0.29773913466068624\n",
      "train loss:0.36012926792911054\n",
      "train loss:0.31012043336041933\n",
      "=== epoch:46, train acc:0.92, test acc:0.83 ===\n",
      "train loss:0.4122044400179499\n",
      "train loss:0.34717567979848096\n",
      "train loss:0.38379546602975373\n",
      "train loss:0.5066170811918014\n",
      "=== epoch:47, train acc:0.9325, test acc:0.82 ===\n",
      "train loss:0.39946307896691235\n",
      "train loss:0.3616211386670826\n",
      "train loss:0.3983401828320672\n",
      "train loss:0.3477513318678889\n",
      "=== epoch:48, train acc:0.935, test acc:0.83 ===\n",
      "train loss:0.2662645328283082\n",
      "train loss:0.27362932709762644\n",
      "train loss:0.3555789307695244\n",
      "train loss:0.3381247350572658\n",
      "=== epoch:49, train acc:0.9375, test acc:0.82 ===\n",
      "train loss:0.3778075828473982\n",
      "train loss:0.2861961467736791\n",
      "train loss:0.2568405512893751\n",
      "train loss:0.3876497689051366\n",
      "=== epoch:50, train acc:0.9425, test acc:0.83 ===\n",
      "train loss:0.38556440290394434\n",
      "train loss:0.2558308678679486\n",
      "train loss:0.3185511861390328\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.82\n",
      "val_acc: 0.8300 | lr: 0.0094, weight_decay: 0.0000\n",
      "train loss:2.368444903861684\n",
      "=== epoch:1, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3872202063439993\n",
      "train loss:2.445980669587185\n",
      "train loss:2.3589691881366868\n",
      "train loss:2.4211781186679757\n",
      "=== epoch:2, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.396676733464191\n",
      "train loss:2.4432038838924828\n",
      "train loss:2.279666947174525\n",
      "train loss:2.357088803461428\n",
      "=== epoch:3, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4320203343444544\n",
      "train loss:2.3904677092271625\n",
      "train loss:2.442080924327028\n",
      "train loss:2.4027820196962915\n",
      "=== epoch:4, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.430715642053559\n",
      "train loss:2.418484588324903\n",
      "train loss:2.3463455436086442\n",
      "train loss:2.407375740976211\n",
      "=== epoch:5, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4084077457955866\n",
      "train loss:2.3886836877509676\n",
      "train loss:2.379152019937082\n",
      "train loss:2.4634112084966655\n",
      "=== epoch:6, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3550753159007316\n",
      "train loss:2.4326056209680083\n",
      "train loss:2.436373705639385\n",
      "train loss:2.4061940379183597\n",
      "=== epoch:7, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3859954010044\n",
      "train loss:2.325491564489889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3800660988480464\n",
      "train loss:2.4493531326405065\n",
      "=== epoch:8, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3946732987954515\n",
      "train loss:2.5194078437599314\n",
      "train loss:2.326353964560171\n",
      "train loss:2.4198593467755884\n",
      "=== epoch:9, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.486192747645258\n",
      "train loss:2.4644828112727497\n",
      "train loss:2.347223232366146\n",
      "train loss:2.3633944216506344\n",
      "=== epoch:10, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.378016941673876\n",
      "train loss:2.4411155804101887\n",
      "train loss:2.365401780758408\n",
      "train loss:2.495939661310412\n",
      "=== epoch:11, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4452351434245916\n",
      "train loss:2.4191046885435945\n",
      "train loss:2.3924231988559033\n",
      "train loss:2.306447130197246\n",
      "=== epoch:12, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4613204104175406\n",
      "train loss:2.4159207745357105\n",
      "train loss:2.4435808609978142\n",
      "train loss:2.430548271699587\n",
      "=== epoch:13, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3944616233698826\n",
      "train loss:2.3819668294083605\n",
      "train loss:2.407167180551956\n",
      "train loss:2.4182844837226103\n",
      "=== epoch:14, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.392231856389388\n",
      "train loss:2.413290900725503\n",
      "train loss:2.4328383506229616\n",
      "train loss:2.514648595767839\n",
      "=== epoch:15, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3601378128971042\n",
      "train loss:2.4797910767550984\n",
      "train loss:2.3437644940503275\n",
      "train loss:2.4519823958021614\n",
      "=== epoch:16, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.47227290030579\n",
      "train loss:2.463168610773006\n",
      "train loss:2.416121702353586\n",
      "train loss:2.378324380789521\n",
      "=== epoch:17, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.409909847852619\n",
      "train loss:2.414801801183201\n",
      "train loss:2.4135014390199756\n",
      "train loss:2.4531988357183527\n",
      "=== epoch:18, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.5008851048524336\n",
      "train loss:2.4049416571114075\n",
      "train loss:2.37561971509386\n",
      "train loss:2.4756606047192973\n",
      "=== epoch:19, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4490998703502673\n",
      "train loss:2.424575230601145\n",
      "train loss:2.4169897035327375\n",
      "train loss:2.419821521616196\n",
      "=== epoch:20, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.413930292310608\n",
      "train loss:2.324744531170152\n",
      "train loss:2.3464401907618857\n",
      "train loss:2.4621159012812694\n",
      "=== epoch:21, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.328524952186168\n",
      "train loss:2.427272810668203\n",
      "train loss:2.321627582471801\n",
      "train loss:2.3812706852163905\n",
      "=== epoch:22, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4528378930676284\n",
      "train loss:2.26335238746538\n",
      "train loss:2.4075784536495686\n",
      "train loss:2.418889685232898\n",
      "=== epoch:23, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.299736400598054\n",
      "train loss:2.441340785317792\n",
      "train loss:2.4983452502203414\n",
      "train loss:2.3847420617317554\n",
      "=== epoch:24, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.340758181424095\n",
      "train loss:2.461185029158238\n",
      "train loss:2.4130592059164817\n",
      "train loss:2.3550926526930875\n",
      "=== epoch:25, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.369340589689703\n",
      "train loss:2.3352325406221346\n",
      "train loss:2.3050619600441196\n",
      "train loss:2.411740585639339\n",
      "=== epoch:26, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.36142476006444\n",
      "train loss:2.4344962828791705\n",
      "train loss:2.3883638714533397\n",
      "train loss:2.384590322534235\n",
      "=== epoch:27, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.431962219790434\n",
      "train loss:2.4169966634258673\n",
      "train loss:2.3272329964468295\n",
      "train loss:2.4401166230633606\n",
      "=== epoch:28, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3647711311509383\n",
      "train loss:2.3806971944627446\n",
      "train loss:2.454478636065124\n",
      "train loss:2.411166994254152\n",
      "=== epoch:29, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.426531293242904\n",
      "train loss:2.4453604622428173\n",
      "train loss:2.3431656075532517\n",
      "train loss:2.489962407807545\n",
      "=== epoch:30, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.379852676247972\n",
      "train loss:2.477746159079198\n",
      "train loss:2.4122079117399715\n",
      "train loss:2.4574004160878484\n",
      "=== epoch:31, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3946186417630746\n",
      "train loss:2.389564207924145\n",
      "train loss:2.414345338606763\n",
      "train loss:2.400606653952834\n",
      "=== epoch:32, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.409431408613833\n",
      "train loss:2.452694774016819\n",
      "train loss:2.4240971637025726\n",
      "train loss:2.3945313731419917\n",
      "=== epoch:33, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.362969740285823\n",
      "train loss:2.4288484551880014\n",
      "train loss:2.3373700926775576\n",
      "train loss:2.3981386065704333\n",
      "=== epoch:34, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3666303321710256\n",
      "train loss:2.3490283971325883\n",
      "train loss:2.4147245901520846\n",
      "train loss:2.4147875485117525\n",
      "=== epoch:35, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3998109092546493\n",
      "train loss:2.433630579448603\n",
      "train loss:2.442614782749693\n",
      "train loss:2.4462426461594053\n",
      "=== epoch:36, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.404312665954687\n",
      "train loss:2.405635191288398\n",
      "train loss:2.362568417039097\n",
      "train loss:2.388532502912469\n",
      "=== epoch:37, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.455761747638693\n",
      "train loss:2.4181268049264637\n",
      "train loss:2.3512433255665885\n",
      "train loss:2.4194204163447908\n",
      "=== epoch:38, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3487121835291958\n",
      "train loss:2.358842854604703\n",
      "train loss:2.3806446325372614\n",
      "train loss:2.3875047283664874\n",
      "=== epoch:39, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4493136300329326\n",
      "train loss:2.446031788401158\n",
      "train loss:2.418869861326081\n",
      "train loss:2.4134339216095313\n",
      "=== epoch:40, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3636094936260084\n",
      "train loss:2.371648564486523\n",
      "train loss:2.400148221871608\n",
      "train loss:2.4430740687113888\n",
      "=== epoch:41, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.367023056381034\n",
      "train loss:2.4989105121579143\n",
      "train loss:2.3526249693604115\n",
      "train loss:2.4238390962168874\n",
      "=== epoch:42, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3948141627349364\n",
      "train loss:2.3845103189409955\n",
      "train loss:2.3334379688508937\n",
      "train loss:2.3364660816861735\n",
      "=== epoch:43, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.449862904883053\n",
      "train loss:2.476222278569249\n",
      "train loss:2.3448813251464915\n",
      "train loss:2.4378523735041306\n",
      "=== epoch:44, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4738817780179727\n",
      "train loss:2.3952568096259736\n",
      "train loss:2.3726723709206903\n",
      "train loss:2.344131970134239\n",
      "=== epoch:45, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.442267771405921\n",
      "train loss:2.3288459755895\n",
      "train loss:2.4037794059597726\n",
      "train loss:2.386358818527123\n",
      "=== epoch:46, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3532256946675036\n",
      "train loss:2.3711826119897736\n",
      "train loss:2.404290026909893\n",
      "train loss:2.437232850102291\n",
      "=== epoch:47, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.376875132057968\n",
      "train loss:2.4770776906665906\n",
      "train loss:2.392148435944855\n",
      "train loss:2.3233229653095555\n",
      "=== epoch:48, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.357600850045157\n",
      "train loss:2.3807503553046097\n",
      "train loss:2.386450920010751\n",
      "train loss:2.4078227509053494\n",
      "=== epoch:49, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.310897285832234\n",
      "train loss:2.419202737484176\n",
      "train loss:2.316156643966101\n",
      "train loss:2.455173371292193\n",
      "=== epoch:50, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.321954461772304\n",
      "train loss:2.435206713380611\n",
      "train loss:2.4835071666704507\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.2\n",
      "val_acc: 0.2000 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.39277890499749\n",
      "=== epoch:1, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.3747435837912736\n",
      "train loss:2.319355459956515\n",
      "train loss:2.3513833414250143\n",
      "train loss:2.4801350836979132\n",
      "=== epoch:2, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.2920626436091887\n",
      "train loss:2.322831089935744\n",
      "train loss:2.448802126068985\n",
      "train loss:2.3735523884582435\n",
      "=== epoch:3, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.3298033298607956\n",
      "train loss:2.391912793158955\n",
      "train loss:2.409293113365459\n",
      "train loss:2.434813473456934\n",
      "=== epoch:4, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.2845564005554877\n",
      "train loss:2.3345057712184665\n",
      "train loss:2.3888743009098463\n",
      "train loss:2.3414728974008687\n",
      "=== epoch:5, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.4416265475547227\n",
      "train loss:2.393372519115794\n",
      "train loss:2.262012388742246\n",
      "train loss:2.4134207203172973\n",
      "=== epoch:6, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.5252710518268118\n",
      "train loss:2.4461666031246994\n",
      "train loss:2.416851416911969\n",
      "train loss:2.3424347809724337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:7, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.357484009226006\n",
      "train loss:2.3414575055209657\n",
      "train loss:2.511608009560709\n",
      "train loss:2.436964862443465\n",
      "=== epoch:8, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.4441460002702695\n",
      "train loss:2.402661369413137\n",
      "train loss:2.4412293428209457\n",
      "train loss:2.33344018197751\n",
      "=== epoch:9, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.398478134374765\n",
      "train loss:2.3507628644947927\n",
      "train loss:2.5053671735030174\n",
      "train loss:2.4118523642544174\n",
      "=== epoch:10, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.3741886492575768\n",
      "train loss:2.3826191949447493\n",
      "train loss:2.383391847567505\n",
      "train loss:2.3871886313086597\n",
      "=== epoch:11, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.433332807445962\n",
      "train loss:2.387773261280854\n",
      "train loss:2.401742684081042\n",
      "train loss:2.4323137765850626\n",
      "=== epoch:12, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.417314765308581\n",
      "train loss:2.428516804948602\n",
      "train loss:2.3615488005683662\n",
      "train loss:2.4263360957690456\n",
      "=== epoch:13, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.4227273466526986\n",
      "train loss:2.3856948686444324\n",
      "train loss:2.4288163170720565\n",
      "train loss:2.368338734890489\n",
      "=== epoch:14, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.403734858924233\n",
      "train loss:2.3649286636919564\n",
      "train loss:2.3388370895023765\n",
      "train loss:2.3408747561769885\n",
      "=== epoch:15, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.3302290754799344\n",
      "train loss:2.2795517244320846\n",
      "train loss:2.340081491117194\n",
      "train loss:2.456913234263069\n",
      "=== epoch:16, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.3743605493102002\n",
      "train loss:2.3874779345268577\n",
      "train loss:2.4693935683618684\n",
      "train loss:2.4146149744966454\n",
      "=== epoch:17, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.4548610398575037\n",
      "train loss:2.3739303923473742\n",
      "train loss:2.372746469260651\n",
      "train loss:2.33374324026274\n",
      "=== epoch:18, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.391969496778361\n",
      "train loss:2.335649869333265\n",
      "train loss:2.4027468769178184\n",
      "train loss:2.3648096587624274\n",
      "=== epoch:19, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.3177064973902386\n",
      "train loss:2.3738245891024063\n",
      "train loss:2.3285563129460205\n",
      "train loss:2.4003058733682283\n",
      "=== epoch:20, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.4467276265040896\n",
      "train loss:2.418616221987981\n",
      "train loss:2.3788202696289313\n",
      "train loss:2.3358101248896967\n",
      "=== epoch:21, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.3849855293163387\n",
      "train loss:2.3542808748783037\n",
      "train loss:2.3556945662349067\n",
      "train loss:2.436363883922573\n",
      "=== epoch:22, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.336784683900201\n",
      "train loss:2.3783722027011165\n",
      "train loss:2.3304161460883264\n",
      "train loss:2.3353102613189862\n",
      "=== epoch:23, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.42246300986881\n",
      "train loss:2.36528337934843\n",
      "train loss:2.2980396373456955\n",
      "train loss:2.382781531845836\n",
      "=== epoch:24, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.482333022386038\n",
      "train loss:2.2861507925181286\n",
      "train loss:2.3852284664828307\n",
      "train loss:2.404925716299773\n",
      "=== epoch:25, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.498186534698603\n",
      "train loss:2.3931028977056523\n",
      "train loss:2.37797822061707\n",
      "train loss:2.366536605920098\n",
      "=== epoch:26, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.3987175236286182\n",
      "train loss:2.4726853101094792\n",
      "train loss:2.4327935449816196\n",
      "train loss:2.4561179581396178\n",
      "=== epoch:27, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.4523216687243274\n",
      "train loss:2.325285672619009\n",
      "train loss:2.316440705958737\n",
      "train loss:2.384106025754084\n",
      "=== epoch:28, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.3568314221880238\n",
      "train loss:2.2840455421615995\n",
      "train loss:2.3835251370377932\n",
      "train loss:2.290339979221097\n",
      "=== epoch:29, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.4570256618484847\n",
      "train loss:2.3723801037949785\n",
      "train loss:2.3778645185411786\n",
      "train loss:2.333156152035653\n",
      "=== epoch:30, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.4321863877256322\n",
      "train loss:2.3181723355848076\n",
      "train loss:2.4766215871351767\n",
      "train loss:2.3821680424229865\n",
      "=== epoch:31, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.36351414536672\n",
      "train loss:2.391290892744696\n",
      "train loss:2.354449297611085\n",
      "train loss:2.3577739631518826\n",
      "=== epoch:32, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.309372094390104\n",
      "train loss:2.267416066657347\n",
      "train loss:2.342057181908675\n",
      "train loss:2.3602649222465932\n",
      "=== epoch:33, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.375094545583644\n",
      "train loss:2.4454807992169103\n",
      "train loss:2.3728505867998613\n",
      "train loss:2.3974112600547115\n",
      "=== epoch:34, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.367206811027971\n",
      "train loss:2.386356986821033\n",
      "train loss:2.374350310854608\n",
      "train loss:2.3561990431428645\n",
      "=== epoch:35, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.2714131124413783\n",
      "train loss:2.4411103641989538\n",
      "train loss:2.3860565428360943\n",
      "train loss:2.3506198411028874\n",
      "=== epoch:36, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.3673844071350394\n",
      "train loss:2.3000709286448897\n",
      "train loss:2.384955470706109\n",
      "train loss:2.3620495122751852\n",
      "=== epoch:37, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.3982348998149012\n",
      "train loss:2.4352503817256372\n",
      "train loss:2.3836803349227123\n",
      "train loss:2.437796617754547\n",
      "=== epoch:38, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.2589361325886874\n",
      "train loss:2.3777801678523134\n",
      "train loss:2.273873167603602\n",
      "train loss:2.254101364354244\n",
      "=== epoch:39, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.3759178097334166\n",
      "train loss:2.328657604408139\n",
      "train loss:2.359371694084531\n",
      "train loss:2.342207401589017\n",
      "=== epoch:40, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.394793793656653\n",
      "train loss:2.394837754481279\n",
      "train loss:2.3393144341648444\n",
      "train loss:2.3427223061176665\n",
      "=== epoch:41, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.295474937353343\n",
      "train loss:2.3253309087653706\n",
      "train loss:2.4088153319631047\n",
      "train loss:2.3251247137258657\n",
      "=== epoch:42, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.368172366575203\n",
      "train loss:2.376994747850273\n",
      "train loss:2.4842028398318186\n",
      "train loss:2.3743445065723607\n",
      "=== epoch:43, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.3242877910362116\n",
      "train loss:2.4161087777842867\n",
      "train loss:2.403698981931101\n",
      "train loss:2.287985144393827\n",
      "=== epoch:44, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.399395876071533\n",
      "train loss:2.384912798477961\n",
      "train loss:2.27367249981119\n",
      "train loss:2.401639530924536\n",
      "=== epoch:45, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.365739355981747\n",
      "train loss:2.3451286004442227\n",
      "train loss:2.1895619885180038\n",
      "train loss:2.4251301393511846\n",
      "=== epoch:46, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.325860973622774\n",
      "train loss:2.3365339915318972\n",
      "train loss:2.4279913310898866\n",
      "train loss:2.470842153618519\n",
      "=== epoch:47, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.4005477937679127\n",
      "train loss:2.3847871018314546\n",
      "train loss:2.405150052798969\n",
      "train loss:2.3281508469013823\n",
      "=== epoch:48, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.3187318219018653\n",
      "train loss:2.3383468014775852\n",
      "train loss:2.3907773351734436\n",
      "train loss:2.314071730439801\n",
      "=== epoch:49, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.381009735942976\n",
      "train loss:2.403330601702907\n",
      "train loss:2.4340812475126654\n",
      "train loss:2.3792797885261336\n",
      "=== epoch:50, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.3294999305610653\n",
      "train loss:2.3489705820858497\n",
      "train loss:2.313337453174344\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.280743076793905\n",
      "=== epoch:1, train acc:0.12, test acc:0.16 ===\n",
      "train loss:2.3385009472043086\n",
      "train loss:2.3414024335375774\n",
      "train loss:2.363364542483141\n",
      "train loss:2.364266544242327\n",
      "=== epoch:2, train acc:0.12, test acc:0.16 ===\n",
      "train loss:2.355428275735714\n",
      "train loss:2.381037498770985\n",
      "train loss:2.3837835908256384\n",
      "train loss:2.380262986949502\n",
      "=== epoch:3, train acc:0.12, test acc:0.16 ===\n",
      "train loss:2.3714608132004287\n",
      "train loss:2.3656971143496635\n",
      "train loss:2.313165286495111\n",
      "train loss:2.3288317514337007\n",
      "=== epoch:4, train acc:0.12, test acc:0.16 ===\n",
      "train loss:2.354452407493353\n",
      "train loss:2.376976585129241\n",
      "train loss:2.339750819998063\n",
      "train loss:2.3057739181970813\n",
      "=== epoch:5, train acc:0.12, test acc:0.16 ===\n",
      "train loss:2.3443211630292193\n",
      "train loss:2.317422529587424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3526141921821093\n",
      "train loss:2.333070586905231\n",
      "=== epoch:6, train acc:0.12, test acc:0.16 ===\n",
      "train loss:2.3119620549973274\n",
      "train loss:2.359785696767035\n",
      "train loss:2.296863813513218\n",
      "train loss:2.3591581405527027\n",
      "=== epoch:7, train acc:0.12, test acc:0.16 ===\n",
      "train loss:2.365008682843856\n",
      "train loss:2.3045858133957022\n",
      "train loss:2.3336740702466168\n",
      "train loss:2.3075517221408433\n",
      "=== epoch:8, train acc:0.12, test acc:0.16 ===\n",
      "train loss:2.2864641286897998\n",
      "train loss:2.2968840816928466\n",
      "train loss:2.3073407572336047\n",
      "train loss:2.3479783774384515\n",
      "=== epoch:9, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.3405969596516156\n",
      "train loss:2.329008533446122\n",
      "train loss:2.3233202605187144\n",
      "train loss:2.334241628707203\n",
      "=== epoch:10, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.346930628386301\n",
      "train loss:2.3535195944936786\n",
      "train loss:2.3313414870000435\n",
      "train loss:2.3788373438033728\n",
      "=== epoch:11, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.3277140230615716\n",
      "train loss:2.3389196330186452\n",
      "train loss:2.371540537529857\n",
      "train loss:2.349529341843537\n",
      "=== epoch:12, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.375937406275471\n",
      "train loss:2.3458009095911767\n",
      "train loss:2.34711722386325\n",
      "train loss:2.297674189559202\n",
      "=== epoch:13, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.3387277021981485\n",
      "train loss:2.3738644417409662\n",
      "train loss:2.303248356238706\n",
      "train loss:2.3111253409309263\n",
      "=== epoch:14, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.360167658226287\n",
      "train loss:2.369638329979409\n",
      "train loss:2.291445766908354\n",
      "train loss:2.341074479228504\n",
      "=== epoch:15, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.3463255631835134\n",
      "train loss:2.398856350692577\n",
      "train loss:2.2987086275023048\n",
      "train loss:2.3106913639078104\n",
      "=== epoch:16, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.314028204672967\n",
      "train loss:2.3539141048294083\n",
      "train loss:2.3287251395657496\n",
      "train loss:2.30296505747999\n",
      "=== epoch:17, train acc:0.1225, test acc:0.16 ===\n",
      "train loss:2.3754083773530024\n",
      "train loss:2.3727455838704583\n",
      "train loss:2.3328873555740426\n",
      "train loss:2.311770648998467\n",
      "=== epoch:18, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.296062479724535\n",
      "train loss:2.3483763924435492\n",
      "train loss:2.355632408335931\n",
      "train loss:2.318324084637177\n",
      "=== epoch:19, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.2956054627601152\n",
      "train loss:2.3222234033021416\n",
      "train loss:2.265357322991671\n",
      "train loss:2.314368232798833\n",
      "=== epoch:20, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.370677935106321\n",
      "train loss:2.365866206046838\n",
      "train loss:2.385489540474684\n",
      "train loss:2.342862975104558\n",
      "=== epoch:21, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.3060250967194627\n",
      "train loss:2.336030653960822\n",
      "train loss:2.3316832050968515\n",
      "train loss:2.283660653019168\n",
      "=== epoch:22, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.343331464592815\n",
      "train loss:2.3196331062234146\n",
      "train loss:2.374388134860366\n",
      "train loss:2.322443532050412\n",
      "=== epoch:23, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.317520996766917\n",
      "train loss:2.3371795371484687\n",
      "train loss:2.350858456525637\n",
      "train loss:2.340828223586374\n",
      "=== epoch:24, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.325236491906614\n",
      "train loss:2.3826596146493646\n",
      "train loss:2.3075500108616813\n",
      "train loss:2.3538330699443817\n",
      "=== epoch:25, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.3368213009223564\n",
      "train loss:2.3107874449053196\n",
      "train loss:2.3350575155248188\n",
      "train loss:2.3267121060090292\n",
      "=== epoch:26, train acc:0.125, test acc:0.16 ===\n",
      "train loss:2.333401387430448\n",
      "train loss:2.3909806124319903\n",
      "train loss:2.3600640882489823\n",
      "train loss:2.3157480866236546\n",
      "=== epoch:27, train acc:0.1275, test acc:0.16 ===\n",
      "train loss:2.376417031148968\n",
      "train loss:2.3294635905094276\n",
      "train loss:2.3305938567508675\n",
      "train loss:2.3498910961716732\n",
      "=== epoch:28, train acc:0.1275, test acc:0.16 ===\n",
      "train loss:2.3357024385904643\n",
      "train loss:2.340999451193413\n",
      "train loss:2.325475445840965\n",
      "train loss:2.2778874628662114\n",
      "=== epoch:29, train acc:0.1275, test acc:0.16 ===\n",
      "train loss:2.287403110964432\n",
      "train loss:2.390129338581131\n",
      "train loss:2.349631206696387\n",
      "train loss:2.3512344328532633\n",
      "=== epoch:30, train acc:0.1275, test acc:0.16 ===\n",
      "train loss:2.33664463960957\n",
      "train loss:2.34617811639263\n",
      "train loss:2.2934885991524063\n",
      "train loss:2.323804112702272\n",
      "=== epoch:31, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3666556917906205\n",
      "train loss:2.344623524897567\n",
      "train loss:2.3441727987157597\n",
      "train loss:2.330986564928782\n",
      "=== epoch:32, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3635876777495057\n",
      "train loss:2.368946390597066\n",
      "train loss:2.3932822736259802\n",
      "train loss:2.311319979787984\n",
      "=== epoch:33, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3521680005508365\n",
      "train loss:2.35350756396444\n",
      "train loss:2.2510647889103863\n",
      "train loss:2.3216606060554614\n",
      "=== epoch:34, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.351949488322498\n",
      "train loss:2.3267877278197893\n",
      "train loss:2.3385613908959195\n",
      "train loss:2.3145461429313663\n",
      "=== epoch:35, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3426999581060963\n",
      "train loss:2.301142921769012\n",
      "train loss:2.349293479928142\n",
      "train loss:2.3402986927537786\n",
      "=== epoch:36, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.360385981361451\n",
      "train loss:2.2847382751455\n",
      "train loss:2.297059523826611\n",
      "train loss:2.3521236390745326\n",
      "=== epoch:37, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3147477664679887\n",
      "train loss:2.352204633963019\n",
      "train loss:2.303081649500761\n",
      "train loss:2.309391116423752\n",
      "=== epoch:38, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3510611993260158\n",
      "train loss:2.3189471087122824\n",
      "train loss:2.353799435365583\n",
      "train loss:2.295717013868777\n",
      "=== epoch:39, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3567544730144356\n",
      "train loss:2.3161529347764707\n",
      "train loss:2.32041470872928\n",
      "train loss:2.320099907964068\n",
      "=== epoch:40, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.356226709779647\n",
      "train loss:2.345999997344726\n",
      "train loss:2.313057265429558\n",
      "train loss:2.308453827708534\n",
      "=== epoch:41, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3652432085611603\n",
      "train loss:2.3452343232199193\n",
      "train loss:2.338943110801333\n",
      "train loss:2.3102796863666404\n",
      "=== epoch:42, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.336397311769324\n",
      "train loss:2.3039594804135684\n",
      "train loss:2.3555856071970935\n",
      "train loss:2.343147085098817\n",
      "=== epoch:43, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3655055798308346\n",
      "train loss:2.34647164852584\n",
      "train loss:2.339662233428406\n",
      "train loss:2.3528715594443064\n",
      "=== epoch:44, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3449529658955806\n",
      "train loss:2.379133181010644\n",
      "train loss:2.32224780325986\n",
      "train loss:2.339685107378205\n",
      "=== epoch:45, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3483985157040785\n",
      "train loss:2.3782437126277713\n",
      "train loss:2.378695054902404\n",
      "train loss:2.317338093453358\n",
      "=== epoch:46, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.342540389071063\n",
      "train loss:2.303885291330925\n",
      "train loss:2.345904581237626\n",
      "train loss:2.344986847086053\n",
      "=== epoch:47, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.383759576422359\n",
      "train loss:2.2992727819807786\n",
      "train loss:2.2811015956940603\n",
      "train loss:2.3622953411453804\n",
      "=== epoch:48, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.2876490611597036\n",
      "train loss:2.370018195511903\n",
      "train loss:2.33189846238923\n",
      "train loss:2.3218686877867745\n",
      "=== epoch:49, train acc:0.13, test acc:0.16 ===\n",
      "train loss:2.3371341971883326\n",
      "train loss:2.344442144146492\n",
      "train loss:2.3183806172186245\n",
      "train loss:2.375477053359607\n",
      "=== epoch:50, train acc:0.1325, test acc:0.16 ===\n",
      "train loss:2.3529998822199074\n",
      "train loss:2.3284060214389597\n",
      "train loss:2.3745025279666323\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.16\n",
      "val_acc: 0.1600 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.462271707527151\n",
      "=== epoch:1, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.393772606956514\n",
      "train loss:2.2940001937143877\n",
      "train loss:2.4154298605916735\n",
      "train loss:2.4305980115204853\n",
      "=== epoch:2, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.3933379277768547\n",
      "train loss:2.422038556418409\n",
      "train loss:2.362130659074061\n",
      "train loss:2.3546885143505754\n",
      "=== epoch:3, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.4055144483524646\n",
      "train loss:2.3307631443779755\n",
      "train loss:2.3320132461685543\n",
      "train loss:2.4091488855960836\n",
      "=== epoch:4, train acc:0.1025, test acc:0.1 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3107250457614623\n",
      "train loss:2.380093676982206\n",
      "train loss:2.3298733945289407\n",
      "train loss:2.367185981882082\n",
      "=== epoch:5, train acc:0.1075, test acc:0.11 ===\n",
      "train loss:2.279572023303019\n",
      "train loss:2.396706062884592\n",
      "train loss:2.287850492007375\n",
      "train loss:2.298307595887373\n",
      "=== epoch:6, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.2809124940183825\n",
      "train loss:2.308812392568969\n",
      "train loss:2.285307796371763\n",
      "train loss:2.3233369873169627\n",
      "=== epoch:7, train acc:0.12, test acc:0.13 ===\n",
      "train loss:2.2868057445972827\n",
      "train loss:2.2772570947350377\n",
      "train loss:2.3503788407351207\n",
      "train loss:2.205511664602214\n",
      "=== epoch:8, train acc:0.1275, test acc:0.16 ===\n",
      "train loss:2.3419393161796065\n",
      "train loss:2.2583272002035284\n",
      "train loss:2.2752519047092474\n",
      "train loss:2.3160516237622906\n",
      "=== epoch:9, train acc:0.1375, test acc:0.17 ===\n",
      "train loss:2.2803262389564916\n",
      "train loss:2.220700362695974\n",
      "train loss:2.260942325650671\n",
      "train loss:2.236404656133887\n",
      "=== epoch:10, train acc:0.145, test acc:0.17 ===\n",
      "train loss:2.3127272193977007\n",
      "train loss:2.3525913556709406\n",
      "train loss:2.2064456041925347\n",
      "train loss:2.2414636877179857\n",
      "=== epoch:11, train acc:0.155, test acc:0.17 ===\n",
      "train loss:2.2052400160137315\n",
      "train loss:2.212414111790691\n",
      "train loss:2.2630638021398672\n",
      "train loss:2.328957312444722\n",
      "=== epoch:12, train acc:0.175, test acc:0.19 ===\n",
      "train loss:2.2808326583236638\n",
      "train loss:2.269781388878615\n",
      "train loss:2.216498934149346\n",
      "train loss:2.1969577507707205\n",
      "=== epoch:13, train acc:0.185, test acc:0.21 ===\n",
      "train loss:2.281965123679208\n",
      "train loss:2.1678916768674625\n",
      "train loss:2.237902247774861\n",
      "train loss:2.2274451314834525\n",
      "=== epoch:14, train acc:0.205, test acc:0.23 ===\n",
      "train loss:2.1952590740375393\n",
      "train loss:2.1819828399370476\n",
      "train loss:2.150834343835447\n",
      "train loss:2.1465214397675294\n",
      "=== epoch:15, train acc:0.2175, test acc:0.22 ===\n",
      "train loss:2.17411553088364\n",
      "train loss:2.2132669793210775\n",
      "train loss:2.1650337503406747\n",
      "train loss:2.147043458751736\n",
      "=== epoch:16, train acc:0.2275, test acc:0.23 ===\n",
      "train loss:2.116634602176897\n",
      "train loss:2.1875619056387148\n",
      "train loss:2.1201822174047766\n",
      "train loss:2.162872095763968\n",
      "=== epoch:17, train acc:0.245, test acc:0.23 ===\n",
      "train loss:2.1898713631225624\n",
      "train loss:2.1398902755707163\n",
      "train loss:2.2212203871499367\n",
      "train loss:2.141961349192002\n",
      "=== epoch:18, train acc:0.2525, test acc:0.23 ===\n",
      "train loss:2.1237071196890063\n",
      "train loss:2.200219858252661\n",
      "train loss:2.107253940301165\n",
      "train loss:2.2078927399528796\n",
      "=== epoch:19, train acc:0.2675, test acc:0.27 ===\n",
      "train loss:2.1667217359482387\n",
      "train loss:2.1025878343176965\n",
      "train loss:2.1149179395830675\n",
      "train loss:2.166751887319967\n",
      "=== epoch:20, train acc:0.2825, test acc:0.29 ===\n",
      "train loss:2.1534149169225425\n",
      "train loss:2.129933477601564\n",
      "train loss:2.1770535853041673\n",
      "train loss:2.147150494139847\n",
      "=== epoch:21, train acc:0.295, test acc:0.3 ===\n",
      "train loss:2.1399968065956454\n",
      "train loss:2.086172850619718\n",
      "train loss:2.078054676476797\n",
      "train loss:2.1245083082438274\n",
      "=== epoch:22, train acc:0.31, test acc:0.31 ===\n",
      "train loss:2.128694378156113\n",
      "train loss:2.14406945901161\n",
      "train loss:2.1617384077169635\n",
      "train loss:2.1241205674605563\n",
      "=== epoch:23, train acc:0.325, test acc:0.33 ===\n",
      "train loss:2.1228906425481715\n",
      "train loss:2.1294344641191363\n",
      "train loss:2.130222584178624\n",
      "train loss:2.11348489481524\n",
      "=== epoch:24, train acc:0.335, test acc:0.35 ===\n",
      "train loss:2.1000625331583467\n",
      "train loss:2.1396567643872393\n",
      "train loss:2.1068581905836012\n",
      "train loss:2.1122248250645153\n",
      "=== epoch:25, train acc:0.345, test acc:0.35 ===\n",
      "train loss:2.0630402192097432\n",
      "train loss:2.111122849392067\n",
      "train loss:2.0444769032702186\n",
      "train loss:2.1077847776057923\n",
      "=== epoch:26, train acc:0.3675, test acc:0.37 ===\n",
      "train loss:2.0534574488131065\n",
      "train loss:2.0889346981263737\n",
      "train loss:2.0268208303954074\n",
      "train loss:2.1404946351650644\n",
      "=== epoch:27, train acc:0.375, test acc:0.39 ===\n",
      "train loss:2.0037308047252846\n",
      "train loss:2.067099991905568\n",
      "train loss:2.114423783345474\n",
      "train loss:2.0517336062907674\n",
      "=== epoch:28, train acc:0.39, test acc:0.41 ===\n",
      "train loss:2.0639017131382236\n",
      "train loss:2.070340420973677\n",
      "train loss:2.0349492286450466\n",
      "train loss:2.015238612786984\n",
      "=== epoch:29, train acc:0.3925, test acc:0.39 ===\n",
      "train loss:2.02261408803539\n",
      "train loss:2.0585819606844122\n",
      "train loss:2.0829007508350763\n",
      "train loss:2.026845386647705\n",
      "=== epoch:30, train acc:0.4175, test acc:0.4 ===\n",
      "train loss:2.023722926507749\n",
      "train loss:2.0888913676848\n",
      "train loss:2.015927838726913\n",
      "train loss:2.0343542845002784\n",
      "=== epoch:31, train acc:0.415, test acc:0.43 ===\n",
      "train loss:2.021602706981132\n",
      "train loss:2.07117578711569\n",
      "train loss:2.0062437643223094\n",
      "train loss:2.048365041665981\n",
      "=== epoch:32, train acc:0.4275, test acc:0.43 ===\n",
      "train loss:2.0691525695370085\n",
      "train loss:2.0116225858086727\n",
      "train loss:1.998401937492087\n",
      "train loss:1.9979895462329067\n",
      "=== epoch:33, train acc:0.4375, test acc:0.43 ===\n",
      "train loss:2.0065246338195406\n",
      "train loss:2.0285145752255214\n",
      "train loss:1.9862915580529121\n",
      "train loss:2.000023623609102\n",
      "=== epoch:34, train acc:0.44, test acc:0.43 ===\n",
      "train loss:1.983324660743241\n",
      "train loss:2.0185359575903217\n",
      "train loss:1.8594419059837848\n",
      "train loss:1.9948828387660815\n",
      "=== epoch:35, train acc:0.445, test acc:0.43 ===\n",
      "train loss:2.034611245103691\n",
      "train loss:2.052510418589473\n",
      "train loss:1.9905256485253295\n",
      "train loss:1.9730355323816477\n",
      "=== epoch:36, train acc:0.4375, test acc:0.43 ===\n",
      "train loss:1.9588510441868159\n",
      "train loss:2.0352018563566956\n",
      "train loss:1.9876698618278403\n",
      "train loss:1.9298554456622217\n",
      "=== epoch:37, train acc:0.455, test acc:0.44 ===\n",
      "train loss:1.9090232761121624\n",
      "train loss:1.9864357523231952\n",
      "train loss:1.9509870557708722\n",
      "train loss:1.921500965401604\n",
      "=== epoch:38, train acc:0.465, test acc:0.46 ===\n",
      "train loss:1.94172043859672\n",
      "train loss:1.9541224276199645\n",
      "train loss:1.99458185423681\n",
      "train loss:2.0015327096337048\n",
      "=== epoch:39, train acc:0.4725, test acc:0.46 ===\n",
      "train loss:1.916138842059943\n",
      "train loss:1.9679430379024254\n",
      "train loss:1.867934294478048\n",
      "train loss:1.9520388250849798\n",
      "=== epoch:40, train acc:0.4825, test acc:0.49 ===\n",
      "train loss:1.8264602225204531\n",
      "train loss:1.8643981161254608\n",
      "train loss:1.8882540523536997\n",
      "train loss:1.922829678939051\n",
      "=== epoch:41, train acc:0.49, test acc:0.47 ===\n",
      "train loss:1.88876200545873\n",
      "train loss:1.9573230726981883\n",
      "train loss:1.9098555481346184\n",
      "train loss:1.982163792102034\n",
      "=== epoch:42, train acc:0.5, test acc:0.47 ===\n",
      "train loss:1.9337790734151266\n",
      "train loss:1.9154247532755808\n",
      "train loss:2.049856099393523\n",
      "train loss:1.9249723119390119\n",
      "=== epoch:43, train acc:0.505, test acc:0.5 ===\n",
      "train loss:1.801130692042093\n",
      "train loss:1.9249680878403939\n",
      "train loss:1.828418123687583\n",
      "train loss:1.8299944186079826\n",
      "=== epoch:44, train acc:0.515, test acc:0.5 ===\n",
      "train loss:1.8672129477081814\n",
      "train loss:1.9043608783080428\n",
      "train loss:1.9151472824033038\n",
      "train loss:1.8878030612092718\n",
      "=== epoch:45, train acc:0.5225, test acc:0.5 ===\n",
      "train loss:1.865399266872938\n",
      "train loss:1.867640986721031\n",
      "train loss:1.8409286828802471\n",
      "train loss:1.8889853821860287\n",
      "=== epoch:46, train acc:0.5325, test acc:0.5 ===\n",
      "train loss:1.811385367659211\n",
      "train loss:1.8101755100918464\n",
      "train loss:1.8687039686513085\n",
      "train loss:1.803796238606711\n",
      "=== epoch:47, train acc:0.54, test acc:0.5 ===\n",
      "train loss:1.7756549710396794\n",
      "train loss:1.7278758647149821\n",
      "train loss:1.8073177819950241\n",
      "train loss:1.8245539780868478\n",
      "=== epoch:48, train acc:0.545, test acc:0.51 ===\n",
      "train loss:1.8168802652850249\n",
      "train loss:1.797819996806421\n",
      "train loss:1.752265855440625\n",
      "train loss:1.874645663946675\n",
      "=== epoch:49, train acc:0.5525, test acc:0.52 ===\n",
      "train loss:1.7514700735398945\n",
      "train loss:1.7639016609890226\n",
      "train loss:1.8223822728316355\n",
      "train loss:1.8346430787291665\n",
      "=== epoch:50, train acc:0.56, test acc:0.52 ===\n",
      "train loss:1.8594963615679958\n",
      "train loss:1.7768075592925354\n",
      "train loss:1.810520386055754\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.54\n",
      "val_acc: 0.5200 | lr: 0.0027, weight_decay: 0.0000\n",
      "train loss:2.3143152760517967\n",
      "=== epoch:1, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.37263681300066\n",
      "train loss:2.3449409384289557\n",
      "train loss:2.356383525509779\n",
      "train loss:2.3186019343513897\n",
      "=== epoch:2, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.299428093238595\n",
      "train loss:2.333655510621216\n",
      "train loss:2.3666521744226663\n",
      "train loss:2.333294995912874\n",
      "=== epoch:3, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.3068950645985686\n",
      "train loss:2.3187992208698613\n",
      "train loss:2.357001062786538\n",
      "train loss:2.355432640456331\n",
      "=== epoch:4, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.385169098792344\n",
      "train loss:2.3237807623370967\n",
      "train loss:2.357747864857863\n",
      "train loss:2.3114081399016375\n",
      "=== epoch:5, train acc:0.0975, test acc:0.07 ===\n",
      "train loss:2.3480347133739032\n",
      "train loss:2.325175857721418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.353203978393981\n",
      "train loss:2.3403854066211545\n",
      "=== epoch:6, train acc:0.105, test acc:0.07 ===\n",
      "train loss:2.3075890415340377\n",
      "train loss:2.294553266300306\n",
      "train loss:2.333814321914761\n",
      "train loss:2.3736837135400024\n",
      "=== epoch:7, train acc:0.1075, test acc:0.07 ===\n",
      "train loss:2.350788593138722\n",
      "train loss:2.328132949469567\n",
      "train loss:2.372259582842582\n",
      "train loss:2.3640924440734707\n",
      "=== epoch:8, train acc:0.1075, test acc:0.07 ===\n",
      "train loss:2.3619869714137818\n",
      "train loss:2.314466097010364\n",
      "train loss:2.2949869491066037\n",
      "train loss:2.3140862571449405\n",
      "=== epoch:9, train acc:0.11, test acc:0.08 ===\n",
      "train loss:2.310503768303705\n",
      "train loss:2.3270354149992616\n",
      "train loss:2.2900278370432474\n",
      "train loss:2.3235566559344143\n",
      "=== epoch:10, train acc:0.1175, test acc:0.08 ===\n",
      "train loss:2.3035541343314465\n",
      "train loss:2.268053923400628\n",
      "train loss:2.3183758292628287\n",
      "train loss:2.2795413915479434\n",
      "=== epoch:11, train acc:0.1175, test acc:0.08 ===\n",
      "train loss:2.3280500460698836\n",
      "train loss:2.2743205520546956\n",
      "train loss:2.2977349689959587\n",
      "train loss:2.3146134927590953\n",
      "=== epoch:12, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.2449582836857336\n",
      "train loss:2.286709286364473\n",
      "train loss:2.309774968883288\n",
      "train loss:2.2643112640315746\n",
      "=== epoch:13, train acc:0.125, test acc:0.08 ===\n",
      "train loss:2.2221194592672067\n",
      "train loss:2.345127152579007\n",
      "train loss:2.303223119526262\n",
      "train loss:2.2683914659768383\n",
      "=== epoch:14, train acc:0.125, test acc:0.08 ===\n",
      "train loss:2.2938546542834777\n",
      "train loss:2.258578304647153\n",
      "train loss:2.242545036033598\n",
      "train loss:2.290981969883905\n",
      "=== epoch:15, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.277158026115541\n",
      "train loss:2.243679669103136\n",
      "train loss:2.2387298098565616\n",
      "train loss:2.269472914364314\n",
      "=== epoch:16, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.266173539476825\n",
      "train loss:2.2424799696245143\n",
      "train loss:2.2884432574564686\n",
      "train loss:2.2909313040641925\n",
      "=== epoch:17, train acc:0.1325, test acc:0.11 ===\n",
      "train loss:2.282716173675929\n",
      "train loss:2.2204862544902606\n",
      "train loss:2.2414742775757808\n",
      "train loss:2.238949284149455\n",
      "=== epoch:18, train acc:0.1325, test acc:0.12 ===\n",
      "train loss:2.235833531752121\n",
      "train loss:2.249188484890183\n",
      "train loss:2.223179106399626\n",
      "train loss:2.248401127052633\n",
      "=== epoch:19, train acc:0.1325, test acc:0.12 ===\n",
      "train loss:2.2769527114045465\n",
      "train loss:2.158915672188029\n",
      "train loss:2.244922100015483\n",
      "train loss:2.2692677112470796\n",
      "=== epoch:20, train acc:0.1325, test acc:0.12 ===\n",
      "train loss:2.220112471572676\n",
      "train loss:2.28891080793908\n",
      "train loss:2.1808647354665993\n",
      "train loss:2.2338132629822067\n",
      "=== epoch:21, train acc:0.1325, test acc:0.12 ===\n",
      "train loss:2.265815630430219\n",
      "train loss:2.3069055369735327\n",
      "train loss:2.270286565403047\n",
      "train loss:2.2045713050794045\n",
      "=== epoch:22, train acc:0.1375, test acc:0.13 ===\n",
      "train loss:2.1852184465846336\n",
      "train loss:2.2032506023016967\n",
      "train loss:2.2687060600690785\n",
      "train loss:2.205715445224441\n",
      "=== epoch:23, train acc:0.1475, test acc:0.13 ===\n",
      "train loss:2.227377262271269\n",
      "train loss:2.2329624540511617\n",
      "train loss:2.1954678555511618\n",
      "train loss:2.263656406227141\n",
      "=== epoch:24, train acc:0.1475, test acc:0.15 ===\n",
      "train loss:2.2361591647579355\n",
      "train loss:2.2350670630722957\n",
      "train loss:2.209223722630863\n",
      "train loss:2.231042162794279\n",
      "=== epoch:25, train acc:0.1475, test acc:0.16 ===\n",
      "train loss:2.1983914372679187\n",
      "train loss:2.2147117341205975\n",
      "train loss:2.22452317418178\n",
      "train loss:2.2417505832534483\n",
      "=== epoch:26, train acc:0.1525, test acc:0.16 ===\n",
      "train loss:2.211095301799197\n",
      "train loss:2.2287753709104345\n",
      "train loss:2.2451316342562486\n",
      "train loss:2.2384556952193018\n",
      "=== epoch:27, train acc:0.1575, test acc:0.16 ===\n",
      "train loss:2.261058258284279\n",
      "train loss:2.2311672114450296\n",
      "train loss:2.209801096799535\n",
      "train loss:2.2541492812696284\n",
      "=== epoch:28, train acc:0.1575, test acc:0.17 ===\n",
      "train loss:2.1804945247425973\n",
      "train loss:2.241661046833169\n",
      "train loss:2.24541309467168\n",
      "train loss:2.207525754959034\n",
      "=== epoch:29, train acc:0.16, test acc:0.17 ===\n",
      "train loss:2.1676501293739614\n",
      "train loss:2.2511832748349097\n",
      "train loss:2.2263592955072453\n",
      "train loss:2.218516841327939\n",
      "=== epoch:30, train acc:0.16, test acc:0.18 ===\n",
      "train loss:2.2256115468806126\n",
      "train loss:2.2474863787664194\n",
      "train loss:2.2182636369944335\n",
      "train loss:2.2362033399936005\n",
      "=== epoch:31, train acc:0.165, test acc:0.19 ===\n",
      "train loss:2.2260577449032932\n",
      "train loss:2.2104934871337365\n",
      "train loss:2.210336491515489\n",
      "train loss:2.168604325190781\n",
      "=== epoch:32, train acc:0.18, test acc:0.19 ===\n",
      "train loss:2.1656255187403466\n",
      "train loss:2.199673453395916\n",
      "train loss:2.2072193847830537\n",
      "train loss:2.173122912549918\n",
      "=== epoch:33, train acc:0.1875, test acc:0.19 ===\n",
      "train loss:2.1932019246915098\n",
      "train loss:2.181596924749536\n",
      "train loss:2.205916324940047\n",
      "train loss:2.1644664665270317\n",
      "=== epoch:34, train acc:0.19, test acc:0.19 ===\n",
      "train loss:2.220920874548148\n",
      "train loss:2.1892054686848947\n",
      "train loss:2.210553175837978\n",
      "train loss:2.2071164360235564\n",
      "=== epoch:35, train acc:0.19, test acc:0.19 ===\n",
      "train loss:2.2216085501032827\n",
      "train loss:2.1787774245232394\n",
      "train loss:2.2077420320525247\n",
      "train loss:2.1527444668778757\n",
      "=== epoch:36, train acc:0.1925, test acc:0.19 ===\n",
      "train loss:2.142471394166133\n",
      "train loss:2.1898531544827047\n",
      "train loss:2.246409222233124\n",
      "train loss:2.230225014243479\n",
      "=== epoch:37, train acc:0.195, test acc:0.2 ===\n",
      "train loss:2.219569801656423\n",
      "train loss:2.1734166757969056\n",
      "train loss:2.2113950584644066\n",
      "train loss:2.235410784504856\n",
      "=== epoch:38, train acc:0.1925, test acc:0.2 ===\n",
      "train loss:2.201628637118741\n",
      "train loss:2.1528977472831765\n",
      "train loss:2.1921120422926683\n",
      "train loss:2.1815072140873033\n",
      "=== epoch:39, train acc:0.195, test acc:0.2 ===\n",
      "train loss:2.2130852198734057\n",
      "train loss:2.2256484085759\n",
      "train loss:2.152128208868642\n",
      "train loss:2.1614155215667656\n",
      "=== epoch:40, train acc:0.2, test acc:0.21 ===\n",
      "train loss:2.1856721830055075\n",
      "train loss:2.1907159193555445\n",
      "train loss:2.1691431805675316\n",
      "train loss:2.1953328202858993\n",
      "=== epoch:41, train acc:0.21, test acc:0.22 ===\n",
      "train loss:2.1636659169628913\n",
      "train loss:2.1805416859063125\n",
      "train loss:2.175377712350843\n",
      "train loss:2.115593199617101\n",
      "=== epoch:42, train acc:0.22, test acc:0.21 ===\n",
      "train loss:2.2096845794744793\n",
      "train loss:2.22313104656672\n",
      "train loss:2.165354749748591\n",
      "train loss:2.1488596561383857\n",
      "=== epoch:43, train acc:0.23, test acc:0.21 ===\n",
      "train loss:2.206872953209645\n",
      "train loss:2.189974489187872\n",
      "train loss:2.1382428845393124\n",
      "train loss:2.143287307180362\n",
      "=== epoch:44, train acc:0.23, test acc:0.21 ===\n",
      "train loss:2.216430943397599\n",
      "train loss:2.175523623276978\n",
      "train loss:2.1516794889920257\n",
      "train loss:2.243812011789465\n",
      "=== epoch:45, train acc:0.2325, test acc:0.22 ===\n",
      "train loss:2.16371869967772\n",
      "train loss:2.153473636518972\n",
      "train loss:2.1971410084572702\n",
      "train loss:2.196792851290699\n",
      "=== epoch:46, train acc:0.235, test acc:0.21 ===\n",
      "train loss:2.171869500577531\n",
      "train loss:2.1758476883369124\n",
      "train loss:2.181201139381841\n",
      "train loss:2.206895680859301\n",
      "=== epoch:47, train acc:0.2375, test acc:0.21 ===\n",
      "train loss:2.1504154409438265\n",
      "train loss:2.114711533533\n",
      "train loss:2.1799440409378135\n",
      "train loss:2.167561308160936\n",
      "=== epoch:48, train acc:0.2425, test acc:0.21 ===\n",
      "train loss:2.1135159151331067\n",
      "train loss:2.1375152838924483\n",
      "train loss:2.161471022453486\n",
      "train loss:2.144833244213368\n",
      "=== epoch:49, train acc:0.24, test acc:0.23 ===\n",
      "train loss:2.1417257948869435\n",
      "train loss:2.1635512482051555\n",
      "train loss:2.127962671068405\n",
      "train loss:2.132032371579391\n",
      "=== epoch:50, train acc:0.245, test acc:0.24 ===\n",
      "train loss:2.146424212990562\n",
      "train loss:2.1428755355246945\n",
      "train loss:2.186640634310789\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.25\n",
      "val_acc: 0.2400 | lr: 0.0009, weight_decay: 0.0000\n",
      "train loss:2.406988760588588\n",
      "=== epoch:1, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4030791433244936\n",
      "train loss:2.458545383493456\n",
      "train loss:2.4056743138997763\n",
      "train loss:2.3872434613112756\n",
      "=== epoch:2, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3862120070799455\n",
      "train loss:2.4388803596495894\n",
      "train loss:2.4126343049722405\n",
      "train loss:2.436516173161798\n",
      "=== epoch:3, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3946894389658584\n",
      "train loss:2.407448825990935\n",
      "train loss:2.43247983771287\n",
      "train loss:2.4278110862009874\n",
      "=== epoch:4, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4136967638895377\n",
      "train loss:2.425238240030899\n",
      "train loss:2.4074978842166024\n",
      "train loss:2.417806912525672\n",
      "=== epoch:5, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4112925302039514\n",
      "train loss:2.4590247323225185\n",
      "train loss:2.416780569717018\n",
      "train loss:2.3682219883106033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:6, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.383086699889092\n",
      "train loss:2.3791357779111144\n",
      "train loss:2.419926109174264\n",
      "train loss:2.4461683055135945\n",
      "=== epoch:7, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.405622902064675\n",
      "train loss:2.391582763350129\n",
      "train loss:2.4051614734493265\n",
      "train loss:2.386138667533659\n",
      "=== epoch:8, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.403916984243252\n",
      "train loss:2.418267035580605\n",
      "train loss:2.442293041459218\n",
      "train loss:2.4068620912446153\n",
      "=== epoch:9, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.394391283100322\n",
      "train loss:2.4223841225219274\n",
      "train loss:2.434454796418606\n",
      "train loss:2.4594576306383864\n",
      "=== epoch:10, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4546503598253238\n",
      "train loss:2.395122001647204\n",
      "train loss:2.4263926502629536\n",
      "train loss:2.4542974108304842\n",
      "=== epoch:11, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.385460059171553\n",
      "train loss:2.441887300666438\n",
      "train loss:2.4275457293818636\n",
      "train loss:2.3628326885272886\n",
      "=== epoch:12, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.36798597400091\n",
      "train loss:2.4054388854905744\n",
      "train loss:2.3970617183881715\n",
      "train loss:2.389486708667427\n",
      "=== epoch:13, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.357598275840156\n",
      "train loss:2.401829632930441\n",
      "train loss:2.425282006483942\n",
      "train loss:2.40444648715771\n",
      "=== epoch:14, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.422212266396706\n",
      "train loss:2.429999377603732\n",
      "train loss:2.426711658482052\n",
      "train loss:2.431467678842912\n",
      "=== epoch:15, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4729515812770417\n",
      "train loss:2.4386252946118647\n",
      "train loss:2.4088172861337505\n",
      "train loss:2.3846795142038695\n",
      "=== epoch:16, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.439633199084108\n",
      "train loss:2.427629878044488\n",
      "train loss:2.451254777664443\n",
      "train loss:2.4021053277144584\n",
      "=== epoch:17, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.451102094413957\n",
      "train loss:2.4063150439792813\n",
      "train loss:2.3864758873678036\n",
      "train loss:2.4271129459476843\n",
      "=== epoch:18, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4129569283249905\n",
      "train loss:2.404191620448339\n",
      "train loss:2.4031421496335614\n",
      "train loss:2.440224274490092\n",
      "=== epoch:19, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.41084831563083\n",
      "train loss:2.404296235881728\n",
      "train loss:2.4399074023088443\n",
      "train loss:2.4359048126329426\n",
      "=== epoch:20, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.33325344685376\n",
      "train loss:2.4175154077914396\n",
      "train loss:2.4161429955247598\n",
      "train loss:2.468629731802873\n",
      "=== epoch:21, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.418613064652909\n",
      "train loss:2.432768923198643\n",
      "train loss:2.402972493807126\n",
      "train loss:2.40584104370723\n",
      "=== epoch:22, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.443771361720527\n",
      "train loss:2.4110468537765546\n",
      "train loss:2.405074693300549\n",
      "train loss:2.406068352668482\n",
      "=== epoch:23, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4135244691350994\n",
      "train loss:2.3862058929797407\n",
      "train loss:2.3961321636897264\n",
      "train loss:2.445427121137489\n",
      "=== epoch:24, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.398309088540811\n",
      "train loss:2.3624302897452276\n",
      "train loss:2.396086415583354\n",
      "train loss:2.3421062226089755\n",
      "=== epoch:25, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.422683073788669\n",
      "train loss:2.398480982504132\n",
      "train loss:2.437502170147508\n",
      "train loss:2.3980397463356162\n",
      "=== epoch:26, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3954166710768687\n",
      "train loss:2.3966583915526116\n",
      "train loss:2.437574449518821\n",
      "train loss:2.39907832780373\n",
      "=== epoch:27, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3340126294350934\n",
      "train loss:2.360812284385887\n",
      "train loss:2.4161461665880735\n",
      "train loss:2.430598627217951\n",
      "=== epoch:28, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4232124747400916\n",
      "train loss:2.421782943459833\n",
      "train loss:2.4393082710980836\n",
      "train loss:2.4180608484581825\n",
      "=== epoch:29, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4449628798904213\n",
      "train loss:2.410655391231543\n",
      "train loss:2.446564162266482\n",
      "train loss:2.426347234257512\n",
      "=== epoch:30, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3803005045018\n",
      "train loss:2.3652215151452856\n",
      "train loss:2.4091577802900574\n",
      "train loss:2.435298071104984\n",
      "=== epoch:31, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3968088035192596\n",
      "train loss:2.3740936002724737\n",
      "train loss:2.3959559386907108\n",
      "train loss:2.3782744541417116\n",
      "=== epoch:32, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.416556764404802\n",
      "train loss:2.436836258989462\n",
      "train loss:2.441529747263466\n",
      "train loss:2.426771282303687\n",
      "=== epoch:33, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4188737865507757\n",
      "train loss:2.407379793959898\n",
      "train loss:2.3984670797655183\n",
      "train loss:2.441770432747172\n",
      "=== epoch:34, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.430709371294889\n",
      "train loss:2.402968407189652\n",
      "train loss:2.4285905958125626\n",
      "train loss:2.397364992469215\n",
      "=== epoch:35, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3951541169156436\n",
      "train loss:2.381977535209519\n",
      "train loss:2.348651844971645\n",
      "train loss:2.423197752785835\n",
      "=== epoch:36, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4508286110588093\n",
      "train loss:2.4036297401994937\n",
      "train loss:2.407655175090924\n",
      "train loss:2.4257292954028795\n",
      "=== epoch:37, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.363984837572724\n",
      "train loss:2.424847279323298\n",
      "train loss:2.381230055672041\n",
      "train loss:2.40961307955513\n",
      "=== epoch:38, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3716604103328405\n",
      "train loss:2.4278803225129133\n",
      "train loss:2.464275525438075\n",
      "train loss:2.395035788645436\n",
      "=== epoch:39, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4030384283321333\n",
      "train loss:2.400962849595825\n",
      "train loss:2.4174762302221637\n",
      "train loss:2.4083929652642557\n",
      "=== epoch:40, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4126300950779287\n",
      "train loss:2.4139585396098036\n",
      "train loss:2.4413475172522507\n",
      "train loss:2.445591882874058\n",
      "=== epoch:41, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.413658467977041\n",
      "train loss:2.3814439959943083\n",
      "train loss:2.45809107723511\n",
      "train loss:2.434843145778502\n",
      "=== epoch:42, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4233873652075957\n",
      "train loss:2.417900145796026\n",
      "train loss:2.4286670191330386\n",
      "train loss:2.3714694810930124\n",
      "=== epoch:43, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3792458351000016\n",
      "train loss:2.388249960565899\n",
      "train loss:2.4131530138484347\n",
      "train loss:2.438415776844545\n",
      "=== epoch:44, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.41643536955014\n",
      "train loss:2.3782759171213392\n",
      "train loss:2.3932397442415088\n",
      "train loss:2.4254738571208523\n",
      "=== epoch:45, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.409415423999556\n",
      "train loss:2.3904394306977133\n",
      "train loss:2.440896881730548\n",
      "train loss:2.3712774164645674\n",
      "=== epoch:46, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3877412434483367\n",
      "train loss:2.400487661903992\n",
      "train loss:2.3913390518703443\n",
      "train loss:2.4003369034122577\n",
      "=== epoch:47, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4102446834718507\n",
      "train loss:2.415864629517737\n",
      "train loss:2.3952357374106796\n",
      "train loss:2.386341957630984\n",
      "=== epoch:48, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.376975472758127\n",
      "train loss:2.4047758161356705\n",
      "train loss:2.4423139938352483\n",
      "train loss:2.433931527887748\n",
      "=== epoch:49, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3914045910419026\n",
      "train loss:2.392729408376959\n",
      "train loss:2.373689770913864\n",
      "train loss:2.3950029729100155\n",
      "=== epoch:50, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3895115560833182\n",
      "train loss:2.39579203055501\n",
      "train loss:2.4326139995515303\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0000, weight_decay: 0.0001\n",
      "train loss:2.4204704034584577\n",
      "=== epoch:1, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.4337520801216823\n",
      "train loss:2.4129105548254075\n",
      "train loss:2.372316813365618\n",
      "train loss:2.3640526821689734\n",
      "=== epoch:2, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.4486357488574595\n",
      "train loss:2.3242731235262086\n",
      "train loss:2.3683209077116727\n",
      "train loss:2.442055134296722\n",
      "=== epoch:3, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.4040051253016954\n",
      "train loss:2.387902621445786\n",
      "train loss:2.4067732695544293\n",
      "train loss:2.336306345610309\n",
      "=== epoch:4, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.3622299019562205\n",
      "train loss:2.3998473341425695\n",
      "train loss:2.361699253567781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3521867123957807\n",
      "=== epoch:5, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.3537039862887297\n",
      "train loss:2.304083510952786\n",
      "train loss:2.346665105651925\n",
      "train loss:2.387543849651156\n",
      "=== epoch:6, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.335971470773144\n",
      "train loss:2.407583911065041\n",
      "train loss:2.441336265813399\n",
      "train loss:2.4493304148875654\n",
      "=== epoch:7, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.425099807424918\n",
      "train loss:2.328121817875793\n",
      "train loss:2.370046419330175\n",
      "train loss:2.378380799461438\n",
      "=== epoch:8, train acc:0.085, test acc:0.09 ===\n",
      "train loss:2.4028141365745688\n",
      "train loss:2.438472855178422\n",
      "train loss:2.3641460889048123\n",
      "train loss:2.3768331482333136\n",
      "=== epoch:9, train acc:0.085, test acc:0.09 ===\n",
      "train loss:2.307566218522109\n",
      "train loss:2.376114715107931\n",
      "train loss:2.3355500544505836\n",
      "train loss:2.302967951140566\n",
      "=== epoch:10, train acc:0.085, test acc:0.09 ===\n",
      "train loss:2.3819318331534802\n",
      "train loss:2.456363915154648\n",
      "train loss:2.416632478322917\n",
      "train loss:2.307383314841414\n",
      "=== epoch:11, train acc:0.085, test acc:0.09 ===\n",
      "train loss:2.3690165854326426\n",
      "train loss:2.3479086475956934\n",
      "train loss:2.321492479111539\n",
      "train loss:2.4242116857348157\n",
      "=== epoch:12, train acc:0.085, test acc:0.09 ===\n",
      "train loss:2.4189808004094333\n",
      "train loss:2.326316599273507\n",
      "train loss:2.3480635415377766\n",
      "train loss:2.3879001459275213\n",
      "=== epoch:13, train acc:0.085, test acc:0.09 ===\n",
      "train loss:2.3755729276586885\n",
      "train loss:2.3833874582737535\n",
      "train loss:2.404236449073617\n",
      "train loss:2.4053256918611283\n",
      "=== epoch:14, train acc:0.085, test acc:0.09 ===\n",
      "train loss:2.432677878595082\n",
      "train loss:2.3877090017731666\n",
      "train loss:2.3697327748133827\n",
      "train loss:2.3817364429526156\n",
      "=== epoch:15, train acc:0.085, test acc:0.09 ===\n",
      "train loss:2.4379125392188037\n",
      "train loss:2.394617711620168\n",
      "train loss:2.3696691840806094\n",
      "train loss:2.304947022706687\n",
      "=== epoch:16, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4211964724088983\n",
      "train loss:2.4137983162620356\n",
      "train loss:2.3040109826099373\n",
      "train loss:2.3977197785149853\n",
      "=== epoch:17, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.354256687493177\n",
      "train loss:2.353487231236858\n",
      "train loss:2.2916909741346307\n",
      "train loss:2.389171924165294\n",
      "=== epoch:18, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.346781756109679\n",
      "train loss:2.3128604842613396\n",
      "train loss:2.365928268362914\n",
      "train loss:2.3604042229354527\n",
      "=== epoch:19, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.334304046247549\n",
      "train loss:2.301987270313948\n",
      "train loss:2.3421846039721603\n",
      "train loss:2.3508628121497415\n",
      "=== epoch:20, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.3214125647937727\n",
      "train loss:2.3409990846585034\n",
      "train loss:2.4188469547193754\n",
      "train loss:2.42724748565061\n",
      "=== epoch:21, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.4344714020827083\n",
      "train loss:2.296701830794453\n",
      "train loss:2.288492969976895\n",
      "train loss:2.363718811992009\n",
      "=== epoch:22, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.3166433322676596\n",
      "train loss:2.281742054179432\n",
      "train loss:2.3001065033275596\n",
      "train loss:2.3975502442690315\n",
      "=== epoch:23, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.386079292005307\n",
      "train loss:2.329524396670055\n",
      "train loss:2.3536743028431473\n",
      "train loss:2.376370370725463\n",
      "=== epoch:24, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.2678598925601734\n",
      "train loss:2.3641662341022984\n",
      "train loss:2.375585530273421\n",
      "train loss:2.3074208452820346\n",
      "=== epoch:25, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.434306263865203\n",
      "train loss:2.398541644170572\n",
      "train loss:2.293683672497095\n",
      "train loss:2.324412207468789\n",
      "=== epoch:26, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.3997898210629383\n",
      "train loss:2.361652164746897\n",
      "train loss:2.359020495867233\n",
      "train loss:2.3401126352732424\n",
      "=== epoch:27, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.375015018797029\n",
      "train loss:2.3629808734365056\n",
      "train loss:2.3611144100910244\n",
      "train loss:2.336166477545289\n",
      "=== epoch:28, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.27602110557361\n",
      "train loss:2.3661551614185417\n",
      "train loss:2.3358020823244248\n",
      "train loss:2.370309828003958\n",
      "=== epoch:29, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.3212610004130374\n",
      "train loss:2.3655226067967874\n",
      "train loss:2.3246552639100977\n",
      "train loss:2.317399217205496\n",
      "=== epoch:30, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.3722284739965107\n",
      "train loss:2.329888993764918\n",
      "train loss:2.362533373469254\n",
      "train loss:2.3459339181465717\n",
      "=== epoch:31, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.3150148363233507\n",
      "train loss:2.304116074942051\n",
      "train loss:2.4053912584490784\n",
      "train loss:2.3260997644810892\n",
      "=== epoch:32, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.30970734754711\n",
      "train loss:2.2733066658856345\n",
      "train loss:2.3358251790983537\n",
      "train loss:2.2709976258274356\n",
      "=== epoch:33, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.357580860749058\n",
      "train loss:2.3423340087200835\n",
      "train loss:2.386155953862472\n",
      "train loss:2.310881731163889\n",
      "=== epoch:34, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.353651910850896\n",
      "train loss:2.370248144784478\n",
      "train loss:2.3923881388284474\n",
      "train loss:2.3687808368891106\n",
      "=== epoch:35, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.372014979966399\n",
      "train loss:2.4076669148192074\n",
      "train loss:2.294160483429007\n",
      "train loss:2.3432812841273756\n",
      "=== epoch:36, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.381320415884657\n",
      "train loss:2.356551576634593\n",
      "train loss:2.3132304267626678\n",
      "train loss:2.2865790705991906\n",
      "=== epoch:37, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.3036272659600256\n",
      "train loss:2.3588254538971745\n",
      "train loss:2.3856907253485486\n",
      "train loss:2.309263776400775\n",
      "=== epoch:38, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.373651532232514\n",
      "train loss:2.3195328163743594\n",
      "train loss:2.384679122562002\n",
      "train loss:2.366859114585366\n",
      "=== epoch:39, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.3067696374663718\n",
      "train loss:2.3571437873557692\n",
      "train loss:2.334845387619397\n",
      "train loss:2.372479617379748\n",
      "=== epoch:40, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.3145285414001826\n",
      "train loss:2.368097554125129\n",
      "train loss:2.334304989701121\n",
      "train loss:2.3655331578428647\n",
      "=== epoch:41, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.3988127104615\n",
      "train loss:2.3401782348257485\n",
      "train loss:2.3863036532019755\n",
      "train loss:2.3306596693493113\n",
      "=== epoch:42, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.3903035916210533\n",
      "train loss:2.301609705911066\n",
      "train loss:2.3249470830655494\n",
      "train loss:2.270398200437933\n",
      "=== epoch:43, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.300137950736445\n",
      "train loss:2.381933880986775\n",
      "train loss:2.3415305319192994\n",
      "train loss:2.2900765262805973\n",
      "=== epoch:44, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.351780128466868\n",
      "train loss:2.3300477963552906\n",
      "train loss:2.2688764397000143\n",
      "train loss:2.3381085703597133\n",
      "=== epoch:45, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.3782019980885627\n",
      "train loss:2.2528572061068615\n",
      "train loss:2.300303686941916\n",
      "train loss:2.2988514003286986\n",
      "=== epoch:46, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.342585486895191\n",
      "train loss:2.3458848932892122\n",
      "train loss:2.3193933210722117\n",
      "train loss:2.353126727226095\n",
      "=== epoch:47, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.327812341249771\n",
      "train loss:2.391163498661891\n",
      "train loss:2.3325612576887464\n",
      "train loss:2.305852956607045\n",
      "=== epoch:48, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.259663658034084\n",
      "train loss:2.2611523800683284\n",
      "train loss:2.333440246580524\n",
      "train loss:2.380828988491298\n",
      "=== epoch:49, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.323702453685674\n",
      "train loss:2.3605208028919384\n",
      "train loss:2.308324366169482\n",
      "train loss:2.298108308329282\n",
      "=== epoch:50, train acc:0.085, test acc:0.07 ===\n",
      "train loss:2.292094863752197\n",
      "train loss:2.318600703080071\n",
      "train loss:2.338368420566289\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0002, weight_decay: 0.0000\n",
      "train loss:2.362018690289268\n",
      "=== epoch:1, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.33494271597565\n",
      "train loss:2.328520782791823\n",
      "train loss:2.343873044268154\n",
      "train loss:2.3312955883795143\n",
      "=== epoch:2, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.321116172603927\n",
      "train loss:2.3515904487930865\n",
      "train loss:2.3845594280195392\n",
      "train loss:2.369175255024903\n",
      "=== epoch:3, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3638150572524723\n",
      "train loss:2.354981389229489\n",
      "train loss:2.3495859119629254\n",
      "train loss:2.3667442225766115\n",
      "=== epoch:4, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3533805128479135\n",
      "train loss:2.36133657006658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3572258301231286\n",
      "train loss:2.337899345385085\n",
      "=== epoch:5, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.379536102703022\n",
      "train loss:2.3688225111851313\n",
      "train loss:2.3744561419324817\n",
      "train loss:2.3274182462416135\n",
      "=== epoch:6, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3514537406267246\n",
      "train loss:2.3438056821110185\n",
      "train loss:2.3290440170447186\n",
      "train loss:2.3456155421217653\n",
      "=== epoch:7, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.368312562614771\n",
      "train loss:2.366671248515194\n",
      "train loss:2.3549666770746303\n",
      "train loss:2.3698745345270433\n",
      "=== epoch:8, train acc:0.06, test acc:0.07 ===\n",
      "train loss:2.342823403770743\n",
      "train loss:2.3418712968900084\n",
      "train loss:2.3345118803578373\n",
      "train loss:2.344015543398712\n",
      "=== epoch:9, train acc:0.06, test acc:0.07 ===\n",
      "train loss:2.340596558045757\n",
      "train loss:2.321562610706562\n",
      "train loss:2.325996597343736\n",
      "train loss:2.3522864976237474\n",
      "=== epoch:10, train acc:0.06, test acc:0.07 ===\n",
      "train loss:2.3498104120109873\n",
      "train loss:2.3555468627704963\n",
      "train loss:2.3463815137961026\n",
      "train loss:2.3617370145018395\n",
      "=== epoch:11, train acc:0.06, test acc:0.07 ===\n",
      "train loss:2.354090064722231\n",
      "train loss:2.3875554542014523\n",
      "train loss:2.331338998850628\n",
      "train loss:2.350860531042481\n",
      "=== epoch:12, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.339606377902446\n",
      "train loss:2.3313373730620333\n",
      "train loss:2.359887142803507\n",
      "train loss:2.3240458788708622\n",
      "=== epoch:13, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3395443293344873\n",
      "train loss:2.374405856900655\n",
      "train loss:2.3593566280409513\n",
      "train loss:2.358375305487943\n",
      "=== epoch:14, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.374415131945332\n",
      "train loss:2.3521323760670754\n",
      "train loss:2.3585757678144565\n",
      "train loss:2.3318108633646393\n",
      "=== epoch:15, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3492462001719754\n",
      "train loss:2.3641026598183705\n",
      "train loss:2.3445740503675365\n",
      "train loss:2.3408842182118375\n",
      "=== epoch:16, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.34980646147312\n",
      "train loss:2.355427240634112\n",
      "train loss:2.365557468540946\n",
      "train loss:2.31484928155136\n",
      "=== epoch:17, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.325149620154822\n",
      "train loss:2.328957779904054\n",
      "train loss:2.357992710943993\n",
      "train loss:2.3530510175060253\n",
      "=== epoch:18, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3298752944640557\n",
      "train loss:2.327887689121135\n",
      "train loss:2.378629782279056\n",
      "train loss:2.346046673874371\n",
      "=== epoch:19, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3295945267134823\n",
      "train loss:2.3728279443760756\n",
      "train loss:2.3469967217798517\n",
      "train loss:2.362576249649595\n",
      "=== epoch:20, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3380236859713652\n",
      "train loss:2.340714412231859\n",
      "train loss:2.3459691900530135\n",
      "train loss:2.343607379455082\n",
      "=== epoch:21, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3563995286977493\n",
      "train loss:2.348471524171452\n",
      "train loss:2.3605379030924794\n",
      "train loss:2.3338335397571717\n",
      "=== epoch:22, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.348645513801507\n",
      "train loss:2.368010849283969\n",
      "train loss:2.338961917402091\n",
      "train loss:2.334946692358537\n",
      "=== epoch:23, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3367023197798837\n",
      "train loss:2.363894396569231\n",
      "train loss:2.356583142019802\n",
      "train loss:2.331786512819046\n",
      "=== epoch:24, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.325314881271651\n",
      "train loss:2.319924736247245\n",
      "train loss:2.3370354647269274\n",
      "train loss:2.3642670679179143\n",
      "=== epoch:25, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3556666993666298\n",
      "train loss:2.3400366911181036\n",
      "train loss:2.363386126973598\n",
      "train loss:2.3429723528898845\n",
      "=== epoch:26, train acc:0.0625, test acc:0.07 ===\n",
      "train loss:2.3347547694789488\n",
      "train loss:2.3528228980806487\n",
      "train loss:2.3435707519138402\n",
      "train loss:2.3216486136644248\n",
      "=== epoch:27, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3510691346094537\n",
      "train loss:2.339813265738809\n",
      "train loss:2.326719269182688\n",
      "train loss:2.3214359411285157\n",
      "=== epoch:28, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3220826515407027\n",
      "train loss:2.3038002662493455\n",
      "train loss:2.348075083522125\n",
      "train loss:2.3150711019332566\n",
      "=== epoch:29, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.352007940754396\n",
      "train loss:2.3475537517326432\n",
      "train loss:2.3462988975904793\n",
      "train loss:2.3378544917379385\n",
      "=== epoch:30, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.361824736332845\n",
      "train loss:2.3326695497572945\n",
      "train loss:2.3459044336974464\n",
      "train loss:2.3555048661031672\n",
      "=== epoch:31, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3561809949964694\n",
      "train loss:2.3269642360382883\n",
      "train loss:2.338607652601551\n",
      "train loss:2.290233239854368\n",
      "=== epoch:32, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.36130031543026\n",
      "train loss:2.3193845664061206\n",
      "train loss:2.3313933707872136\n",
      "train loss:2.331557076439954\n",
      "=== epoch:33, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3556393444823196\n",
      "train loss:2.334546041500744\n",
      "train loss:2.3234793313154465\n",
      "train loss:2.3364014209945743\n",
      "=== epoch:34, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.332033175578769\n",
      "train loss:2.299206126154875\n",
      "train loss:2.308954264391838\n",
      "train loss:2.3410869463354214\n",
      "=== epoch:35, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3180014566561855\n",
      "train loss:2.371955756846638\n",
      "train loss:2.316909040005805\n",
      "train loss:2.3278949515305714\n",
      "=== epoch:36, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3397919647438146\n",
      "train loss:2.310587935593106\n",
      "train loss:2.350677495073336\n",
      "train loss:2.3402623200989323\n",
      "=== epoch:37, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3224275301738495\n",
      "train loss:2.3439281712820192\n",
      "train loss:2.35285314556421\n",
      "train loss:2.333761348934384\n",
      "=== epoch:38, train acc:0.0675, test acc:0.07 ===\n",
      "train loss:2.33599655733876\n",
      "train loss:2.3001443291130292\n",
      "train loss:2.3394559873636496\n",
      "train loss:2.310057546239136\n",
      "=== epoch:39, train acc:0.0675, test acc:0.07 ===\n",
      "train loss:2.32259893136331\n",
      "train loss:2.3335157404165527\n",
      "train loss:2.321628579667226\n",
      "train loss:2.324080612277535\n",
      "=== epoch:40, train acc:0.0675, test acc:0.07 ===\n",
      "train loss:2.3098305103880037\n",
      "train loss:2.316059651548904\n",
      "train loss:2.305488482909842\n",
      "train loss:2.3391459715641125\n",
      "=== epoch:41, train acc:0.0675, test acc:0.07 ===\n",
      "train loss:2.3139984774384206\n",
      "train loss:2.32098280793171\n",
      "train loss:2.3517019264357306\n",
      "train loss:2.318331857814211\n",
      "=== epoch:42, train acc:0.0675, test acc:0.07 ===\n",
      "train loss:2.3381551521494406\n",
      "train loss:2.338755979875477\n",
      "train loss:2.325306827892035\n",
      "train loss:2.3115869372990328\n",
      "=== epoch:43, train acc:0.0675, test acc:0.07 ===\n",
      "train loss:2.3170756753369433\n",
      "train loss:2.3320589840571264\n",
      "train loss:2.359559314610476\n",
      "train loss:2.3295961787230293\n",
      "=== epoch:44, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.354705168443032\n",
      "train loss:2.312496162511809\n",
      "train loss:2.344531688681009\n",
      "train loss:2.363528352984883\n",
      "=== epoch:45, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3202496794577683\n",
      "train loss:2.345232274134841\n",
      "train loss:2.343260126298931\n",
      "train loss:2.36184683886616\n",
      "=== epoch:46, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.304892558660278\n",
      "train loss:2.3452902849874224\n",
      "train loss:2.324733232412312\n",
      "train loss:2.318075548179765\n",
      "=== epoch:47, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.340360032687896\n",
      "train loss:2.2916510764409614\n",
      "train loss:2.3105897843787533\n",
      "train loss:2.3269066080996805\n",
      "=== epoch:48, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.342974649953634\n",
      "train loss:2.309314549319558\n",
      "train loss:2.31677899366106\n",
      "train loss:2.290847877654508\n",
      "=== epoch:49, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3395965762765507\n",
      "train loss:2.2810517873597234\n",
      "train loss:2.310467776907167\n",
      "train loss:2.316173940546722\n",
      "=== epoch:50, train acc:0.065, test acc:0.07 ===\n",
      "train loss:2.3017619071092157\n",
      "train loss:2.3192203042613033\n",
      "train loss:2.345018749624863\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.3697099891927365\n",
      "=== epoch:1, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.36583295359006\n",
      "train loss:2.351768437805317\n",
      "train loss:2.286662269261484\n",
      "train loss:2.327540913667564\n",
      "=== epoch:2, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.3527294726476455\n",
      "train loss:2.348946900334856\n",
      "train loss:2.34441543632801\n",
      "train loss:2.406307183705596\n",
      "=== epoch:3, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.401723980327153\n",
      "train loss:2.340294471844204\n",
      "train loss:2.374240109190274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.379857932638641\n",
      "=== epoch:4, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.359544239967221\n",
      "train loss:2.359247115683515\n",
      "train loss:2.406137725317431\n",
      "train loss:2.379800448618341\n",
      "=== epoch:5, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.346849567464841\n",
      "train loss:2.3584786162944322\n",
      "train loss:2.3913119815651425\n",
      "train loss:2.3458940376989763\n",
      "=== epoch:6, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.36753266880043\n",
      "train loss:2.338121947668001\n",
      "train loss:2.370131614070664\n",
      "train loss:2.3340203713715626\n",
      "=== epoch:7, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.373343575893107\n",
      "train loss:2.3431089314727283\n",
      "train loss:2.386097155890164\n",
      "train loss:2.3579577763261454\n",
      "=== epoch:8, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.35760229736717\n",
      "train loss:2.3844086533299222\n",
      "train loss:2.3133205524056235\n",
      "train loss:2.3718461122337615\n",
      "=== epoch:9, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.4164423330832694\n",
      "train loss:2.407540743005336\n",
      "train loss:2.4024025730721257\n",
      "train loss:2.348654858326915\n",
      "=== epoch:10, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.3922042059896\n",
      "train loss:2.355049238150586\n",
      "train loss:2.388848469116179\n",
      "train loss:2.4267547506671643\n",
      "=== epoch:11, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.400517232989623\n",
      "train loss:2.388295787676856\n",
      "train loss:2.339627545227536\n",
      "train loss:2.399100522859039\n",
      "=== epoch:12, train acc:0.115, test acc:0.06 ===\n",
      "train loss:2.3437103168600735\n",
      "train loss:2.3111392978876504\n",
      "train loss:2.3563115247094784\n",
      "train loss:2.4093278401542606\n",
      "=== epoch:13, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.358253695710274\n",
      "train loss:2.4293942405911233\n",
      "train loss:2.331940765354482\n",
      "train loss:2.3531153374151437\n",
      "=== epoch:14, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.331229836677955\n",
      "train loss:2.385251427284208\n",
      "train loss:2.43263888514789\n",
      "train loss:2.334469344771083\n",
      "=== epoch:15, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3683026126806306\n",
      "train loss:2.336282670442834\n",
      "train loss:2.364369409357811\n",
      "train loss:2.342353416874174\n",
      "=== epoch:16, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.376901229029678\n",
      "train loss:2.420194456591833\n",
      "train loss:2.3113328012916647\n",
      "train loss:2.3550212244624293\n",
      "=== epoch:17, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3182234749369095\n",
      "train loss:2.3727640742205502\n",
      "train loss:2.3839049371133303\n",
      "train loss:2.355318691419738\n",
      "=== epoch:18, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3852097716384426\n",
      "train loss:2.3691790351559376\n",
      "train loss:2.329918888678466\n",
      "train loss:2.4031102248519036\n",
      "=== epoch:19, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3744652385606515\n",
      "train loss:2.358558866886719\n",
      "train loss:2.3642061040362985\n",
      "train loss:2.3892002586777465\n",
      "=== epoch:20, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.347390692265286\n",
      "train loss:2.3330694159773366\n",
      "train loss:2.316834648239117\n",
      "train loss:2.3986755603814576\n",
      "=== epoch:21, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.371742751140551\n",
      "train loss:2.3617442257955132\n",
      "train loss:2.2960452353563454\n",
      "train loss:2.362192234418513\n",
      "=== epoch:22, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3513560951656816\n",
      "train loss:2.3763263960203487\n",
      "train loss:2.360023070318985\n",
      "train loss:2.3565237456939383\n",
      "=== epoch:23, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3533222012657147\n",
      "train loss:2.344401059848142\n",
      "train loss:2.39474263105698\n",
      "train loss:2.359006264073328\n",
      "=== epoch:24, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3585658371066813\n",
      "train loss:2.3884831889136935\n",
      "train loss:2.342365915747445\n",
      "train loss:2.3325438374122056\n",
      "=== epoch:25, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.404213398811797\n",
      "train loss:2.379668331479903\n",
      "train loss:2.357311124029791\n",
      "train loss:2.377204244105073\n",
      "=== epoch:26, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3558958413382918\n",
      "train loss:2.38913997064088\n",
      "train loss:2.336038982588788\n",
      "train loss:2.3123559011578863\n",
      "=== epoch:27, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3464303619720974\n",
      "train loss:2.3709426505534585\n",
      "train loss:2.3379233097149585\n",
      "train loss:2.368253350587239\n",
      "=== epoch:28, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.351775455274652\n",
      "train loss:2.3535152712448384\n",
      "train loss:2.3292910972302745\n",
      "train loss:2.416492497770038\n",
      "=== epoch:29, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.30044922614376\n",
      "train loss:2.3635211324990886\n",
      "train loss:2.3491756336662073\n",
      "train loss:2.364806586362689\n",
      "=== epoch:30, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.385098404475105\n",
      "train loss:2.3695531766803075\n",
      "train loss:2.2698929169416413\n",
      "train loss:2.3585256059450415\n",
      "=== epoch:31, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3579756716708977\n",
      "train loss:2.3651704461448566\n",
      "train loss:2.394436073137842\n",
      "train loss:2.3449782968209765\n",
      "=== epoch:32, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3481986101490113\n",
      "train loss:2.347664864103614\n",
      "train loss:2.3324330231579324\n",
      "train loss:2.3684922836343434\n",
      "=== epoch:33, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3878315562552355\n",
      "train loss:2.3101319662076687\n",
      "train loss:2.409398089813859\n",
      "train loss:2.39161950682281\n",
      "=== epoch:34, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3326919702878284\n",
      "train loss:2.3532407734091048\n",
      "train loss:2.372716521174185\n",
      "train loss:2.3814089201376833\n",
      "=== epoch:35, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3227510940286282\n",
      "train loss:2.3401193571111274\n",
      "train loss:2.315656913142558\n",
      "train loss:2.321153651579827\n",
      "=== epoch:36, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.4000162771620155\n",
      "train loss:2.35606773614556\n",
      "train loss:2.418162609563273\n",
      "train loss:2.33112676160091\n",
      "=== epoch:37, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.418808024848934\n",
      "train loss:2.354445422289134\n",
      "train loss:2.4035217709458614\n",
      "train loss:2.425377598683354\n",
      "=== epoch:38, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3496675091763346\n",
      "train loss:2.3842491430069255\n",
      "train loss:2.3363491216628276\n",
      "train loss:2.371451618350788\n",
      "=== epoch:39, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3844321143781615\n",
      "train loss:2.3421632233130767\n",
      "train loss:2.3552401546065127\n",
      "train loss:2.3331950902580254\n",
      "=== epoch:40, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.335157559119503\n",
      "train loss:2.2789686941281335\n",
      "train loss:2.3366634669799407\n",
      "train loss:2.359329259802658\n",
      "=== epoch:41, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.328970767411182\n",
      "train loss:2.3728277130791904\n",
      "train loss:2.367318380714416\n",
      "train loss:2.3359679632977075\n",
      "=== epoch:42, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.360797820467235\n",
      "train loss:2.36802763815763\n",
      "train loss:2.3508291739215457\n",
      "train loss:2.412704310162316\n",
      "=== epoch:43, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.359781946424564\n",
      "train loss:2.374815395197616\n",
      "train loss:2.3782147658128276\n",
      "train loss:2.3077158518028744\n",
      "=== epoch:44, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3897129583714722\n",
      "train loss:2.3493341599810074\n",
      "train loss:2.3783115484455504\n",
      "train loss:2.3239582310518947\n",
      "=== epoch:45, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.340756991887396\n",
      "train loss:2.3448494319982096\n",
      "train loss:2.3136554869403314\n",
      "train loss:2.395372949304484\n",
      "=== epoch:46, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.323154431356314\n",
      "train loss:2.3067481291866665\n",
      "train loss:2.336882675925799\n",
      "train loss:2.358167246403214\n",
      "=== epoch:47, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3579970024376133\n",
      "train loss:2.381930322315757\n",
      "train loss:2.3694376079871318\n",
      "train loss:2.33669448446404\n",
      "=== epoch:48, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3359377118849167\n",
      "train loss:2.3554592293347536\n",
      "train loss:2.3107861596414607\n",
      "train loss:2.351737198332425\n",
      "=== epoch:49, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.3401274657351445\n",
      "train loss:2.3522781522970395\n",
      "train loss:2.334289127247779\n",
      "train loss:2.3591484332820976\n",
      "=== epoch:50, train acc:0.1175, test acc:0.06 ===\n",
      "train loss:2.302575189490908\n",
      "train loss:2.3609851384485734\n",
      "train loss:2.335129859462618\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.06\n",
      "val_acc: 0.0600 | lr: 0.0000, weight_decay: 0.0001\n",
      "train loss:2.380717308278933\n",
      "=== epoch:1, train acc:0.075, test acc:0.05 ===\n",
      "train loss:2.3921504869244887\n",
      "train loss:2.4644325504097884\n",
      "train loss:2.493102314661233\n",
      "train loss:2.4202792930023627\n",
      "=== epoch:2, train acc:0.075, test acc:0.05 ===\n",
      "train loss:2.4698735259231595\n",
      "train loss:2.389444919746261\n",
      "train loss:2.3973568614515854\n",
      "train loss:2.3555880756618923\n",
      "=== epoch:3, train acc:0.0775, test acc:0.05 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4418885673983017\n",
      "train loss:2.4823199760844963\n",
      "train loss:2.4005507462237485\n",
      "train loss:2.3388543163872826\n",
      "=== epoch:4, train acc:0.0775, test acc:0.05 ===\n",
      "train loss:2.4456584143588667\n",
      "train loss:2.3574497233091707\n",
      "train loss:2.4106439254389924\n",
      "train loss:2.403255374098072\n",
      "=== epoch:5, train acc:0.0775, test acc:0.05 ===\n",
      "train loss:2.4449626619877614\n",
      "train loss:2.4070480491608732\n",
      "train loss:2.4697347233215066\n",
      "train loss:2.5053480143657465\n",
      "=== epoch:6, train acc:0.0775, test acc:0.05 ===\n",
      "train loss:2.375095659724143\n",
      "train loss:2.3700582280897633\n",
      "train loss:2.290577046255046\n",
      "train loss:2.385638594353425\n",
      "=== epoch:7, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.432231246614657\n",
      "train loss:2.4747902145239764\n",
      "train loss:2.413907807293462\n",
      "train loss:2.449602037091113\n",
      "=== epoch:8, train acc:0.0825, test acc:0.07 ===\n",
      "train loss:2.317832789953944\n",
      "train loss:2.3805676886279\n",
      "train loss:2.402021815337373\n",
      "train loss:2.543628144685591\n",
      "=== epoch:9, train acc:0.0825, test acc:0.07 ===\n",
      "train loss:2.4559480696063942\n",
      "train loss:2.4034520095441776\n",
      "train loss:2.438636335576655\n",
      "train loss:2.4775903666038026\n",
      "=== epoch:10, train acc:0.0825, test acc:0.07 ===\n",
      "train loss:2.3643827484598336\n",
      "train loss:2.3242796809296298\n",
      "train loss:2.360842549033775\n",
      "train loss:2.492992413228128\n",
      "=== epoch:11, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.3775485084532333\n",
      "train loss:2.3814152465871943\n",
      "train loss:2.4533302520919924\n",
      "train loss:2.338702579499188\n",
      "=== epoch:12, train acc:0.0825, test acc:0.08 ===\n",
      "train loss:2.410600372315391\n",
      "train loss:2.4425052634794313\n",
      "train loss:2.3301299667666533\n",
      "train loss:2.411617987499728\n",
      "=== epoch:13, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4447697961689503\n",
      "train loss:2.3116844547562154\n",
      "train loss:2.427830431915554\n",
      "train loss:2.354880058819833\n",
      "=== epoch:14, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4180012844095105\n",
      "train loss:2.4516499932741445\n",
      "train loss:2.47671870081018\n",
      "train loss:2.4219826954623858\n",
      "=== epoch:15, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.3574927631409994\n",
      "train loss:2.351183050205241\n",
      "train loss:2.358982485852991\n",
      "train loss:2.436555336585276\n",
      "=== epoch:16, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.376573624186835\n",
      "train loss:2.465149399059293\n",
      "train loss:2.420008131514503\n",
      "train loss:2.359151023543063\n",
      "=== epoch:17, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4014018714337113\n",
      "train loss:2.4059680352352886\n",
      "train loss:2.4098419169734417\n",
      "train loss:2.3751645688208156\n",
      "=== epoch:18, train acc:0.0875, test acc:0.08 ===\n",
      "train loss:2.438814378125593\n",
      "train loss:2.451687011898893\n",
      "train loss:2.3284288483814235\n",
      "train loss:2.3590704693928135\n",
      "=== epoch:19, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.34146433233202\n",
      "train loss:2.4379380573963507\n",
      "train loss:2.4850367049084565\n",
      "train loss:2.3343134388226385\n",
      "=== epoch:20, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.39684138463884\n",
      "train loss:2.445770647749605\n",
      "train loss:2.460032969518621\n",
      "train loss:2.414699566863168\n",
      "=== epoch:21, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.35456228423413\n",
      "train loss:2.409338949209658\n",
      "train loss:2.4226035270877166\n",
      "train loss:2.3515203115973793\n",
      "=== epoch:22, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.4164349193711594\n",
      "train loss:2.4488690086621414\n",
      "train loss:2.3033683997036807\n",
      "train loss:2.3839096853782267\n",
      "=== epoch:23, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.4046606077559596\n",
      "train loss:2.393806373666708\n",
      "train loss:2.360292137952273\n",
      "train loss:2.3202572503510375\n",
      "=== epoch:24, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.471748937655766\n",
      "train loss:2.3949402238562927\n",
      "train loss:2.3524347640088332\n",
      "train loss:2.438955719895312\n",
      "=== epoch:25, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.359347291876191\n",
      "train loss:2.3437797567025087\n",
      "train loss:2.442698893954674\n",
      "train loss:2.3844278783294777\n",
      "=== epoch:26, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.391206501861402\n",
      "train loss:2.3274772755746924\n",
      "train loss:2.428653063687937\n",
      "train loss:2.357708957822977\n",
      "=== epoch:27, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.357845020672273\n",
      "train loss:2.421051209760809\n",
      "train loss:2.344245465115938\n",
      "train loss:2.3771120829975634\n",
      "=== epoch:28, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.399782437801383\n",
      "train loss:2.39820832540022\n",
      "train loss:2.325136479870388\n",
      "train loss:2.323495467917271\n",
      "=== epoch:29, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.335901291764884\n",
      "train loss:2.437381515206896\n",
      "train loss:2.358300262007524\n",
      "train loss:2.3543390762042136\n",
      "=== epoch:30, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.3988598339736438\n",
      "train loss:2.3983915521541466\n",
      "train loss:2.4132362789695847\n",
      "train loss:2.387625866348914\n",
      "=== epoch:31, train acc:0.0875, test acc:0.1 ===\n",
      "train loss:2.3597797099078117\n",
      "train loss:2.3857515767475284\n",
      "train loss:2.382029235417081\n",
      "train loss:2.359193993395299\n",
      "=== epoch:32, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.436185035169701\n",
      "train loss:2.3665393523767717\n",
      "train loss:2.3155304278116904\n",
      "train loss:2.3973221426256517\n",
      "=== epoch:33, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3624015447651225\n",
      "train loss:2.371088722657656\n",
      "train loss:2.350277249963216\n",
      "train loss:2.4212624032323866\n",
      "=== epoch:34, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.35272619701224\n",
      "train loss:2.4336023350141103\n",
      "train loss:2.437762113940584\n",
      "train loss:2.342255185708777\n",
      "=== epoch:35, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.288804380584382\n",
      "train loss:2.4332787742832536\n",
      "train loss:2.3968689754849755\n",
      "train loss:2.3572070915830423\n",
      "=== epoch:36, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3553646958517542\n",
      "train loss:2.3032839098383158\n",
      "train loss:2.3133233200675276\n",
      "train loss:2.285547861332033\n",
      "=== epoch:37, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.389061268351243\n",
      "train loss:2.4206995520856056\n",
      "train loss:2.4261066591437954\n",
      "train loss:2.428531951976264\n",
      "=== epoch:38, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.3343354448002325\n",
      "train loss:2.383938675655041\n",
      "train loss:2.3470040855795866\n",
      "train loss:2.333497089605141\n",
      "=== epoch:39, train acc:0.095, test acc:0.1 ===\n",
      "train loss:2.4312707147776873\n",
      "train loss:2.301943820593073\n",
      "train loss:2.2905330635305017\n",
      "train loss:2.391578832539296\n",
      "=== epoch:40, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.4444972750830045\n",
      "train loss:2.3141403090703365\n",
      "train loss:2.4139932955185386\n",
      "train loss:2.348680537630929\n",
      "=== epoch:41, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3572745271111057\n",
      "train loss:2.3914900986893834\n",
      "train loss:2.3607052779029734\n",
      "train loss:2.3911942316856023\n",
      "=== epoch:42, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3184309344942258\n",
      "train loss:2.294323572528326\n",
      "train loss:2.3901127104093267\n",
      "train loss:2.381400356227732\n",
      "=== epoch:43, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3389561389493556\n",
      "train loss:2.34846807427168\n",
      "train loss:2.3112355305795393\n",
      "train loss:2.3785887408998803\n",
      "=== epoch:44, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.2911307089806847\n",
      "train loss:2.3562408504880485\n",
      "train loss:2.364496111113134\n",
      "train loss:2.374542764936178\n",
      "=== epoch:45, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.387833588545108\n",
      "train loss:2.2949047347323117\n",
      "train loss:2.338740742800985\n",
      "train loss:2.4024310704318097\n",
      "=== epoch:46, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3322350182403473\n",
      "train loss:2.388598137786966\n",
      "train loss:2.397421503746653\n",
      "train loss:2.2890879478687145\n",
      "=== epoch:47, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3948952278666567\n",
      "train loss:2.300240005617163\n",
      "train loss:2.3215965299439616\n",
      "train loss:2.3671184746630667\n",
      "=== epoch:48, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.331519223024586\n",
      "train loss:2.3340224322449874\n",
      "train loss:2.345463552054665\n",
      "train loss:2.3636192086828687\n",
      "=== epoch:49, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.2471664872998964\n",
      "train loss:2.336911817864814\n",
      "train loss:2.4052621499507647\n",
      "train loss:2.3024890363225174\n",
      "=== epoch:50, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3797657540220496\n",
      "train loss:2.3784420863557223\n",
      "train loss:2.335839832500469\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0002, weight_decay: 0.0000\n",
      "train loss:2.730456238631438\n",
      "=== epoch:1, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5746502853360513\n",
      "train loss:2.704972478610303\n",
      "train loss:2.6673600661937154\n",
      "train loss:2.726194425601899\n",
      "=== epoch:2, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.634207469912424\n",
      "train loss:2.5636461603375245\n",
      "train loss:2.594449845154048\n",
      "train loss:2.640489750812642\n",
      "=== epoch:3, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.637679714040789\n",
      "train loss:2.794023186580709\n",
      "train loss:2.5556003956753237\n",
      "train loss:2.578809793081825\n",
      "=== epoch:4, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.6799362189012474\n",
      "train loss:2.5801450645823527\n",
      "train loss:2.6541584618265306\n",
      "train loss:2.6099624835868784\n",
      "=== epoch:5, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.614635374258519\n",
      "train loss:2.5497560507736168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.6284466699367597\n",
      "train loss:2.602453953806289\n",
      "=== epoch:6, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.656583241435333\n",
      "train loss:2.63902496385999\n",
      "train loss:2.689974301520553\n",
      "train loss:2.6833835522180465\n",
      "=== epoch:7, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.671502096467065\n",
      "train loss:2.653349064163756\n",
      "train loss:2.6008731869796966\n",
      "train loss:2.6244890441938717\n",
      "=== epoch:8, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.6575157863459986\n",
      "train loss:2.661042792802835\n",
      "train loss:2.6894897213428766\n",
      "train loss:2.661761292309859\n",
      "=== epoch:9, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.7634004212537415\n",
      "train loss:2.6334962335823517\n",
      "train loss:2.6597985079980093\n",
      "train loss:2.644140577585656\n",
      "=== epoch:10, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.700594017790785\n",
      "train loss:2.5581726146119754\n",
      "train loss:2.6579213729765887\n",
      "train loss:2.663356167644945\n",
      "=== epoch:11, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.6057379748791565\n",
      "train loss:2.5627382175535796\n",
      "train loss:2.7382957691763026\n",
      "train loss:2.6498563021655426\n",
      "=== epoch:12, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.709457072471389\n",
      "train loss:2.5753386935698797\n",
      "train loss:2.644371861982796\n",
      "train loss:2.5982448072470956\n",
      "=== epoch:13, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.589025277789066\n",
      "train loss:2.655186987095245\n",
      "train loss:2.6552472890793544\n",
      "train loss:2.6111263576590535\n",
      "=== epoch:14, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5888991988163084\n",
      "train loss:2.608652225465288\n",
      "train loss:2.587115975889893\n",
      "train loss:2.6090525138892517\n",
      "=== epoch:15, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.6673798090415874\n",
      "train loss:2.7239273154324533\n",
      "train loss:2.622708523057361\n",
      "train loss:2.691750284384275\n",
      "=== epoch:16, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.501838277656069\n",
      "train loss:2.5825820052271458\n",
      "train loss:2.555428398037683\n",
      "train loss:2.4917098276433687\n",
      "=== epoch:17, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.519323961665144\n",
      "train loss:2.5229142490076084\n",
      "train loss:2.6439302218684064\n",
      "train loss:2.60992319631844\n",
      "=== epoch:18, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4740952834425776\n",
      "train loss:2.66890863045916\n",
      "train loss:2.5504316688147415\n",
      "train loss:2.4820667000685432\n",
      "=== epoch:19, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.524861572668333\n",
      "train loss:2.4781839134526806\n",
      "train loss:2.6626512129575395\n",
      "train loss:2.5419404831842054\n",
      "=== epoch:20, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5377813600051713\n",
      "train loss:2.6836844889737024\n",
      "train loss:2.589108424090356\n",
      "train loss:2.529632002478268\n",
      "=== epoch:21, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5496525143515254\n",
      "train loss:2.6146447348260446\n",
      "train loss:2.6004886607892423\n",
      "train loss:2.561085915114894\n",
      "=== epoch:22, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.505660159075564\n",
      "train loss:2.5612075212381753\n",
      "train loss:2.5163153291758333\n",
      "train loss:2.6468228349417875\n",
      "=== epoch:23, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4275859255875267\n",
      "train loss:2.5364454920970885\n",
      "train loss:2.628460436197498\n",
      "train loss:2.517006247471694\n",
      "=== epoch:24, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5720730248278048\n",
      "train loss:2.543934015261469\n",
      "train loss:2.679161087630193\n",
      "train loss:2.5733767240245564\n",
      "=== epoch:25, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.609697664920041\n",
      "train loss:2.617855601417164\n",
      "train loss:2.543912465517287\n",
      "train loss:2.544619547751894\n",
      "=== epoch:26, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.641827551836164\n",
      "train loss:2.63783635043512\n",
      "train loss:2.546118140837079\n",
      "train loss:2.5830067075408807\n",
      "=== epoch:27, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5118094196335403\n",
      "train loss:2.5021497927768017\n",
      "train loss:2.555032806323787\n",
      "train loss:2.539970106917301\n",
      "=== epoch:28, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5823683721166537\n",
      "train loss:2.4423675358793537\n",
      "train loss:2.495357744703147\n",
      "train loss:2.6183900272358094\n",
      "=== epoch:29, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.523670323303963\n",
      "train loss:2.592574901531924\n",
      "train loss:2.521791151060745\n",
      "train loss:2.5067207159659737\n",
      "=== epoch:30, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.454438284031345\n",
      "train loss:2.522744672796052\n",
      "train loss:2.5168850319781995\n",
      "train loss:2.501096964518092\n",
      "=== epoch:31, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5349245395038844\n",
      "train loss:2.4888561297279033\n",
      "train loss:2.5386495434953122\n",
      "train loss:2.494619868096064\n",
      "=== epoch:32, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5025414967331954\n",
      "train loss:2.489738094750793\n",
      "train loss:2.496171878521907\n",
      "train loss:2.4930083244276555\n",
      "=== epoch:33, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.509322099963929\n",
      "train loss:2.5447566548263745\n",
      "train loss:2.4551365180408236\n",
      "train loss:2.4497483126162667\n",
      "=== epoch:34, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5521950060033753\n",
      "train loss:2.5236106183716474\n",
      "train loss:2.590819188483375\n",
      "train loss:2.4738143094845797\n",
      "=== epoch:35, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.547943374043637\n",
      "train loss:2.4743766758764725\n",
      "train loss:2.468486180183136\n",
      "train loss:2.625513713967542\n",
      "=== epoch:36, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.434218496844267\n",
      "train loss:2.492566637987457\n",
      "train loss:2.467150106654829\n",
      "train loss:2.4989768919779154\n",
      "=== epoch:37, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5472877058102887\n",
      "train loss:2.627233007619673\n",
      "train loss:2.5593532966896544\n",
      "train loss:2.4196566067775027\n",
      "=== epoch:38, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4638538530782075\n",
      "train loss:2.59937118164886\n",
      "train loss:2.4863127454527993\n",
      "train loss:2.5332688810654416\n",
      "=== epoch:39, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5124048995454618\n",
      "train loss:2.5202298712599918\n",
      "train loss:2.514553809492992\n",
      "train loss:2.504213949566347\n",
      "=== epoch:40, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4662617620186245\n",
      "train loss:2.4753363678939158\n",
      "train loss:2.603551741896035\n",
      "train loss:2.6071689689290016\n",
      "=== epoch:41, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.460323084459667\n",
      "train loss:2.4184087569414823\n",
      "train loss:2.4831053508290197\n",
      "train loss:2.515989358012226\n",
      "=== epoch:42, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4845325767896456\n",
      "train loss:2.407290698100875\n",
      "train loss:2.555428875248668\n",
      "train loss:2.404656814457103\n",
      "=== epoch:43, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4931838937631756\n",
      "train loss:2.400602040313621\n",
      "train loss:2.4339074441236965\n",
      "train loss:2.433102245161482\n",
      "=== epoch:44, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4553635714089057\n",
      "train loss:2.479486684987994\n",
      "train loss:2.353711576793394\n",
      "train loss:2.549975358870402\n",
      "=== epoch:45, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.405937526912672\n",
      "train loss:2.5371972082996734\n",
      "train loss:2.4339223178993876\n",
      "train loss:2.534533728474993\n",
      "=== epoch:46, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4605472961644796\n",
      "train loss:2.552628439234222\n",
      "train loss:2.552677458719989\n",
      "train loss:2.5002944909430953\n",
      "=== epoch:47, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.4736157037051663\n",
      "train loss:2.433238162892909\n",
      "train loss:2.4830159459982406\n",
      "train loss:2.4562424783770025\n",
      "=== epoch:48, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.420195775156535\n",
      "train loss:2.4599898402406484\n",
      "train loss:2.5025285146090703\n",
      "train loss:2.50522847893305\n",
      "=== epoch:49, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.5065918234329536\n",
      "train loss:2.439177962053319\n",
      "train loss:2.5059053616099116\n",
      "train loss:2.4619039276245354\n",
      "=== epoch:50, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.45073621901743\n",
      "train loss:2.570725062300826\n",
      "train loss:2.4638693638291254\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.4192300784017413\n",
      "=== epoch:1, train acc:0.065, test acc:0.14 ===\n",
      "train loss:2.418214570900593\n",
      "train loss:2.4992633972847975\n",
      "train loss:2.3727145843317747\n",
      "train loss:2.4166915175290025\n",
      "=== epoch:2, train acc:0.0675, test acc:0.13 ===\n",
      "train loss:2.415487323077757\n",
      "train loss:2.3187510558606945\n",
      "train loss:2.450125496844526\n",
      "train loss:2.348358325319375\n",
      "=== epoch:3, train acc:0.0725, test acc:0.13 ===\n",
      "train loss:2.442415206249192\n",
      "train loss:2.394891587084064\n",
      "train loss:2.367489621747827\n",
      "train loss:2.4260822879482635\n",
      "=== epoch:4, train acc:0.0725, test acc:0.13 ===\n",
      "train loss:2.384704357061009\n",
      "train loss:2.3829087079088778\n",
      "train loss:2.352051040027657\n",
      "train loss:2.3565458613786805\n",
      "=== epoch:5, train acc:0.0725, test acc:0.12 ===\n",
      "train loss:2.465985658716426\n",
      "train loss:2.443439119981903\n",
      "train loss:2.4859002551397777\n",
      "train loss:2.397614907891724\n",
      "=== epoch:6, train acc:0.0725, test acc:0.12 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4956723328478807\n",
      "train loss:2.5008405027908456\n",
      "train loss:2.479420185784648\n",
      "train loss:2.4912746209192944\n",
      "=== epoch:7, train acc:0.07, test acc:0.12 ===\n",
      "train loss:2.338637487092539\n",
      "train loss:2.475419871028378\n",
      "train loss:2.3432628399238484\n",
      "train loss:2.477362093888675\n",
      "=== epoch:8, train acc:0.07, test acc:0.13 ===\n",
      "train loss:2.288969599699976\n",
      "train loss:2.46262618817402\n",
      "train loss:2.368521292875856\n",
      "train loss:2.418796857320147\n",
      "=== epoch:9, train acc:0.065, test acc:0.14 ===\n",
      "train loss:2.48360805246713\n",
      "train loss:2.373772634566688\n",
      "train loss:2.349871328900788\n",
      "train loss:2.403287508617892\n",
      "=== epoch:10, train acc:0.065, test acc:0.14 ===\n",
      "train loss:2.4470158116507945\n",
      "train loss:2.2853882580454425\n",
      "train loss:2.318135652884751\n",
      "train loss:2.4106118455838805\n",
      "=== epoch:11, train acc:0.0625, test acc:0.14 ===\n",
      "train loss:2.462090045736113\n",
      "train loss:2.4277543250252718\n",
      "train loss:2.449958337492935\n",
      "train loss:2.3557805439123345\n",
      "=== epoch:12, train acc:0.065, test acc:0.14 ===\n",
      "train loss:2.3543944279860582\n",
      "train loss:2.443973097490198\n",
      "train loss:2.3944436066525383\n",
      "train loss:2.4277120564128642\n",
      "=== epoch:13, train acc:0.065, test acc:0.14 ===\n",
      "train loss:2.3824308652868016\n",
      "train loss:2.353730797199465\n",
      "train loss:2.3685251763187947\n",
      "train loss:2.3747294218328197\n",
      "=== epoch:14, train acc:0.0675, test acc:0.14 ===\n",
      "train loss:2.4383098257609257\n",
      "train loss:2.396034927839965\n",
      "train loss:2.4183710467274833\n",
      "train loss:2.388201179630124\n",
      "=== epoch:15, train acc:0.07, test acc:0.14 ===\n",
      "train loss:2.4244473966801796\n",
      "train loss:2.431151712314949\n",
      "train loss:2.3714403602246494\n",
      "train loss:2.3136497615140916\n",
      "=== epoch:16, train acc:0.07, test acc:0.14 ===\n",
      "train loss:2.3747080981754745\n",
      "train loss:2.2739732799549435\n",
      "train loss:2.3549636309221484\n",
      "train loss:2.393707481817638\n",
      "=== epoch:17, train acc:0.075, test acc:0.14 ===\n",
      "train loss:2.2888576239239438\n",
      "train loss:2.3044068110269893\n",
      "train loss:2.385103899503618\n",
      "train loss:2.319467034863187\n",
      "=== epoch:18, train acc:0.08, test acc:0.14 ===\n",
      "train loss:2.3895872259157476\n",
      "train loss:2.352624391634917\n",
      "train loss:2.36264081376069\n",
      "train loss:2.387938857408196\n",
      "=== epoch:19, train acc:0.085, test acc:0.14 ===\n",
      "train loss:2.290417575320741\n",
      "train loss:2.288438751887372\n",
      "train loss:2.3800855550665094\n",
      "train loss:2.294635244975448\n",
      "=== epoch:20, train acc:0.0875, test acc:0.13 ===\n",
      "train loss:2.3933081761624133\n",
      "train loss:2.4033202591739573\n",
      "train loss:2.263316003179257\n",
      "train loss:2.3320683887428078\n",
      "=== epoch:21, train acc:0.0875, test acc:0.13 ===\n",
      "train loss:2.3537590003383193\n",
      "train loss:2.3645259580070985\n",
      "train loss:2.3842905558253453\n",
      "train loss:2.3234639607012455\n",
      "=== epoch:22, train acc:0.09, test acc:0.13 ===\n",
      "train loss:2.33220767043058\n",
      "train loss:2.3407478944052427\n",
      "train loss:2.4176956440169945\n",
      "train loss:2.3944444056532954\n",
      "=== epoch:23, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.250272317842447\n",
      "train loss:2.2600793748097647\n",
      "train loss:2.437621863056201\n",
      "train loss:2.3180042109010657\n",
      "=== epoch:24, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.382506527977845\n",
      "train loss:2.268803310190975\n",
      "train loss:2.2748465133444946\n",
      "train loss:2.2714899025590616\n",
      "=== epoch:25, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.323955358433803\n",
      "train loss:2.349071311027164\n",
      "train loss:2.314931426212001\n",
      "train loss:2.3121628953317175\n",
      "=== epoch:26, train acc:0.1, test acc:0.14 ===\n",
      "train loss:2.2663668616862904\n",
      "train loss:2.4440199765727315\n",
      "train loss:2.356330094181541\n",
      "train loss:2.3148742188013713\n",
      "=== epoch:27, train acc:0.1025, test acc:0.14 ===\n",
      "train loss:2.331486702523167\n",
      "train loss:2.3471284609017027\n",
      "train loss:2.333482679975925\n",
      "train loss:2.297362313572374\n",
      "=== epoch:28, train acc:0.11, test acc:0.14 ===\n",
      "train loss:2.2995620160900407\n",
      "train loss:2.302261928604453\n",
      "train loss:2.2815230785782603\n",
      "train loss:2.342486376197362\n",
      "=== epoch:29, train acc:0.11, test acc:0.14 ===\n",
      "train loss:2.3329471442251593\n",
      "train loss:2.296046600474585\n",
      "train loss:2.3614697144602212\n",
      "train loss:2.1935778218135438\n",
      "=== epoch:30, train acc:0.1125, test acc:0.14 ===\n",
      "train loss:2.4240928254211687\n",
      "train loss:2.3627745966293157\n",
      "train loss:2.2146208772902036\n",
      "train loss:2.30171101561456\n",
      "=== epoch:31, train acc:0.1175, test acc:0.14 ===\n",
      "train loss:2.2948759058417636\n",
      "train loss:2.3864060043603637\n",
      "train loss:2.36012683177546\n",
      "train loss:2.2273527627723513\n",
      "=== epoch:32, train acc:0.1175, test acc:0.14 ===\n",
      "train loss:2.267372780955246\n",
      "train loss:2.3255293421756957\n",
      "train loss:2.309679793511329\n",
      "train loss:2.250424760882957\n",
      "=== epoch:33, train acc:0.12, test acc:0.14 ===\n",
      "train loss:2.2434552867780133\n",
      "train loss:2.358659755133525\n",
      "train loss:2.3034721399077087\n",
      "train loss:2.260354310720895\n",
      "=== epoch:34, train acc:0.1225, test acc:0.14 ===\n",
      "train loss:2.286741800315588\n",
      "train loss:2.2598615056723053\n",
      "train loss:2.296122766502953\n",
      "train loss:2.306929251646922\n",
      "=== epoch:35, train acc:0.125, test acc:0.14 ===\n",
      "train loss:2.3024121017846175\n",
      "train loss:2.2890801656734956\n",
      "train loss:2.2554541711704386\n",
      "train loss:2.2622560114541175\n",
      "=== epoch:36, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.3497026665155794\n",
      "train loss:2.379567173758902\n",
      "train loss:2.334693424587416\n",
      "train loss:2.2866500989123235\n",
      "=== epoch:37, train acc:0.1325, test acc:0.14 ===\n",
      "train loss:2.313985796019396\n",
      "train loss:2.2487129439522664\n",
      "train loss:2.3502544953584636\n",
      "train loss:2.3815566480573813\n",
      "=== epoch:38, train acc:0.1325, test acc:0.14 ===\n",
      "train loss:2.302799292315918\n",
      "train loss:2.3382288856396993\n",
      "train loss:2.267183171439075\n",
      "train loss:2.2857359452582053\n",
      "=== epoch:39, train acc:0.1325, test acc:0.14 ===\n",
      "train loss:2.254388720163049\n",
      "train loss:2.336263435579296\n",
      "train loss:2.1995745138633533\n",
      "train loss:2.367327330295202\n",
      "=== epoch:40, train acc:0.135, test acc:0.14 ===\n",
      "train loss:2.223228670827383\n",
      "train loss:2.2921516853365715\n",
      "train loss:2.234318477631584\n",
      "train loss:2.38818945118104\n",
      "=== epoch:41, train acc:0.1375, test acc:0.14 ===\n",
      "train loss:2.268704363637552\n",
      "train loss:2.3631217787696737\n",
      "train loss:2.2563986486635708\n",
      "train loss:2.2281551218731637\n",
      "=== epoch:42, train acc:0.14, test acc:0.14 ===\n",
      "train loss:2.288541952572498\n",
      "train loss:2.339431375967154\n",
      "train loss:2.3453906424774678\n",
      "train loss:2.3201668569354954\n",
      "=== epoch:43, train acc:0.1425, test acc:0.13 ===\n",
      "train loss:2.238339445301231\n",
      "train loss:2.329711098219827\n",
      "train loss:2.2722513364771166\n",
      "train loss:2.2710941981046675\n",
      "=== epoch:44, train acc:0.1425, test acc:0.13 ===\n",
      "train loss:2.3103335886026763\n",
      "train loss:2.2734401451905426\n",
      "train loss:2.2439869803507784\n",
      "train loss:2.341820270027097\n",
      "=== epoch:45, train acc:0.1425, test acc:0.13 ===\n",
      "train loss:2.2653329111835037\n",
      "train loss:2.2592171214210928\n",
      "train loss:2.182011777023916\n",
      "train loss:2.279846587674509\n",
      "=== epoch:46, train acc:0.1425, test acc:0.13 ===\n",
      "train loss:2.2767096871893777\n",
      "train loss:2.2376436265646897\n",
      "train loss:2.2769093368702675\n",
      "train loss:2.304098874178242\n",
      "=== epoch:47, train acc:0.145, test acc:0.13 ===\n",
      "train loss:2.333170810719534\n",
      "train loss:2.295997575663082\n",
      "train loss:2.235477510197201\n",
      "train loss:2.2550930769146715\n",
      "=== epoch:48, train acc:0.15, test acc:0.13 ===\n",
      "train loss:2.25843330435484\n",
      "train loss:2.2341634279296576\n",
      "train loss:2.21785981771068\n",
      "train loss:2.205190753673189\n",
      "=== epoch:49, train acc:0.15, test acc:0.12 ===\n",
      "train loss:2.2435706369204027\n",
      "train loss:2.3134888455287688\n",
      "train loss:2.330780248073124\n",
      "train loss:2.285983790856621\n",
      "=== epoch:50, train acc:0.1525, test acc:0.12 ===\n",
      "train loss:2.229108409656508\n",
      "train loss:2.293044404590106\n",
      "train loss:2.247872420572619\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0004, weight_decay: 0.0000\n",
      "train loss:2.437226849661524\n",
      "=== epoch:1, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3639770720057705\n",
      "train loss:2.296465852821786\n",
      "train loss:2.3848829587058327\n",
      "train loss:2.3628778515456847\n",
      "=== epoch:2, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.325272975695293\n",
      "train loss:2.322651394211779\n",
      "train loss:2.4519414201995353\n",
      "train loss:2.3443916898982136\n",
      "=== epoch:3, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3388044542690416\n",
      "train loss:2.3936665827737724\n",
      "train loss:2.3824130120661695\n",
      "train loss:2.3766407453279776\n",
      "=== epoch:4, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.310307332741162\n",
      "train loss:2.3773575645429\n",
      "train loss:2.335110270063659\n",
      "train loss:2.3840094720003284\n",
      "=== epoch:5, train acc:0.0975, test acc:0.1 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.396872151573154\n",
      "train loss:2.427695056037359\n",
      "train loss:2.3443602328529547\n",
      "train loss:2.3739349731686588\n",
      "=== epoch:6, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.4061410808263353\n",
      "train loss:2.3498224858553765\n",
      "train loss:2.426317412471872\n",
      "train loss:2.333530693509324\n",
      "=== epoch:7, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.301914847571789\n",
      "train loss:2.374620718563628\n",
      "train loss:2.3269045984135532\n",
      "train loss:2.473431914703988\n",
      "=== epoch:8, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.388254609201894\n",
      "train loss:2.3453503943570446\n",
      "train loss:2.36475330352136\n",
      "train loss:2.3358292745831872\n",
      "=== epoch:9, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3389230212263756\n",
      "train loss:2.337732454842091\n",
      "train loss:2.3466375822999472\n",
      "train loss:2.3576045339841363\n",
      "=== epoch:10, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.4252174345335895\n",
      "train loss:2.3089072348526627\n",
      "train loss:2.3181586965185494\n",
      "train loss:2.3652116178225624\n",
      "=== epoch:11, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3548580455124943\n",
      "train loss:2.390246001686132\n",
      "train loss:2.3556550916618746\n",
      "train loss:2.3772567014952\n",
      "=== epoch:12, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.330108551290936\n",
      "train loss:2.4070623926147383\n",
      "train loss:2.3871344479320857\n",
      "train loss:2.451925129768952\n",
      "=== epoch:13, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.4141685873996614\n",
      "train loss:2.352676878390691\n",
      "train loss:2.394820205315475\n",
      "train loss:2.330768062360802\n",
      "=== epoch:14, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3890174426551005\n",
      "train loss:2.43031366273658\n",
      "train loss:2.3951905152245696\n",
      "train loss:2.379484918931034\n",
      "=== epoch:15, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.416371154325548\n",
      "train loss:2.3477983751039333\n",
      "train loss:2.4651462978091905\n",
      "train loss:2.408229637039685\n",
      "=== epoch:16, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3825223214022944\n",
      "train loss:2.4381997179655603\n",
      "train loss:2.355986789730823\n",
      "train loss:2.39117357693737\n",
      "=== epoch:17, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.388870077144334\n",
      "train loss:2.4166302711770737\n",
      "train loss:2.3890705792681572\n",
      "train loss:2.395156694159746\n",
      "=== epoch:18, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3591262023332566\n",
      "train loss:2.36245186586787\n",
      "train loss:2.3644457461668997\n",
      "train loss:2.3794512454856527\n",
      "=== epoch:19, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.397632623513636\n",
      "train loss:2.3958835087921\n",
      "train loss:2.3472085273622274\n",
      "train loss:2.3714624643419326\n",
      "=== epoch:20, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.319929361845642\n",
      "train loss:2.3982859388849853\n",
      "train loss:2.4572123709210345\n",
      "train loss:2.3259854290822686\n",
      "=== epoch:21, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.390198623694858\n",
      "train loss:2.355968626879904\n",
      "train loss:2.339304801857483\n",
      "train loss:2.387062204336393\n",
      "=== epoch:22, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.338091519249087\n",
      "train loss:2.360803279430851\n",
      "train loss:2.3601582490569837\n",
      "train loss:2.3476406411619837\n",
      "=== epoch:23, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.358880681428989\n",
      "train loss:2.37766127106162\n",
      "train loss:2.397609100534269\n",
      "train loss:2.3995197371079158\n",
      "=== epoch:24, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.472541782638274\n",
      "train loss:2.4060018526131883\n",
      "train loss:2.3557500186999265\n",
      "train loss:2.3644074909783743\n",
      "=== epoch:25, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.34508530645293\n",
      "train loss:2.3363885049235322\n",
      "train loss:2.3647560257026177\n",
      "train loss:2.3735571294617\n",
      "=== epoch:26, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3607987482924067\n",
      "train loss:2.400342718422993\n",
      "train loss:2.387154266064727\n",
      "train loss:2.2715589573031303\n",
      "=== epoch:27, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3913446131087017\n",
      "train loss:2.285831808114655\n",
      "train loss:2.3970379729926075\n",
      "train loss:2.4031313058271646\n",
      "=== epoch:28, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3410402245884265\n",
      "train loss:2.2845749925123062\n",
      "train loss:2.3645669643056557\n",
      "train loss:2.424525474469947\n",
      "=== epoch:29, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.4198960084420453\n",
      "train loss:2.299527325882051\n",
      "train loss:2.404972992266887\n",
      "train loss:2.3482512984899646\n",
      "=== epoch:30, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3810733047570416\n",
      "train loss:2.3784746383419977\n",
      "train loss:2.3377927867000037\n",
      "train loss:2.3281041359296384\n",
      "=== epoch:31, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3709696804529896\n",
      "train loss:2.40988039205319\n",
      "train loss:2.376562191643884\n",
      "train loss:2.396283455270936\n",
      "=== epoch:32, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.428115682153034\n",
      "train loss:2.368019210316851\n",
      "train loss:2.423022866990763\n",
      "train loss:2.3745468187006007\n",
      "=== epoch:33, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3619052259414657\n",
      "train loss:2.330268557494963\n",
      "train loss:2.277122673328697\n",
      "train loss:2.4080040476156648\n",
      "=== epoch:34, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.383820196912215\n",
      "train loss:2.399863170513764\n",
      "train loss:2.4441149167543377\n",
      "train loss:2.3608314752674158\n",
      "=== epoch:35, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.2864923737125835\n",
      "train loss:2.3507273801574433\n",
      "train loss:2.3803338220186006\n",
      "train loss:2.396898962006719\n",
      "=== epoch:36, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.326147769247356\n",
      "train loss:2.332531600084166\n",
      "train loss:2.380626418026677\n",
      "train loss:2.350319262678795\n",
      "=== epoch:37, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3379531777739877\n",
      "train loss:2.33266174197106\n",
      "train loss:2.4040503728118603\n",
      "train loss:2.2988929104264515\n",
      "=== epoch:38, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.2878130302652893\n",
      "train loss:2.368604211739748\n",
      "train loss:2.3027801476136793\n",
      "train loss:2.388542401045055\n",
      "=== epoch:39, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3188836928491066\n",
      "train loss:2.3812944178533337\n",
      "train loss:2.451335976693976\n",
      "train loss:2.372599752330029\n",
      "=== epoch:40, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3790823721946013\n",
      "train loss:2.3242344806180215\n",
      "train loss:2.3639214561493733\n",
      "train loss:2.390571601485298\n",
      "=== epoch:41, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3912714613804336\n",
      "train loss:2.3692270038627377\n",
      "train loss:2.3826198223974986\n",
      "train loss:2.3708225789222377\n",
      "=== epoch:42, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.359003183141213\n",
      "train loss:2.3854599489143253\n",
      "train loss:2.373107563103728\n",
      "train loss:2.3677365968122004\n",
      "=== epoch:43, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.345699350804535\n",
      "train loss:2.3647101594163087\n",
      "train loss:2.41951874220492\n",
      "train loss:2.365649019823348\n",
      "=== epoch:44, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.397992831384206\n",
      "train loss:2.36213510179879\n",
      "train loss:2.4156058825120397\n",
      "train loss:2.3876278695553106\n",
      "=== epoch:45, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3867418807634357\n",
      "train loss:2.3358393033663982\n",
      "train loss:2.4052814728422867\n",
      "train loss:2.3517116816464108\n",
      "=== epoch:46, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.386330777171729\n",
      "train loss:2.350471272425403\n",
      "train loss:2.4474712196892487\n",
      "train loss:2.3769893189490148\n",
      "=== epoch:47, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3787886196011083\n",
      "train loss:2.33391916092547\n",
      "train loss:2.3643219161597284\n",
      "train loss:2.341011977878403\n",
      "=== epoch:48, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.337990013029589\n",
      "train loss:2.328500113091335\n",
      "train loss:2.3689729048350725\n",
      "train loss:2.3634004165949305\n",
      "=== epoch:49, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3045083069731485\n",
      "train loss:2.348081466880388\n",
      "train loss:2.352191520506689\n",
      "train loss:2.4019080513300497\n",
      "=== epoch:50, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.3968013802004084\n",
      "train loss:2.3844706341385122\n",
      "train loss:2.408318553329563\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3980732693546054\n",
      "=== epoch:1, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.409586525898287\n",
      "train loss:2.33570264815743\n",
      "train loss:2.4190043831380574\n",
      "train loss:2.3320322709538464\n",
      "=== epoch:2, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3793225361437598\n",
      "train loss:2.326027469831725\n",
      "train loss:2.332130090676469\n",
      "train loss:2.3804514966914896\n",
      "=== epoch:3, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.40392437465722\n",
      "train loss:2.386005103733366\n",
      "train loss:2.302873523647772\n",
      "train loss:2.3540643604820226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:4, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3658998876587294\n",
      "train loss:2.3555687130790255\n",
      "train loss:2.3851173115835387\n",
      "train loss:2.3918402662541185\n",
      "=== epoch:5, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.451394376439206\n",
      "train loss:2.3408511011152497\n",
      "train loss:2.4271077785151345\n",
      "train loss:2.419723467551257\n",
      "=== epoch:6, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.371183708269414\n",
      "train loss:2.3826296912454947\n",
      "train loss:2.3889214042751137\n",
      "train loss:2.3413495813583522\n",
      "=== epoch:7, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3718089423449635\n",
      "train loss:2.4083083794313396\n",
      "train loss:2.4329982348782693\n",
      "train loss:2.3183527307552643\n",
      "=== epoch:8, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3418657656577024\n",
      "train loss:2.3846021099630974\n",
      "train loss:2.345086738053097\n",
      "train loss:2.377202672408441\n",
      "=== epoch:9, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.2998743662322805\n",
      "train loss:2.3877071502043834\n",
      "train loss:2.3814322442378537\n",
      "train loss:2.356984044941\n",
      "=== epoch:10, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3708944320027294\n",
      "train loss:2.311067754069645\n",
      "train loss:2.3915331565960765\n",
      "train loss:2.326249097718541\n",
      "=== epoch:11, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.40405791661425\n",
      "train loss:2.3574732339884297\n",
      "train loss:2.338158433213821\n",
      "train loss:2.3750567042844053\n",
      "=== epoch:12, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.4007903026234745\n",
      "train loss:2.3534757485060758\n",
      "train loss:2.3779774972020644\n",
      "train loss:2.3276633424386355\n",
      "=== epoch:13, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3789574525474673\n",
      "train loss:2.3860926291496685\n",
      "train loss:2.3946813811106575\n",
      "train loss:2.3322795769780678\n",
      "=== epoch:14, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.4254287961260586\n",
      "train loss:2.329065946906898\n",
      "train loss:2.407709439741103\n",
      "train loss:2.285366312037132\n",
      "=== epoch:15, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.368507937333299\n",
      "train loss:2.3400252755838196\n",
      "train loss:2.4098681745349273\n",
      "train loss:2.3726626697353748\n",
      "=== epoch:16, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.371212121750765\n",
      "train loss:2.3261897489527876\n",
      "train loss:2.3355836196066844\n",
      "train loss:2.3685955060635564\n",
      "=== epoch:17, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.355861485753258\n",
      "train loss:2.3746740825811083\n",
      "train loss:2.343790306140789\n",
      "train loss:2.389683046843549\n",
      "=== epoch:18, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.310998357899478\n",
      "train loss:2.3772947945759637\n",
      "train loss:2.3804355406077224\n",
      "train loss:2.37020100920158\n",
      "=== epoch:19, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3586292083908083\n",
      "train loss:2.3428080046366686\n",
      "train loss:2.3461431395443766\n",
      "train loss:2.382461641473059\n",
      "=== epoch:20, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.366777799910103\n",
      "train loss:2.327790082577948\n",
      "train loss:2.386510081249105\n",
      "train loss:2.3822021207012978\n",
      "=== epoch:21, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3867761610511797\n",
      "train loss:2.3651574785618306\n",
      "train loss:2.394232892201832\n",
      "train loss:2.3376632545234397\n",
      "=== epoch:22, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3558927503639855\n",
      "train loss:2.4052221126665283\n",
      "train loss:2.3202813596957585\n",
      "train loss:2.3341307096668884\n",
      "=== epoch:23, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.403699568674354\n",
      "train loss:2.3565862730260507\n",
      "train loss:2.420066677005356\n",
      "train loss:2.3752788105530915\n",
      "=== epoch:24, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3542328743435323\n",
      "train loss:2.3583539559491853\n",
      "train loss:2.3949596434191096\n",
      "train loss:2.31360264917272\n",
      "=== epoch:25, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.330522097442778\n",
      "train loss:2.389376083160712\n",
      "train loss:2.366173818701673\n",
      "train loss:2.3676906824718977\n",
      "=== epoch:26, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.373441492248083\n",
      "train loss:2.3834647313721202\n",
      "train loss:2.3626425476525608\n",
      "train loss:2.373009075408383\n",
      "=== epoch:27, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3831445295798668\n",
      "train loss:2.3493389583238407\n",
      "train loss:2.347079160742706\n",
      "train loss:2.380561514792579\n",
      "=== epoch:28, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3765915526626005\n",
      "train loss:2.403774450390583\n",
      "train loss:2.391488970705236\n",
      "train loss:2.3584731272505723\n",
      "=== epoch:29, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3810962019233646\n",
      "train loss:2.3274368977817623\n",
      "train loss:2.386431576810651\n",
      "train loss:2.3207169592306878\n",
      "=== epoch:30, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3837598812018013\n",
      "train loss:2.351805636708784\n",
      "train loss:2.4059503302677685\n",
      "train loss:2.340103476526094\n",
      "=== epoch:31, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.331935877210603\n",
      "train loss:2.2939875980976465\n",
      "train loss:2.3927957844320775\n",
      "train loss:2.3806923534627766\n",
      "=== epoch:32, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.337487571646056\n",
      "train loss:2.430727014541522\n",
      "train loss:2.4058132056596095\n",
      "train loss:2.32915743739462\n",
      "=== epoch:33, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.4056381415072625\n",
      "train loss:2.3422394007238334\n",
      "train loss:2.4434044655020952\n",
      "train loss:2.3498709859098046\n",
      "=== epoch:34, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3893708912378604\n",
      "train loss:2.4229185435177802\n",
      "train loss:2.447827570879155\n",
      "train loss:2.3929116701215016\n",
      "=== epoch:35, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3937952117950436\n",
      "train loss:2.340225763526316\n",
      "train loss:2.3436752162242174\n",
      "train loss:2.3577354105706116\n",
      "=== epoch:36, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.4586274519918545\n",
      "train loss:2.329628598221237\n",
      "train loss:2.3940259795531325\n",
      "train loss:2.333807429077353\n",
      "=== epoch:37, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.357359963869506\n",
      "train loss:2.307069173496855\n",
      "train loss:2.4115978540757625\n",
      "train loss:2.398470932235339\n",
      "=== epoch:38, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.319872249577464\n",
      "train loss:2.381597549472692\n",
      "train loss:2.384793479495444\n",
      "train loss:2.4152015867156744\n",
      "=== epoch:39, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.389234928880032\n",
      "train loss:2.4626816448584083\n",
      "train loss:2.393464797998919\n",
      "train loss:2.318240635239016\n",
      "=== epoch:40, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3633587357851025\n",
      "train loss:2.408153774167908\n",
      "train loss:2.3638049889858217\n",
      "train loss:2.393226665725685\n",
      "=== epoch:41, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3774905993637376\n",
      "train loss:2.3171421367143346\n",
      "train loss:2.365667389065447\n",
      "train loss:2.3871192041758174\n",
      "=== epoch:42, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.387351815769406\n",
      "train loss:2.356396876358694\n",
      "train loss:2.4268794665694755\n",
      "train loss:2.3137974409702036\n",
      "=== epoch:43, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3780135484743528\n",
      "train loss:2.315009782374774\n",
      "train loss:2.4247322666904374\n",
      "train loss:2.3693323568942724\n",
      "=== epoch:44, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3945170183167175\n",
      "train loss:2.4161925526731336\n",
      "train loss:2.3803336087511724\n",
      "train loss:2.3351997617123676\n",
      "=== epoch:45, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.4178329860670793\n",
      "train loss:2.4362140360277156\n",
      "train loss:2.3594332128803903\n",
      "train loss:2.441194692684357\n",
      "=== epoch:46, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3550041809528492\n",
      "train loss:2.3260460474434104\n",
      "train loss:2.385486796254579\n",
      "train loss:2.342526776326906\n",
      "=== epoch:47, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.2928027010448275\n",
      "train loss:2.362667901627626\n",
      "train loss:2.398455879229833\n",
      "train loss:2.3804732619337785\n",
      "=== epoch:48, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.4190761518515873\n",
      "train loss:2.3384466019474552\n",
      "train loss:2.3856002416559994\n",
      "train loss:2.3347672172056195\n",
      "=== epoch:49, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.421637797278133\n",
      "train loss:2.3338063351618246\n",
      "train loss:2.395807863831312\n",
      "train loss:2.371366797512403\n",
      "=== epoch:50, train acc:0.075, test acc:0.07 ===\n",
      "train loss:2.3313514597948997\n",
      "train loss:2.381929763884375\n",
      "train loss:2.355674369181413\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3846494381230245\n",
      "=== epoch:1, train acc:0.0775, test acc:0.09 ===\n",
      "train loss:2.34127690895053\n",
      "train loss:2.3302675976026754\n",
      "train loss:2.3239390944524096\n",
      "train loss:2.333941604358976\n",
      "=== epoch:2, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.3310498937146384\n",
      "train loss:2.34234522015138\n",
      "train loss:2.330632490440033\n",
      "train loss:2.3236675915290386\n",
      "=== epoch:3, train acc:0.095, test acc:0.08 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.338068564515632\n",
      "train loss:2.3677412522583174\n",
      "train loss:2.333500564908986\n",
      "train loss:2.2864107919740877\n",
      "=== epoch:4, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.3071399844537854\n",
      "train loss:2.414257795256616\n",
      "train loss:2.315775423056926\n",
      "train loss:2.3603567654947555\n",
      "=== epoch:5, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.3208563615808013\n",
      "train loss:2.406316290431085\n",
      "train loss:2.287842958873184\n",
      "train loss:2.3403643885405527\n",
      "=== epoch:6, train acc:0.11, test acc:0.09 ===\n",
      "train loss:2.3190350927019434\n",
      "train loss:2.301250414647375\n",
      "train loss:2.259707959478176\n",
      "train loss:2.3035708706918365\n",
      "=== epoch:7, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.2878339344452923\n",
      "train loss:2.247615711062026\n",
      "train loss:2.2609163889390875\n",
      "train loss:2.2578412834693053\n",
      "=== epoch:8, train acc:0.11, test acc:0.11 ===\n",
      "train loss:2.3431735920919623\n",
      "train loss:2.2748168984252617\n",
      "train loss:2.2844686782329395\n",
      "train loss:2.273143637081301\n",
      "=== epoch:9, train acc:0.115, test acc:0.12 ===\n",
      "train loss:2.2942682244573533\n",
      "train loss:2.31602303895154\n",
      "train loss:2.275899015538501\n",
      "train loss:2.244008198162489\n",
      "=== epoch:10, train acc:0.12, test acc:0.12 ===\n",
      "train loss:2.2998682858767965\n",
      "train loss:2.2609178168592683\n",
      "train loss:2.2990898063171494\n",
      "train loss:2.2450280769970026\n",
      "=== epoch:11, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.2432291938683186\n",
      "train loss:2.2829525876699206\n",
      "train loss:2.272705239711121\n",
      "train loss:2.274678714713354\n",
      "=== epoch:12, train acc:0.1425, test acc:0.13 ===\n",
      "train loss:2.247852700726001\n",
      "train loss:2.1852655053953685\n",
      "train loss:2.239066374359838\n",
      "train loss:2.222406909197085\n",
      "=== epoch:13, train acc:0.1425, test acc:0.14 ===\n",
      "train loss:2.218858127897875\n",
      "train loss:2.232915071216341\n",
      "train loss:2.2430883398545407\n",
      "train loss:2.216175862529851\n",
      "=== epoch:14, train acc:0.1475, test acc:0.15 ===\n",
      "train loss:2.2482800534504483\n",
      "train loss:2.2414696251732553\n",
      "train loss:2.263436048514691\n",
      "train loss:2.2424371491197297\n",
      "=== epoch:15, train acc:0.1525, test acc:0.14 ===\n",
      "train loss:2.2686625530372573\n",
      "train loss:2.250610559583788\n",
      "train loss:2.211499442220937\n",
      "train loss:2.2563877419472758\n",
      "=== epoch:16, train acc:0.155, test acc:0.15 ===\n",
      "train loss:2.2190447939156543\n",
      "train loss:2.2558613727559256\n",
      "train loss:2.234718917201246\n",
      "train loss:2.217742152516481\n",
      "=== epoch:17, train acc:0.1675, test acc:0.16 ===\n",
      "train loss:2.1719955724825426\n",
      "train loss:2.2277008719493856\n",
      "train loss:2.1891004177408426\n",
      "train loss:2.2133279836793784\n",
      "=== epoch:18, train acc:0.1725, test acc:0.17 ===\n",
      "train loss:2.251501637485392\n",
      "train loss:2.1707199176876437\n",
      "train loss:2.2430257289353\n",
      "train loss:2.187644315823283\n",
      "=== epoch:19, train acc:0.18, test acc:0.19 ===\n",
      "train loss:2.2003320405731834\n",
      "train loss:2.2105930839601022\n",
      "train loss:2.2230437443852553\n",
      "train loss:2.169601880127599\n",
      "=== epoch:20, train acc:0.1825, test acc:0.21 ===\n",
      "train loss:2.182889383046822\n",
      "train loss:2.2122652955695665\n",
      "train loss:2.1664684689058396\n",
      "train loss:2.197252979096116\n",
      "=== epoch:21, train acc:0.1975, test acc:0.22 ===\n",
      "train loss:2.13155125716942\n",
      "train loss:2.1814720058994617\n",
      "train loss:2.158424620448123\n",
      "train loss:2.2353808127846975\n",
      "=== epoch:22, train acc:0.21, test acc:0.23 ===\n",
      "train loss:2.1860411611322976\n",
      "train loss:2.1832745061750276\n",
      "train loss:2.180650912259586\n",
      "train loss:2.201415673660045\n",
      "=== epoch:23, train acc:0.22, test acc:0.23 ===\n",
      "train loss:2.2168410352789856\n",
      "train loss:2.2084269346600753\n",
      "train loss:2.1808933015779637\n",
      "train loss:2.2098487111737777\n",
      "=== epoch:24, train acc:0.2275, test acc:0.25 ===\n",
      "train loss:2.191346125930085\n",
      "train loss:2.232967366582348\n",
      "train loss:2.225623809331859\n",
      "train loss:2.167426113816214\n",
      "=== epoch:25, train acc:0.245, test acc:0.26 ===\n",
      "train loss:2.1720410221100575\n",
      "train loss:2.154157544176902\n",
      "train loss:2.164783486029182\n",
      "train loss:2.1890295798721344\n",
      "=== epoch:26, train acc:0.2525, test acc:0.27 ===\n",
      "train loss:2.1388704218393118\n",
      "train loss:2.156718222104274\n",
      "train loss:2.1441253657236987\n",
      "train loss:2.12351119158702\n",
      "=== epoch:27, train acc:0.2625, test acc:0.27 ===\n",
      "train loss:2.1395240755868405\n",
      "train loss:2.1555342534089657\n",
      "train loss:2.1377337759531057\n",
      "train loss:2.1371629754688173\n",
      "=== epoch:28, train acc:0.27, test acc:0.27 ===\n",
      "train loss:2.166872142694882\n",
      "train loss:2.1337670410885856\n",
      "train loss:2.1709767246922493\n",
      "train loss:2.133285535410594\n",
      "=== epoch:29, train acc:0.2775, test acc:0.28 ===\n",
      "train loss:2.1436749335658947\n",
      "train loss:2.1404815123566814\n",
      "train loss:2.1037729587780136\n",
      "train loss:2.1517513832696067\n",
      "=== epoch:30, train acc:0.2825, test acc:0.28 ===\n",
      "train loss:2.1290191470522757\n",
      "train loss:2.1493053387619137\n",
      "train loss:2.1333197625785494\n",
      "train loss:2.1614109977104197\n",
      "=== epoch:31, train acc:0.2875, test acc:0.28 ===\n",
      "train loss:2.144802406041379\n",
      "train loss:2.1735329102328187\n",
      "train loss:2.0998940799777897\n",
      "train loss:2.1056627465536297\n",
      "=== epoch:32, train acc:0.2875, test acc:0.28 ===\n",
      "train loss:2.1715331828434663\n",
      "train loss:2.1091696176180292\n",
      "train loss:2.1372482961489307\n",
      "train loss:2.1518195541377825\n",
      "=== epoch:33, train acc:0.3, test acc:0.31 ===\n",
      "train loss:2.1113249910863514\n",
      "train loss:2.1543022406128003\n",
      "train loss:2.181765485717814\n",
      "train loss:2.102295660776992\n",
      "=== epoch:34, train acc:0.3125, test acc:0.31 ===\n",
      "train loss:2.182369593192968\n",
      "train loss:2.1392170189746156\n",
      "train loss:2.144200131416035\n",
      "train loss:2.1355243115059053\n",
      "=== epoch:35, train acc:0.3225, test acc:0.3 ===\n",
      "train loss:2.0998772944908572\n",
      "train loss:2.1140239404705956\n",
      "train loss:2.122130614124957\n",
      "train loss:2.124096677112552\n",
      "=== epoch:36, train acc:0.3375, test acc:0.31 ===\n",
      "train loss:2.107324997871397\n",
      "train loss:2.071349428074326\n",
      "train loss:2.1388019845180914\n",
      "train loss:2.139682522529548\n",
      "=== epoch:37, train acc:0.3475, test acc:0.31 ===\n",
      "train loss:2.093631090000015\n",
      "train loss:2.1215721145015776\n",
      "train loss:2.08610595894662\n",
      "train loss:2.095884615950599\n",
      "=== epoch:38, train acc:0.3575, test acc:0.32 ===\n",
      "train loss:2.043343669992177\n",
      "train loss:2.0779498152627984\n",
      "train loss:2.1196287152292577\n",
      "train loss:2.098591256437902\n",
      "=== epoch:39, train acc:0.3675, test acc:0.34 ===\n",
      "train loss:2.08144759329256\n",
      "train loss:2.104236469893826\n",
      "train loss:2.122115624412926\n",
      "train loss:2.093095136760933\n",
      "=== epoch:40, train acc:0.3725, test acc:0.33 ===\n",
      "train loss:2.081033119894028\n",
      "train loss:2.110511935991958\n",
      "train loss:2.066459548137557\n",
      "train loss:2.0718304168049446\n",
      "=== epoch:41, train acc:0.375, test acc:0.35 ===\n",
      "train loss:2.0231309558660078\n",
      "train loss:2.070600947520884\n",
      "train loss:2.0787433023980864\n",
      "train loss:2.0603686025137353\n",
      "=== epoch:42, train acc:0.38, test acc:0.34 ===\n",
      "train loss:2.1010143769241796\n",
      "train loss:2.0523499839324586\n",
      "train loss:2.0867379289863806\n",
      "train loss:2.080593169875976\n",
      "=== epoch:43, train acc:0.3875, test acc:0.34 ===\n",
      "train loss:1.9694982972976038\n",
      "train loss:2.1077714104962313\n",
      "train loss:2.0741467950229953\n",
      "train loss:2.049501586561079\n",
      "=== epoch:44, train acc:0.39, test acc:0.34 ===\n",
      "train loss:2.0342135132246\n",
      "train loss:2.0642630942669267\n",
      "train loss:2.0870217487589393\n",
      "train loss:2.0766383341013483\n",
      "=== epoch:45, train acc:0.3925, test acc:0.34 ===\n",
      "train loss:2.037436987944909\n",
      "train loss:2.0372674264634756\n",
      "train loss:2.0664766088055244\n",
      "train loss:2.031153192708871\n",
      "=== epoch:46, train acc:0.4025, test acc:0.34 ===\n",
      "train loss:2.0580734316902607\n",
      "train loss:1.9968673252839677\n",
      "train loss:2.0282519977716484\n",
      "train loss:2.051263038318182\n",
      "=== epoch:47, train acc:0.4275, test acc:0.35 ===\n",
      "train loss:1.999679852406541\n",
      "train loss:1.9737614820015883\n",
      "train loss:2.0063910030400747\n",
      "train loss:2.0382632521728423\n",
      "=== epoch:48, train acc:0.435, test acc:0.37 ===\n",
      "train loss:2.0337129685582207\n",
      "train loss:2.038132941641728\n",
      "train loss:2.0577307683639203\n",
      "train loss:2.0096566674426946\n",
      "=== epoch:49, train acc:0.44, test acc:0.38 ===\n",
      "train loss:2.027675593842445\n",
      "train loss:2.0158712175311337\n",
      "train loss:2.000055896315166\n",
      "train loss:2.0469269854486125\n",
      "=== epoch:50, train acc:0.445, test acc:0.38 ===\n",
      "train loss:1.9835761958952824\n",
      "train loss:2.0217159767330917\n",
      "train loss:2.0278369153650098\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.38\n",
      "val_acc: 0.3800 | lr: 0.0025, weight_decay: 0.0000\n",
      "train loss:2.43154593599512\n",
      "=== epoch:1, train acc:0.085, test acc:0.08 ===\n",
      "train loss:2.4374186108231037\n",
      "train loss:2.4730118471249147\n",
      "train loss:2.5143718289731547\n",
      "train loss:2.427266496108236\n",
      "=== epoch:2, train acc:0.08, test acc:0.08 ===\n",
      "train loss:2.4518799791611214\n",
      "train loss:2.4513933829866175\n",
      "train loss:2.448930003485415\n",
      "train loss:2.411543591173652\n",
      "=== epoch:3, train acc:0.08, test acc:0.07 ===\n",
      "train loss:2.418326130707693\n",
      "train loss:2.4464463457698917\n",
      "train loss:2.371473033412461\n",
      "train loss:2.4336117907894974\n",
      "=== epoch:4, train acc:0.08, test acc:0.09 ===\n",
      "train loss:2.3750455818001566\n",
      "train loss:2.3961293779048916\n",
      "train loss:2.390069845124478\n",
      "train loss:2.41956609770725\n",
      "=== epoch:5, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.408823964866767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3411261691836702\n",
      "train loss:2.3842613680163214\n",
      "train loss:2.3084799456284597\n",
      "=== epoch:6, train acc:0.09, test acc:0.11 ===\n",
      "train loss:2.299783764860287\n",
      "train loss:2.376237565296057\n",
      "train loss:2.3485760546512573\n",
      "train loss:2.265245808323418\n",
      "=== epoch:7, train acc:0.0875, test acc:0.12 ===\n",
      "train loss:2.354093576888378\n",
      "train loss:2.364709908195936\n",
      "train loss:2.2819977237611466\n",
      "train loss:2.321566361653335\n",
      "=== epoch:8, train acc:0.0925, test acc:0.11 ===\n",
      "train loss:2.32093950571525\n",
      "train loss:2.329187379044625\n",
      "train loss:2.283615936534351\n",
      "train loss:2.2782006361177074\n",
      "=== epoch:9, train acc:0.0975, test acc:0.12 ===\n",
      "train loss:2.279134620114777\n",
      "train loss:2.3502060057192926\n",
      "train loss:2.269004450128073\n",
      "train loss:2.307352391559241\n",
      "=== epoch:10, train acc:0.11, test acc:0.12 ===\n",
      "train loss:2.331972773092141\n",
      "train loss:2.3470914357819757\n",
      "train loss:2.2939679609685077\n",
      "train loss:2.299133856830931\n",
      "=== epoch:11, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.273246687081496\n",
      "train loss:2.28276257046159\n",
      "train loss:2.2813006761472217\n",
      "train loss:2.279310387010942\n",
      "=== epoch:12, train acc:0.125, test acc:0.13 ===\n",
      "train loss:2.2612441612806835\n",
      "train loss:2.3111642593702495\n",
      "train loss:2.2661391329782883\n",
      "train loss:2.261107512987193\n",
      "=== epoch:13, train acc:0.135, test acc:0.13 ===\n",
      "train loss:2.289769050574379\n",
      "train loss:2.256157268087372\n",
      "train loss:2.234178245567618\n",
      "train loss:2.2618339940961256\n",
      "=== epoch:14, train acc:0.1425, test acc:0.13 ===\n",
      "train loss:2.273257827936569\n",
      "train loss:2.2370575899452305\n",
      "train loss:2.2857246234037074\n",
      "train loss:2.2433852207221445\n",
      "=== epoch:15, train acc:0.145, test acc:0.13 ===\n",
      "train loss:2.233920055147521\n",
      "train loss:2.2611693156769195\n",
      "train loss:2.2536383911591695\n",
      "train loss:2.2448330283689892\n",
      "=== epoch:16, train acc:0.155, test acc:0.12 ===\n",
      "train loss:2.2400547651998197\n",
      "train loss:2.2524393083722276\n",
      "train loss:2.2399779458091262\n",
      "train loss:2.23331370948332\n",
      "=== epoch:17, train acc:0.1625, test acc:0.13 ===\n",
      "train loss:2.247699743403687\n",
      "train loss:2.1987450308042784\n",
      "train loss:2.1945784392356082\n",
      "train loss:2.229577521017014\n",
      "=== epoch:18, train acc:0.175, test acc:0.13 ===\n",
      "train loss:2.229914579341652\n",
      "train loss:2.2354236447458744\n",
      "train loss:2.1986934907242213\n",
      "train loss:2.2144665637383256\n",
      "=== epoch:19, train acc:0.1825, test acc:0.14 ===\n",
      "train loss:2.2290710256686377\n",
      "train loss:2.2549514913553175\n",
      "train loss:2.217822846060028\n",
      "train loss:2.2351149464543334\n",
      "=== epoch:20, train acc:0.205, test acc:0.14 ===\n",
      "train loss:2.212832592409575\n",
      "train loss:2.226183442690943\n",
      "train loss:2.1977241089170234\n",
      "train loss:2.223574776286916\n",
      "=== epoch:21, train acc:0.2125, test acc:0.15 ===\n",
      "train loss:2.2258838730704364\n",
      "train loss:2.2108564583383608\n",
      "train loss:2.1979867023068103\n",
      "train loss:2.176637099371598\n",
      "=== epoch:22, train acc:0.2125, test acc:0.18 ===\n",
      "train loss:2.173506159229946\n",
      "train loss:2.232496904776177\n",
      "train loss:2.1926525193629396\n",
      "train loss:2.185726953830834\n",
      "=== epoch:23, train acc:0.225, test acc:0.18 ===\n",
      "train loss:2.1768062372146946\n",
      "train loss:2.1538408048657747\n",
      "train loss:2.1801964668316645\n",
      "train loss:2.1772826664249236\n",
      "=== epoch:24, train acc:0.23, test acc:0.19 ===\n",
      "train loss:2.2020366419119815\n",
      "train loss:2.181862976550792\n",
      "train loss:2.1624637609464186\n",
      "train loss:2.21290249613117\n",
      "=== epoch:25, train acc:0.2375, test acc:0.2 ===\n",
      "train loss:2.193271719769107\n",
      "train loss:2.1918017795194444\n",
      "train loss:2.169971344476331\n",
      "train loss:2.18542546870938\n",
      "=== epoch:26, train acc:0.24, test acc:0.21 ===\n",
      "train loss:2.185984844638879\n",
      "train loss:2.2009083558160523\n",
      "train loss:2.1847591979726926\n",
      "train loss:2.15055667107576\n",
      "=== epoch:27, train acc:0.2525, test acc:0.21 ===\n",
      "train loss:2.165467638757243\n",
      "train loss:2.1717761791947\n",
      "train loss:2.158791849055025\n",
      "train loss:2.1594550583164147\n",
      "=== epoch:28, train acc:0.255, test acc:0.22 ===\n",
      "train loss:2.146178211427546\n",
      "train loss:2.139339963877906\n",
      "train loss:2.1702432715020525\n",
      "train loss:2.1171899021196965\n",
      "=== epoch:29, train acc:0.26, test acc:0.22 ===\n",
      "train loss:2.140306881052101\n",
      "train loss:2.1496556957309103\n",
      "train loss:2.125652473908641\n",
      "train loss:2.175163445654935\n",
      "=== epoch:30, train acc:0.27, test acc:0.22 ===\n",
      "train loss:2.1263540141410666\n",
      "train loss:2.1678958143445595\n",
      "train loss:2.121030134744956\n",
      "train loss:2.137635485305276\n",
      "=== epoch:31, train acc:0.28, test acc:0.24 ===\n",
      "train loss:2.1248346867585934\n",
      "train loss:2.142127516335472\n",
      "train loss:2.0940185054138203\n",
      "train loss:2.1665280842281733\n",
      "=== epoch:32, train acc:0.2925, test acc:0.27 ===\n",
      "train loss:2.0953678351744744\n",
      "train loss:2.116854374695824\n",
      "train loss:2.1000227965342035\n",
      "train loss:2.159801877551805\n",
      "=== epoch:33, train acc:0.3025, test acc:0.29 ===\n",
      "train loss:2.098222290237081\n",
      "train loss:2.1068370613597205\n",
      "train loss:2.1164928284845654\n",
      "train loss:2.07452466319462\n",
      "=== epoch:34, train acc:0.3075, test acc:0.28 ===\n",
      "train loss:2.063447871951841\n",
      "train loss:2.1040405234992483\n",
      "train loss:2.112778400874098\n",
      "train loss:2.0907584133265558\n",
      "=== epoch:35, train acc:0.32, test acc:0.28 ===\n",
      "train loss:2.125452599595026\n",
      "train loss:2.0688482041356595\n",
      "train loss:2.1227503594768655\n",
      "train loss:2.0850261657085736\n",
      "=== epoch:36, train acc:0.3325, test acc:0.3 ===\n",
      "train loss:2.10180325374124\n",
      "train loss:2.0081394380731212\n",
      "train loss:2.0943733550910273\n",
      "train loss:2.0704288197032437\n",
      "=== epoch:37, train acc:0.3475, test acc:0.3 ===\n",
      "train loss:2.073630721816461\n",
      "train loss:2.0769873404680124\n",
      "train loss:2.041241504772398\n",
      "train loss:2.0416759565104687\n",
      "=== epoch:38, train acc:0.35, test acc:0.28 ===\n",
      "train loss:2.0952545534283322\n",
      "train loss:2.1038369721690096\n",
      "train loss:2.059372694272502\n",
      "train loss:2.078322455715802\n",
      "=== epoch:39, train acc:0.35, test acc:0.3 ===\n",
      "train loss:2.0841456817883643\n",
      "train loss:2.09126515207151\n",
      "train loss:2.057974686060534\n",
      "train loss:2.072002823329768\n",
      "=== epoch:40, train acc:0.3675, test acc:0.31 ===\n",
      "train loss:2.0734218520834067\n",
      "train loss:2.0390875299580378\n",
      "train loss:2.0536915600397867\n",
      "train loss:2.0322062323192123\n",
      "=== epoch:41, train acc:0.3725, test acc:0.31 ===\n",
      "train loss:2.0878218729023867\n",
      "train loss:2.0575414152853284\n",
      "train loss:2.0583812997096698\n",
      "train loss:1.9785811984197186\n",
      "=== epoch:42, train acc:0.375, test acc:0.33 ===\n",
      "train loss:2.0549339697224944\n",
      "train loss:1.9945157799460325\n",
      "train loss:2.0608211076315697\n",
      "train loss:2.0719887511430692\n",
      "=== epoch:43, train acc:0.385, test acc:0.33 ===\n",
      "train loss:1.988014667805617\n",
      "train loss:2.0209618813563477\n",
      "train loss:1.9965981637475039\n",
      "train loss:2.047375570525546\n",
      "=== epoch:44, train acc:0.4125, test acc:0.36 ===\n",
      "train loss:2.0191429043384903\n",
      "train loss:2.0304872309024997\n",
      "train loss:1.9959944812066381\n",
      "train loss:2.011308268052407\n",
      "=== epoch:45, train acc:0.415, test acc:0.36 ===\n",
      "train loss:2.073313542887161\n",
      "train loss:2.0060243179721122\n",
      "train loss:1.9424679738717534\n",
      "train loss:1.9368050256569147\n",
      "=== epoch:46, train acc:0.4325, test acc:0.39 ===\n",
      "train loss:2.0315360538393326\n",
      "train loss:2.007617543403227\n",
      "train loss:1.981922628012972\n",
      "train loss:1.9553122358225843\n",
      "=== epoch:47, train acc:0.44, test acc:0.39 ===\n",
      "train loss:1.9869108240672324\n",
      "train loss:1.9548508537444824\n",
      "train loss:1.9197963257590154\n",
      "train loss:2.001036533298448\n",
      "=== epoch:48, train acc:0.435, test acc:0.39 ===\n",
      "train loss:2.008997959672263\n",
      "train loss:1.9462822856503286\n",
      "train loss:2.0085284490494475\n",
      "train loss:1.9514673604687236\n",
      "=== epoch:49, train acc:0.4425, test acc:0.41 ===\n",
      "train loss:2.00266317632194\n",
      "train loss:1.9352486050443585\n",
      "train loss:1.8857042910027026\n",
      "train loss:2.0247780312213237\n",
      "=== epoch:50, train acc:0.4525, test acc:0.41 ===\n",
      "train loss:1.8775687596058181\n",
      "train loss:1.975144590769638\n",
      "train loss:1.9128213862113022\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.41\n",
      "val_acc: 0.4100 | lr: 0.0026, weight_decay: 0.0000\n",
      "train loss:2.5268547916122426\n",
      "=== epoch:1, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4851466598830267\n",
      "train loss:2.537383334771501\n",
      "train loss:2.5784910885130405\n",
      "train loss:2.372217992125176\n",
      "=== epoch:2, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.523083515308063\n",
      "train loss:2.531767636439197\n",
      "train loss:2.4822032156230356\n",
      "train loss:2.4460270088661766\n",
      "=== epoch:3, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.455028530396811\n",
      "train loss:2.398929391130609\n",
      "train loss:2.4769280534924065\n",
      "train loss:2.3901451861508507\n",
      "=== epoch:4, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.504827904373228\n",
      "train loss:2.4669606595080946\n",
      "train loss:2.3942397124145405\n",
      "train loss:2.440821057910953\n",
      "=== epoch:5, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4620452722554624\n",
      "train loss:2.4501854385617885\n",
      "train loss:2.3985608859418326\n",
      "train loss:2.5307224755156827\n",
      "=== epoch:6, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4598293124129023\n",
      "train loss:2.449105638741461\n",
      "train loss:2.2906482745360908\n",
      "train loss:2.4751280941204596\n",
      "=== epoch:7, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.400620379995947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.403528835265921\n",
      "train loss:2.465129676113988\n",
      "train loss:2.4435543978477585\n",
      "=== epoch:8, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.411731717139995\n",
      "train loss:2.464377344183364\n",
      "train loss:2.5534159927266304\n",
      "train loss:2.54206722924307\n",
      "=== epoch:9, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.366702235845105\n",
      "train loss:2.445913414291466\n",
      "train loss:2.3835010162434833\n",
      "train loss:2.4177366851722106\n",
      "=== epoch:10, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.559453244117617\n",
      "train loss:2.4225549183667443\n",
      "train loss:2.488810916929132\n",
      "train loss:2.455220889184162\n",
      "=== epoch:11, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4059157674685556\n",
      "train loss:2.542928704773801\n",
      "train loss:2.4275811808541397\n",
      "train loss:2.4515036158758727\n",
      "=== epoch:12, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4309416646928956\n",
      "train loss:2.5630102101549626\n",
      "train loss:2.516774506988677\n",
      "train loss:2.380821588165006\n",
      "=== epoch:13, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4032293363518216\n",
      "train loss:2.5176018627959893\n",
      "train loss:2.434640469607636\n",
      "train loss:2.390526480953616\n",
      "=== epoch:14, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.476788438328835\n",
      "train loss:2.467695653117346\n",
      "train loss:2.5406602096069184\n",
      "train loss:2.3847472007440125\n",
      "=== epoch:15, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.452913141035327\n",
      "train loss:2.42927675562407\n",
      "train loss:2.3297765955436556\n",
      "train loss:2.468512747456002\n",
      "=== epoch:16, train acc:0.0875, test acc:0.07 ===\n",
      "train loss:2.4377067091426046\n",
      "train loss:2.441872702863145\n",
      "train loss:2.517021906989289\n",
      "train loss:2.4549963949462903\n",
      "=== epoch:17, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4587710085872283\n",
      "train loss:2.355177393206259\n",
      "train loss:2.4075315087776907\n",
      "train loss:2.4730035125903953\n",
      "=== epoch:18, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.482768173230596\n",
      "train loss:2.4394245619400077\n",
      "train loss:2.441505040926073\n",
      "train loss:2.462273442012142\n",
      "=== epoch:19, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4527627850637366\n",
      "train loss:2.348999719182573\n",
      "train loss:2.4352038325257976\n",
      "train loss:2.435030241989453\n",
      "=== epoch:20, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.432390655578995\n",
      "train loss:2.5025094784392325\n",
      "train loss:2.434046503340299\n",
      "train loss:2.3332707395485732\n",
      "=== epoch:21, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4549173229737415\n",
      "train loss:2.4087641423935042\n",
      "train loss:2.4576021333870552\n",
      "train loss:2.405798239028193\n",
      "=== epoch:22, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.5098455202134438\n",
      "train loss:2.4264251602560027\n",
      "train loss:2.422694650930214\n",
      "train loss:2.4940658127638726\n",
      "=== epoch:23, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4183508461622267\n",
      "train loss:2.4686621589441358\n",
      "train loss:2.3742198741853398\n",
      "train loss:2.489707801374534\n",
      "=== epoch:24, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.503698369136979\n",
      "train loss:2.331040013582794\n",
      "train loss:2.4244074431775577\n",
      "train loss:2.4400778666566363\n",
      "=== epoch:25, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4631954922989214\n",
      "train loss:2.4332305489492314\n",
      "train loss:2.639817174903905\n",
      "train loss:2.363757727667541\n",
      "=== epoch:26, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.490493546557818\n",
      "train loss:2.4120124768536244\n",
      "train loss:2.482620746275873\n",
      "train loss:2.376910542653112\n",
      "=== epoch:27, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4530289511869023\n",
      "train loss:2.580098750925049\n",
      "train loss:2.4028091067055484\n",
      "train loss:2.503618284150451\n",
      "=== epoch:28, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.5130732951535397\n",
      "train loss:2.4357428467994886\n",
      "train loss:2.365718900957533\n",
      "train loss:2.383908660180041\n",
      "=== epoch:29, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4653658145275754\n",
      "train loss:2.426781275969062\n",
      "train loss:2.539674572212973\n",
      "train loss:2.5030452269252503\n",
      "=== epoch:30, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4550937151725885\n",
      "train loss:2.345066120137399\n",
      "train loss:2.492500662368556\n",
      "train loss:2.536374382523413\n",
      "=== epoch:31, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4395171351791776\n",
      "train loss:2.380018328481817\n",
      "train loss:2.3868552683399953\n",
      "train loss:2.4325485035325527\n",
      "=== epoch:32, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.427268988941432\n",
      "train loss:2.491824205510826\n",
      "train loss:2.493616159640123\n",
      "train loss:2.434277524416814\n",
      "=== epoch:33, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.3836082636011735\n",
      "train loss:2.472979560077491\n",
      "train loss:2.391382152329993\n",
      "train loss:2.3156241911668016\n",
      "=== epoch:34, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4553576254796123\n",
      "train loss:2.4527098678519574\n",
      "train loss:2.3921490768001235\n",
      "train loss:2.477697342923667\n",
      "=== epoch:35, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4068450598843047\n",
      "train loss:2.470515965392695\n",
      "train loss:2.2968487473478447\n",
      "train loss:2.475592245648079\n",
      "=== epoch:36, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.451170265085304\n",
      "train loss:2.484076609441881\n",
      "train loss:2.338495016379875\n",
      "train loss:2.352896115758932\n",
      "=== epoch:37, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.493063617886886\n",
      "train loss:2.453823195115612\n",
      "train loss:2.4083213280293636\n",
      "train loss:2.4421883119347623\n",
      "=== epoch:38, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4303995390157884\n",
      "train loss:2.3021533693399636\n",
      "train loss:2.4466064583319382\n",
      "train loss:2.4948121798527096\n",
      "=== epoch:39, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.3681934194143324\n",
      "train loss:2.3883744106452194\n",
      "train loss:2.5133450193212767\n",
      "train loss:2.4360409449142906\n",
      "=== epoch:40, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.453669953894927\n",
      "train loss:2.4311941286768053\n",
      "train loss:2.4854032939541035\n",
      "train loss:2.4555971944587305\n",
      "=== epoch:41, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.497465677484608\n",
      "train loss:2.383743249666459\n",
      "train loss:2.459806946931506\n",
      "train loss:2.423925626808233\n",
      "=== epoch:42, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.362151183435847\n",
      "train loss:2.496357795246696\n",
      "train loss:2.4844877051754772\n",
      "train loss:2.381374335356504\n",
      "=== epoch:43, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.390467963742131\n",
      "train loss:2.373742847196776\n",
      "train loss:2.3967545584848\n",
      "train loss:2.438540148007299\n",
      "=== epoch:44, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4018670459889027\n",
      "train loss:2.4973226732425338\n",
      "train loss:2.4575916938505884\n",
      "train loss:2.449263783024\n",
      "=== epoch:45, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.477842111065731\n",
      "train loss:2.4675383205451893\n",
      "train loss:2.491910705274952\n",
      "train loss:2.5376775424232476\n",
      "=== epoch:46, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4377561766649607\n",
      "train loss:2.4791682388715137\n",
      "train loss:2.4681756153372953\n",
      "train loss:2.5240007626165957\n",
      "=== epoch:47, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.42555612086329\n",
      "train loss:2.3485157059856245\n",
      "train loss:2.4261048692491203\n",
      "train loss:2.371202348146542\n",
      "=== epoch:48, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.495466049174886\n",
      "train loss:2.4163703293223784\n",
      "train loss:2.45560366521099\n",
      "train loss:2.475934324654936\n",
      "=== epoch:49, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.3666892187103388\n",
      "train loss:2.41418675062917\n",
      "train loss:2.416161517674528\n",
      "train loss:2.403585576884389\n",
      "=== epoch:50, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4560544128149275\n",
      "train loss:2.452989218507237\n",
      "train loss:2.2931832708254314\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.513036570359481\n",
      "=== epoch:1, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.453260411750107\n",
      "train loss:2.448950164396644\n",
      "train loss:2.3530045068707017\n",
      "train loss:2.463448902974297\n",
      "=== epoch:2, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.3651641902556917\n",
      "train loss:2.392818081657051\n",
      "train loss:2.437580603508172\n",
      "train loss:2.5064591426790526\n",
      "=== epoch:3, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.465922558472991\n",
      "train loss:2.4654484875551628\n",
      "train loss:2.474722925635197\n",
      "train loss:2.407196273764643\n",
      "=== epoch:4, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4394152469580184\n",
      "train loss:2.479899123672526\n",
      "train loss:2.4651284474128596\n",
      "train loss:2.474525473296401\n",
      "=== epoch:5, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4163253547236474\n",
      "train loss:2.44265293243321\n",
      "train loss:2.3834551547464775\n",
      "train loss:2.5083254553026038\n",
      "=== epoch:6, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4492626458585245\n",
      "train loss:2.4354741949833567\n",
      "train loss:2.455336515619143\n",
      "train loss:2.3881365753641934\n",
      "=== epoch:7, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4385832827120044\n",
      "train loss:2.4413703479567057\n",
      "train loss:2.4269376355781453\n",
      "train loss:2.435306584628314\n",
      "=== epoch:8, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.425955339598034\n",
      "train loss:2.3923123775331634\n",
      "train loss:2.482387137001498\n",
      "train loss:2.479467340783143\n",
      "=== epoch:9, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4886889150677853\n",
      "train loss:2.459342484941091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4265366737219036\n",
      "train loss:2.443459467344755\n",
      "=== epoch:10, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4442998250704924\n",
      "train loss:2.457134831268768\n",
      "train loss:2.437141949293011\n",
      "train loss:2.4512340884888233\n",
      "=== epoch:11, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.456081213287254\n",
      "train loss:2.456386778452079\n",
      "train loss:2.4279234365968674\n",
      "train loss:2.4244266733136235\n",
      "=== epoch:12, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.5161338644415197\n",
      "train loss:2.4652561989190995\n",
      "train loss:2.512577840218408\n",
      "train loss:2.4153345753243505\n",
      "=== epoch:13, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.436886330856069\n",
      "train loss:2.418821864622742\n",
      "train loss:2.4701757954781547\n",
      "train loss:2.43396836639072\n",
      "=== epoch:14, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4351091979875914\n",
      "train loss:2.4104619170852266\n",
      "train loss:2.41396992214712\n",
      "train loss:2.506339351538657\n",
      "=== epoch:15, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.427230346948672\n",
      "train loss:2.4629409766478463\n",
      "train loss:2.4935622101086214\n",
      "train loss:2.4659895133482324\n",
      "=== epoch:16, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.47422676420048\n",
      "train loss:2.4598592738524943\n",
      "train loss:2.583631901987056\n",
      "train loss:2.412028545799311\n",
      "=== epoch:17, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.447216674066364\n",
      "train loss:2.433993482566466\n",
      "train loss:2.4723683674304864\n",
      "train loss:2.4154410713387984\n",
      "=== epoch:18, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.513197367723361\n",
      "train loss:2.3764629060230895\n",
      "train loss:2.477633054519343\n",
      "train loss:2.500936830107462\n",
      "=== epoch:19, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.3966152260742093\n",
      "train loss:2.5131148568436172\n",
      "train loss:2.3979920270170925\n",
      "train loss:2.4246377593609765\n",
      "=== epoch:20, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4196313417358217\n",
      "train loss:2.395638645867221\n",
      "train loss:2.3797836024587085\n",
      "train loss:2.450081862541597\n",
      "=== epoch:21, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4895470467065715\n",
      "train loss:2.424322289002456\n",
      "train loss:2.417054643245845\n",
      "train loss:2.480489352533616\n",
      "=== epoch:22, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4343856210698074\n",
      "train loss:2.4581368274951707\n",
      "train loss:2.4485722382511037\n",
      "train loss:2.476676026923829\n",
      "=== epoch:23, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.509653554595599\n",
      "train loss:2.436489449100809\n",
      "train loss:2.5259681286273232\n",
      "train loss:2.4400696449012496\n",
      "=== epoch:24, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.521828574048491\n",
      "train loss:2.4779237485174272\n",
      "train loss:2.448120769805248\n",
      "train loss:2.3493083807173374\n",
      "=== epoch:25, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.450698445283249\n",
      "train loss:2.405084562082318\n",
      "train loss:2.376688033752628\n",
      "train loss:2.5127568846876596\n",
      "=== epoch:26, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.5366698700302237\n",
      "train loss:2.488593177009179\n",
      "train loss:2.4431068679612657\n",
      "train loss:2.447834523996036\n",
      "=== epoch:27, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4436712232002074\n",
      "train loss:2.407950041722437\n",
      "train loss:2.417925163880602\n",
      "train loss:2.4588938228454955\n",
      "=== epoch:28, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.461113009737125\n",
      "train loss:2.516729997803275\n",
      "train loss:2.522939477232771\n",
      "train loss:2.4003494305822346\n",
      "=== epoch:29, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4964362476908986\n",
      "train loss:2.43507012613456\n",
      "train loss:2.413746353970914\n",
      "train loss:2.4838458827161882\n",
      "=== epoch:30, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.50392553727105\n",
      "train loss:2.478628156725037\n",
      "train loss:2.4700189404542052\n",
      "train loss:2.46635442650771\n",
      "=== epoch:31, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.526538027473134\n",
      "train loss:2.4526146867908394\n",
      "train loss:2.5122985306107877\n",
      "train loss:2.5187559718619106\n",
      "=== epoch:32, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4189731172010234\n",
      "train loss:2.3895014068114486\n",
      "train loss:2.433921898175075\n",
      "train loss:2.3980833091038147\n",
      "=== epoch:33, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.5547919682053486\n",
      "train loss:2.485183473427312\n",
      "train loss:2.3477406849608293\n",
      "train loss:2.4482929626023036\n",
      "=== epoch:34, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4177647817547636\n",
      "train loss:2.3681370026512547\n",
      "train loss:2.4635488175155693\n",
      "train loss:2.4486378062884873\n",
      "=== epoch:35, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4337036743317904\n",
      "train loss:2.4563314846891124\n",
      "train loss:2.421459328823394\n",
      "train loss:2.521099979107991\n",
      "=== epoch:36, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4442218822947703\n",
      "train loss:2.401663871587952\n",
      "train loss:2.383517340464664\n",
      "train loss:2.492970207490333\n",
      "=== epoch:37, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4974558180533046\n",
      "train loss:2.4644409347877896\n",
      "train loss:2.4827847461446684\n",
      "train loss:2.4755684113413614\n",
      "=== epoch:38, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4301349285711074\n",
      "train loss:2.432625513473982\n",
      "train loss:2.4320924120507543\n",
      "train loss:2.4543371722975245\n",
      "=== epoch:39, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.4530363537502495\n",
      "train loss:2.4621637722136014\n",
      "train loss:2.4666728172882744\n",
      "train loss:2.4686737525846643\n",
      "=== epoch:40, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.481433212523019\n",
      "train loss:2.45789110722399\n",
      "train loss:2.5245994932466997\n",
      "train loss:2.479546668227092\n",
      "=== epoch:41, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.42546455537762\n",
      "train loss:2.486409338838616\n",
      "train loss:2.43231835567866\n",
      "train loss:2.473810142584341\n",
      "=== epoch:42, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.4226336622145417\n",
      "train loss:2.409584485475988\n",
      "train loss:2.4092027652137347\n",
      "train loss:2.486833461607697\n",
      "=== epoch:43, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.419335539703946\n",
      "train loss:2.499835468496982\n",
      "train loss:2.445713615806499\n",
      "train loss:2.410364434848915\n",
      "=== epoch:44, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.486177969981618\n",
      "train loss:2.355061728613793\n",
      "train loss:2.529766098078132\n",
      "train loss:2.3985852242122503\n",
      "=== epoch:45, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.4681615619304065\n",
      "train loss:2.5010840855430123\n",
      "train loss:2.4318086808200428\n",
      "train loss:2.3681514421803223\n",
      "=== epoch:46, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.4337599672974997\n",
      "train loss:2.3978871176768712\n",
      "train loss:2.52959764492242\n",
      "train loss:2.4730226038236367\n",
      "=== epoch:47, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.374730647474733\n",
      "train loss:2.4339446309305055\n",
      "train loss:2.4129519168141726\n",
      "train loss:2.417826010741492\n",
      "=== epoch:48, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.405098160822108\n",
      "train loss:2.434010492876234\n",
      "train loss:2.452415584477357\n",
      "train loss:2.4026704049419845\n",
      "=== epoch:49, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.5089208912729615\n",
      "train loss:2.482565488559395\n",
      "train loss:2.438331465490308\n",
      "train loss:2.5161489189122395\n",
      "=== epoch:50, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.462460005357047\n",
      "train loss:2.452522043719998\n",
      "train loss:2.4546885942054666\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.425047595279353\n",
      "=== epoch:1, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.417026019085908\n",
      "train loss:2.4072039120784927\n",
      "train loss:2.4503180482388642\n",
      "train loss:2.423928846151022\n",
      "=== epoch:2, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4233490274365406\n",
      "train loss:2.381361870082449\n",
      "train loss:2.3754100315151203\n",
      "train loss:2.440564639835484\n",
      "=== epoch:3, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.3814147292594985\n",
      "train loss:2.4325718534947773\n",
      "train loss:2.4293650523945107\n",
      "train loss:2.3783752562312013\n",
      "=== epoch:4, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4130195781075137\n",
      "train loss:2.3793981354907823\n",
      "train loss:2.419412227840288\n",
      "train loss:2.366718002222031\n",
      "=== epoch:5, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.448746860133504\n",
      "train loss:2.380682752524661\n",
      "train loss:2.3486292333442407\n",
      "train loss:2.427179552936884\n",
      "=== epoch:6, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4194194576665136\n",
      "train loss:2.460344005799313\n",
      "train loss:2.3912506347188467\n",
      "train loss:2.383436584323692\n",
      "=== epoch:7, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.396514873631906\n",
      "train loss:2.4011912426119912\n",
      "train loss:2.438345834967018\n",
      "train loss:2.4092886072076913\n",
      "=== epoch:8, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4254418796314203\n",
      "train loss:2.404527691300796\n",
      "train loss:2.4020148662184697\n",
      "train loss:2.397644245241859\n",
      "=== epoch:9, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.427610783731591\n",
      "train loss:2.4658889352528655\n",
      "train loss:2.3273060351352073\n",
      "train loss:2.439897654256571\n",
      "=== epoch:10, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.3377585745616103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.394017760225131\n",
      "train loss:2.4047847787786054\n",
      "train loss:2.4526945634851316\n",
      "=== epoch:11, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.3801283665428272\n",
      "train loss:2.42268816284678\n",
      "train loss:2.4569984849309243\n",
      "train loss:2.435737387297064\n",
      "=== epoch:12, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.33424818698099\n",
      "train loss:2.367766294170085\n",
      "train loss:2.4040640872849095\n",
      "train loss:2.398188973177184\n",
      "=== epoch:13, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.4105321778549773\n",
      "train loss:2.3654296135141584\n",
      "train loss:2.395732430677253\n",
      "train loss:2.407303057094092\n",
      "=== epoch:14, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.389815205638331\n",
      "train loss:2.4106748385323966\n",
      "train loss:2.3920265442325697\n",
      "train loss:2.425090312531643\n",
      "=== epoch:15, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.4409327379995607\n",
      "train loss:2.4485755420978412\n",
      "train loss:2.4037896767860465\n",
      "train loss:2.424111318626407\n",
      "=== epoch:16, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.400555171469473\n",
      "train loss:2.3700183385115716\n",
      "train loss:2.3993634065239116\n",
      "train loss:2.4147528609663746\n",
      "=== epoch:17, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.454807413927289\n",
      "train loss:2.446068889894327\n",
      "train loss:2.351453309614466\n",
      "train loss:2.3627341462952733\n",
      "=== epoch:18, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.451217237383715\n",
      "train loss:2.4239421942547157\n",
      "train loss:2.43097141486093\n",
      "train loss:2.41416386809977\n",
      "=== epoch:19, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4413395263140574\n",
      "train loss:2.365302012946561\n",
      "train loss:2.4275078554546643\n",
      "train loss:2.399541088751612\n",
      "=== epoch:20, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.3824638397269644\n",
      "train loss:2.3826099496629296\n",
      "train loss:2.3847344942434745\n",
      "train loss:2.3880386560151474\n",
      "=== epoch:21, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4691198817678104\n",
      "train loss:2.382076407277869\n",
      "train loss:2.4261882086348967\n",
      "train loss:2.4678241260278018\n",
      "=== epoch:22, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.484480837621982\n",
      "train loss:2.436282780695359\n",
      "train loss:2.3697320743896166\n",
      "train loss:2.407096163790059\n",
      "=== epoch:23, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.422596665286372\n",
      "train loss:2.374548442334342\n",
      "train loss:2.4292902330989805\n",
      "train loss:2.3780648864646876\n",
      "=== epoch:24, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.5073924671698085\n",
      "train loss:2.483752994671679\n",
      "train loss:2.4012010972572444\n",
      "train loss:2.3911910328870243\n",
      "=== epoch:25, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4043644586321586\n",
      "train loss:2.4141844180172356\n",
      "train loss:2.4607695137833425\n",
      "train loss:2.4193337330977953\n",
      "=== epoch:26, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.3590514920183767\n",
      "train loss:2.4389871546815183\n",
      "train loss:2.4005220490787713\n",
      "train loss:2.37231118676471\n",
      "=== epoch:27, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4197369997760436\n",
      "train loss:2.492984805464608\n",
      "train loss:2.387293361819466\n",
      "train loss:2.373995455524524\n",
      "=== epoch:28, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4063611410526233\n",
      "train loss:2.3634958704347344\n",
      "train loss:2.447718130416207\n",
      "train loss:2.3787721862955014\n",
      "=== epoch:29, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.400479402308773\n",
      "train loss:2.4364300544973805\n",
      "train loss:2.377282376655342\n",
      "train loss:2.390427148024518\n",
      "=== epoch:30, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.408771921299888\n",
      "train loss:2.38909314252896\n",
      "train loss:2.3560701729744467\n",
      "train loss:2.418091270897692\n",
      "=== epoch:31, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.409713650978832\n",
      "train loss:2.4109675155992787\n",
      "train loss:2.4187966124853983\n",
      "train loss:2.3776686075164406\n",
      "=== epoch:32, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.447712937378999\n",
      "train loss:2.3571472504068125\n",
      "train loss:2.3770183747601235\n",
      "train loss:2.396322384985203\n",
      "=== epoch:33, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.321319843242589\n",
      "train loss:2.433321805803111\n",
      "train loss:2.4327179777946246\n",
      "train loss:2.4100369772647086\n",
      "=== epoch:34, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.403381825727299\n",
      "train loss:2.403852538684863\n",
      "train loss:2.403232788525292\n",
      "train loss:2.4224214700177518\n",
      "=== epoch:35, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4051630481667763\n",
      "train loss:2.414420754262151\n",
      "train loss:2.4353971098170035\n",
      "train loss:2.4092540863533944\n",
      "=== epoch:36, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.3648890088975447\n",
      "train loss:2.3529390673952553\n",
      "train loss:2.3766859645403464\n",
      "train loss:2.3911290017603295\n",
      "=== epoch:37, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4069899583761067\n",
      "train loss:2.4090795015645687\n",
      "train loss:2.4276085492888226\n",
      "train loss:2.4169693486121404\n",
      "=== epoch:38, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4377106766132313\n",
      "train loss:2.418825382732592\n",
      "train loss:2.3964351003802635\n",
      "train loss:2.4528913758766318\n",
      "=== epoch:39, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.391789634966423\n",
      "train loss:2.376580840763295\n",
      "train loss:2.4515499925419255\n",
      "train loss:2.4278014893182043\n",
      "=== epoch:40, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.406462561660605\n",
      "train loss:2.4106200415222423\n",
      "train loss:2.3636362511806253\n",
      "train loss:2.3826963581260108\n",
      "=== epoch:41, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.4007613458008366\n",
      "train loss:2.388720484476336\n",
      "train loss:2.397774826440953\n",
      "train loss:2.4053824581990106\n",
      "=== epoch:42, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.3280166713938035\n",
      "train loss:2.4074077499541566\n",
      "train loss:2.4050924784314733\n",
      "train loss:2.405723239312426\n",
      "=== epoch:43, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.3575330415682543\n",
      "train loss:2.4520249674452477\n",
      "train loss:2.357084018652662\n",
      "train loss:2.3541117435909182\n",
      "=== epoch:44, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.383863198813427\n",
      "train loss:2.3741653624962797\n",
      "train loss:2.3795841769406243\n",
      "train loss:2.4109903526039878\n",
      "=== epoch:45, train acc:0.115, test acc:0.15 ===\n",
      "train loss:2.37976891623722\n",
      "train loss:2.37246685599031\n",
      "train loss:2.384516663124115\n",
      "train loss:2.410337093866128\n",
      "=== epoch:46, train acc:0.1175, test acc:0.15 ===\n",
      "train loss:2.3910882319228084\n",
      "train loss:2.4285840886738432\n",
      "train loss:2.439933093189481\n",
      "train loss:2.3789971410878783\n",
      "=== epoch:47, train acc:0.1175, test acc:0.15 ===\n",
      "train loss:2.3824710906461406\n",
      "train loss:2.343818345347565\n",
      "train loss:2.4135164423231377\n",
      "train loss:2.372873992528191\n",
      "=== epoch:48, train acc:0.1175, test acc:0.15 ===\n",
      "train loss:2.3799658239656303\n",
      "train loss:2.371737401368464\n",
      "train loss:2.362698251022448\n",
      "train loss:2.415497454133708\n",
      "=== epoch:49, train acc:0.1175, test acc:0.15 ===\n",
      "train loss:2.396932486674725\n",
      "train loss:2.425994544922669\n",
      "train loss:2.3560181291699367\n",
      "train loss:2.3610957989128973\n",
      "=== epoch:50, train acc:0.1175, test acc:0.15 ===\n",
      "train loss:2.4093186200924963\n",
      "train loss:2.372822833231248\n",
      "train loss:2.393351049414022\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.15\n",
      "val_acc: 0.1500 | lr: 0.0001, weight_decay: 0.0001\n",
      "train loss:2.6348738660951576\n",
      "=== epoch:1, train acc:0.0825, test acc:0.07 ===\n",
      "train loss:2.681892747227324\n",
      "train loss:2.6247122970656824\n",
      "train loss:2.6717412151146642\n",
      "train loss:2.686203972561613\n",
      "=== epoch:2, train acc:0.0825, test acc:0.07 ===\n",
      "train loss:2.561684547294366\n",
      "train loss:2.5698273350165017\n",
      "train loss:2.560941349728584\n",
      "train loss:2.666002623661268\n",
      "=== epoch:3, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.614223357170331\n",
      "train loss:2.5653073459477196\n",
      "train loss:2.452501999638137\n",
      "train loss:2.438729233749938\n",
      "=== epoch:4, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.4387997167581923\n",
      "train loss:2.572612791540169\n",
      "train loss:2.489818627337438\n",
      "train loss:2.3778530491368346\n",
      "=== epoch:5, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.484219969954934\n",
      "train loss:2.4678687171094826\n",
      "train loss:2.6212505409039304\n",
      "train loss:2.546548492750394\n",
      "=== epoch:6, train acc:0.0975, test acc:0.06 ===\n",
      "train loss:2.4370297925368383\n",
      "train loss:2.501880346324645\n",
      "train loss:2.5451071265239986\n",
      "train loss:2.4671907530924115\n",
      "=== epoch:7, train acc:0.11, test acc:0.07 ===\n",
      "train loss:2.4617070542433517\n",
      "train loss:2.6258201864354995\n",
      "train loss:2.488650301510578\n",
      "train loss:2.4250940036397153\n",
      "=== epoch:8, train acc:0.12, test acc:0.07 ===\n",
      "train loss:2.43983518867108\n",
      "train loss:2.3795187684881873\n",
      "train loss:2.4444572384064136\n",
      "train loss:2.3457340128036357\n",
      "=== epoch:9, train acc:0.1225, test acc:0.08 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3606265134831688\n",
      "train loss:2.394965964196426\n",
      "train loss:2.515338410445589\n",
      "train loss:2.4326571333743967\n",
      "=== epoch:10, train acc:0.12, test acc:0.08 ===\n",
      "train loss:2.4440102457319046\n",
      "train loss:2.379218457446599\n",
      "train loss:2.3862300137407844\n",
      "train loss:2.4080516001066927\n",
      "=== epoch:11, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.3904253210228483\n",
      "train loss:2.3897895261573594\n",
      "train loss:2.398872921466353\n",
      "train loss:2.45323879518269\n",
      "=== epoch:12, train acc:0.125, test acc:0.08 ===\n",
      "train loss:2.3241213876148628\n",
      "train loss:2.3340446693684034\n",
      "train loss:2.310555464413368\n",
      "train loss:2.3892057205350286\n",
      "=== epoch:13, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.333715685267656\n",
      "train loss:2.372130791965754\n",
      "train loss:2.2755860287687892\n",
      "train loss:2.3380320026220627\n",
      "=== epoch:14, train acc:0.1275, test acc:0.09 ===\n",
      "train loss:2.4160557511930976\n",
      "train loss:2.334366327774349\n",
      "train loss:2.3187426531536772\n",
      "train loss:2.4416696266496154\n",
      "=== epoch:15, train acc:0.1225, test acc:0.1 ===\n",
      "train loss:2.4582752021102725\n",
      "train loss:2.374322500543847\n",
      "train loss:2.3201482420036688\n",
      "train loss:2.2963665832116185\n",
      "=== epoch:16, train acc:0.1225, test acc:0.1 ===\n",
      "train loss:2.4077595597435617\n",
      "train loss:2.232913738896047\n",
      "train loss:2.339076189117255\n",
      "train loss:2.3237697329636955\n",
      "=== epoch:17, train acc:0.13, test acc:0.09 ===\n",
      "train loss:2.345673933562295\n",
      "train loss:2.363048168884048\n",
      "train loss:2.426354347691796\n",
      "train loss:2.3101884756593463\n",
      "=== epoch:18, train acc:0.1325, test acc:0.09 ===\n",
      "train loss:2.3092806039091816\n",
      "train loss:2.3112972681484325\n",
      "train loss:2.3390527087263284\n",
      "train loss:2.408136946145574\n",
      "=== epoch:19, train acc:0.135, test acc:0.1 ===\n",
      "train loss:2.345117306868361\n",
      "train loss:2.2852431499648236\n",
      "train loss:2.255731541992245\n",
      "train loss:2.2859660200658727\n",
      "=== epoch:20, train acc:0.14, test acc:0.11 ===\n",
      "train loss:2.290437240099845\n",
      "train loss:2.3174390410939343\n",
      "train loss:2.291758775981775\n",
      "train loss:2.2877882497087874\n",
      "=== epoch:21, train acc:0.1475, test acc:0.11 ===\n",
      "train loss:2.24345758265987\n",
      "train loss:2.2468891597757588\n",
      "train loss:2.2851035936868462\n",
      "train loss:2.3483512921459977\n",
      "=== epoch:22, train acc:0.1525, test acc:0.12 ===\n",
      "train loss:2.240635506137714\n",
      "train loss:2.301838850171854\n",
      "train loss:2.296111838291149\n",
      "train loss:2.3677431196282104\n",
      "=== epoch:23, train acc:0.1525, test acc:0.12 ===\n",
      "train loss:2.3239486652275008\n",
      "train loss:2.306523456158713\n",
      "train loss:2.3326298690019303\n",
      "train loss:2.310840143342703\n",
      "=== epoch:24, train acc:0.15, test acc:0.13 ===\n",
      "train loss:2.2440698418231686\n",
      "train loss:2.2875786562809814\n",
      "train loss:2.245439336934907\n",
      "train loss:2.299497128576976\n",
      "=== epoch:25, train acc:0.1525, test acc:0.14 ===\n",
      "train loss:2.313126187232185\n",
      "train loss:2.278716989155096\n",
      "train loss:2.2634142202739573\n",
      "train loss:2.2627919148802054\n",
      "=== epoch:26, train acc:0.1525, test acc:0.14 ===\n",
      "train loss:2.2889976141443666\n",
      "train loss:2.2821995866680913\n",
      "train loss:2.288313531736813\n",
      "train loss:2.2475026336139896\n",
      "=== epoch:27, train acc:0.1575, test acc:0.14 ===\n",
      "train loss:2.2259865058630677\n",
      "train loss:2.278921795217702\n",
      "train loss:2.25208191614414\n",
      "train loss:2.163847630313899\n",
      "=== epoch:28, train acc:0.1675, test acc:0.14 ===\n",
      "train loss:2.2611225389060112\n",
      "train loss:2.1846847610356814\n",
      "train loss:2.175191776293092\n",
      "train loss:2.301770451121538\n",
      "=== epoch:29, train acc:0.1725, test acc:0.14 ===\n",
      "train loss:2.255156329167469\n",
      "train loss:2.254587320113545\n",
      "train loss:2.23391492393955\n",
      "train loss:2.2781683149001304\n",
      "=== epoch:30, train acc:0.185, test acc:0.15 ===\n",
      "train loss:2.2527403702921207\n",
      "train loss:2.199372017238818\n",
      "train loss:2.2603761397919566\n",
      "train loss:2.2225327520088713\n",
      "=== epoch:31, train acc:0.1875, test acc:0.15 ===\n",
      "train loss:2.2757743256170486\n",
      "train loss:2.2493657628621073\n",
      "train loss:2.213514420455046\n",
      "train loss:2.3072270055883086\n",
      "=== epoch:32, train acc:0.1925, test acc:0.15 ===\n",
      "train loss:2.1782068121024376\n",
      "train loss:2.2574077409666597\n",
      "train loss:2.1836252130914007\n",
      "train loss:2.246811518929034\n",
      "=== epoch:33, train acc:0.1925, test acc:0.15 ===\n",
      "train loss:2.248859266988747\n",
      "train loss:2.218924987570631\n",
      "train loss:2.246194111659997\n",
      "train loss:2.1763480266272115\n",
      "=== epoch:34, train acc:0.1925, test acc:0.17 ===\n",
      "train loss:2.191898420341286\n",
      "train loss:2.196176433673301\n",
      "train loss:2.1973279553772587\n",
      "train loss:2.2899296723040434\n",
      "=== epoch:35, train acc:0.19, test acc:0.16 ===\n",
      "train loss:2.252677312049026\n",
      "train loss:2.167540764973607\n",
      "train loss:2.2943204715054613\n",
      "train loss:2.198876022771261\n",
      "=== epoch:36, train acc:0.1925, test acc:0.17 ===\n",
      "train loss:2.227605897559586\n",
      "train loss:2.1616611587576138\n",
      "train loss:2.2327290582021027\n",
      "train loss:2.200283767037556\n",
      "=== epoch:37, train acc:0.1925, test acc:0.17 ===\n",
      "train loss:2.15773856987161\n",
      "train loss:2.1989634247338716\n",
      "train loss:2.241292089946935\n",
      "train loss:2.166055085434447\n",
      "=== epoch:38, train acc:0.2, test acc:0.17 ===\n",
      "train loss:2.144673431419049\n",
      "train loss:2.192125135270374\n",
      "train loss:2.1814444576762404\n",
      "train loss:2.1911496693777255\n",
      "=== epoch:39, train acc:0.2025, test acc:0.17 ===\n",
      "train loss:2.1932554732278597\n",
      "train loss:2.217150873152883\n",
      "train loss:2.2225067580335147\n",
      "train loss:2.2260368602813116\n",
      "=== epoch:40, train acc:0.205, test acc:0.17 ===\n",
      "train loss:2.170798964245816\n",
      "train loss:2.192804356748323\n",
      "train loss:2.1593964147289095\n",
      "train loss:2.1077598324736875\n",
      "=== epoch:41, train acc:0.2075, test acc:0.17 ===\n",
      "train loss:2.2169130429529154\n",
      "train loss:2.1947308145204873\n",
      "train loss:2.2072812941478475\n",
      "train loss:2.1953579801950287\n",
      "=== epoch:42, train acc:0.21, test acc:0.18 ===\n",
      "train loss:2.1979064094849634\n",
      "train loss:2.1508352981101706\n",
      "train loss:2.111497601397712\n",
      "train loss:2.16036330515358\n",
      "=== epoch:43, train acc:0.215, test acc:0.18 ===\n",
      "train loss:2.19570053187086\n",
      "train loss:2.133305034277867\n",
      "train loss:2.122861918416833\n",
      "train loss:2.17051123281805\n",
      "=== epoch:44, train acc:0.2225, test acc:0.18 ===\n",
      "train loss:2.1973062052971604\n",
      "train loss:2.13232035666996\n",
      "train loss:2.1037473858109816\n",
      "train loss:2.2003211598319443\n",
      "=== epoch:45, train acc:0.22, test acc:0.17 ===\n",
      "train loss:2.097652232286496\n",
      "train loss:2.1718736226392013\n",
      "train loss:2.182075707762907\n",
      "train loss:2.108066751207021\n",
      "=== epoch:46, train acc:0.23, test acc:0.17 ===\n",
      "train loss:2.1614642479495947\n",
      "train loss:2.2178236691997175\n",
      "train loss:2.1487556023021384\n",
      "train loss:2.1513545842219357\n",
      "=== epoch:47, train acc:0.2325, test acc:0.17 ===\n",
      "train loss:2.112076299876482\n",
      "train loss:2.145701386754695\n",
      "train loss:2.1964417987035496\n",
      "train loss:2.111086578143454\n",
      "=== epoch:48, train acc:0.235, test acc:0.18 ===\n",
      "train loss:2.0836454353093314\n",
      "train loss:2.1654918324904027\n",
      "train loss:2.1732212358278638\n",
      "train loss:2.113309581824345\n",
      "=== epoch:49, train acc:0.235, test acc:0.18 ===\n",
      "train loss:2.1025218246544166\n",
      "train loss:2.1727469143476243\n",
      "train loss:2.088945015200702\n",
      "train loss:2.18432908070077\n",
      "=== epoch:50, train acc:0.2375, test acc:0.19 ===\n",
      "train loss:2.1403145494149696\n",
      "train loss:2.137782380414975\n",
      "train loss:2.1381038178887213\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.19\n",
      "val_acc: 0.1900 | lr: 0.0010, weight_decay: 0.0000\n",
      "train loss:2.2994024920261236\n",
      "=== epoch:1, train acc:0.1225, test acc:0.1 ===\n",
      "train loss:2.2653036755358222\n",
      "train loss:2.3738094838814074\n",
      "train loss:2.3237835745692723\n",
      "train loss:2.2930493294705148\n",
      "=== epoch:2, train acc:0.1325, test acc:0.1 ===\n",
      "train loss:2.3612874011439553\n",
      "train loss:2.3521790555346853\n",
      "train loss:2.3141622259183365\n",
      "train loss:2.2962761636630087\n",
      "=== epoch:3, train acc:0.145, test acc:0.1 ===\n",
      "train loss:2.289908142762757\n",
      "train loss:2.3567225655204873\n",
      "train loss:2.2681499969749455\n",
      "train loss:2.276605105997086\n",
      "=== epoch:4, train acc:0.155, test acc:0.11 ===\n",
      "train loss:2.2979177063335943\n",
      "train loss:2.257550639265052\n",
      "train loss:2.2886125659854586\n",
      "train loss:2.3007194400096656\n",
      "=== epoch:5, train acc:0.165, test acc:0.12 ===\n",
      "train loss:2.276645677456383\n",
      "train loss:2.2959127321870754\n",
      "train loss:2.2516538563996895\n",
      "train loss:2.292407797679156\n",
      "=== epoch:6, train acc:0.18, test acc:0.12 ===\n",
      "train loss:2.28243052840612\n",
      "train loss:2.245372948856912\n",
      "train loss:2.3029343493570855\n",
      "train loss:2.249399872074865\n",
      "=== epoch:7, train acc:0.1825, test acc:0.13 ===\n",
      "train loss:2.2412391889820533\n",
      "train loss:2.238925839704981\n",
      "train loss:2.2466802933927625\n",
      "train loss:2.233304051225212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:8, train acc:0.195, test acc:0.15 ===\n",
      "train loss:2.17366456422065\n",
      "train loss:2.251460969230112\n",
      "train loss:2.2489181130489246\n",
      "train loss:2.2666410064227804\n",
      "=== epoch:9, train acc:0.2025, test acc:0.16 ===\n",
      "train loss:2.1936371547491644\n",
      "train loss:2.2046308068317293\n",
      "train loss:2.210496289475489\n",
      "train loss:2.218574485300364\n",
      "=== epoch:10, train acc:0.21, test acc:0.18 ===\n",
      "train loss:2.208764809265793\n",
      "train loss:2.2117361602112187\n",
      "train loss:2.1397138431218146\n",
      "train loss:2.2476044794655676\n",
      "=== epoch:11, train acc:0.2175, test acc:0.18 ===\n",
      "train loss:2.205976627826758\n",
      "train loss:2.223511335766147\n",
      "train loss:2.1792347189781576\n",
      "train loss:2.183327037947834\n",
      "=== epoch:12, train acc:0.225, test acc:0.2 ===\n",
      "train loss:2.175921725382462\n",
      "train loss:2.16032139663971\n",
      "train loss:2.184998032777438\n",
      "train loss:2.147783736910379\n",
      "=== epoch:13, train acc:0.225, test acc:0.23 ===\n",
      "train loss:2.178607150773949\n",
      "train loss:2.222914255849994\n",
      "train loss:2.1588848329843366\n",
      "train loss:2.179180558336372\n",
      "=== epoch:14, train acc:0.245, test acc:0.23 ===\n",
      "train loss:2.1907946715107043\n",
      "train loss:2.1593048437512716\n",
      "train loss:2.1464732279090613\n",
      "train loss:2.140901661768779\n",
      "=== epoch:15, train acc:0.2525, test acc:0.24 ===\n",
      "train loss:2.143670141202883\n",
      "train loss:2.1566664404374323\n",
      "train loss:2.159305317590203\n",
      "train loss:2.1756244654426995\n",
      "=== epoch:16, train acc:0.2625, test acc:0.24 ===\n",
      "train loss:2.0949239142187386\n",
      "train loss:2.1843732264549938\n",
      "train loss:2.1421385555476777\n",
      "train loss:2.1540838646326415\n",
      "=== epoch:17, train acc:0.265, test acc:0.25 ===\n",
      "train loss:2.1420771174278133\n",
      "train loss:2.119010341457989\n",
      "train loss:2.0987919746732837\n",
      "train loss:2.1312654073156505\n",
      "=== epoch:18, train acc:0.2775, test acc:0.25 ===\n",
      "train loss:2.189507111146108\n",
      "train loss:2.0685053408832452\n",
      "train loss:2.131593472469057\n",
      "train loss:2.1064929750991577\n",
      "=== epoch:19, train acc:0.295, test acc:0.23 ===\n",
      "train loss:2.1440581407023114\n",
      "train loss:2.1176032460424916\n",
      "train loss:2.085247809263757\n",
      "train loss:2.0651904748810623\n",
      "=== epoch:20, train acc:0.2975, test acc:0.23 ===\n",
      "train loss:2.0751160215055284\n",
      "train loss:2.0539531549465093\n",
      "train loss:2.1243436925550574\n",
      "train loss:2.0655598063023084\n",
      "=== epoch:21, train acc:0.3, test acc:0.27 ===\n",
      "train loss:2.0170504179394704\n",
      "train loss:2.1147688378520373\n",
      "train loss:2.1039266066929843\n",
      "train loss:2.093748937188075\n",
      "=== epoch:22, train acc:0.305, test acc:0.28 ===\n",
      "train loss:2.091456620660806\n",
      "train loss:2.1050455077489425\n",
      "train loss:2.089009747239833\n",
      "train loss:2.0770518488703296\n",
      "=== epoch:23, train acc:0.3125, test acc:0.29 ===\n",
      "train loss:2.0428692574040865\n",
      "train loss:2.081559746323512\n",
      "train loss:1.9962543806008866\n",
      "train loss:2.0702829171467534\n",
      "=== epoch:24, train acc:0.325, test acc:0.31 ===\n",
      "train loss:1.9705549977561108\n",
      "train loss:2.0023682920694355\n",
      "train loss:2.0303303450443253\n",
      "train loss:2.0916066181482083\n",
      "=== epoch:25, train acc:0.34, test acc:0.3 ===\n",
      "train loss:1.9483123638327933\n",
      "train loss:1.9708718500178894\n",
      "train loss:2.030161286322834\n",
      "train loss:2.0440057362016275\n",
      "=== epoch:26, train acc:0.355, test acc:0.33 ===\n",
      "train loss:2.030714501752449\n",
      "train loss:2.08519314990368\n",
      "train loss:1.9658105342882406\n",
      "train loss:2.0516158776620665\n",
      "=== epoch:27, train acc:0.3675, test acc:0.36 ===\n",
      "train loss:2.0494133904394065\n",
      "train loss:1.991400526202474\n",
      "train loss:1.9739339583895879\n",
      "train loss:1.9733069527805043\n",
      "=== epoch:28, train acc:0.3875, test acc:0.34 ===\n",
      "train loss:2.0067819498525714\n",
      "train loss:1.963273042871686\n",
      "train loss:2.0343647206236724\n",
      "train loss:1.977586614268575\n",
      "=== epoch:29, train acc:0.405, test acc:0.37 ===\n",
      "train loss:1.9875307015595778\n",
      "train loss:2.046149785160457\n",
      "train loss:1.9454431387144377\n",
      "train loss:2.0335913515681416\n",
      "=== epoch:30, train acc:0.405, test acc:0.37 ===\n",
      "train loss:1.9535819783502797\n",
      "train loss:1.9963581963488406\n",
      "train loss:2.0256583219722613\n",
      "train loss:1.9067855535062177\n",
      "=== epoch:31, train acc:0.4225, test acc:0.38 ===\n",
      "train loss:1.9796329393842262\n",
      "train loss:1.9687026192184252\n",
      "train loss:1.957914969679003\n",
      "train loss:1.9379806640589061\n",
      "=== epoch:32, train acc:0.4325, test acc:0.37 ===\n",
      "train loss:1.9508886946469493\n",
      "train loss:1.9805261681607098\n",
      "train loss:1.9534340921199342\n",
      "train loss:1.9811039256000562\n",
      "=== epoch:33, train acc:0.445, test acc:0.4 ===\n",
      "train loss:1.9421550238243805\n",
      "train loss:1.926585552919061\n",
      "train loss:1.982037835080616\n",
      "train loss:1.9857992706327865\n",
      "=== epoch:34, train acc:0.445, test acc:0.41 ===\n",
      "train loss:1.9149345720315343\n",
      "train loss:1.876598415954419\n",
      "train loss:1.8587623946722773\n",
      "train loss:1.916161340906151\n",
      "=== epoch:35, train acc:0.45, test acc:0.4 ===\n",
      "train loss:1.9532097360669507\n",
      "train loss:1.9061152578428175\n",
      "train loss:1.9373642605795984\n",
      "train loss:2.0227315360395384\n",
      "=== epoch:36, train acc:0.4675, test acc:0.41 ===\n",
      "train loss:1.993828180347079\n",
      "train loss:1.8836692471282195\n",
      "train loss:1.950101614769779\n",
      "train loss:1.901841004248599\n",
      "=== epoch:37, train acc:0.475, test acc:0.41 ===\n",
      "train loss:1.8990743624757098\n",
      "train loss:1.9143427857718294\n",
      "train loss:1.9312324038107107\n",
      "train loss:1.8751165134206058\n",
      "=== epoch:38, train acc:0.4825, test acc:0.44 ===\n",
      "train loss:1.8839345148037494\n",
      "train loss:1.8978815137730123\n",
      "train loss:1.9449914707539482\n",
      "train loss:1.9234896921279576\n",
      "=== epoch:39, train acc:0.4975, test acc:0.46 ===\n",
      "train loss:1.8267863135614357\n",
      "train loss:1.91979400827383\n",
      "train loss:1.7658338313549304\n",
      "train loss:1.890985327475417\n",
      "=== epoch:40, train acc:0.5075, test acc:0.47 ===\n",
      "train loss:1.8404955406136325\n",
      "train loss:1.8498702021055125\n",
      "train loss:1.888719060686482\n",
      "train loss:1.9355894505033788\n",
      "=== epoch:41, train acc:0.53, test acc:0.47 ===\n",
      "train loss:1.7731572027194114\n",
      "train loss:1.86521094297389\n",
      "train loss:1.8035165784739025\n",
      "train loss:1.7866585707845728\n",
      "=== epoch:42, train acc:0.535, test acc:0.49 ===\n",
      "train loss:1.853174391572381\n",
      "train loss:1.7703149274931311\n",
      "train loss:1.7726227625404702\n",
      "train loss:1.8303805273592182\n",
      "=== epoch:43, train acc:0.545, test acc:0.5 ===\n",
      "train loss:1.8274023748970607\n",
      "train loss:1.810313988470917\n",
      "train loss:1.8610057720140782\n",
      "train loss:1.7655721878891848\n",
      "=== epoch:44, train acc:0.5475, test acc:0.52 ===\n",
      "train loss:1.8005745693799393\n",
      "train loss:1.7751593349586594\n",
      "train loss:1.7671438882696735\n",
      "train loss:1.780523653845963\n",
      "=== epoch:45, train acc:0.55, test acc:0.53 ===\n",
      "train loss:1.8826969811903522\n",
      "train loss:1.7148910319641826\n",
      "train loss:1.6690890728519137\n",
      "train loss:1.8369793827429477\n",
      "=== epoch:46, train acc:0.56, test acc:0.51 ===\n",
      "train loss:1.8097649927391481\n",
      "train loss:1.7718392246195018\n",
      "train loss:1.799032684224524\n",
      "train loss:1.6137841989931665\n",
      "=== epoch:47, train acc:0.575, test acc:0.49 ===\n",
      "train loss:1.8495969697795933\n",
      "train loss:1.7653065192298945\n",
      "train loss:1.7524125781366398\n",
      "train loss:1.8168493323403496\n",
      "=== epoch:48, train acc:0.5725, test acc:0.53 ===\n",
      "train loss:1.7387338150352878\n",
      "train loss:1.7937085263453592\n",
      "train loss:1.7864152700426135\n",
      "train loss:1.795252070573953\n",
      "=== epoch:49, train acc:0.5875, test acc:0.55 ===\n",
      "train loss:1.7175753200941968\n",
      "train loss:1.6691051141035165\n",
      "train loss:1.6406590678938902\n",
      "train loss:1.742119451912219\n",
      "=== epoch:50, train acc:0.585, test acc:0.57 ===\n",
      "train loss:1.6959594290382318\n",
      "train loss:1.6609143021994544\n",
      "train loss:1.714404517957873\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.57\n",
      "val_acc: 0.5700 | lr: 0.0026, weight_decay: 0.0000\n",
      "train loss:2.3276035093585716\n",
      "=== epoch:1, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3282582347925604\n",
      "train loss:2.3295797497231\n",
      "train loss:2.3341019112377848\n",
      "train loss:2.31248718380461\n",
      "=== epoch:2, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3306438504679847\n",
      "train loss:2.323345882571492\n",
      "train loss:2.331019004294103\n",
      "train loss:2.3431994416479833\n",
      "=== epoch:3, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.334455245933153\n",
      "train loss:2.3076340969578846\n",
      "train loss:2.280871279442844\n",
      "train loss:2.284270916871977\n",
      "=== epoch:4, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.299399158341086\n",
      "train loss:2.3205003544056164\n",
      "train loss:2.306210566643168\n",
      "train loss:2.322591977780821\n",
      "=== epoch:5, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3434529871907515\n",
      "train loss:2.3346311734060103\n",
      "train loss:2.3019215501373282\n",
      "train loss:2.315397691236413\n",
      "=== epoch:6, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3771149447952187\n",
      "train loss:2.333413405416099\n",
      "train loss:2.318986444966953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.308685696571935\n",
      "=== epoch:7, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.369436215035983\n",
      "train loss:2.2758778470421186\n",
      "train loss:2.3383138627962166\n",
      "train loss:2.3498259706603117\n",
      "=== epoch:8, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3048473847530833\n",
      "train loss:2.3202189539837343\n",
      "train loss:2.3089636699249207\n",
      "train loss:2.337660139058265\n",
      "=== epoch:9, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.330377709702037\n",
      "train loss:2.3301665224752783\n",
      "train loss:2.3480934145380292\n",
      "train loss:2.2961444567474407\n",
      "=== epoch:10, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3604194773588\n",
      "train loss:2.341207024590255\n",
      "train loss:2.3327874494756644\n",
      "train loss:2.3849480670799497\n",
      "=== epoch:11, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3462926616932163\n",
      "train loss:2.314457735620617\n",
      "train loss:2.3182174836605354\n",
      "train loss:2.2992262208391305\n",
      "=== epoch:12, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3235958386589246\n",
      "train loss:2.3456516843371586\n",
      "train loss:2.316407365074561\n",
      "train loss:2.326466759229516\n",
      "=== epoch:13, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.317707465663195\n",
      "train loss:2.3042695681853043\n",
      "train loss:2.309434029114022\n",
      "train loss:2.3737599269903122\n",
      "=== epoch:14, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.295752387814945\n",
      "train loss:2.385674357710154\n",
      "train loss:2.3424740199374\n",
      "train loss:2.3425762569350495\n",
      "=== epoch:15, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3116205576916675\n",
      "train loss:2.349755597337335\n",
      "train loss:2.317665906986737\n",
      "train loss:2.3527190590193054\n",
      "=== epoch:16, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.262811378964097\n",
      "train loss:2.330843594764607\n",
      "train loss:2.2993266252710978\n",
      "train loss:2.325086213442964\n",
      "=== epoch:17, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3249308272987443\n",
      "train loss:2.344906782909886\n",
      "train loss:2.3185646492161487\n",
      "train loss:2.355110424994034\n",
      "=== epoch:18, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3003171815775456\n",
      "train loss:2.3179408987224357\n",
      "train loss:2.358554605933791\n",
      "train loss:2.3059893270633327\n",
      "=== epoch:19, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.295580917000542\n",
      "train loss:2.3853255454387714\n",
      "train loss:2.2787168957628734\n",
      "train loss:2.3177698518065055\n",
      "=== epoch:20, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3423224868634085\n",
      "train loss:2.324175471845276\n",
      "train loss:2.3294923934343523\n",
      "train loss:2.300664093991566\n",
      "=== epoch:21, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.348552562375394\n",
      "train loss:2.336454107924856\n",
      "train loss:2.3030732249424752\n",
      "train loss:2.327570378501811\n",
      "=== epoch:22, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3334698440655126\n",
      "train loss:2.334481776018328\n",
      "train loss:2.364175220342274\n",
      "train loss:2.35324681689846\n",
      "=== epoch:23, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3779514002388167\n",
      "train loss:2.2981374831766814\n",
      "train loss:2.2887432855543337\n",
      "train loss:2.3024595301330186\n",
      "=== epoch:24, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3136092118495344\n",
      "train loss:2.3347096809437415\n",
      "train loss:2.344752947964058\n",
      "train loss:2.339919806807926\n",
      "=== epoch:25, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3398068091846063\n",
      "train loss:2.370216966464692\n",
      "train loss:2.341485521094219\n",
      "train loss:2.327791439256716\n",
      "=== epoch:26, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.327536192746842\n",
      "train loss:2.3341162237962587\n",
      "train loss:2.334080833692083\n",
      "train loss:2.317953526306368\n",
      "=== epoch:27, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3222587572000175\n",
      "train loss:2.328992375909233\n",
      "train loss:2.314568907431153\n",
      "train loss:2.347962418506089\n",
      "=== epoch:28, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3000932347085117\n",
      "train loss:2.2777495224538113\n",
      "train loss:2.364280864995634\n",
      "train loss:2.35074869156989\n",
      "=== epoch:29, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3446244979442885\n",
      "train loss:2.3183511526604517\n",
      "train loss:2.3031195325926275\n",
      "train loss:2.3283654169889894\n",
      "=== epoch:30, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3245324615670357\n",
      "train loss:2.2876081090345854\n",
      "train loss:2.333803271872116\n",
      "train loss:2.327082174648697\n",
      "=== epoch:31, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3004572967246784\n",
      "train loss:2.2988300428075883\n",
      "train loss:2.3177989512960555\n",
      "train loss:2.3158997589116646\n",
      "=== epoch:32, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.347510166898468\n",
      "train loss:2.325546662916582\n",
      "train loss:2.3503932751941985\n",
      "train loss:2.348438598223553\n",
      "=== epoch:33, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.347754530215265\n",
      "train loss:2.3339471804746776\n",
      "train loss:2.3475141821296006\n",
      "train loss:2.34132388638705\n",
      "=== epoch:34, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.298392179918907\n",
      "train loss:2.3395736210844538\n",
      "train loss:2.304004417264593\n",
      "train loss:2.355461791921436\n",
      "=== epoch:35, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3561850644025117\n",
      "train loss:2.322759997051226\n",
      "train loss:2.341176605204762\n",
      "train loss:2.3343367115803595\n",
      "=== epoch:36, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3564970117039796\n",
      "train loss:2.288305505600655\n",
      "train loss:2.3355039351606246\n",
      "train loss:2.320768428284876\n",
      "=== epoch:37, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.327862243013559\n",
      "train loss:2.330219984578659\n",
      "train loss:2.3530594301002834\n",
      "train loss:2.278118981271644\n",
      "=== epoch:38, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.348809885826855\n",
      "train loss:2.3532635924179206\n",
      "train loss:2.3485394780198066\n",
      "train loss:2.334554809581401\n",
      "=== epoch:39, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.315533407636613\n",
      "train loss:2.358334884747796\n",
      "train loss:2.398936986426506\n",
      "train loss:2.281130055403408\n",
      "=== epoch:40, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.330263564070966\n",
      "train loss:2.3297783980005544\n",
      "train loss:2.337587302672243\n",
      "train loss:2.3582970351826607\n",
      "=== epoch:41, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3804197050702527\n",
      "train loss:2.3173740269433396\n",
      "train loss:2.3295560576258976\n",
      "train loss:2.3397474965310274\n",
      "=== epoch:42, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.308492128581057\n",
      "train loss:2.3757882210149988\n",
      "train loss:2.3309599956756704\n",
      "train loss:2.3289645013290854\n",
      "=== epoch:43, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.340222139243929\n",
      "train loss:2.3494482588793635\n",
      "train loss:2.280929385746792\n",
      "train loss:2.3323510928854856\n",
      "=== epoch:44, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3109597700756765\n",
      "train loss:2.3108765548545116\n",
      "train loss:2.325081639361628\n",
      "train loss:2.341371039238163\n",
      "=== epoch:45, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3355477574112973\n",
      "train loss:2.3422647203628824\n",
      "train loss:2.3263372107206806\n",
      "train loss:2.2974623755524735\n",
      "=== epoch:46, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3851189694466486\n",
      "train loss:2.3272164044228467\n",
      "train loss:2.3327360244013233\n",
      "train loss:2.349343116908165\n",
      "=== epoch:47, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3106601070678887\n",
      "train loss:2.3254021744745548\n",
      "train loss:2.336656387842718\n",
      "train loss:2.3191233822811976\n",
      "=== epoch:48, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.319009371943471\n",
      "train loss:2.3112011653510875\n",
      "train loss:2.3317483928287754\n",
      "train loss:2.308996115348584\n",
      "=== epoch:49, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.3465583558157777\n",
      "train loss:2.369433443820451\n",
      "train loss:2.299625947229621\n",
      "train loss:2.2948942683551143\n",
      "=== epoch:50, train acc:0.07, test acc:0.05 ===\n",
      "train loss:2.320429237229181\n",
      "train loss:2.373469901000956\n",
      "train loss:2.3614348343417833\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.05\n",
      "val_acc: 0.0500 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.329158883243265\n",
      "=== epoch:1, train acc:0.13, test acc:0.2 ===\n",
      "train loss:2.4437022350837623\n",
      "train loss:2.3159067911980937\n",
      "train loss:2.417170515744604\n",
      "train loss:2.4170124335283085\n",
      "=== epoch:2, train acc:0.1275, test acc:0.2 ===\n",
      "train loss:2.452959851672227\n",
      "train loss:2.456519560631481\n",
      "train loss:2.460134365365179\n",
      "train loss:2.3594452700535844\n",
      "=== epoch:3, train acc:0.1275, test acc:0.2 ===\n",
      "train loss:2.430319485725543\n",
      "train loss:2.3584769915401003\n",
      "train loss:2.2840450326930153\n",
      "train loss:2.3996623512784683\n",
      "=== epoch:4, train acc:0.1275, test acc:0.2 ===\n",
      "train loss:2.4318416293618164\n",
      "train loss:2.353741650071987\n",
      "train loss:2.310178991295208\n",
      "train loss:2.3381968755022506\n",
      "=== epoch:5, train acc:0.1275, test acc:0.2 ===\n",
      "train loss:2.3874362293228337\n",
      "train loss:2.3664654930047226\n",
      "train loss:2.4064062686205117\n",
      "train loss:2.3856349932439174\n",
      "=== epoch:6, train acc:0.125, test acc:0.2 ===\n",
      "train loss:2.4297713098644405\n",
      "train loss:2.4425444489684844\n",
      "train loss:2.439031525018392\n",
      "train loss:2.4385120521163812\n",
      "=== epoch:7, train acc:0.125, test acc:0.2 ===\n",
      "train loss:2.380861582149972\n",
      "train loss:2.4174862347139925\n",
      "train loss:2.4731081582638206\n",
      "train loss:2.3542274005987056\n",
      "=== epoch:8, train acc:0.125, test acc:0.2 ===\n",
      "train loss:2.3662137970338417\n",
      "train loss:2.407307433549086\n",
      "train loss:2.3038722336296167\n",
      "train loss:2.30031412280728\n",
      "=== epoch:9, train acc:0.125, test acc:0.2 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.310586244199973\n",
      "train loss:2.3547441161005724\n",
      "train loss:2.438407698733763\n",
      "train loss:2.3596885251740063\n",
      "=== epoch:10, train acc:0.125, test acc:0.2 ===\n",
      "train loss:2.341770441776487\n",
      "train loss:2.480990984111357\n",
      "train loss:2.353896755372286\n",
      "train loss:2.3271828458802664\n",
      "=== epoch:11, train acc:0.1275, test acc:0.2 ===\n",
      "train loss:2.307938344399206\n",
      "train loss:2.4051333439989095\n",
      "train loss:2.386856808893575\n",
      "train loss:2.3140309964783943\n",
      "=== epoch:12, train acc:0.1275, test acc:0.2 ===\n",
      "train loss:2.2998946960923603\n",
      "train loss:2.253663543615643\n",
      "train loss:2.4031752564185203\n",
      "train loss:2.4314128044420142\n",
      "=== epoch:13, train acc:0.1275, test acc:0.21 ===\n",
      "train loss:2.343856687265038\n",
      "train loss:2.3327778805678796\n",
      "train loss:2.4184314455989355\n",
      "train loss:2.3353485918046912\n",
      "=== epoch:14, train acc:0.125, test acc:0.21 ===\n",
      "train loss:2.413722741373823\n",
      "train loss:2.3337450183352577\n",
      "train loss:2.3845125251216324\n",
      "train loss:2.3559502032236317\n",
      "=== epoch:15, train acc:0.125, test acc:0.21 ===\n",
      "train loss:2.4358000812682166\n",
      "train loss:2.353396932229951\n",
      "train loss:2.318632458004081\n",
      "train loss:2.3776515161497382\n",
      "=== epoch:16, train acc:0.125, test acc:0.21 ===\n",
      "train loss:2.3847542220488296\n",
      "train loss:2.408316117975332\n",
      "train loss:2.327683682161377\n",
      "train loss:2.4719771471119834\n",
      "=== epoch:17, train acc:0.125, test acc:0.21 ===\n",
      "train loss:2.428643907113204\n",
      "train loss:2.3778753793842378\n",
      "train loss:2.353883414948866\n",
      "train loss:2.314817896308766\n",
      "=== epoch:18, train acc:0.125, test acc:0.21 ===\n",
      "train loss:2.455131811003458\n",
      "train loss:2.370622321950423\n",
      "train loss:2.3952089859853944\n",
      "train loss:2.348093950554352\n",
      "=== epoch:19, train acc:0.1275, test acc:0.21 ===\n",
      "train loss:2.3418525006373994\n",
      "train loss:2.310148389587965\n",
      "train loss:2.2762317833126944\n",
      "train loss:2.2936180277791136\n",
      "=== epoch:20, train acc:0.1275, test acc:0.23 ===\n",
      "train loss:2.4629626967060743\n",
      "train loss:2.375468913494145\n",
      "train loss:2.3877212869336883\n",
      "train loss:2.3261017383511033\n",
      "=== epoch:21, train acc:0.1275, test acc:0.23 ===\n",
      "train loss:2.3451210109953045\n",
      "train loss:2.366229764110966\n",
      "train loss:2.360255726800666\n",
      "train loss:2.372538978744008\n",
      "=== epoch:22, train acc:0.1275, test acc:0.22 ===\n",
      "train loss:2.328182007728859\n",
      "train loss:2.3389163580156636\n",
      "train loss:2.363548863973496\n",
      "train loss:2.3248297133600935\n",
      "=== epoch:23, train acc:0.13, test acc:0.23 ===\n",
      "train loss:2.4278163930525856\n",
      "train loss:2.3541720389763108\n",
      "train loss:2.424852731316698\n",
      "train loss:2.3918284733129727\n",
      "=== epoch:24, train acc:0.13, test acc:0.23 ===\n",
      "train loss:2.360107135489791\n",
      "train loss:2.217459510964216\n",
      "train loss:2.3172423032409926\n",
      "train loss:2.3480586364394616\n",
      "=== epoch:25, train acc:0.13, test acc:0.23 ===\n",
      "train loss:2.253823107942472\n",
      "train loss:2.3187143560667276\n",
      "train loss:2.3693941629961417\n",
      "train loss:2.316963521321203\n",
      "=== epoch:26, train acc:0.13, test acc:0.23 ===\n",
      "train loss:2.3550439111209176\n",
      "train loss:2.296103587438275\n",
      "train loss:2.398300753601703\n",
      "train loss:2.3436865613948825\n",
      "=== epoch:27, train acc:0.13, test acc:0.23 ===\n",
      "train loss:2.41213857404619\n",
      "train loss:2.3500617373433452\n",
      "train loss:2.3241040318871766\n",
      "train loss:2.332741378544854\n",
      "=== epoch:28, train acc:0.13, test acc:0.24 ===\n",
      "train loss:2.3683970230101012\n",
      "train loss:2.348676276375169\n",
      "train loss:2.2586036179188573\n",
      "train loss:2.4049448939830422\n",
      "=== epoch:29, train acc:0.1325, test acc:0.24 ===\n",
      "train loss:2.347537939668568\n",
      "train loss:2.2842092113892223\n",
      "train loss:2.367133912949283\n",
      "train loss:2.300514501035685\n",
      "=== epoch:30, train acc:0.1325, test acc:0.24 ===\n",
      "train loss:2.2466284516541117\n",
      "train loss:2.3632393718894726\n",
      "train loss:2.330888126973026\n",
      "train loss:2.3466590229385154\n",
      "=== epoch:31, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.366952833538562\n",
      "train loss:2.461025209869905\n",
      "train loss:2.3237251032142234\n",
      "train loss:2.330869728543757\n",
      "=== epoch:32, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.4220056110623656\n",
      "train loss:2.369226517157802\n",
      "train loss:2.355294513730206\n",
      "train loss:2.2668846872431696\n",
      "=== epoch:33, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.3419368006966903\n",
      "train loss:2.383837626743511\n",
      "train loss:2.3328825632096675\n",
      "train loss:2.3275040589645486\n",
      "=== epoch:34, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.3420261632725996\n",
      "train loss:2.3692675094893096\n",
      "train loss:2.3488956012330076\n",
      "train loss:2.277203496450587\n",
      "=== epoch:35, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.3666131642368535\n",
      "train loss:2.277927602947378\n",
      "train loss:2.303408201751765\n",
      "train loss:2.3972933620551546\n",
      "=== epoch:36, train acc:0.1325, test acc:0.24 ===\n",
      "train loss:2.36556731612664\n",
      "train loss:2.34769926760233\n",
      "train loss:2.3407746624586103\n",
      "train loss:2.3261177463910574\n",
      "=== epoch:37, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.2544219313933467\n",
      "train loss:2.3763318700011054\n",
      "train loss:2.3588024169132757\n",
      "train loss:2.4037240657789476\n",
      "=== epoch:38, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.3586557167430464\n",
      "train loss:2.3218861574132434\n",
      "train loss:2.3663179322594066\n",
      "train loss:2.3385807275581323\n",
      "=== epoch:39, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.3866275114585225\n",
      "train loss:2.262447281938544\n",
      "train loss:2.3124585303078606\n",
      "train loss:2.32753345755579\n",
      "=== epoch:40, train acc:0.135, test acc:0.24 ===\n",
      "train loss:2.3194693198471423\n",
      "train loss:2.3811118111099456\n",
      "train loss:2.297833614279024\n",
      "train loss:2.340995765528019\n",
      "=== epoch:41, train acc:0.1375, test acc:0.24 ===\n",
      "train loss:2.369533184240872\n",
      "train loss:2.3144281785114735\n",
      "train loss:2.3409922687122164\n",
      "train loss:2.346083116046153\n",
      "=== epoch:42, train acc:0.1375, test acc:0.24 ===\n",
      "train loss:2.32365297519219\n",
      "train loss:2.3144661062892045\n",
      "train loss:2.38149872995474\n",
      "train loss:2.3804701932130583\n",
      "=== epoch:43, train acc:0.1375, test acc:0.24 ===\n",
      "train loss:2.372116425479743\n",
      "train loss:2.282749681998591\n",
      "train loss:2.2746186254092398\n",
      "train loss:2.359562440334188\n",
      "=== epoch:44, train acc:0.1375, test acc:0.24 ===\n",
      "train loss:2.2985680747305826\n",
      "train loss:2.3341301598629225\n",
      "train loss:2.3392372484273056\n",
      "train loss:2.278480936033093\n",
      "=== epoch:45, train acc:0.14, test acc:0.24 ===\n",
      "train loss:2.3334458198040533\n",
      "train loss:2.370312734094288\n",
      "train loss:2.302423235141197\n",
      "train loss:2.3317047976230403\n",
      "=== epoch:46, train acc:0.14, test acc:0.24 ===\n",
      "train loss:2.3054811416173666\n",
      "train loss:2.4419692804178186\n",
      "train loss:2.3960745842608957\n",
      "train loss:2.4286155013807473\n",
      "=== epoch:47, train acc:0.14, test acc:0.24 ===\n",
      "train loss:2.3351414811029914\n",
      "train loss:2.35749921331924\n",
      "train loss:2.309133276828116\n",
      "train loss:2.327932379679197\n",
      "=== epoch:48, train acc:0.1375, test acc:0.24 ===\n",
      "train loss:2.343089232171425\n",
      "train loss:2.304507176681489\n",
      "train loss:2.2517781741661707\n",
      "train loss:2.3859783937668384\n",
      "=== epoch:49, train acc:0.1375, test acc:0.24 ===\n",
      "train loss:2.38269836773912\n",
      "train loss:2.3273970887388487\n",
      "train loss:2.2969260521558383\n",
      "train loss:2.3016689394216296\n",
      "=== epoch:50, train acc:0.1375, test acc:0.24 ===\n",
      "train loss:2.3248751922794932\n",
      "train loss:2.349930167578913\n",
      "train loss:2.3025630735737024\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.24\n",
      "val_acc: 0.2400 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.353005129017956\n",
      "=== epoch:1, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.3688513443233017\n",
      "train loss:2.4165636820445227\n",
      "train loss:2.423205230393835\n",
      "train loss:2.4045188628850735\n",
      "=== epoch:2, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.396635183041589\n",
      "train loss:2.4356882150845736\n",
      "train loss:2.3822052137933354\n",
      "train loss:2.418823878437547\n",
      "=== epoch:3, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.3398041548930517\n",
      "train loss:2.3101572178433716\n",
      "train loss:2.3629976756507873\n",
      "train loss:2.3750126477090747\n",
      "=== epoch:4, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.332213849878314\n",
      "train loss:2.3767593662869944\n",
      "train loss:2.3349300020810317\n",
      "train loss:2.3817564412995345\n",
      "=== epoch:5, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.33063075608023\n",
      "train loss:2.349112401562348\n",
      "train loss:2.387186437069052\n",
      "train loss:2.3587576341119236\n",
      "=== epoch:6, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.334433316418109\n",
      "train loss:2.315238945749104\n",
      "train loss:2.3592944945325214\n",
      "train loss:2.3311287562637912\n",
      "=== epoch:7, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3112935833524206\n",
      "train loss:2.317604173204416\n",
      "train loss:2.291062338988978\n",
      "train loss:2.397918718891882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:8, train acc:0.1225, test acc:0.13 ===\n",
      "train loss:2.361619796131717\n",
      "train loss:2.373234479700111\n",
      "train loss:2.2751954319890313\n",
      "train loss:2.297743617555661\n",
      "=== epoch:9, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.2748127414041517\n",
      "train loss:2.31026088953857\n",
      "train loss:2.300503608280206\n",
      "train loss:2.3674335653834917\n",
      "=== epoch:10, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.308765548433597\n",
      "train loss:2.2791828678331374\n",
      "train loss:2.28887726673411\n",
      "train loss:2.3706216910463085\n",
      "=== epoch:11, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3016332582393817\n",
      "train loss:2.307755339671201\n",
      "train loss:2.2786465954219475\n",
      "train loss:2.343269575137763\n",
      "=== epoch:12, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.338219261431139\n",
      "train loss:2.3334719058323747\n",
      "train loss:2.3093567434902313\n",
      "train loss:2.3675256886562317\n",
      "=== epoch:13, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.384812652257056\n",
      "train loss:2.2880184206349994\n",
      "train loss:2.3419749791742706\n",
      "train loss:2.3477432024810296\n",
      "=== epoch:14, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.4113120071781537\n",
      "train loss:2.279204628405962\n",
      "train loss:2.34554983779064\n",
      "train loss:2.3214213075311254\n",
      "=== epoch:15, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3485946348959685\n",
      "train loss:2.447311375899627\n",
      "train loss:2.3558346845372635\n",
      "train loss:2.376048398761371\n",
      "=== epoch:16, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3621859002740986\n",
      "train loss:2.303157193684165\n",
      "train loss:2.3359857052892994\n",
      "train loss:2.3578507391148738\n",
      "=== epoch:17, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.254909203661985\n",
      "train loss:2.3766579664978433\n",
      "train loss:2.400837510612006\n",
      "train loss:2.4009632983584552\n",
      "=== epoch:18, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3443859858836538\n",
      "train loss:2.418765102279408\n",
      "train loss:2.291790042518036\n",
      "train loss:2.3394733754184256\n",
      "=== epoch:19, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.326159415427098\n",
      "train loss:2.329825839711616\n",
      "train loss:2.318188444383422\n",
      "train loss:2.352427153203941\n",
      "=== epoch:20, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3007568654310453\n",
      "train loss:2.323548130739312\n",
      "train loss:2.3548104836790396\n",
      "train loss:2.4288834299186766\n",
      "=== epoch:21, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.309252619942578\n",
      "train loss:2.35971340202433\n",
      "train loss:2.327141557323719\n",
      "train loss:2.301178685490094\n",
      "=== epoch:22, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3236543196203763\n",
      "train loss:2.3217459113832692\n",
      "train loss:2.2805235135576547\n",
      "train loss:2.3763284658684602\n",
      "=== epoch:23, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3394230333042128\n",
      "train loss:2.2836601015041746\n",
      "train loss:2.3231611052109242\n",
      "train loss:2.2936540481352177\n",
      "=== epoch:24, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3050485855753395\n",
      "train loss:2.338983844594054\n",
      "train loss:2.3538383443675794\n",
      "train loss:2.360281747604061\n",
      "=== epoch:25, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.298621279345176\n",
      "train loss:2.284227966425883\n",
      "train loss:2.3031366119022256\n",
      "train loss:2.315347794059121\n",
      "=== epoch:26, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.317019451184344\n",
      "train loss:2.291936047651619\n",
      "train loss:2.2786949147159765\n",
      "train loss:2.249681695184472\n",
      "=== epoch:27, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.240325390376753\n",
      "train loss:2.3359756078257203\n",
      "train loss:2.2982146943036184\n",
      "train loss:2.331558403016589\n",
      "=== epoch:28, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.396205464332648\n",
      "train loss:2.3518332147097274\n",
      "train loss:2.3560202168765274\n",
      "train loss:2.3722957669984237\n",
      "=== epoch:29, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.3351633574951327\n",
      "train loss:2.2958249485249422\n",
      "train loss:2.3638249510773965\n",
      "train loss:2.298631898820892\n",
      "=== epoch:30, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.312518683133225\n",
      "train loss:2.2695046466484494\n",
      "train loss:2.308300432711268\n",
      "train loss:2.3761083145096413\n",
      "=== epoch:31, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.3342959826212204\n",
      "train loss:2.261723129172157\n",
      "train loss:2.320221287092978\n",
      "train loss:2.344272528668688\n",
      "=== epoch:32, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.298092721625789\n",
      "train loss:2.350158053469238\n",
      "train loss:2.2918435799461894\n",
      "train loss:2.3445131923814704\n",
      "=== epoch:33, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.3376829842677753\n",
      "train loss:2.2792134847890937\n",
      "train loss:2.39831772670243\n",
      "train loss:2.281337288877067\n",
      "=== epoch:34, train acc:0.1325, test acc:0.13 ===\n",
      "train loss:2.38158960825418\n",
      "train loss:2.3732708825703104\n",
      "train loss:2.3368569653267426\n",
      "train loss:2.2997001577640326\n",
      "=== epoch:35, train acc:0.1325, test acc:0.13 ===\n",
      "train loss:2.331262489623308\n",
      "train loss:2.3043105127663326\n",
      "train loss:2.2641522479284584\n",
      "train loss:2.240502487585518\n",
      "=== epoch:36, train acc:0.1325, test acc:0.13 ===\n",
      "train loss:2.359498834451583\n",
      "train loss:2.278144236491383\n",
      "train loss:2.3089496615234903\n",
      "train loss:2.3150626431759265\n",
      "=== epoch:37, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3705385620363617\n",
      "train loss:2.3311477886128253\n",
      "train loss:2.26438434959648\n",
      "train loss:2.3036379874848354\n",
      "=== epoch:38, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.306368144591061\n",
      "train loss:2.335371807589479\n",
      "train loss:2.361471357679031\n",
      "train loss:2.242669735776042\n",
      "=== epoch:39, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3020513994872966\n",
      "train loss:2.3559599005443976\n",
      "train loss:2.3254354935932797\n",
      "train loss:2.2967943783445097\n",
      "=== epoch:40, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.3570145488431016\n",
      "train loss:2.291400373037229\n",
      "train loss:2.32784852785645\n",
      "train loss:2.2938112624812232\n",
      "=== epoch:41, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.361756047253042\n",
      "train loss:2.2592860871414255\n",
      "train loss:2.3060472007084276\n",
      "train loss:2.32219997201165\n",
      "=== epoch:42, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.280969677616056\n",
      "train loss:2.3379441513073123\n",
      "train loss:2.2675244732893742\n",
      "train loss:2.26241578264091\n",
      "=== epoch:43, train acc:0.1325, test acc:0.13 ===\n",
      "train loss:2.2680147704043128\n",
      "train loss:2.342192806346121\n",
      "train loss:2.2560540779179816\n",
      "train loss:2.325652833036904\n",
      "=== epoch:44, train acc:0.1325, test acc:0.13 ===\n",
      "train loss:2.232036294953523\n",
      "train loss:2.3249098171786837\n",
      "train loss:2.3108276892084554\n",
      "train loss:2.2976660736916243\n",
      "=== epoch:45, train acc:0.135, test acc:0.13 ===\n",
      "train loss:2.2997131350755966\n",
      "train loss:2.3318760688709905\n",
      "train loss:2.2850411677907574\n",
      "train loss:2.274407456558412\n",
      "=== epoch:46, train acc:0.135, test acc:0.13 ===\n",
      "train loss:2.3047583859116374\n",
      "train loss:2.294122539282569\n",
      "train loss:2.3109031340030963\n",
      "train loss:2.2997511693687476\n",
      "=== epoch:47, train acc:0.135, test acc:0.13 ===\n",
      "train loss:2.2636274042005273\n",
      "train loss:2.288507307961405\n",
      "train loss:2.2865795815824197\n",
      "train loss:2.311697635347098\n",
      "=== epoch:48, train acc:0.135, test acc:0.13 ===\n",
      "train loss:2.288709748992239\n",
      "train loss:2.2843019342351254\n",
      "train loss:2.3114306496391386\n",
      "train loss:2.309572059158421\n",
      "=== epoch:49, train acc:0.1325, test acc:0.13 ===\n",
      "train loss:2.2914964257604358\n",
      "train loss:2.340701127860563\n",
      "train loss:2.3036344291134943\n",
      "train loss:2.309577300106441\n",
      "=== epoch:50, train acc:0.1375, test acc:0.13 ===\n",
      "train loss:2.3597708523582073\n",
      "train loss:2.2950714294127\n",
      "train loss:2.354911393844715\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.13\n",
      "val_acc: 0.1300 | lr: 0.0002, weight_decay: 0.0000\n",
      "train loss:2.3642365145751616\n",
      "=== epoch:1, train acc:0.0975, test acc:0.18 ===\n",
      "train loss:2.338326601454957\n",
      "train loss:2.3739956028601386\n",
      "train loss:2.3702639150927354\n",
      "train loss:2.375158051973978\n",
      "=== epoch:2, train acc:0.0975, test acc:0.18 ===\n",
      "train loss:2.3111745188914763\n",
      "train loss:2.350719319391946\n",
      "train loss:2.349983662791279\n",
      "train loss:2.3653305708673056\n",
      "=== epoch:3, train acc:0.1025, test acc:0.18 ===\n",
      "train loss:2.377635951588933\n",
      "train loss:2.340054179124036\n",
      "train loss:2.2949798129050207\n",
      "train loss:2.346361024109577\n",
      "=== epoch:4, train acc:0.1075, test acc:0.18 ===\n",
      "train loss:2.3339192915090288\n",
      "train loss:2.342758056890438\n",
      "train loss:2.3726087992637255\n",
      "train loss:2.2977462359683467\n",
      "=== epoch:5, train acc:0.1075, test acc:0.18 ===\n",
      "train loss:2.2889608174455556\n",
      "train loss:2.339987019836787\n",
      "train loss:2.3619908126161273\n",
      "train loss:2.3306918726810237\n",
      "=== epoch:6, train acc:0.11, test acc:0.18 ===\n",
      "train loss:2.3681858010031376\n",
      "train loss:2.2654131770410544\n",
      "train loss:2.3617624714992123\n",
      "train loss:2.2929347715280666\n",
      "=== epoch:7, train acc:0.115, test acc:0.18 ===\n",
      "train loss:2.2973516891331656\n",
      "train loss:2.27552138033871\n",
      "train loss:2.273364448138926\n",
      "train loss:2.29861338604702\n",
      "=== epoch:8, train acc:0.1175, test acc:0.18 ===\n",
      "train loss:2.2941158657276386\n",
      "train loss:2.31483283263491\n",
      "train loss:2.362934044552729\n",
      "train loss:2.328019306538602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:9, train acc:0.12, test acc:0.17 ===\n",
      "train loss:2.316161028608046\n",
      "train loss:2.288218354823029\n",
      "train loss:2.282242629579554\n",
      "train loss:2.3147693812154477\n",
      "=== epoch:10, train acc:0.12, test acc:0.18 ===\n",
      "train loss:2.27885853855989\n",
      "train loss:2.4047361317358007\n",
      "train loss:2.3113943677508018\n",
      "train loss:2.250036819138308\n",
      "=== epoch:11, train acc:0.1175, test acc:0.18 ===\n",
      "train loss:2.2522017769919263\n",
      "train loss:2.344519267162915\n",
      "train loss:2.277531036459461\n",
      "train loss:2.3122183084275694\n",
      "=== epoch:12, train acc:0.1275, test acc:0.18 ===\n",
      "train loss:2.3385736867931146\n",
      "train loss:2.24908356908124\n",
      "train loss:2.2794390672020066\n",
      "train loss:2.283518050426578\n",
      "=== epoch:13, train acc:0.1275, test acc:0.18 ===\n",
      "train loss:2.309381759530619\n",
      "train loss:2.326207404894953\n",
      "train loss:2.3247249998857433\n",
      "train loss:2.245296544442415\n",
      "=== epoch:14, train acc:0.1325, test acc:0.18 ===\n",
      "train loss:2.2442114593663574\n",
      "train loss:2.320305781946985\n",
      "train loss:2.284301060062632\n",
      "train loss:2.2717190273640306\n",
      "=== epoch:15, train acc:0.135, test acc:0.18 ===\n",
      "train loss:2.2784166310368814\n",
      "train loss:2.271475784371275\n",
      "train loss:2.2580787559054922\n",
      "train loss:2.3223780124719817\n",
      "=== epoch:16, train acc:0.1425, test acc:0.18 ===\n",
      "train loss:2.2577995109271956\n",
      "train loss:2.2618418754497767\n",
      "train loss:2.2899929561163983\n",
      "train loss:2.2910157232248807\n",
      "=== epoch:17, train acc:0.145, test acc:0.18 ===\n",
      "train loss:2.2659131170263014\n",
      "train loss:2.2686431279549937\n",
      "train loss:2.2889314114295134\n",
      "train loss:2.328492836535995\n",
      "=== epoch:18, train acc:0.1475, test acc:0.19 ===\n",
      "train loss:2.2186356515286096\n",
      "train loss:2.2755266474973777\n",
      "train loss:2.2831901498844447\n",
      "train loss:2.2603599419370974\n",
      "=== epoch:19, train acc:0.15, test acc:0.19 ===\n",
      "train loss:2.236648302890714\n",
      "train loss:2.3392024344509155\n",
      "train loss:2.300784243948065\n",
      "train loss:2.2279050463795578\n",
      "=== epoch:20, train acc:0.155, test acc:0.19 ===\n",
      "train loss:2.2657563165088326\n",
      "train loss:2.313118657074009\n",
      "train loss:2.245904426463875\n",
      "train loss:2.250163643631329\n",
      "=== epoch:21, train acc:0.1575, test acc:0.2 ===\n",
      "train loss:2.30542909343111\n",
      "train loss:2.245396454787106\n",
      "train loss:2.224233854727254\n",
      "train loss:2.251416205098002\n",
      "=== epoch:22, train acc:0.16, test acc:0.2 ===\n",
      "train loss:2.2623542587784007\n",
      "train loss:2.281908816462206\n",
      "train loss:2.296311211566414\n",
      "train loss:2.232834974225504\n",
      "=== epoch:23, train acc:0.1675, test acc:0.2 ===\n",
      "train loss:2.2636735684800064\n",
      "train loss:2.2653415590225046\n",
      "train loss:2.2370781377951134\n",
      "train loss:2.285691770843698\n",
      "=== epoch:24, train acc:0.1725, test acc:0.2 ===\n",
      "train loss:2.24749047566782\n",
      "train loss:2.241362972673467\n",
      "train loss:2.2692251285220797\n",
      "train loss:2.224205172407776\n",
      "=== epoch:25, train acc:0.1725, test acc:0.2 ===\n",
      "train loss:2.2523610007587958\n",
      "train loss:2.2092487767964837\n",
      "train loss:2.190254488762215\n",
      "train loss:2.2076370925188162\n",
      "=== epoch:26, train acc:0.1775, test acc:0.2 ===\n",
      "train loss:2.241260239678514\n",
      "train loss:2.2491772317990537\n",
      "train loss:2.22249449020478\n",
      "train loss:2.264181230635503\n",
      "=== epoch:27, train acc:0.1775, test acc:0.2 ===\n",
      "train loss:2.3035227634954754\n",
      "train loss:2.234327270996081\n",
      "train loss:2.268897317272647\n",
      "train loss:2.2462222480559464\n",
      "=== epoch:28, train acc:0.1775, test acc:0.21 ===\n",
      "train loss:2.2843563464606693\n",
      "train loss:2.2262649194598207\n",
      "train loss:2.2345019705094153\n",
      "train loss:2.2160442437445216\n",
      "=== epoch:29, train acc:0.18, test acc:0.21 ===\n",
      "train loss:2.27402753368182\n",
      "train loss:2.280609853179493\n",
      "train loss:2.2206342570030593\n",
      "train loss:2.21828727788433\n",
      "=== epoch:30, train acc:0.18, test acc:0.21 ===\n",
      "train loss:2.26868771769465\n",
      "train loss:2.2566262331842415\n",
      "train loss:2.2637963362768416\n",
      "train loss:2.19499955776143\n",
      "=== epoch:31, train acc:0.1925, test acc:0.21 ===\n",
      "train loss:2.2104634523443565\n",
      "train loss:2.227790226311829\n",
      "train loss:2.245241436725496\n",
      "train loss:2.2246043121448973\n",
      "=== epoch:32, train acc:0.1975, test acc:0.21 ===\n",
      "train loss:2.2615516802466478\n",
      "train loss:2.1991160477057154\n",
      "train loss:2.196014609185055\n",
      "train loss:2.2196079631694228\n",
      "=== epoch:33, train acc:0.2, test acc:0.21 ===\n",
      "train loss:2.222017742069342\n",
      "train loss:2.210067142384049\n",
      "train loss:2.2499406100946016\n",
      "train loss:2.221327062808117\n",
      "=== epoch:34, train acc:0.205, test acc:0.21 ===\n",
      "train loss:2.2067976801934055\n",
      "train loss:2.178552211184403\n",
      "train loss:2.2047631647454278\n",
      "train loss:2.2139494049054225\n",
      "=== epoch:35, train acc:0.205, test acc:0.21 ===\n",
      "train loss:2.217496106883878\n",
      "train loss:2.2034814558423705\n",
      "train loss:2.1770503238511054\n",
      "train loss:2.1179898754206086\n",
      "=== epoch:36, train acc:0.2125, test acc:0.22 ===\n",
      "train loss:2.197836948582643\n",
      "train loss:2.1855656598151465\n",
      "train loss:2.2249392882659174\n",
      "train loss:2.166168924177162\n",
      "=== epoch:37, train acc:0.22, test acc:0.22 ===\n",
      "train loss:2.17967331954192\n",
      "train loss:2.1995876483180203\n",
      "train loss:2.2143675978393613\n",
      "train loss:2.1680171678134466\n",
      "=== epoch:38, train acc:0.225, test acc:0.22 ===\n",
      "train loss:2.2175989228861064\n",
      "train loss:2.1869697452535246\n",
      "train loss:2.1955713488608937\n",
      "train loss:2.238074857937621\n",
      "=== epoch:39, train acc:0.2275, test acc:0.23 ===\n",
      "train loss:2.1906543522006543\n",
      "train loss:2.1934422807812326\n",
      "train loss:2.1720784523122014\n",
      "train loss:2.2264214734435397\n",
      "=== epoch:40, train acc:0.2375, test acc:0.24 ===\n",
      "train loss:2.225359183694007\n",
      "train loss:2.1698755310912183\n",
      "train loss:2.1762261490931674\n",
      "train loss:2.150889306005042\n",
      "=== epoch:41, train acc:0.2375, test acc:0.24 ===\n",
      "train loss:2.2055209513728675\n",
      "train loss:2.2026426870602327\n",
      "train loss:2.231207313608605\n",
      "train loss:2.167085425118272\n",
      "=== epoch:42, train acc:0.2425, test acc:0.24 ===\n",
      "train loss:2.1759572859824132\n",
      "train loss:2.2432078825746022\n",
      "train loss:2.1373014203862235\n",
      "train loss:2.201727346215372\n",
      "=== epoch:43, train acc:0.245, test acc:0.24 ===\n",
      "train loss:2.113056233566547\n",
      "train loss:2.1912178491353367\n",
      "train loss:2.195580225491287\n",
      "train loss:2.2057639027910696\n",
      "=== epoch:44, train acc:0.245, test acc:0.24 ===\n",
      "train loss:2.150249901479392\n",
      "train loss:2.165296205949582\n",
      "train loss:2.1410420865463102\n",
      "train loss:2.173294463213676\n",
      "=== epoch:45, train acc:0.2475, test acc:0.25 ===\n",
      "train loss:2.184891174418617\n",
      "train loss:2.13562182054379\n",
      "train loss:2.148449107421659\n",
      "train loss:2.151205199564027\n",
      "=== epoch:46, train acc:0.2475, test acc:0.25 ===\n",
      "train loss:2.153926589298702\n",
      "train loss:2.22701154892475\n",
      "train loss:2.193613486828109\n",
      "train loss:2.2145946134756356\n",
      "=== epoch:47, train acc:0.25, test acc:0.27 ===\n",
      "train loss:2.198150108026445\n",
      "train loss:2.1713422196965064\n",
      "train loss:2.1855332860999592\n",
      "train loss:2.208857637576727\n",
      "=== epoch:48, train acc:0.25, test acc:0.27 ===\n",
      "train loss:2.130835586035654\n",
      "train loss:2.21249102526781\n",
      "train loss:2.146363272173389\n",
      "train loss:2.161295509853432\n",
      "=== epoch:49, train acc:0.25, test acc:0.27 ===\n",
      "train loss:2.186083138961491\n",
      "train loss:2.134510487515742\n",
      "train loss:2.147549769837652\n",
      "train loss:2.1913777789108053\n",
      "=== epoch:50, train acc:0.25, test acc:0.27 ===\n",
      "train loss:2.1880286884076234\n",
      "train loss:2.1523165503566077\n",
      "train loss:2.2027904608966646\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.27\n",
      "val_acc: 0.2700 | lr: 0.0008, weight_decay: 0.0000\n",
      "train loss:2.5579321857689497\n",
      "=== epoch:1, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.7077196364113814\n",
      "train loss:2.6488462800904435\n",
      "train loss:2.724455870021608\n",
      "train loss:2.67523368020468\n",
      "=== epoch:2, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.66610628920754\n",
      "train loss:2.7290313314125436\n",
      "train loss:2.58834957759878\n",
      "train loss:2.72805532966209\n",
      "=== epoch:3, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.571446114929157\n",
      "train loss:2.608747216910522\n",
      "train loss:2.5379996660862503\n",
      "train loss:2.6359504732854404\n",
      "=== epoch:4, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.80036007733084\n",
      "train loss:2.472409992756518\n",
      "train loss:2.7172565476645305\n",
      "train loss:2.6240128041720436\n",
      "=== epoch:5, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.681573388861802\n",
      "train loss:2.6740919718510696\n",
      "train loss:2.698057821339515\n",
      "train loss:2.571830859054266\n",
      "=== epoch:6, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5786947143431744\n",
      "train loss:2.6955585771110684\n",
      "train loss:2.680554485364903\n",
      "train loss:2.653126256112826\n",
      "=== epoch:7, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6556784515341376\n",
      "train loss:2.6522937726100944\n",
      "train loss:2.561722036555303\n",
      "train loss:2.6381388858679293\n",
      "=== epoch:8, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5277158996752602\n",
      "train loss:2.683634820817636\n",
      "train loss:2.802177142861414\n",
      "train loss:2.7003854931227216\n",
      "=== epoch:9, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6511561385110807\n",
      "train loss:2.729901630217043\n",
      "train loss:2.6408797239549084\n",
      "train loss:2.7573687656813344\n",
      "=== epoch:10, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.7730509638004714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.5732436690891944\n",
      "train loss:2.68955368526111\n",
      "train loss:2.710859017964741\n",
      "=== epoch:11, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.683027080726585\n",
      "train loss:2.699913558941731\n",
      "train loss:2.582786175567995\n",
      "train loss:2.527397464603996\n",
      "=== epoch:12, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.629202373259663\n",
      "train loss:2.7067387010289465\n",
      "train loss:2.6616540210897046\n",
      "train loss:2.6381293993128785\n",
      "=== epoch:13, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.702535200724606\n",
      "train loss:2.6709560002447006\n",
      "train loss:2.6889738430351233\n",
      "train loss:2.6433514876670774\n",
      "=== epoch:14, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.655019532345676\n",
      "train loss:2.662477625477442\n",
      "train loss:2.57825057312732\n",
      "train loss:2.76277626700046\n",
      "=== epoch:15, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.7281791462192713\n",
      "train loss:2.6008706381451074\n",
      "train loss:2.6585140205139592\n",
      "train loss:2.558553171659739\n",
      "=== epoch:16, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5803195307678113\n",
      "train loss:2.658192971458428\n",
      "train loss:2.686456990102486\n",
      "train loss:2.6200242959511697\n",
      "=== epoch:17, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5960575746330057\n",
      "train loss:2.72339025603718\n",
      "train loss:2.6552950797067267\n",
      "train loss:2.5859282925798506\n",
      "=== epoch:18, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6311823773380545\n",
      "train loss:2.7168579552338596\n",
      "train loss:2.6414561437338016\n",
      "train loss:2.7205274871441087\n",
      "=== epoch:19, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6418194336601983\n",
      "train loss:2.7280976341710446\n",
      "train loss:2.5400236773740628\n",
      "train loss:2.654949535291572\n",
      "=== epoch:20, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.7627180699881455\n",
      "train loss:2.7236915955098637\n",
      "train loss:2.8356526716326074\n",
      "train loss:2.5812232455158672\n",
      "=== epoch:21, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.703404590510922\n",
      "train loss:2.6582904840146715\n",
      "train loss:2.8546929697581964\n",
      "train loss:2.6010670978261734\n",
      "=== epoch:22, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.590073388611664\n",
      "train loss:2.6241482721372424\n",
      "train loss:2.6735843624371727\n",
      "train loss:2.66809010187567\n",
      "=== epoch:23, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.4372846895155864\n",
      "train loss:2.4311334547425854\n",
      "train loss:2.621847890782206\n",
      "train loss:2.5298894643450387\n",
      "=== epoch:24, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.757243612846726\n",
      "train loss:2.527499035106961\n",
      "train loss:2.715841521869236\n",
      "train loss:2.5484120928689977\n",
      "=== epoch:25, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.75790074499381\n",
      "train loss:2.639043773084115\n",
      "train loss:2.6343760308459157\n",
      "train loss:2.662077007958446\n",
      "=== epoch:26, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6055974438226177\n",
      "train loss:2.5740405375230613\n",
      "train loss:2.739600380451499\n",
      "train loss:2.4665017055108587\n",
      "=== epoch:27, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6483057083797306\n",
      "train loss:2.7129964240709303\n",
      "train loss:2.6384114118540487\n",
      "train loss:2.700129027354983\n",
      "=== epoch:28, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5285008925373873\n",
      "train loss:2.5785205142062404\n",
      "train loss:2.570164604022156\n",
      "train loss:2.659122367034162\n",
      "=== epoch:29, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.778769774776138\n",
      "train loss:2.6882891559954203\n",
      "train loss:2.5800887190481037\n",
      "train loss:2.485631437213102\n",
      "=== epoch:30, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5767108416265323\n",
      "train loss:2.4553401965293356\n",
      "train loss:2.741766146430321\n",
      "train loss:2.6040339804151573\n",
      "=== epoch:31, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6759908800394667\n",
      "train loss:2.5820302123546055\n",
      "train loss:2.6301687028381\n",
      "train loss:2.5674550016780215\n",
      "=== epoch:32, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6913338626653216\n",
      "train loss:2.621091627629579\n",
      "train loss:2.677000051005443\n",
      "train loss:2.66816591076033\n",
      "=== epoch:33, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.715328863736147\n",
      "train loss:2.6222142694022885\n",
      "train loss:2.428891078016377\n",
      "train loss:2.680365253253658\n",
      "=== epoch:34, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.726481351178741\n",
      "train loss:2.5919063363731967\n",
      "train loss:2.5191521826842544\n",
      "train loss:2.568561223517492\n",
      "=== epoch:35, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.7361054828605047\n",
      "train loss:2.5488147587334056\n",
      "train loss:2.554235612865524\n",
      "train loss:2.731723848169567\n",
      "=== epoch:36, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5900591023253785\n",
      "train loss:2.848691676160472\n",
      "train loss:2.705698148278813\n",
      "train loss:2.7277217856071143\n",
      "=== epoch:37, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5660562360157053\n",
      "train loss:2.4755712920810864\n",
      "train loss:2.5894861473796777\n",
      "train loss:2.6698168081508795\n",
      "=== epoch:38, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6649497413183414\n",
      "train loss:2.683109249574388\n",
      "train loss:2.479348546479269\n",
      "train loss:2.563830555527129\n",
      "=== epoch:39, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.654226483599297\n",
      "train loss:2.646079346975247\n",
      "train loss:2.5882626630841745\n",
      "train loss:2.574342800769398\n",
      "=== epoch:40, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.4870323183284486\n",
      "train loss:2.6549076967773577\n",
      "train loss:2.6232800909219676\n",
      "train loss:2.664554117960149\n",
      "=== epoch:41, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.612175177020779\n",
      "train loss:2.5900355615138686\n",
      "train loss:2.6756327162149067\n",
      "train loss:2.6869508757486473\n",
      "=== epoch:42, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6612867499388333\n",
      "train loss:2.6326446805670765\n",
      "train loss:2.6812378427250354\n",
      "train loss:2.5947267820869775\n",
      "=== epoch:43, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5693683496266435\n",
      "train loss:2.5502797486109197\n",
      "train loss:2.623899457162059\n",
      "train loss:2.7339091404787843\n",
      "=== epoch:44, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.490937096930446\n",
      "train loss:2.6449643845804545\n",
      "train loss:2.6530606743010483\n",
      "train loss:2.707686681812177\n",
      "=== epoch:45, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5373361824327696\n",
      "train loss:2.524546069318077\n",
      "train loss:2.760963026729415\n",
      "train loss:2.60893796575629\n",
      "=== epoch:46, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.5681614284459404\n",
      "train loss:2.6186690718300603\n",
      "train loss:2.6852326567824987\n",
      "train loss:2.5450182346020744\n",
      "=== epoch:47, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.7115139751315827\n",
      "train loss:2.625730666105509\n",
      "train loss:2.57369551644338\n",
      "train loss:2.5638593456323266\n",
      "=== epoch:48, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.656731734670581\n",
      "train loss:2.629941706984888\n",
      "train loss:2.6611165385947526\n",
      "train loss:2.834822787901767\n",
      "=== epoch:49, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.504009272796897\n",
      "train loss:2.5630916609758954\n",
      "train loss:2.6273865669462766\n",
      "train loss:2.5905946208578365\n",
      "=== epoch:50, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.6983622947793244\n",
      "train loss:2.692651024042733\n",
      "train loss:2.6835645531251653\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3643972811126632\n",
      "=== epoch:1, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.394121600207762\n",
      "train loss:2.4862317996452252\n",
      "train loss:2.410336635156428\n",
      "train loss:2.3298513694087624\n",
      "=== epoch:2, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3541339227712763\n",
      "train loss:2.54911765710928\n",
      "train loss:2.3903519816774192\n",
      "train loss:2.43187113205474\n",
      "=== epoch:3, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4352612480047626\n",
      "train loss:2.4207416368829673\n",
      "train loss:2.447095499946156\n",
      "train loss:2.3075079920272703\n",
      "=== epoch:4, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.412849967514251\n",
      "train loss:2.38617689613585\n",
      "train loss:2.4666789897337384\n",
      "train loss:2.36172229927252\n",
      "=== epoch:5, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4180003299932595\n",
      "train loss:2.4272250921185066\n",
      "train loss:2.3233376609737433\n",
      "train loss:2.4104727252849107\n",
      "=== epoch:6, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4610342580751063\n",
      "train loss:2.439301127130904\n",
      "train loss:2.3437503523102077\n",
      "train loss:2.4554077326029073\n",
      "=== epoch:7, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4190178708782346\n",
      "train loss:2.346549809388557\n",
      "train loss:2.411504312509638\n",
      "train loss:2.442141233267898\n",
      "=== epoch:8, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.413615582557715\n",
      "train loss:2.4962380926467076\n",
      "train loss:2.463288942385842\n",
      "train loss:2.3295453106638955\n",
      "=== epoch:9, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.517835459847291\n",
      "train loss:2.3757507807311016\n",
      "train loss:2.425653941783327\n",
      "train loss:2.372578101844225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:10, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.385410791945576\n",
      "train loss:2.4221945604608113\n",
      "train loss:2.3407562592886393\n",
      "train loss:2.4595689157152902\n",
      "=== epoch:11, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.395669620203523\n",
      "train loss:2.4252074918347724\n",
      "train loss:2.4218687788709037\n",
      "train loss:2.4367282877598524\n",
      "=== epoch:12, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3299963660416116\n",
      "train loss:2.454063373708084\n",
      "train loss:2.477935846742876\n",
      "train loss:2.393071007667634\n",
      "=== epoch:13, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.450578092429867\n",
      "train loss:2.413477764200038\n",
      "train loss:2.4615957923865874\n",
      "train loss:2.405748296427839\n",
      "=== epoch:14, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.425498488209247\n",
      "train loss:2.3905817454913545\n",
      "train loss:2.372016543550231\n",
      "train loss:2.4234257087653006\n",
      "=== epoch:15, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3353459832306\n",
      "train loss:2.3645757761344557\n",
      "train loss:2.388152387320765\n",
      "train loss:2.4684649313026696\n",
      "=== epoch:16, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.395034291972914\n",
      "train loss:2.456626534149332\n",
      "train loss:2.438311748886958\n",
      "train loss:2.4288073661131153\n",
      "=== epoch:17, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4878239819643593\n",
      "train loss:2.524045490196829\n",
      "train loss:2.3168866173231737\n",
      "train loss:2.398591844434627\n",
      "=== epoch:18, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3428689728902827\n",
      "train loss:2.4246729064063888\n",
      "train loss:2.3835448926477723\n",
      "train loss:2.4271480717121907\n",
      "=== epoch:19, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.458220720993383\n",
      "train loss:2.3899097543088814\n",
      "train loss:2.4267473627527005\n",
      "train loss:2.3863085525738037\n",
      "=== epoch:20, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.362162988573998\n",
      "train loss:2.4438957047552785\n",
      "train loss:2.327060779315957\n",
      "train loss:2.3790467180274972\n",
      "=== epoch:21, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.37938569005784\n",
      "train loss:2.419114961835975\n",
      "train loss:2.4571446532654435\n",
      "train loss:2.423453486838567\n",
      "=== epoch:22, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4784386458336276\n",
      "train loss:2.4353280247597597\n",
      "train loss:2.3696478133376044\n",
      "train loss:2.4138110024898687\n",
      "=== epoch:23, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3082249310193794\n",
      "train loss:2.4361291254231277\n",
      "train loss:2.4156833116338117\n",
      "train loss:2.3826220075688567\n",
      "=== epoch:24, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.501981618871723\n",
      "train loss:2.322173925385843\n",
      "train loss:2.4557771982461025\n",
      "train loss:2.447226517544693\n",
      "=== epoch:25, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.516794264760253\n",
      "train loss:2.514022538324543\n",
      "train loss:2.395088342073919\n",
      "train loss:2.383338597478615\n",
      "=== epoch:26, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3778765601784904\n",
      "train loss:2.423581791565418\n",
      "train loss:2.3885779216592256\n",
      "train loss:2.455956569599616\n",
      "=== epoch:27, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4658315264638646\n",
      "train loss:2.3664843316178596\n",
      "train loss:2.4017873669303538\n",
      "train loss:2.334882124620038\n",
      "=== epoch:28, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.442030287143473\n",
      "train loss:2.366348184743386\n",
      "train loss:2.339674796618611\n",
      "train loss:2.424306531524246\n",
      "=== epoch:29, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4339705162218155\n",
      "train loss:2.3712540280933454\n",
      "train loss:2.454412138126857\n",
      "train loss:2.372964128830986\n",
      "=== epoch:30, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4204366352616704\n",
      "train loss:2.3810168699453995\n",
      "train loss:2.3591216606330185\n",
      "train loss:2.508456360727494\n",
      "=== epoch:31, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4174131083076875\n",
      "train loss:2.3071893550832625\n",
      "train loss:2.431213007840332\n",
      "train loss:2.372548998808442\n",
      "=== epoch:32, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.451919565708858\n",
      "train loss:2.438664238502076\n",
      "train loss:2.3405165692833676\n",
      "train loss:2.3918514019962855\n",
      "=== epoch:33, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.485458394683968\n",
      "train loss:2.3980097627495383\n",
      "train loss:2.4208219735346597\n",
      "train loss:2.429410990205153\n",
      "=== epoch:34, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3607638323401496\n",
      "train loss:2.3555905026008155\n",
      "train loss:2.4127215992485427\n",
      "train loss:2.4446732890452996\n",
      "=== epoch:35, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4319615975284363\n",
      "train loss:2.454215388745602\n",
      "train loss:2.392183384976359\n",
      "train loss:2.4716929131386696\n",
      "=== epoch:36, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.522916147046825\n",
      "train loss:2.276710998008566\n",
      "train loss:2.3407594418056648\n",
      "train loss:2.3432236478122968\n",
      "=== epoch:37, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4190763730929943\n",
      "train loss:2.426647325454235\n",
      "train loss:2.4989471283105713\n",
      "train loss:2.3500796443450875\n",
      "=== epoch:38, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.459477544080548\n",
      "train loss:2.533050674157393\n",
      "train loss:2.3172879238813024\n",
      "train loss:2.3476806303294766\n",
      "=== epoch:39, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3582843273281062\n",
      "train loss:2.48632442491455\n",
      "train loss:2.3543666017975\n",
      "train loss:2.3664905877661417\n",
      "=== epoch:40, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4698483875338497\n",
      "train loss:2.4521146587695153\n",
      "train loss:2.492711857851971\n",
      "train loss:2.3149908327620157\n",
      "=== epoch:41, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4075959340357467\n",
      "train loss:2.4604430031485887\n",
      "train loss:2.498781992049109\n",
      "train loss:2.465028881160087\n",
      "=== epoch:42, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3678355669067885\n",
      "train loss:2.347078215860243\n",
      "train loss:2.440183519748476\n",
      "train loss:2.3457493184038363\n",
      "=== epoch:43, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.423950413010081\n",
      "train loss:2.3908358860976007\n",
      "train loss:2.383019122304856\n",
      "train loss:2.471377553780711\n",
      "=== epoch:44, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3803358211886505\n",
      "train loss:2.436325064712719\n",
      "train loss:2.4367288072105175\n",
      "train loss:2.366622276952057\n",
      "=== epoch:45, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.418818421965182\n",
      "train loss:2.3591212644518578\n",
      "train loss:2.3859329053930844\n",
      "train loss:2.5392189336978332\n",
      "=== epoch:46, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.3703547453159852\n",
      "train loss:2.5254375438027026\n",
      "train loss:2.378219849528633\n",
      "train loss:2.3859243454307704\n",
      "=== epoch:47, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4125204773490596\n",
      "train loss:2.497869171675895\n",
      "train loss:2.4671456363862125\n",
      "train loss:2.287073944763362\n",
      "=== epoch:48, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.394123122040276\n",
      "train loss:2.393117705778407\n",
      "train loss:2.4615434554630466\n",
      "train loss:2.3181951493359905\n",
      "=== epoch:49, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.4077271848650734\n",
      "train loss:2.419874637591627\n",
      "train loss:2.4753986145730402\n",
      "train loss:2.4925015359124747\n",
      "=== epoch:50, train acc:0.115, test acc:0.08 ===\n",
      "train loss:2.359463840792041\n",
      "train loss:2.393956909218296\n",
      "train loss:2.498295813665273\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.08\n",
      "val_acc: 0.0800 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4137451206920875\n",
      "=== epoch:1, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.3906646463163357\n",
      "train loss:2.3964645732455967\n",
      "train loss:2.4633689956324725\n",
      "train loss:2.516768537303895\n",
      "=== epoch:2, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.37927694422667\n",
      "train loss:2.426323037596566\n",
      "train loss:2.3623385312494802\n",
      "train loss:2.342905445396251\n",
      "=== epoch:3, train acc:0.09, test acc:0.06 ===\n",
      "train loss:2.4092787934614472\n",
      "train loss:2.459433983554248\n",
      "train loss:2.439370416094001\n",
      "train loss:2.379729625441288\n",
      "=== epoch:4, train acc:0.09, test acc:0.05 ===\n",
      "train loss:2.491478799447021\n",
      "train loss:2.413777567584999\n",
      "train loss:2.341507137073207\n",
      "train loss:2.3746363204891834\n",
      "=== epoch:5, train acc:0.095, test acc:0.05 ===\n",
      "train loss:2.3530914341871085\n",
      "train loss:2.426052631485799\n",
      "train loss:2.3421782781623253\n",
      "train loss:2.4663280506634755\n",
      "=== epoch:6, train acc:0.1, test acc:0.05 ===\n",
      "train loss:2.3278292865128236\n",
      "train loss:2.429184196401115\n",
      "train loss:2.3329131835295707\n",
      "train loss:2.350815445479547\n",
      "=== epoch:7, train acc:0.1025, test acc:0.05 ===\n",
      "train loss:2.3727762273215682\n",
      "train loss:2.368694204755482\n",
      "train loss:2.448761948362185\n",
      "train loss:2.3461803445749014\n",
      "=== epoch:8, train acc:0.1075, test acc:0.05 ===\n",
      "train loss:2.36303261400501\n",
      "train loss:2.3460750934265677\n",
      "train loss:2.4565084872929996\n",
      "train loss:2.3522267378772783\n",
      "=== epoch:9, train acc:0.1075, test acc:0.05 ===\n",
      "train loss:2.332295003217099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.386659266721524\n",
      "train loss:2.323923794776809\n",
      "train loss:2.345348077144934\n",
      "=== epoch:10, train acc:0.11, test acc:0.04 ===\n",
      "train loss:2.369417546061472\n",
      "train loss:2.31822415805392\n",
      "train loss:2.3522632476747147\n",
      "train loss:2.3745831366864563\n",
      "=== epoch:11, train acc:0.11, test acc:0.04 ===\n",
      "train loss:2.3693753591542532\n",
      "train loss:2.3756415469065253\n",
      "train loss:2.3267023618726927\n",
      "train loss:2.3069894161962\n",
      "=== epoch:12, train acc:0.11, test acc:0.04 ===\n",
      "train loss:2.346881611640238\n",
      "train loss:2.3719334711553457\n",
      "train loss:2.3254729862029966\n",
      "train loss:2.3010222926732014\n",
      "=== epoch:13, train acc:0.115, test acc:0.04 ===\n",
      "train loss:2.282781046608937\n",
      "train loss:2.349400080221897\n",
      "train loss:2.2895523481618123\n",
      "train loss:2.3990589049913362\n",
      "=== epoch:14, train acc:0.12, test acc:0.04 ===\n",
      "train loss:2.2961236047044555\n",
      "train loss:2.3008695853315646\n",
      "train loss:2.3079693008624425\n",
      "train loss:2.33702752753089\n",
      "=== epoch:15, train acc:0.1225, test acc:0.04 ===\n",
      "train loss:2.3621762129160535\n",
      "train loss:2.332795871176521\n",
      "train loss:2.341704504833047\n",
      "train loss:2.265680006236758\n",
      "=== epoch:16, train acc:0.13, test acc:0.04 ===\n",
      "train loss:2.3411845984943147\n",
      "train loss:2.3216409297700307\n",
      "train loss:2.334224495274396\n",
      "train loss:2.383675976787259\n",
      "=== epoch:17, train acc:0.1325, test acc:0.04 ===\n",
      "train loss:2.2843707163883473\n",
      "train loss:2.284961044697776\n",
      "train loss:2.3345750719909817\n",
      "train loss:2.262641584543471\n",
      "=== epoch:18, train acc:0.1325, test acc:0.05 ===\n",
      "train loss:2.3153002454172973\n",
      "train loss:2.3389411510517086\n",
      "train loss:2.2848829780611957\n",
      "train loss:2.2807638595962914\n",
      "=== epoch:19, train acc:0.135, test acc:0.05 ===\n",
      "train loss:2.2996008187210046\n",
      "train loss:2.315571944106865\n",
      "train loss:2.286353920053695\n",
      "train loss:2.2386052598169375\n",
      "=== epoch:20, train acc:0.135, test acc:0.05 ===\n",
      "train loss:2.276166045805181\n",
      "train loss:2.3005530762818758\n",
      "train loss:2.351156287043196\n",
      "train loss:2.3253663059929384\n",
      "=== epoch:21, train acc:0.14, test acc:0.06 ===\n",
      "train loss:2.2797906179454817\n",
      "train loss:2.339697061418065\n",
      "train loss:2.311423843785545\n",
      "train loss:2.2734088014255356\n",
      "=== epoch:22, train acc:0.14, test acc:0.06 ===\n",
      "train loss:2.224998093495927\n",
      "train loss:2.2998603680507124\n",
      "train loss:2.320567888216788\n",
      "train loss:2.2613920592918135\n",
      "=== epoch:23, train acc:0.14, test acc:0.06 ===\n",
      "train loss:2.2987615883910966\n",
      "train loss:2.274360169974389\n",
      "train loss:2.267032200982704\n",
      "train loss:2.2904828149927994\n",
      "=== epoch:24, train acc:0.14, test acc:0.07 ===\n",
      "train loss:2.2875089080729274\n",
      "train loss:2.291791503374601\n",
      "train loss:2.3343465654974795\n",
      "train loss:2.2479239123579924\n",
      "=== epoch:25, train acc:0.1425, test acc:0.07 ===\n",
      "train loss:2.2509125592025043\n",
      "train loss:2.274504809225332\n",
      "train loss:2.2859024246024253\n",
      "train loss:2.273135446604624\n",
      "=== epoch:26, train acc:0.145, test acc:0.07 ===\n",
      "train loss:2.284591429339659\n",
      "train loss:2.28008311601849\n",
      "train loss:2.2904101959521346\n",
      "train loss:2.3119343347872885\n",
      "=== epoch:27, train acc:0.145, test acc:0.08 ===\n",
      "train loss:2.2558340791589613\n",
      "train loss:2.3052294249487573\n",
      "train loss:2.25540458944791\n",
      "train loss:2.2774097439649514\n",
      "=== epoch:28, train acc:0.1475, test acc:0.08 ===\n",
      "train loss:2.240907997403132\n",
      "train loss:2.2851881329126558\n",
      "train loss:2.192476057901722\n",
      "train loss:2.2924822217654524\n",
      "=== epoch:29, train acc:0.1475, test acc:0.08 ===\n",
      "train loss:2.319637404170957\n",
      "train loss:2.2526097176606785\n",
      "train loss:2.3106787147528443\n",
      "train loss:2.2809233204831103\n",
      "=== epoch:30, train acc:0.145, test acc:0.09 ===\n",
      "train loss:2.2781538501668073\n",
      "train loss:2.267934197815182\n",
      "train loss:2.2419764271374136\n",
      "train loss:2.2339937681114703\n",
      "=== epoch:31, train acc:0.1475, test acc:0.09 ===\n",
      "train loss:2.2583574876605037\n",
      "train loss:2.2392017318373596\n",
      "train loss:2.253565811997974\n",
      "train loss:2.2131573879420263\n",
      "=== epoch:32, train acc:0.1525, test acc:0.11 ===\n",
      "train loss:2.1763931272943156\n",
      "train loss:2.198677708884662\n",
      "train loss:2.2878718594792087\n",
      "train loss:2.231064064079803\n",
      "=== epoch:33, train acc:0.1575, test acc:0.11 ===\n",
      "train loss:2.2771033116576302\n",
      "train loss:2.2148110255143996\n",
      "train loss:2.2478003900031918\n",
      "train loss:2.2316057869957677\n",
      "=== epoch:34, train acc:0.16, test acc:0.12 ===\n",
      "train loss:2.218377882185928\n",
      "train loss:2.186970252473229\n",
      "train loss:2.21356297406994\n",
      "train loss:2.275969212538855\n",
      "=== epoch:35, train acc:0.1675, test acc:0.13 ===\n",
      "train loss:2.2281079499765153\n",
      "train loss:2.2452297285934555\n",
      "train loss:2.2332462726269884\n",
      "train loss:2.274736631096926\n",
      "=== epoch:36, train acc:0.1675, test acc:0.13 ===\n",
      "train loss:2.2673044337270714\n",
      "train loss:2.2009354915269395\n",
      "train loss:2.1813351944122084\n",
      "train loss:2.2453520833045366\n",
      "=== epoch:37, train acc:0.1725, test acc:0.13 ===\n",
      "train loss:2.2541431834494996\n",
      "train loss:2.246138661841557\n",
      "train loss:2.244138171787387\n",
      "train loss:2.241806193183163\n",
      "=== epoch:38, train acc:0.1725, test acc:0.13 ===\n",
      "train loss:2.206906887708348\n",
      "train loss:2.259996246221001\n",
      "train loss:2.267936819626314\n",
      "train loss:2.2268240856159847\n",
      "=== epoch:39, train acc:0.1725, test acc:0.13 ===\n",
      "train loss:2.227776189415539\n",
      "train loss:2.2424518983210047\n",
      "train loss:2.2301175918583396\n",
      "train loss:2.2203663792841932\n",
      "=== epoch:40, train acc:0.1725, test acc:0.13 ===\n",
      "train loss:2.2752170838673256\n",
      "train loss:2.2322347687107014\n",
      "train loss:2.200253649121811\n",
      "train loss:2.1916747751957955\n",
      "=== epoch:41, train acc:0.1775, test acc:0.13 ===\n",
      "train loss:2.255383971313854\n",
      "train loss:2.19727688303597\n",
      "train loss:2.19684384448128\n",
      "train loss:2.2282734802630157\n",
      "=== epoch:42, train acc:0.1875, test acc:0.14 ===\n",
      "train loss:2.2168588339554147\n",
      "train loss:2.221423074836557\n",
      "train loss:2.181115919501915\n",
      "train loss:2.197037150272635\n",
      "=== epoch:43, train acc:0.1875, test acc:0.14 ===\n",
      "train loss:2.2024786399159564\n",
      "train loss:2.2170699365662516\n",
      "train loss:2.221290906752915\n",
      "train loss:2.1729159511335348\n",
      "=== epoch:44, train acc:0.1875, test acc:0.14 ===\n",
      "train loss:2.2445416236576965\n",
      "train loss:2.21300573513466\n",
      "train loss:2.1890494507880605\n",
      "train loss:2.2025138202290884\n",
      "=== epoch:45, train acc:0.185, test acc:0.15 ===\n",
      "train loss:2.1871782908830295\n",
      "train loss:2.185593971705095\n",
      "train loss:2.220495148717352\n",
      "train loss:2.208094908050105\n",
      "=== epoch:46, train acc:0.185, test acc:0.16 ===\n",
      "train loss:2.193519480912086\n",
      "train loss:2.2263518495902\n",
      "train loss:2.2406120528348046\n",
      "train loss:2.1765319384369994\n",
      "=== epoch:47, train acc:0.1875, test acc:0.16 ===\n",
      "train loss:2.1947683193162493\n",
      "train loss:2.179198958307257\n",
      "train loss:2.202832790946624\n",
      "train loss:2.235688069733706\n",
      "=== epoch:48, train acc:0.19, test acc:0.17 ===\n",
      "train loss:2.181939686558955\n",
      "train loss:2.204722186351479\n",
      "train loss:2.187435141721971\n",
      "train loss:2.178663961519196\n",
      "=== epoch:49, train acc:0.195, test acc:0.17 ===\n",
      "train loss:2.194795172319228\n",
      "train loss:2.156836960165712\n",
      "train loss:2.2088152231328912\n",
      "train loss:2.1787379297071445\n",
      "=== epoch:50, train acc:0.1975, test acc:0.17 ===\n",
      "train loss:2.1911269937947964\n",
      "train loss:2.2189134734828864\n",
      "train loss:2.2043162121926088\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.18\n",
      "val_acc: 0.1700 | lr: 0.0010, weight_decay: 0.0000\n",
      "train loss:2.4567359808266094\n",
      "=== epoch:1, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4513481846585115\n",
      "train loss:2.4168623401653226\n",
      "train loss:2.4249070264157737\n",
      "train loss:2.5439543736127592\n",
      "=== epoch:2, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.3839290326047697\n",
      "train loss:2.4306790725858742\n",
      "train loss:2.49936672136019\n",
      "train loss:2.3762596016685564\n",
      "=== epoch:3, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.410688665517005\n",
      "train loss:2.4727081211524475\n",
      "train loss:2.4593806383253414\n",
      "train loss:2.4467634144849244\n",
      "=== epoch:4, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4545668226537463\n",
      "train loss:2.36967217484249\n",
      "train loss:2.515705075184649\n",
      "train loss:2.5520820987827313\n",
      "=== epoch:5, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4082185000050704\n",
      "train loss:2.440576537589245\n",
      "train loss:2.47132234060999\n",
      "train loss:2.529422570956614\n",
      "=== epoch:6, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4754732874141165\n",
      "train loss:2.4925397899151056\n",
      "train loss:2.4824739173268346\n",
      "train loss:2.419996661626304\n",
      "=== epoch:7, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4357933193156724\n",
      "train loss:2.462501252775183\n",
      "train loss:2.4763948727025937\n",
      "train loss:2.397624932099516\n",
      "=== epoch:8, train acc:0.11, test acc:0.15 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3478253295373825\n",
      "train loss:2.4193669555865487\n",
      "train loss:2.4646320394891914\n",
      "train loss:2.392520863528225\n",
      "=== epoch:9, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4510759907438477\n",
      "train loss:2.4468681412544893\n",
      "train loss:2.3634366288918667\n",
      "train loss:2.435514896798901\n",
      "=== epoch:10, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.5161071955452794\n",
      "train loss:2.4355131185598244\n",
      "train loss:2.4291423971674106\n",
      "train loss:2.4361345260504685\n",
      "=== epoch:11, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.488209365227777\n",
      "train loss:2.6075405232841393\n",
      "train loss:2.4343916026698382\n",
      "train loss:2.456278715391891\n",
      "=== epoch:12, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4346064159714658\n",
      "train loss:2.444950344120943\n",
      "train loss:2.505495547948922\n",
      "train loss:2.354946912201935\n",
      "=== epoch:13, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.462514815324243\n",
      "train loss:2.497905673660076\n",
      "train loss:2.4632872642938746\n",
      "train loss:2.359551632275615\n",
      "=== epoch:14, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4295164307087997\n",
      "train loss:2.4618960639992675\n",
      "train loss:2.4654520395906205\n",
      "train loss:2.5085817273516455\n",
      "=== epoch:15, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.475777474967933\n",
      "train loss:2.421367236699827\n",
      "train loss:2.3869434252282375\n",
      "train loss:2.4617662750370863\n",
      "=== epoch:16, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4663935159134063\n",
      "train loss:2.4443530908087103\n",
      "train loss:2.440471889619089\n",
      "train loss:2.4502950297677666\n",
      "=== epoch:17, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4779987387387776\n",
      "train loss:2.4200719442063043\n",
      "train loss:2.422831128605675\n",
      "train loss:2.508497254633779\n",
      "=== epoch:18, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4700748536398103\n",
      "train loss:2.4135372785642204\n",
      "train loss:2.3740494789628963\n",
      "train loss:2.4285739991360176\n",
      "=== epoch:19, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4175715815534033\n",
      "train loss:2.454120675955304\n",
      "train loss:2.444053341665025\n",
      "train loss:2.4729576469850394\n",
      "=== epoch:20, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.406522088736395\n",
      "train loss:2.4381854330000765\n",
      "train loss:2.39834852508913\n",
      "train loss:2.4522337192702404\n",
      "=== epoch:21, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.368343815281216\n",
      "train loss:2.457071712076251\n",
      "train loss:2.5044853589305958\n",
      "train loss:2.4842904626373348\n",
      "=== epoch:22, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.5050759513521106\n",
      "train loss:2.4049743436485778\n",
      "train loss:2.461503592749008\n",
      "train loss:2.414824041898958\n",
      "=== epoch:23, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4988614549207524\n",
      "train loss:2.447589904036059\n",
      "train loss:2.4692013794558756\n",
      "train loss:2.423110822069101\n",
      "=== epoch:24, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.482088344711964\n",
      "train loss:2.390258541800979\n",
      "train loss:2.430447739724818\n",
      "train loss:2.4703336297939873\n",
      "=== epoch:25, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4845233957663315\n",
      "train loss:2.390779295439582\n",
      "train loss:2.3901594351958364\n",
      "train loss:2.423809367110869\n",
      "=== epoch:26, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.3297525085385984\n",
      "train loss:2.442522268211382\n",
      "train loss:2.4790466536970874\n",
      "train loss:2.4208562007111087\n",
      "=== epoch:27, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.473572416336296\n",
      "train loss:2.334382224495512\n",
      "train loss:2.4390331738710644\n",
      "train loss:2.449976076030209\n",
      "=== epoch:28, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.47425487381496\n",
      "train loss:2.4314001679049624\n",
      "train loss:2.430694375387462\n",
      "train loss:2.4453101413737355\n",
      "=== epoch:29, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.379867545086701\n",
      "train loss:2.432951287613961\n",
      "train loss:2.450618036307096\n",
      "train loss:2.437100587769698\n",
      "=== epoch:30, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.491788382277715\n",
      "train loss:2.444767259759267\n",
      "train loss:2.4464893141335757\n",
      "train loss:2.4186249836014317\n",
      "=== epoch:31, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.533599954368726\n",
      "train loss:2.450048066704028\n",
      "train loss:2.4337036126430553\n",
      "train loss:2.4726442525698302\n",
      "=== epoch:32, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.3834317683262736\n",
      "train loss:2.4443746315268213\n",
      "train loss:2.4501967858285307\n",
      "train loss:2.4652621358826488\n",
      "=== epoch:33, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.425631338867303\n",
      "train loss:2.3992776799127973\n",
      "train loss:2.4426450993354645\n",
      "train loss:2.482509176686495\n",
      "=== epoch:34, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.433002819691718\n",
      "train loss:2.4439451011077664\n",
      "train loss:2.5255765921432882\n",
      "train loss:2.542351917044971\n",
      "=== epoch:35, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.448958650826962\n",
      "train loss:2.400362193281425\n",
      "train loss:2.4235740094675045\n",
      "train loss:2.4591621347124644\n",
      "=== epoch:36, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.5308361413929448\n",
      "train loss:2.4383854098315103\n",
      "train loss:2.4280793234794382\n",
      "train loss:2.515969083563661\n",
      "=== epoch:37, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4118706255226336\n",
      "train loss:2.46090704629218\n",
      "train loss:2.3846212232509387\n",
      "train loss:2.474113011401558\n",
      "=== epoch:38, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.490605347715415\n",
      "train loss:2.351678748393958\n",
      "train loss:2.472709737749624\n",
      "train loss:2.394121097263925\n",
      "=== epoch:39, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.36237459499645\n",
      "train loss:2.3924537942774178\n",
      "train loss:2.3873066955846474\n",
      "train loss:2.4876038854078364\n",
      "=== epoch:40, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.334573518749577\n",
      "train loss:2.412949021972777\n",
      "train loss:2.386391406668586\n",
      "train loss:2.4704442046740245\n",
      "=== epoch:41, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.438412929501868\n",
      "train loss:2.4208593365696887\n",
      "train loss:2.4538175006065046\n",
      "train loss:2.3346167207022273\n",
      "=== epoch:42, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4901903293594416\n",
      "train loss:2.4878881221052573\n",
      "train loss:2.4482123614641096\n",
      "train loss:2.4138912574193854\n",
      "=== epoch:43, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4951311228950948\n",
      "train loss:2.3851242605573635\n",
      "train loss:2.405863452524044\n",
      "train loss:2.422725479957788\n",
      "=== epoch:44, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4120553886980374\n",
      "train loss:2.468898081072022\n",
      "train loss:2.372310234204156\n",
      "train loss:2.3471688877081816\n",
      "=== epoch:45, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.555023121830227\n",
      "train loss:2.4410316829617176\n",
      "train loss:2.4568723102577654\n",
      "train loss:2.414744254049934\n",
      "=== epoch:46, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4449562419053534\n",
      "train loss:2.4541938424564584\n",
      "train loss:2.4302027617139124\n",
      "train loss:2.4566835555362494\n",
      "=== epoch:47, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4419073593596785\n",
      "train loss:2.4259821069962952\n",
      "train loss:2.3829514321340954\n",
      "train loss:2.3504880530326595\n",
      "=== epoch:48, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.4054307111919115\n",
      "train loss:2.588804845045467\n",
      "train loss:2.4336306401829213\n",
      "train loss:2.343481618113952\n",
      "=== epoch:49, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.5213841302428475\n",
      "train loss:2.484196055456311\n",
      "train loss:2.4591894289041236\n",
      "train loss:2.404835455640346\n",
      "=== epoch:50, train acc:0.11, test acc:0.15 ===\n",
      "train loss:2.432372780297482\n",
      "train loss:2.4242020327555753\n",
      "train loss:2.4767928175858382\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.15\n",
      "val_acc: 0.1500 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3947260855959027\n",
      "=== epoch:1, train acc:0.0925, test acc:0.06 ===\n",
      "train loss:2.5019285699818705\n",
      "train loss:2.3857960944666767\n",
      "train loss:2.444896291080049\n",
      "train loss:2.4824225258009527\n",
      "=== epoch:2, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.389243935720968\n",
      "train loss:2.3383642373320757\n",
      "train loss:2.5600350204448166\n",
      "train loss:2.4455063312248044\n",
      "=== epoch:3, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.3643423407425908\n",
      "train loss:2.48727978529548\n",
      "train loss:2.402851254664684\n",
      "train loss:2.493462912211366\n",
      "=== epoch:4, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.46632344509739\n",
      "train loss:2.445951271948262\n",
      "train loss:2.469564142684359\n",
      "train loss:2.4983021264852665\n",
      "=== epoch:5, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.465579565776684\n",
      "train loss:2.4693914881816093\n",
      "train loss:2.3381715536135865\n",
      "train loss:2.4727761510656365\n",
      "=== epoch:6, train acc:0.09, test acc:0.07 ===\n",
      "train loss:2.4384673130113703\n",
      "train loss:2.5402629725446353\n",
      "train loss:2.422776591010272\n",
      "train loss:2.478557734844972\n",
      "=== epoch:7, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4632812929283503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4357971296018137\n",
      "train loss:2.400263471848292\n",
      "train loss:2.4776819122410565\n",
      "=== epoch:8, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.37966544026972\n",
      "train loss:2.3997685573910528\n",
      "train loss:2.3884286786378888\n",
      "train loss:2.361306729858663\n",
      "=== epoch:9, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4032737221033833\n",
      "train loss:2.417789527679888\n",
      "train loss:2.4561678992538667\n",
      "train loss:2.4838848765344617\n",
      "=== epoch:10, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.452925017119969\n",
      "train loss:2.339990915345503\n",
      "train loss:2.4288763007987155\n",
      "train loss:2.448183966781385\n",
      "=== epoch:11, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4194668688520284\n",
      "train loss:2.418982150333961\n",
      "train loss:2.3996907371380685\n",
      "train loss:2.4811485054372\n",
      "=== epoch:12, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4663001875451114\n",
      "train loss:2.442141900795322\n",
      "train loss:2.400642649207231\n",
      "train loss:2.491787146934789\n",
      "=== epoch:13, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4252514230285014\n",
      "train loss:2.4666850010415944\n",
      "train loss:2.499786529125641\n",
      "train loss:2.4039624842973626\n",
      "=== epoch:14, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4251803521909534\n",
      "train loss:2.397616555893504\n",
      "train loss:2.3550005186117913\n",
      "train loss:2.38161561146818\n",
      "=== epoch:15, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4694758477226357\n",
      "train loss:2.4373729227819876\n",
      "train loss:2.5260489875913503\n",
      "train loss:2.454330759968218\n",
      "=== epoch:16, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.449710477379464\n",
      "train loss:2.4288690732443006\n",
      "train loss:2.437916488739572\n",
      "train loss:2.506432772847607\n",
      "=== epoch:17, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4235959268824727\n",
      "train loss:2.425708701360832\n",
      "train loss:2.5182778156740686\n",
      "train loss:2.5165358771592397\n",
      "=== epoch:18, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.4850360957294164\n",
      "train loss:2.328841462913132\n",
      "train loss:2.353925543508225\n",
      "train loss:2.443306432074436\n",
      "=== epoch:19, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.37716567046102\n",
      "train loss:2.487533346202765\n",
      "train loss:2.3289146715146107\n",
      "train loss:2.4385952915979705\n",
      "=== epoch:20, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.49371967842605\n",
      "train loss:2.481233989533432\n",
      "train loss:2.433312958546095\n",
      "train loss:2.41596955901294\n",
      "=== epoch:21, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.3277112643287046\n",
      "train loss:2.4643283549881114\n",
      "train loss:2.398771173951113\n",
      "train loss:2.336929583666703\n",
      "=== epoch:22, train acc:0.09, test acc:0.08 ===\n",
      "train loss:2.356021658030258\n",
      "train loss:2.4593933342340786\n",
      "train loss:2.3046936204933584\n",
      "train loss:2.3815274530942756\n",
      "=== epoch:23, train acc:0.0925, test acc:0.08 ===\n",
      "train loss:2.40209556415494\n",
      "train loss:2.4007218981337886\n",
      "train loss:2.4248776156847374\n",
      "train loss:2.3916929313884263\n",
      "=== epoch:24, train acc:0.0925, test acc:0.08 ===\n",
      "train loss:2.367640715857408\n",
      "train loss:2.433909929835182\n",
      "train loss:2.3835994945377736\n",
      "train loss:2.4768754182753607\n",
      "=== epoch:25, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.4065778079427287\n",
      "train loss:2.380409833072252\n",
      "train loss:2.362515239394706\n",
      "train loss:2.452314150335474\n",
      "=== epoch:26, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.4142823006938277\n",
      "train loss:2.4132047748536607\n",
      "train loss:2.481351900130159\n",
      "train loss:2.361443942034243\n",
      "=== epoch:27, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.4214917677280057\n",
      "train loss:2.4357635821767336\n",
      "train loss:2.4380857614128875\n",
      "train loss:2.3587962504042337\n",
      "=== epoch:28, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.460300027541332\n",
      "train loss:2.3992451172388214\n",
      "train loss:2.381730301096667\n",
      "train loss:2.286031722433737\n",
      "=== epoch:29, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.3809657066716787\n",
      "train loss:2.411790863504951\n",
      "train loss:2.357886463164695\n",
      "train loss:2.3854833361475305\n",
      "=== epoch:30, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.3672146474743783\n",
      "train loss:2.503697404438775\n",
      "train loss:2.3819797676902095\n",
      "train loss:2.4614899870177362\n",
      "=== epoch:31, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.454087772122367\n",
      "train loss:2.4492299107176945\n",
      "train loss:2.4506413249114614\n",
      "train loss:2.362383425320338\n",
      "=== epoch:32, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.4580118155617057\n",
      "train loss:2.4743206833173765\n",
      "train loss:2.4503646461734334\n",
      "train loss:2.4391331187988365\n",
      "=== epoch:33, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.494131638212072\n",
      "train loss:2.3575539945235917\n",
      "train loss:2.450696121442392\n",
      "train loss:2.349108791842113\n",
      "=== epoch:34, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.391739313408553\n",
      "train loss:2.403058507061647\n",
      "train loss:2.4398717166446695\n",
      "train loss:2.293803572302014\n",
      "=== epoch:35, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.3388856888296425\n",
      "train loss:2.378589422898249\n",
      "train loss:2.4440915021840595\n",
      "train loss:2.3282938504942137\n",
      "=== epoch:36, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.6294336631225983\n",
      "train loss:2.315824017023772\n",
      "train loss:2.429764426269439\n",
      "train loss:2.3294024844131327\n",
      "=== epoch:37, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.417522931292547\n",
      "train loss:2.4822035633469013\n",
      "train loss:2.3813092233761384\n",
      "train loss:2.493645513559485\n",
      "=== epoch:38, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.415549414851491\n",
      "train loss:2.4742658967916786\n",
      "train loss:2.508796946484236\n",
      "train loss:2.404527197644704\n",
      "=== epoch:39, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.39987948977605\n",
      "train loss:2.4376542302009967\n",
      "train loss:2.3973732022543475\n",
      "train loss:2.4298055961537295\n",
      "=== epoch:40, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.4140582151634\n",
      "train loss:2.4648769480145645\n",
      "train loss:2.402580495417883\n",
      "train loss:2.4610385530323247\n",
      "=== epoch:41, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.3916344219833214\n",
      "train loss:2.412879864696331\n",
      "train loss:2.541413238517873\n",
      "train loss:2.42125921777918\n",
      "=== epoch:42, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.3568059593438795\n",
      "train loss:2.5008491794050562\n",
      "train loss:2.3473763436729267\n",
      "train loss:2.449049330936219\n",
      "=== epoch:43, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.3724704077220675\n",
      "train loss:2.3874581692616\n",
      "train loss:2.412958926117023\n",
      "train loss:2.4137738723908733\n",
      "=== epoch:44, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.416492897942051\n",
      "train loss:2.304633581078771\n",
      "train loss:2.3491832880579953\n",
      "train loss:2.3263342947207715\n",
      "=== epoch:45, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.4021566915581976\n",
      "train loss:2.343934673765018\n",
      "train loss:2.3696229214067763\n",
      "train loss:2.399277020177858\n",
      "=== epoch:46, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.552207767566584\n",
      "train loss:2.4502753418081196\n",
      "train loss:2.427525550574734\n",
      "train loss:2.3140216982282715\n",
      "=== epoch:47, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.482852273467171\n",
      "train loss:2.3333662050842197\n",
      "train loss:2.437670582868012\n",
      "train loss:2.4314246548105873\n",
      "=== epoch:48, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.42394334951618\n",
      "train loss:2.437037609013009\n",
      "train loss:2.408384346245088\n",
      "train loss:2.3773411579330537\n",
      "=== epoch:49, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.449751175531355\n",
      "train loss:2.4356020413732904\n",
      "train loss:2.325351571977882\n",
      "train loss:2.43259863137733\n",
      "=== epoch:50, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.3908162905781594\n",
      "train loss:2.4496018549795147\n",
      "train loss:2.3830082074387935\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.08\n",
      "val_acc: 0.0800 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.346464733631765\n",
      "=== epoch:1, train acc:0.03, test acc:0.05 ===\n",
      "train loss:2.367478545040067\n",
      "train loss:2.3570932713866704\n",
      "train loss:2.427228877554807\n",
      "train loss:2.2717652013533884\n",
      "=== epoch:2, train acc:0.0325, test acc:0.05 ===\n",
      "train loss:2.339186549100799\n",
      "train loss:2.354662688698085\n",
      "train loss:2.3291214402902973\n",
      "train loss:2.294906444026349\n",
      "=== epoch:3, train acc:0.0325, test acc:0.05 ===\n",
      "train loss:2.332251161997422\n",
      "train loss:2.388383092028943\n",
      "train loss:2.3004826954258286\n",
      "train loss:2.324028164315645\n",
      "=== epoch:4, train acc:0.0325, test acc:0.05 ===\n",
      "train loss:2.311137476421258\n",
      "train loss:2.3630746897151234\n",
      "train loss:2.3497831084991803\n",
      "train loss:2.3562295091894367\n",
      "=== epoch:5, train acc:0.0325, test acc:0.05 ===\n",
      "train loss:2.37136518298695\n",
      "train loss:2.3899003787412436\n",
      "train loss:2.347548052208296\n",
      "train loss:2.3195817969846986\n",
      "=== epoch:6, train acc:0.04, test acc:0.05 ===\n",
      "train loss:2.343566229780865\n",
      "train loss:2.3590414733814495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.355148218400644\n",
      "train loss:2.3336716610742005\n",
      "=== epoch:7, train acc:0.0425, test acc:0.05 ===\n",
      "train loss:2.3153188603045236\n",
      "train loss:2.36471086190414\n",
      "train loss:2.290683575738571\n",
      "train loss:2.3186409065515896\n",
      "=== epoch:8, train acc:0.0475, test acc:0.05 ===\n",
      "train loss:2.2955856019142438\n",
      "train loss:2.34192550432339\n",
      "train loss:2.282689326572121\n",
      "train loss:2.3085459952744563\n",
      "=== epoch:9, train acc:0.0525, test acc:0.06 ===\n",
      "train loss:2.304798394544206\n",
      "train loss:2.3022772688825364\n",
      "train loss:2.269191984473397\n",
      "train loss:2.2946113042863603\n",
      "=== epoch:10, train acc:0.06, test acc:0.05 ===\n",
      "train loss:2.3479976406479355\n",
      "train loss:2.2908269285635563\n",
      "train loss:2.2979265537637037\n",
      "train loss:2.322790362200707\n",
      "=== epoch:11, train acc:0.065, test acc:0.06 ===\n",
      "train loss:2.2738796100431404\n",
      "train loss:2.2906338569478173\n",
      "train loss:2.303316967003881\n",
      "train loss:2.296970834610667\n",
      "=== epoch:12, train acc:0.0775, test acc:0.06 ===\n",
      "train loss:2.2794537903531946\n",
      "train loss:2.2426376262820926\n",
      "train loss:2.2474298069059646\n",
      "train loss:2.2782849246653014\n",
      "=== epoch:13, train acc:0.0775, test acc:0.06 ===\n",
      "train loss:2.2470234395503126\n",
      "train loss:2.2646343123727597\n",
      "train loss:2.238953262028222\n",
      "train loss:2.2662577180916283\n",
      "=== epoch:14, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.2477878648566985\n",
      "train loss:2.2673340927430257\n",
      "train loss:2.264984243364998\n",
      "train loss:2.276907415107326\n",
      "=== epoch:15, train acc:0.0875, test acc:0.06 ===\n",
      "train loss:2.288608943387062\n",
      "train loss:2.2749571035702854\n",
      "train loss:2.2940001758458144\n",
      "train loss:2.263683356552893\n",
      "=== epoch:16, train acc:0.095, test acc:0.07 ===\n",
      "train loss:2.2299311960899004\n",
      "train loss:2.2501936936686273\n",
      "train loss:2.2633958531209024\n",
      "train loss:2.2063326538727956\n",
      "=== epoch:17, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.210961468745016\n",
      "train loss:2.220634023529049\n",
      "train loss:2.24197235428633\n",
      "train loss:2.2133334717578075\n",
      "=== epoch:18, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.2433520219841765\n",
      "train loss:2.174488561591616\n",
      "train loss:2.2640023568962078\n",
      "train loss:2.206419947581325\n",
      "=== epoch:19, train acc:0.105, test acc:0.1 ===\n",
      "train loss:2.1958447665925647\n",
      "train loss:2.2366739634250252\n",
      "train loss:2.1979895969573766\n",
      "train loss:2.2502693328552574\n",
      "=== epoch:20, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.2298409032704756\n",
      "train loss:2.2274137772941343\n",
      "train loss:2.2078272631605897\n",
      "train loss:2.249331513054065\n",
      "=== epoch:21, train acc:0.1075, test acc:0.12 ===\n",
      "train loss:2.2340828191199087\n",
      "train loss:2.2293884246215083\n",
      "train loss:2.2160320714442334\n",
      "train loss:2.2018891418315194\n",
      "=== epoch:22, train acc:0.125, test acc:0.13 ===\n",
      "train loss:2.184068294632045\n",
      "train loss:2.213221523113665\n",
      "train loss:2.1983289508585857\n",
      "train loss:2.2172642134533875\n",
      "=== epoch:23, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.207104715246327\n",
      "train loss:2.201500644919404\n",
      "train loss:2.209881361826213\n",
      "train loss:2.208821777711741\n",
      "=== epoch:24, train acc:0.1475, test acc:0.12 ===\n",
      "train loss:2.149192906421759\n",
      "train loss:2.152841797048437\n",
      "train loss:2.207421146221526\n",
      "train loss:2.2235890437922903\n",
      "=== epoch:25, train acc:0.15, test acc:0.13 ===\n",
      "train loss:2.178465859843306\n",
      "train loss:2.193402593259531\n",
      "train loss:2.1789257146260694\n",
      "train loss:2.1794643374194496\n",
      "=== epoch:26, train acc:0.1625, test acc:0.13 ===\n",
      "train loss:2.176603205945733\n",
      "train loss:2.148785563095614\n",
      "train loss:2.179073478641331\n",
      "train loss:2.1884331846094907\n",
      "=== epoch:27, train acc:0.17, test acc:0.16 ===\n",
      "train loss:2.1783443298657224\n",
      "train loss:2.2019643927224184\n",
      "train loss:2.1237342031741475\n",
      "train loss:2.153777700491948\n",
      "=== epoch:28, train acc:0.1775, test acc:0.16 ===\n",
      "train loss:2.1486149706928326\n",
      "train loss:2.1749940320563392\n",
      "train loss:2.1406309682065956\n",
      "train loss:2.148115794058287\n",
      "=== epoch:29, train acc:0.18, test acc:0.17 ===\n",
      "train loss:2.179927122903124\n",
      "train loss:2.148074522091698\n",
      "train loss:2.1150952872120037\n",
      "train loss:2.187244830046627\n",
      "=== epoch:30, train acc:0.1875, test acc:0.18 ===\n",
      "train loss:2.1680903542855323\n",
      "train loss:2.1517666339536823\n",
      "train loss:2.1407006388613916\n",
      "train loss:2.121974844141823\n",
      "=== epoch:31, train acc:0.205, test acc:0.21 ===\n",
      "train loss:2.168008645903756\n",
      "train loss:2.0984762748490478\n",
      "train loss:2.168842490252368\n",
      "train loss:2.119272136412537\n",
      "=== epoch:32, train acc:0.2125, test acc:0.22 ===\n",
      "train loss:2.1649332785211075\n",
      "train loss:2.173406456350857\n",
      "train loss:2.1346162465418783\n",
      "train loss:2.1692278279622035\n",
      "=== epoch:33, train acc:0.23, test acc:0.23 ===\n",
      "train loss:2.0927804815108706\n",
      "train loss:2.0841529668853322\n",
      "train loss:2.0879707724116945\n",
      "train loss:2.0647589217352667\n",
      "=== epoch:34, train acc:0.2325, test acc:0.23 ===\n",
      "train loss:2.1200243374970102\n",
      "train loss:2.131567369844843\n",
      "train loss:2.1179321555833672\n",
      "train loss:2.13049411558713\n",
      "=== epoch:35, train acc:0.2475, test acc:0.23 ===\n",
      "train loss:2.101981384904026\n",
      "train loss:2.104937298577113\n",
      "train loss:2.1198245618403204\n",
      "train loss:2.1214322845979066\n",
      "=== epoch:36, train acc:0.26, test acc:0.27 ===\n",
      "train loss:2.143992996175814\n",
      "train loss:2.0893083097201344\n",
      "train loss:2.067875049408985\n",
      "train loss:2.1170736761592397\n",
      "=== epoch:37, train acc:0.2725, test acc:0.29 ===\n",
      "train loss:2.076594297506822\n",
      "train loss:2.14195877430707\n",
      "train loss:2.1143899717316827\n",
      "train loss:2.0987637348001855\n",
      "=== epoch:38, train acc:0.29, test acc:0.29 ===\n",
      "train loss:2.1077356296107355\n",
      "train loss:2.0802133208791926\n",
      "train loss:2.0428341605067035\n",
      "train loss:2.112003261359192\n",
      "=== epoch:39, train acc:0.3075, test acc:0.3 ===\n",
      "train loss:2.1010664837309676\n",
      "train loss:2.0764163695803766\n",
      "train loss:2.068728850562136\n",
      "train loss:2.047775485381616\n",
      "=== epoch:40, train acc:0.325, test acc:0.31 ===\n",
      "train loss:2.1327292014971344\n",
      "train loss:2.062314433975739\n",
      "train loss:2.0568536806711366\n",
      "train loss:2.097781833336215\n",
      "=== epoch:41, train acc:0.3425, test acc:0.33 ===\n",
      "train loss:2.0706779137354716\n",
      "train loss:2.0783493761109857\n",
      "train loss:2.088439979308109\n",
      "train loss:2.030828500576813\n",
      "=== epoch:42, train acc:0.3575, test acc:0.34 ===\n",
      "train loss:2.023668461540289\n",
      "train loss:2.062396602894675\n",
      "train loss:2.0538706644957925\n",
      "train loss:2.0903814150478377\n",
      "=== epoch:43, train acc:0.3575, test acc:0.36 ===\n",
      "train loss:2.026690848655184\n",
      "train loss:2.009085895609503\n",
      "train loss:2.0350160730277764\n",
      "train loss:2.028776100471492\n",
      "=== epoch:44, train acc:0.36, test acc:0.37 ===\n",
      "train loss:2.02309472290321\n",
      "train loss:2.0082188195389272\n",
      "train loss:2.0655619250427084\n",
      "train loss:1.998286263482877\n",
      "=== epoch:45, train acc:0.38, test acc:0.36 ===\n",
      "train loss:2.041076333823957\n",
      "train loss:2.1229411979167083\n",
      "train loss:2.045116571461276\n",
      "train loss:1.9843184029294427\n",
      "=== epoch:46, train acc:0.3875, test acc:0.4 ===\n",
      "train loss:2.005552184357164\n",
      "train loss:2.033117311314277\n",
      "train loss:1.974833515880203\n",
      "train loss:2.0477196275254737\n",
      "=== epoch:47, train acc:0.41, test acc:0.42 ===\n",
      "train loss:2.008117596666221\n",
      "train loss:2.024644393132556\n",
      "train loss:1.9611836840945247\n",
      "train loss:2.056415278589302\n",
      "=== epoch:48, train acc:0.4225, test acc:0.42 ===\n",
      "train loss:2.0021826061629358\n",
      "train loss:1.9987721472761644\n",
      "train loss:2.0113339748687604\n",
      "train loss:2.0121591397470264\n",
      "=== epoch:49, train acc:0.4275, test acc:0.43 ===\n",
      "train loss:1.9719753840417995\n",
      "train loss:1.9754217827466332\n",
      "train loss:2.014771517107236\n",
      "train loss:1.9835634920565657\n",
      "=== epoch:50, train acc:0.44, test acc:0.43 ===\n",
      "train loss:1.9377446550029487\n",
      "train loss:2.018630460169929\n",
      "train loss:2.0497166108730824\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.44\n",
      "val_acc: 0.4300 | lr: 0.0017, weight_decay: 0.0000\n",
      "train loss:2.4655620356073453\n",
      "=== epoch:1, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.47163482418853\n",
      "train loss:2.383980147116487\n",
      "train loss:2.4622184053756775\n",
      "train loss:2.3402741049188216\n",
      "=== epoch:2, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.507252170962451\n",
      "train loss:2.5624128010010265\n",
      "train loss:2.3713583393016404\n",
      "train loss:2.405320350913073\n",
      "=== epoch:3, train acc:0.105, test acc:0.09 ===\n",
      "train loss:2.3406239357713114\n",
      "train loss:2.4573149235490743\n",
      "train loss:2.4431029660195693\n",
      "train loss:2.4293586799671636\n",
      "=== epoch:4, train acc:0.1125, test acc:0.09 ===\n",
      "train loss:2.3905520321391904\n",
      "train loss:2.2895620901782054\n",
      "train loss:2.34293591935507\n",
      "train loss:2.339349202581968\n",
      "=== epoch:5, train acc:0.1125, test acc:0.1 ===\n",
      "train loss:2.4088012615471626\n",
      "train loss:2.2509605308825833\n",
      "train loss:2.3467663371282836\n",
      "train loss:2.348477377609683\n",
      "=== epoch:6, train acc:0.11, test acc:0.12 ===\n",
      "train loss:2.370330499797443\n",
      "train loss:2.2553713259346044\n",
      "train loss:2.2933743867953447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.29298303237969\n",
      "=== epoch:7, train acc:0.115, test acc:0.13 ===\n",
      "train loss:2.246958055300556\n",
      "train loss:2.3228922602969395\n",
      "train loss:2.3206689452699023\n",
      "train loss:2.341646941667914\n",
      "=== epoch:8, train acc:0.1175, test acc:0.12 ===\n",
      "train loss:2.2473512677621112\n",
      "train loss:2.3179745811902284\n",
      "train loss:2.303623352937804\n",
      "train loss:2.2123636948838743\n",
      "=== epoch:9, train acc:0.1275, test acc:0.12 ===\n",
      "train loss:2.241578023454\n",
      "train loss:2.312319181858335\n",
      "train loss:2.172447406891196\n",
      "train loss:2.2562865404013843\n",
      "=== epoch:10, train acc:0.1375, test acc:0.12 ===\n",
      "train loss:2.228186587376675\n",
      "train loss:2.2451013991222077\n",
      "train loss:2.365612753726508\n",
      "train loss:2.266722365788988\n",
      "=== epoch:11, train acc:0.14, test acc:0.11 ===\n",
      "train loss:2.2126337239565923\n",
      "train loss:2.3555019395197836\n",
      "train loss:2.286033970874352\n",
      "train loss:2.200426985350396\n",
      "=== epoch:12, train acc:0.1475, test acc:0.15 ===\n",
      "train loss:2.1601897915394455\n",
      "train loss:2.2478620681020924\n",
      "train loss:2.1849821314129017\n",
      "train loss:2.1831853173495697\n",
      "=== epoch:13, train acc:0.1475, test acc:0.15 ===\n",
      "train loss:2.2405956093114905\n",
      "train loss:2.2258672741295853\n",
      "train loss:2.216001382639506\n",
      "train loss:2.2783694212792436\n",
      "=== epoch:14, train acc:0.165, test acc:0.15 ===\n",
      "train loss:2.1814574059924907\n",
      "train loss:2.1810411096449664\n",
      "train loss:2.207114163503314\n",
      "train loss:2.206117191927079\n",
      "=== epoch:15, train acc:0.18, test acc:0.16 ===\n",
      "train loss:2.1781023320988644\n",
      "train loss:2.2269807594845985\n",
      "train loss:2.1864569010099304\n",
      "train loss:2.151312197206845\n",
      "=== epoch:16, train acc:0.1925, test acc:0.15 ===\n",
      "train loss:2.165749811449158\n",
      "train loss:2.1681475029876376\n",
      "train loss:2.211023854010249\n",
      "train loss:2.1598510911275395\n",
      "=== epoch:17, train acc:0.1975, test acc:0.17 ===\n",
      "train loss:2.105104373092794\n",
      "train loss:2.143732820313187\n",
      "train loss:2.109776407947302\n",
      "train loss:2.1511109756641114\n",
      "=== epoch:18, train acc:0.195, test acc:0.19 ===\n",
      "train loss:2.119578514914025\n",
      "train loss:2.1762927307476625\n",
      "train loss:2.1694700157089364\n",
      "train loss:2.168406447732948\n",
      "=== epoch:19, train acc:0.21, test acc:0.21 ===\n",
      "train loss:2.096094259921205\n",
      "train loss:2.1356570396538093\n",
      "train loss:2.1612012042064372\n",
      "train loss:2.0985962096610455\n",
      "=== epoch:20, train acc:0.22, test acc:0.21 ===\n",
      "train loss:2.1675398019009697\n",
      "train loss:2.140344417765038\n",
      "train loss:2.2063494643977166\n",
      "train loss:2.2168443902377937\n",
      "=== epoch:21, train acc:0.2325, test acc:0.22 ===\n",
      "train loss:2.217218455847017\n",
      "train loss:2.190996525307172\n",
      "train loss:2.1577956054125518\n",
      "train loss:2.109381940132817\n",
      "=== epoch:22, train acc:0.2375, test acc:0.22 ===\n",
      "train loss:2.107916027553757\n",
      "train loss:2.09577667371422\n",
      "train loss:2.1719520768917517\n",
      "train loss:2.1377938885557124\n",
      "=== epoch:23, train acc:0.255, test acc:0.25 ===\n",
      "train loss:2.1630035994215424\n",
      "train loss:2.15271698281093\n",
      "train loss:2.1164496139440643\n",
      "train loss:2.1546849021219296\n",
      "=== epoch:24, train acc:0.27, test acc:0.26 ===\n",
      "train loss:2.1346746211330965\n",
      "train loss:2.042980558150677\n",
      "train loss:2.040587149297928\n",
      "train loss:2.148757151361581\n",
      "=== epoch:25, train acc:0.2725, test acc:0.29 ===\n",
      "train loss:2.178143544714558\n",
      "train loss:2.1777041723663766\n",
      "train loss:2.0590283207910813\n",
      "train loss:2.0572984752796954\n",
      "=== epoch:26, train acc:0.3025, test acc:0.29 ===\n",
      "train loss:2.0340687899556698\n",
      "train loss:2.143663380110407\n",
      "train loss:1.9779549266793168\n",
      "train loss:2.0728591335903745\n",
      "=== epoch:27, train acc:0.3025, test acc:0.3 ===\n",
      "train loss:2.045764040176384\n",
      "train loss:2.0844798409661256\n",
      "train loss:2.0788895279860373\n",
      "train loss:2.0877814320374966\n",
      "=== epoch:28, train acc:0.32, test acc:0.3 ===\n",
      "train loss:2.084683907283511\n",
      "train loss:2.069280513307785\n",
      "train loss:2.0673317387046017\n",
      "train loss:2.0682440017001236\n",
      "=== epoch:29, train acc:0.3225, test acc:0.3 ===\n",
      "train loss:2.0315783228213307\n",
      "train loss:2.0598184611708654\n",
      "train loss:2.0646988882761073\n",
      "train loss:2.0558475158446883\n",
      "=== epoch:30, train acc:0.3325, test acc:0.32 ===\n",
      "train loss:2.077536334145688\n",
      "train loss:2.005493867470304\n",
      "train loss:2.0153610868576823\n",
      "train loss:2.0771859084282256\n",
      "=== epoch:31, train acc:0.3425, test acc:0.32 ===\n",
      "train loss:2.062234573014914\n",
      "train loss:2.0589422497713996\n",
      "train loss:2.081611264065663\n",
      "train loss:1.9521707347621544\n",
      "=== epoch:32, train acc:0.355, test acc:0.36 ===\n",
      "train loss:2.0449577726188695\n",
      "train loss:2.0062258822274313\n",
      "train loss:2.03263597877071\n",
      "train loss:2.0247186772924084\n",
      "=== epoch:33, train acc:0.355, test acc:0.36 ===\n",
      "train loss:2.0349405057939625\n",
      "train loss:2.027928700161885\n",
      "train loss:1.9956723330030053\n",
      "train loss:1.895833289840638\n",
      "=== epoch:34, train acc:0.3625, test acc:0.37 ===\n",
      "train loss:2.067746679467473\n",
      "train loss:2.028886504223594\n",
      "train loss:1.9913953352272773\n",
      "train loss:1.9546519800936026\n",
      "=== epoch:35, train acc:0.375, test acc:0.39 ===\n",
      "train loss:2.051013260202525\n",
      "train loss:2.0241057172116936\n",
      "train loss:2.0431065135225617\n",
      "train loss:1.9781666009861043\n",
      "=== epoch:36, train acc:0.3825, test acc:0.37 ===\n",
      "train loss:1.9681283760211632\n",
      "train loss:2.051528214606026\n",
      "train loss:1.9889227858333276\n",
      "train loss:2.028266966414609\n",
      "=== epoch:37, train acc:0.375, test acc:0.36 ===\n",
      "train loss:1.9578989768108974\n",
      "train loss:1.9625817397989378\n",
      "train loss:1.9905401437260055\n",
      "train loss:1.9253648365728855\n",
      "=== epoch:38, train acc:0.3975, test acc:0.41 ===\n",
      "train loss:2.0071793831219993\n",
      "train loss:2.0011269363835855\n",
      "train loss:1.916245970707061\n",
      "train loss:1.9720550418134084\n",
      "=== epoch:39, train acc:0.41, test acc:0.44 ===\n",
      "train loss:1.910071971802659\n",
      "train loss:1.928013942290123\n",
      "train loss:1.9933758600004978\n",
      "train loss:1.9284707744667773\n",
      "=== epoch:40, train acc:0.4375, test acc:0.46 ===\n",
      "train loss:1.9347541811464402\n",
      "train loss:2.013256367815153\n",
      "train loss:1.9568638534765619\n",
      "train loss:1.8993000244760583\n",
      "=== epoch:41, train acc:0.445, test acc:0.45 ===\n",
      "train loss:1.8816074505247664\n",
      "train loss:1.8578649763592792\n",
      "train loss:2.049486816234389\n",
      "train loss:1.890863065234274\n",
      "=== epoch:42, train acc:0.4475, test acc:0.46 ===\n",
      "train loss:1.9313553364038807\n",
      "train loss:1.9570475632745414\n",
      "train loss:1.9183675467635322\n",
      "train loss:2.0002897338184265\n",
      "=== epoch:43, train acc:0.4475, test acc:0.46 ===\n",
      "train loss:1.8910492192900978\n",
      "train loss:1.9189824587036826\n",
      "train loss:1.922724256209634\n",
      "train loss:1.9199594073608066\n",
      "=== epoch:44, train acc:0.455, test acc:0.47 ===\n",
      "train loss:1.9148209856373264\n",
      "train loss:1.9631652449875325\n",
      "train loss:1.940694437523125\n",
      "train loss:1.863192358561368\n",
      "=== epoch:45, train acc:0.4475, test acc:0.46 ===\n",
      "train loss:1.976160776702349\n",
      "train loss:1.9436998393102536\n",
      "train loss:1.9332882022899955\n",
      "train loss:1.9042887413717897\n",
      "=== epoch:46, train acc:0.455, test acc:0.48 ===\n",
      "train loss:1.9466066433647216\n",
      "train loss:1.8973129448803436\n",
      "train loss:1.90044596991002\n",
      "train loss:1.874467289284322\n",
      "=== epoch:47, train acc:0.465, test acc:0.47 ===\n",
      "train loss:1.8535837882926085\n",
      "train loss:1.912686530782677\n",
      "train loss:1.8607161980871112\n",
      "train loss:1.9214763385112752\n",
      "=== epoch:48, train acc:0.4675, test acc:0.47 ===\n",
      "train loss:1.9371203930805414\n",
      "train loss:1.8635448919184614\n",
      "train loss:1.90771153552153\n",
      "train loss:1.9104365470626457\n",
      "=== epoch:49, train acc:0.475, test acc:0.47 ===\n",
      "train loss:1.841340300201627\n",
      "train loss:1.8499468735313873\n",
      "train loss:1.8877068973792228\n",
      "train loss:1.8576301005124056\n",
      "=== epoch:50, train acc:0.4725, test acc:0.47 ===\n",
      "train loss:1.8440855645693566\n",
      "train loss:1.7995114734213373\n",
      "train loss:1.9070259121696844\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.48\n",
      "val_acc: 0.4700 | lr: 0.0018, weight_decay: 0.0000\n",
      "train loss:2.38720710827687\n",
      "=== epoch:1, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.3098248494420757\n",
      "train loss:2.3958241814936048\n",
      "train loss:2.380990187870782\n",
      "train loss:2.354763693338011\n",
      "=== epoch:2, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.3715195519248202\n",
      "train loss:2.413788522068674\n",
      "train loss:2.3995583761666524\n",
      "train loss:2.381341096174875\n",
      "=== epoch:3, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.4134316835155345\n",
      "train loss:2.413184381565409\n",
      "train loss:2.4041813273143933\n",
      "train loss:2.432544257786283\n",
      "=== epoch:4, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.326674374483357\n",
      "train loss:2.406665782862531\n",
      "train loss:2.3551298824002966\n",
      "train loss:2.3331105375592776\n",
      "=== epoch:5, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.3785498326590626\n",
      "train loss:2.394840330610363\n",
      "train loss:2.422898950991648\n",
      "train loss:2.3548149251087866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:6, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.3762994459865703\n",
      "train loss:2.3711743254940454\n",
      "train loss:2.3747550425374016\n",
      "train loss:2.3767064945807084\n",
      "=== epoch:7, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.3644287233720465\n",
      "train loss:2.389061542550989\n",
      "train loss:2.3754237538795553\n",
      "train loss:2.3730267444065016\n",
      "=== epoch:8, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.385628176893182\n",
      "train loss:2.438923510901036\n",
      "train loss:2.4144745397904175\n",
      "train loss:2.3662614321792756\n",
      "=== epoch:9, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.418495176680561\n",
      "train loss:2.3334907407434415\n",
      "train loss:2.3976244384349576\n",
      "train loss:2.334016390343452\n",
      "=== epoch:10, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4198675039610293\n",
      "train loss:2.378519738394818\n",
      "train loss:2.3608199357307957\n",
      "train loss:2.4191571282497533\n",
      "=== epoch:11, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.400844200029503\n",
      "train loss:2.400506026159184\n",
      "train loss:2.401427254192737\n",
      "train loss:2.3728665520898264\n",
      "=== epoch:12, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4106448652966095\n",
      "train loss:2.3737417851408718\n",
      "train loss:2.4009480838174033\n",
      "train loss:2.423426053343178\n",
      "=== epoch:13, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3973362948245236\n",
      "train loss:2.3536095770725836\n",
      "train loss:2.389036032955189\n",
      "train loss:2.4426710756045624\n",
      "=== epoch:14, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3503299276163063\n",
      "train loss:2.407212671060044\n",
      "train loss:2.401226231680375\n",
      "train loss:2.3695022294121704\n",
      "=== epoch:15, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4480008274179323\n",
      "train loss:2.3331134256821664\n",
      "train loss:2.379644332824367\n",
      "train loss:2.3837057745331833\n",
      "=== epoch:16, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3773843913349717\n",
      "train loss:2.3787276305875973\n",
      "train loss:2.4078738314217336\n",
      "train loss:2.407925926972463\n",
      "=== epoch:17, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.365799189572567\n",
      "train loss:2.407539424808167\n",
      "train loss:2.395700144607269\n",
      "train loss:2.3639414943223724\n",
      "=== epoch:18, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3981567877067547\n",
      "train loss:2.3570381418304422\n",
      "train loss:2.380621131661551\n",
      "train loss:2.3785968200968717\n",
      "=== epoch:19, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.41804355678874\n",
      "train loss:2.3993751638285206\n",
      "train loss:2.433556221393971\n",
      "train loss:2.4228187555372838\n",
      "=== epoch:20, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3632802085041504\n",
      "train loss:2.406165715277023\n",
      "train loss:2.3649363931935183\n",
      "train loss:2.370055795157329\n",
      "=== epoch:21, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3834667173389046\n",
      "train loss:2.396284845513627\n",
      "train loss:2.3973836389103034\n",
      "train loss:2.4200123994622253\n",
      "=== epoch:22, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4286922053787086\n",
      "train loss:2.359472202029298\n",
      "train loss:2.4099986945696257\n",
      "train loss:2.3456840319323904\n",
      "=== epoch:23, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3881399620674686\n",
      "train loss:2.415878405483187\n",
      "train loss:2.4134194733610146\n",
      "train loss:2.395887162536827\n",
      "=== epoch:24, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.372449357436173\n",
      "train loss:2.4419645197266218\n",
      "train loss:2.385554055455301\n",
      "train loss:2.4022016609116648\n",
      "=== epoch:25, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4179540959337853\n",
      "train loss:2.3819515343141595\n",
      "train loss:2.3734054020195687\n",
      "train loss:2.357481651934052\n",
      "=== epoch:26, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3744748523623134\n",
      "train loss:2.3852837170184564\n",
      "train loss:2.38822733491577\n",
      "train loss:2.437373711953903\n",
      "=== epoch:27, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.339223749278586\n",
      "train loss:2.4072302903717673\n",
      "train loss:2.404864492942168\n",
      "train loss:2.412386891422771\n",
      "=== epoch:28, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.418302085568564\n",
      "train loss:2.3521830638803083\n",
      "train loss:2.4227505444739728\n",
      "train loss:2.3829419149836255\n",
      "=== epoch:29, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.425595201837694\n",
      "train loss:2.385483702380534\n",
      "train loss:2.4079182559573007\n",
      "train loss:2.384588597100318\n",
      "=== epoch:30, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4197023446580435\n",
      "train loss:2.3968192414652028\n",
      "train loss:2.360628920942094\n",
      "train loss:2.3598279145904404\n",
      "=== epoch:31, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3396313569328213\n",
      "train loss:2.3978555143537856\n",
      "train loss:2.365511619918071\n",
      "train loss:2.357505304344214\n",
      "=== epoch:32, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4296589404329962\n",
      "train loss:2.39831168605927\n",
      "train loss:2.3861997368446133\n",
      "train loss:2.393008270526966\n",
      "=== epoch:33, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.336330377589594\n",
      "train loss:2.426437040292156\n",
      "train loss:2.3793467640883206\n",
      "train loss:2.331819689232241\n",
      "=== epoch:34, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.41147516473373\n",
      "train loss:2.4148819838532614\n",
      "train loss:2.4422894819436936\n",
      "train loss:2.3861881347599465\n",
      "=== epoch:35, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.390882696177289\n",
      "train loss:2.423712064034614\n",
      "train loss:2.4106450859610074\n",
      "train loss:2.4204687010727937\n",
      "=== epoch:36, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3986051223440024\n",
      "train loss:2.4292285428306317\n",
      "train loss:2.33925907870131\n",
      "train loss:2.345873517603109\n",
      "=== epoch:37, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.403430834108941\n",
      "train loss:2.433932036474138\n",
      "train loss:2.3689723514547696\n",
      "train loss:2.388238952474132\n",
      "=== epoch:38, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3760143996774525\n",
      "train loss:2.353131504462392\n",
      "train loss:2.4383496785807113\n",
      "train loss:2.3953562633349135\n",
      "=== epoch:39, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3884646616422245\n",
      "train loss:2.3482485731841893\n",
      "train loss:2.386550800351889\n",
      "train loss:2.41711809018699\n",
      "=== epoch:40, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.378522465652978\n",
      "train loss:2.3909602801500527\n",
      "train loss:2.3998531779434256\n",
      "train loss:2.319276945436627\n",
      "=== epoch:41, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3766262058606\n",
      "train loss:2.37201400076368\n",
      "train loss:2.404428187952556\n",
      "train loss:2.4240676604804507\n",
      "=== epoch:42, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4179560679881598\n",
      "train loss:2.377247326292237\n",
      "train loss:2.394141876627954\n",
      "train loss:2.3723358108752284\n",
      "=== epoch:43, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.389819890903452\n",
      "train loss:2.4212064524739794\n",
      "train loss:2.3828491875978015\n",
      "train loss:2.378836146405944\n",
      "=== epoch:44, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3954344622562793\n",
      "train loss:2.3793628878883295\n",
      "train loss:2.4051305216688346\n",
      "train loss:2.3946963068803395\n",
      "=== epoch:45, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3823136482215728\n",
      "train loss:2.418929165037247\n",
      "train loss:2.4236983780917334\n",
      "train loss:2.3768961109539366\n",
      "=== epoch:46, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.374738280999794\n",
      "train loss:2.340995032838731\n",
      "train loss:2.3560503512963935\n",
      "train loss:2.364232604815443\n",
      "=== epoch:47, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3695195727046423\n",
      "train loss:2.371011766439171\n",
      "train loss:2.364474620834782\n",
      "train loss:2.4383400514483515\n",
      "=== epoch:48, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.4186195476622245\n",
      "train loss:2.403894721197744\n",
      "train loss:2.4233047060038353\n",
      "train loss:2.368617352569807\n",
      "=== epoch:49, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3619328710085847\n",
      "train loss:2.4040778837506913\n",
      "train loss:2.3890708880750795\n",
      "train loss:2.389819537664925\n",
      "=== epoch:50, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.359712879761771\n",
      "train loss:2.391168679615999\n",
      "train loss:2.402157963698356\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.13\n",
      "val_acc: 0.1300 | lr: 0.0000, weight_decay: 0.0001\n",
      "train loss:2.344900813088033\n",
      "=== epoch:1, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.376416414933409\n",
      "train loss:2.344249352855456\n",
      "train loss:2.4608594357497355\n",
      "train loss:2.378600261294666\n",
      "=== epoch:2, train acc:0.1125, test acc:0.11 ===\n",
      "train loss:2.3297661283123294\n",
      "train loss:2.3342525749931973\n",
      "train loss:2.3499745328454904\n",
      "train loss:2.243974489852611\n",
      "=== epoch:3, train acc:0.14, test acc:0.11 ===\n",
      "train loss:2.28933898884696\n",
      "train loss:2.2535357947907135\n",
      "train loss:2.339122595100411\n",
      "train loss:2.255078673273698\n",
      "=== epoch:4, train acc:0.1575, test acc:0.11 ===\n",
      "train loss:2.2955375883766833\n",
      "train loss:2.3040785206014327\n",
      "train loss:2.279724391289989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.295477528432685\n",
      "=== epoch:5, train acc:0.18, test acc:0.15 ===\n",
      "train loss:2.209262614443273\n",
      "train loss:2.2338124194088356\n",
      "train loss:2.2737950411094614\n",
      "train loss:2.297986357061518\n",
      "=== epoch:6, train acc:0.195, test acc:0.16 ===\n",
      "train loss:2.2482168521241594\n",
      "train loss:2.309670439111348\n",
      "train loss:2.195340688216574\n",
      "train loss:2.222052179784434\n",
      "=== epoch:7, train acc:0.21, test acc:0.18 ===\n",
      "train loss:2.222300043408995\n",
      "train loss:2.2675289726443855\n",
      "train loss:2.249803200827161\n",
      "train loss:2.167032598083945\n",
      "=== epoch:8, train acc:0.2325, test acc:0.21 ===\n",
      "train loss:2.208204876940672\n",
      "train loss:2.232547300350492\n",
      "train loss:2.25082742663503\n",
      "train loss:2.244788546943425\n",
      "=== epoch:9, train acc:0.245, test acc:0.22 ===\n",
      "train loss:2.1936312714028148\n",
      "train loss:2.1896478359030422\n",
      "train loss:2.1718060133392023\n",
      "train loss:2.1560452373408037\n",
      "=== epoch:10, train acc:0.2525, test acc:0.22 ===\n",
      "train loss:2.161300269601519\n",
      "train loss:2.20753423434574\n",
      "train loss:2.1899884147370807\n",
      "train loss:2.1980496377701906\n",
      "=== epoch:11, train acc:0.2725, test acc:0.22 ===\n",
      "train loss:2.189310437018429\n",
      "train loss:2.1739861426078932\n",
      "train loss:2.142617190402133\n",
      "train loss:2.1328647049567437\n",
      "=== epoch:12, train acc:0.29, test acc:0.23 ===\n",
      "train loss:2.1494973902565793\n",
      "train loss:2.1615883380630607\n",
      "train loss:2.180426880872092\n",
      "train loss:2.1092708352050242\n",
      "=== epoch:13, train acc:0.2925, test acc:0.23 ===\n",
      "train loss:2.169079592877178\n",
      "train loss:2.1464098559312017\n",
      "train loss:2.1432701617880903\n",
      "train loss:2.1285554414980488\n",
      "=== epoch:14, train acc:0.3075, test acc:0.24 ===\n",
      "train loss:2.1254937201187594\n",
      "train loss:2.1053833057625138\n",
      "train loss:2.1287655804183014\n",
      "train loss:2.105467403605712\n",
      "=== epoch:15, train acc:0.325, test acc:0.26 ===\n",
      "train loss:2.1194476065008514\n",
      "train loss:2.1259592346224028\n",
      "train loss:2.05687118342656\n",
      "train loss:2.080790763964086\n",
      "=== epoch:16, train acc:0.345, test acc:0.3 ===\n",
      "train loss:2.0890274693932582\n",
      "train loss:2.103706717724345\n",
      "train loss:2.0927125712411643\n",
      "train loss:2.08517454112641\n",
      "=== epoch:17, train acc:0.355, test acc:0.32 ===\n",
      "train loss:2.0569655109872595\n",
      "train loss:2.1699599292088014\n",
      "train loss:1.9963329704797903\n",
      "train loss:2.1716957655712252\n",
      "=== epoch:18, train acc:0.3625, test acc:0.33 ===\n",
      "train loss:2.1141907770456747\n",
      "train loss:2.0987156106901903\n",
      "train loss:2.050028984352065\n",
      "train loss:1.9800672554829541\n",
      "=== epoch:19, train acc:0.375, test acc:0.33 ===\n",
      "train loss:2.007814168589184\n",
      "train loss:2.150347555292935\n",
      "train loss:2.089365234193204\n",
      "train loss:2.08026533687821\n",
      "=== epoch:20, train acc:0.3925, test acc:0.37 ===\n",
      "train loss:1.9874243826316118\n",
      "train loss:2.1026160712162807\n",
      "train loss:2.0025404727027296\n",
      "train loss:1.9540041694980304\n",
      "=== epoch:21, train acc:0.4175, test acc:0.36 ===\n",
      "train loss:2.00634606934056\n",
      "train loss:2.0706524396358508\n",
      "train loss:2.0146209142686673\n",
      "train loss:2.0099346487310754\n",
      "=== epoch:22, train acc:0.4375, test acc:0.41 ===\n",
      "train loss:2.0080680115490344\n",
      "train loss:1.985557163221761\n",
      "train loss:2.0177972712088583\n",
      "train loss:1.931144716101401\n",
      "=== epoch:23, train acc:0.4625, test acc:0.45 ===\n",
      "train loss:2.004997158946926\n",
      "train loss:1.9996853462537538\n",
      "train loss:1.990534720364326\n",
      "train loss:1.9402957809417365\n",
      "=== epoch:24, train acc:0.4675, test acc:0.45 ===\n",
      "train loss:1.966657204471505\n",
      "train loss:2.021467037987814\n",
      "train loss:1.9997602620512982\n",
      "train loss:1.9385737379941472\n",
      "=== epoch:25, train acc:0.5, test acc:0.48 ===\n",
      "train loss:1.9352162167201639\n",
      "train loss:1.9222433986783152\n",
      "train loss:1.9362778970954453\n",
      "train loss:1.9902752193981812\n",
      "=== epoch:26, train acc:0.5025, test acc:0.5 ===\n",
      "train loss:1.9060921367552484\n",
      "train loss:1.9248433215737495\n",
      "train loss:1.9348791689696476\n",
      "train loss:1.8571552860386487\n",
      "=== epoch:27, train acc:0.5275, test acc:0.52 ===\n",
      "train loss:1.982369821086561\n",
      "train loss:1.885284524052052\n",
      "train loss:1.950904398832858\n",
      "train loss:1.8356340249305758\n",
      "=== epoch:28, train acc:0.545, test acc:0.55 ===\n",
      "train loss:1.8949111168229025\n",
      "train loss:1.8539133582164242\n",
      "train loss:1.8925393864267754\n",
      "train loss:1.8084585024824547\n",
      "=== epoch:29, train acc:0.545, test acc:0.55 ===\n",
      "train loss:1.933690501864714\n",
      "train loss:1.76384892871092\n",
      "train loss:1.8458891630772616\n",
      "train loss:1.8906460513201757\n",
      "=== epoch:30, train acc:0.54, test acc:0.55 ===\n",
      "train loss:1.9790791202546174\n",
      "train loss:1.8870025440326306\n",
      "train loss:1.8950558533304471\n",
      "train loss:1.877111151407229\n",
      "=== epoch:31, train acc:0.5625, test acc:0.56 ===\n",
      "train loss:1.8476546740528417\n",
      "train loss:1.9362277019223775\n",
      "train loss:1.8355508958023274\n",
      "train loss:1.7532102137232506\n",
      "=== epoch:32, train acc:0.5775, test acc:0.57 ===\n",
      "train loss:1.7371272314825097\n",
      "train loss:1.822725424802325\n",
      "train loss:1.7910488486186282\n",
      "train loss:1.840309022193779\n",
      "=== epoch:33, train acc:0.5925, test acc:0.59 ===\n",
      "train loss:1.7116762527480291\n",
      "train loss:1.8188042213803868\n",
      "train loss:1.812777694665153\n",
      "train loss:1.7883936391660546\n",
      "=== epoch:34, train acc:0.6, test acc:0.61 ===\n",
      "train loss:1.7109494090968993\n",
      "train loss:1.7780690565885635\n",
      "train loss:1.7759061253901156\n",
      "train loss:1.722102975664118\n",
      "=== epoch:35, train acc:0.61, test acc:0.61 ===\n",
      "train loss:1.7168887783620834\n",
      "train loss:1.6740075813504476\n",
      "train loss:1.7634550055183928\n",
      "train loss:1.7055256059107406\n",
      "=== epoch:36, train acc:0.6175, test acc:0.61 ===\n",
      "train loss:1.5651403685374534\n",
      "train loss:1.751236314387624\n",
      "train loss:1.776317743402612\n",
      "train loss:1.7464085868801893\n",
      "=== epoch:37, train acc:0.63, test acc:0.62 ===\n",
      "train loss:1.6897490967224744\n",
      "train loss:1.6180783535262082\n",
      "train loss:1.6608272845855823\n",
      "train loss:1.7191065638478613\n",
      "=== epoch:38, train acc:0.63, test acc:0.65 ===\n",
      "train loss:1.64969948878732\n",
      "train loss:1.7773967854097363\n",
      "train loss:1.5738634323676266\n",
      "train loss:1.5842588980586707\n",
      "=== epoch:39, train acc:0.645, test acc:0.65 ===\n",
      "train loss:1.6704769495516538\n",
      "train loss:1.4966688721445498\n",
      "train loss:1.6570003091268999\n",
      "train loss:1.483882714907554\n",
      "=== epoch:40, train acc:0.635, test acc:0.66 ===\n",
      "train loss:1.5907856033091108\n",
      "train loss:1.6588270708643873\n",
      "train loss:1.6055458718330897\n",
      "train loss:1.5378593089838895\n",
      "=== epoch:41, train acc:0.645, test acc:0.68 ===\n",
      "train loss:1.5717829127805583\n",
      "train loss:1.5572251094398888\n",
      "train loss:1.5922882402230671\n",
      "train loss:1.518746930912888\n",
      "=== epoch:42, train acc:0.65, test acc:0.68 ===\n",
      "train loss:1.5561347138434227\n",
      "train loss:1.5401490288745945\n",
      "train loss:1.5588201610409012\n",
      "train loss:1.5415610282078178\n",
      "=== epoch:43, train acc:0.6675, test acc:0.68 ===\n",
      "train loss:1.542830216638606\n",
      "train loss:1.534492484176881\n",
      "train loss:1.5230685923536087\n",
      "train loss:1.5174446365215013\n",
      "=== epoch:44, train acc:0.6625, test acc:0.69 ===\n",
      "train loss:1.6178671728158758\n",
      "train loss:1.5892053469588887\n",
      "train loss:1.4725474862400785\n",
      "train loss:1.463372873441963\n",
      "=== epoch:45, train acc:0.6775, test acc:0.69 ===\n",
      "train loss:1.4364432238899383\n",
      "train loss:1.5121971459025727\n",
      "train loss:1.3912314896778388\n",
      "train loss:1.4277363632595725\n",
      "=== epoch:46, train acc:0.68, test acc:0.69 ===\n",
      "train loss:1.3787590882660712\n",
      "train loss:1.4006376058787922\n",
      "train loss:1.5017380967005787\n",
      "train loss:1.4547900892783685\n",
      "=== epoch:47, train acc:0.69, test acc:0.7 ===\n",
      "train loss:1.4532861788587474\n",
      "train loss:1.4657427710217863\n",
      "train loss:1.4834918827859642\n",
      "train loss:1.3880433141884156\n",
      "=== epoch:48, train acc:0.6925, test acc:0.69 ===\n",
      "train loss:1.3063192085185915\n",
      "train loss:1.3428620873615724\n",
      "train loss:1.5058927944612324\n",
      "train loss:1.3586915701126507\n",
      "=== epoch:49, train acc:0.6975, test acc:0.69 ===\n",
      "train loss:1.2880687325843503\n",
      "train loss:1.2527458976096697\n",
      "train loss:1.394361824472634\n",
      "train loss:1.3398483132474353\n",
      "=== epoch:50, train acc:0.7, test acc:0.69 ===\n",
      "train loss:1.345133693231143\n",
      "train loss:1.4065078243874825\n",
      "train loss:1.3517043459953333\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.69\n",
      "val_acc: 0.6900 | lr: 0.0045, weight_decay: 0.0000\n",
      "train loss:2.2507239478129537\n",
      "=== epoch:1, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.279430215380077\n",
      "train loss:2.288286879541793\n",
      "train loss:2.334863107338569\n",
      "train loss:2.3405684317121214\n",
      "=== epoch:2, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.2995436554217\n",
      "train loss:2.2812971479648465\n",
      "train loss:2.301397271837089\n",
      "train loss:2.2791506426982564\n",
      "=== epoch:3, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.2847652286046265\n",
      "train loss:2.298889489456436\n",
      "train loss:2.280783573633497\n",
      "train loss:2.2356810371655516\n",
      "=== epoch:4, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.3369161636127362\n",
      "train loss:2.310207776874568\n",
      "train loss:2.2605259556509574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2792371272778023\n",
      "=== epoch:5, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.270332901225212\n",
      "train loss:2.2929135438967005\n",
      "train loss:2.2872358026643114\n",
      "train loss:2.291315398714463\n",
      "=== epoch:6, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.294375625103333\n",
      "train loss:2.287713654491137\n",
      "train loss:2.331095422023427\n",
      "train loss:2.3508147599290794\n",
      "=== epoch:7, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.284575815560669\n",
      "train loss:2.3268296250490272\n",
      "train loss:2.29349818027089\n",
      "train loss:2.2742976782840074\n",
      "=== epoch:8, train acc:0.1, test acc:0.18 ===\n",
      "train loss:2.234492111302313\n",
      "train loss:2.3588937600816076\n",
      "train loss:2.32830865702882\n",
      "train loss:2.289346492480333\n",
      "=== epoch:9, train acc:0.1, test acc:0.18 ===\n",
      "train loss:2.2988334277252727\n",
      "train loss:2.3311883656065766\n",
      "train loss:2.264063803262921\n",
      "train loss:2.29888974565914\n",
      "=== epoch:10, train acc:0.1, test acc:0.18 ===\n",
      "train loss:2.3358428588377036\n",
      "train loss:2.27290822842929\n",
      "train loss:2.309088753359302\n",
      "train loss:2.2888692330319365\n",
      "=== epoch:11, train acc:0.1, test acc:0.18 ===\n",
      "train loss:2.2807466848257407\n",
      "train loss:2.306439872360231\n",
      "train loss:2.3269489422651755\n",
      "train loss:2.308767676533217\n",
      "=== epoch:12, train acc:0.1025, test acc:0.18 ===\n",
      "train loss:2.2680177776805457\n",
      "train loss:2.3328679911314922\n",
      "train loss:2.281132494270587\n",
      "train loss:2.290247676007476\n",
      "=== epoch:13, train acc:0.1025, test acc:0.18 ===\n",
      "train loss:2.2953827850865904\n",
      "train loss:2.2664532147681244\n",
      "train loss:2.3175672488311068\n",
      "train loss:2.3073294594798543\n",
      "=== epoch:14, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.2794436836499634\n",
      "train loss:2.2634125758302686\n",
      "train loss:2.2538990990971586\n",
      "train loss:2.2846866691055228\n",
      "=== epoch:15, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.327981763486416\n",
      "train loss:2.3343072109944507\n",
      "train loss:2.3101796056132726\n",
      "train loss:2.2794395886165533\n",
      "=== epoch:16, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.2678930033449998\n",
      "train loss:2.264960498973874\n",
      "train loss:2.304830315795718\n",
      "train loss:2.286093897995211\n",
      "=== epoch:17, train acc:0.1025, test acc:0.18 ===\n",
      "train loss:2.290243426818207\n",
      "train loss:2.263734788032976\n",
      "train loss:2.2860167304316934\n",
      "train loss:2.2807951373233926\n",
      "=== epoch:18, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.3222339672048227\n",
      "train loss:2.282622876728629\n",
      "train loss:2.3025693435650227\n",
      "train loss:2.2421734794873833\n",
      "=== epoch:19, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.319850112486111\n",
      "train loss:2.272605125227768\n",
      "train loss:2.2991710503302243\n",
      "train loss:2.285061247129008\n",
      "=== epoch:20, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.3355116333727617\n",
      "train loss:2.3085161673206502\n",
      "train loss:2.336079028523216\n",
      "train loss:2.248920810442137\n",
      "=== epoch:21, train acc:0.105, test acc:0.18 ===\n",
      "train loss:2.2819800229713474\n",
      "train loss:2.2388708060705467\n",
      "train loss:2.283130632988045\n",
      "train loss:2.318107398001503\n",
      "=== epoch:22, train acc:0.105, test acc:0.17 ===\n",
      "train loss:2.3174401031152594\n",
      "train loss:2.3353418604067646\n",
      "train loss:2.3263208135748665\n",
      "train loss:2.2773570776881753\n",
      "=== epoch:23, train acc:0.105, test acc:0.17 ===\n",
      "train loss:2.337726617018597\n",
      "train loss:2.2864124984272474\n",
      "train loss:2.3153149180504626\n",
      "train loss:2.269325561170327\n",
      "=== epoch:24, train acc:0.105, test acc:0.17 ===\n",
      "train loss:2.289277044720872\n",
      "train loss:2.3544532479018323\n",
      "train loss:2.2835391395047067\n",
      "train loss:2.2746461215039875\n",
      "=== epoch:25, train acc:0.11, test acc:0.18 ===\n",
      "train loss:2.303428892313707\n",
      "train loss:2.244131512913209\n",
      "train loss:2.3009949376067693\n",
      "train loss:2.2226097821612227\n",
      "=== epoch:26, train acc:0.11, test acc:0.18 ===\n",
      "train loss:2.304906796950628\n",
      "train loss:2.302744155325506\n",
      "train loss:2.2564604657910334\n",
      "train loss:2.2938719421941536\n",
      "=== epoch:27, train acc:0.11, test acc:0.18 ===\n",
      "train loss:2.3021964375906103\n",
      "train loss:2.3038017904074066\n",
      "train loss:2.3048061233222255\n",
      "train loss:2.337431023925739\n",
      "=== epoch:28, train acc:0.11, test acc:0.18 ===\n",
      "train loss:2.274012364992337\n",
      "train loss:2.3472263278592562\n",
      "train loss:2.291911949069858\n",
      "train loss:2.280845991585973\n",
      "=== epoch:29, train acc:0.11, test acc:0.18 ===\n",
      "train loss:2.2849860596647145\n",
      "train loss:2.262536828332774\n",
      "train loss:2.2939141411688215\n",
      "train loss:2.271965946109433\n",
      "=== epoch:30, train acc:0.1125, test acc:0.18 ===\n",
      "train loss:2.2702144366960035\n",
      "train loss:2.298463226582358\n",
      "train loss:2.3076925253512224\n",
      "train loss:2.237910095297362\n",
      "=== epoch:31, train acc:0.1125, test acc:0.18 ===\n",
      "train loss:2.3133568044685577\n",
      "train loss:2.3180462247344344\n",
      "train loss:2.298755708470368\n",
      "train loss:2.3409370915459164\n",
      "=== epoch:32, train acc:0.1125, test acc:0.18 ===\n",
      "train loss:2.2678001354730317\n",
      "train loss:2.2386924543627713\n",
      "train loss:2.274465012206909\n",
      "train loss:2.275072452050896\n",
      "=== epoch:33, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.2978247154868336\n",
      "train loss:2.334005281777102\n",
      "train loss:2.26600303089014\n",
      "train loss:2.254032857179259\n",
      "=== epoch:34, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.3117681650400344\n",
      "train loss:2.2650273361861015\n",
      "train loss:2.270379199181811\n",
      "train loss:2.2610713739091763\n",
      "=== epoch:35, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.2292765894495\n",
      "train loss:2.297954088430663\n",
      "train loss:2.2551791004332316\n",
      "train loss:2.297137892403748\n",
      "=== epoch:36, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.274432716282756\n",
      "train loss:2.3099161557581143\n",
      "train loss:2.2825959734898915\n",
      "train loss:2.253160411803865\n",
      "=== epoch:37, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.294840551781132\n",
      "train loss:2.3102060918977196\n",
      "train loss:2.2996857287764545\n",
      "train loss:2.242265186978428\n",
      "=== epoch:38, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.266573537349943\n",
      "train loss:2.2642845281161446\n",
      "train loss:2.2214759598214546\n",
      "train loss:2.282326942143231\n",
      "=== epoch:39, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.25459532221434\n",
      "train loss:2.273940629038694\n",
      "train loss:2.302877004448307\n",
      "train loss:2.2540779750247726\n",
      "=== epoch:40, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.298750652025992\n",
      "train loss:2.287580457876297\n",
      "train loss:2.2786012146831522\n",
      "train loss:2.2578516452979542\n",
      "=== epoch:41, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.259708568034376\n",
      "train loss:2.2992284684378115\n",
      "train loss:2.282790788886908\n",
      "train loss:2.248107303194768\n",
      "=== epoch:42, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.3214049150179346\n",
      "train loss:2.30424984746233\n",
      "train loss:2.3104293201710324\n",
      "train loss:2.228710008886391\n",
      "=== epoch:43, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.3134989751584416\n",
      "train loss:2.293374672844995\n",
      "train loss:2.28080399895163\n",
      "train loss:2.2758256454829775\n",
      "=== epoch:44, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.2749031041788133\n",
      "train loss:2.268816449851512\n",
      "train loss:2.3436171226733378\n",
      "train loss:2.293483020113121\n",
      "=== epoch:45, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.2766426674106057\n",
      "train loss:2.2676188864999007\n",
      "train loss:2.2969017468849153\n",
      "train loss:2.3172584006406165\n",
      "=== epoch:46, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.2534098369711586\n",
      "train loss:2.2716877508379008\n",
      "train loss:2.2625847070026417\n",
      "train loss:2.3189247733078435\n",
      "=== epoch:47, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.3257601595084094\n",
      "train loss:2.269855719333608\n",
      "train loss:2.243320931549322\n",
      "train loss:2.2627654678826743\n",
      "=== epoch:48, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.3271006123038855\n",
      "train loss:2.3018446966919552\n",
      "train loss:2.249201850987754\n",
      "train loss:2.2283188584133162\n",
      "=== epoch:49, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.286867913133307\n",
      "train loss:2.262126316428824\n",
      "train loss:2.2868988678472917\n",
      "train loss:2.315947511589558\n",
      "=== epoch:50, train acc:0.1125, test acc:0.17 ===\n",
      "train loss:2.3075319825112626\n",
      "train loss:2.2408920333351965\n",
      "train loss:2.339897555690329\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.17\n",
      "val_acc: 0.1700 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.466489489979691\n",
      "=== epoch:1, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.49163468867445\n",
      "train loss:2.399951139634338\n",
      "train loss:2.334403696460506\n",
      "train loss:2.3873711177362167\n",
      "=== epoch:2, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.495050913277559\n",
      "train loss:2.5141084793526733\n",
      "train loss:2.3939398755916175\n",
      "train loss:2.417721851964618\n",
      "=== epoch:3, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.44062727864282\n",
      "train loss:2.4584697632474475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3893689700776948\n",
      "train loss:2.449791527256849\n",
      "=== epoch:4, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.5596190935957575\n",
      "train loss:2.466067121938383\n",
      "train loss:2.3623146883915753\n",
      "train loss:2.4232172534971124\n",
      "=== epoch:5, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.372888629363916\n",
      "train loss:2.521336329170552\n",
      "train loss:2.4724591747036286\n",
      "train loss:2.4387029200570143\n",
      "=== epoch:6, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.474606540335505\n",
      "train loss:2.459431581543182\n",
      "train loss:2.4542384375009405\n",
      "train loss:2.4835631853807176\n",
      "=== epoch:7, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4141408820144497\n",
      "train loss:2.427259622738793\n",
      "train loss:2.4776406971576037\n",
      "train loss:2.414619622395757\n",
      "=== epoch:8, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.503560487706604\n",
      "train loss:2.3818383991600167\n",
      "train loss:2.2846278682409507\n",
      "train loss:2.498563823427471\n",
      "=== epoch:9, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.457648481400027\n",
      "train loss:2.40606318445136\n",
      "train loss:2.461698655900964\n",
      "train loss:2.46333613896292\n",
      "=== epoch:10, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4386292567903585\n",
      "train loss:2.4417690164744434\n",
      "train loss:2.4411288797594564\n",
      "train loss:2.389899836805024\n",
      "=== epoch:11, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.374940885250371\n",
      "train loss:2.3781071025631717\n",
      "train loss:2.441732733731295\n",
      "train loss:2.432032084767675\n",
      "=== epoch:12, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.488477725133825\n",
      "train loss:2.4423996355915927\n",
      "train loss:2.347263634949221\n",
      "train loss:2.421234611192562\n",
      "=== epoch:13, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.489228018485001\n",
      "train loss:2.4938948882965173\n",
      "train loss:2.428964258896717\n",
      "train loss:2.4183562145153896\n",
      "=== epoch:14, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4506497161750582\n",
      "train loss:2.4177662091522953\n",
      "train loss:2.371653958998062\n",
      "train loss:2.417903901198573\n",
      "=== epoch:15, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4654412490604978\n",
      "train loss:2.4023680455815164\n",
      "train loss:2.3802214942117894\n",
      "train loss:2.4693301058972983\n",
      "=== epoch:16, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4300873510504477\n",
      "train loss:2.4013216239698365\n",
      "train loss:2.4026819020200536\n",
      "train loss:2.44650381012424\n",
      "=== epoch:17, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4553268069199925\n",
      "train loss:2.3908274817618143\n",
      "train loss:2.405351791263804\n",
      "train loss:2.4203035551709107\n",
      "=== epoch:18, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.3361242638736885\n",
      "train loss:2.4288553669735684\n",
      "train loss:2.467347675723471\n",
      "train loss:2.3513066646921312\n",
      "=== epoch:19, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4510439306426\n",
      "train loss:2.4771956817636775\n",
      "train loss:2.4244859043352966\n",
      "train loss:2.3986143226274437\n",
      "=== epoch:20, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.3396211342550433\n",
      "train loss:2.5518158266073283\n",
      "train loss:2.4602146177420856\n",
      "train loss:2.4481566288389875\n",
      "=== epoch:21, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4623518343552733\n",
      "train loss:2.3736682514301175\n",
      "train loss:2.39141669886011\n",
      "train loss:2.3477776396741525\n",
      "=== epoch:22, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.429833070083114\n",
      "train loss:2.4798964738293283\n",
      "train loss:2.3994874465490037\n",
      "train loss:2.4952999506263147\n",
      "=== epoch:23, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.5302651873850097\n",
      "train loss:2.4761073393952246\n",
      "train loss:2.4967845481723274\n",
      "train loss:2.476943917322904\n",
      "=== epoch:24, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.576449325710217\n",
      "train loss:2.318281749546721\n",
      "train loss:2.5015411896037203\n",
      "train loss:2.385087834596532\n",
      "=== epoch:25, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4837166982465178\n",
      "train loss:2.331230525966903\n",
      "train loss:2.381837539258911\n",
      "train loss:2.41279677406084\n",
      "=== epoch:26, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4398867115583123\n",
      "train loss:2.3858790458453587\n",
      "train loss:2.414613257486063\n",
      "train loss:2.47499032055456\n",
      "=== epoch:27, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4204674995934248\n",
      "train loss:2.4009515635575687\n",
      "train loss:2.395647469519458\n",
      "train loss:2.414881110284952\n",
      "=== epoch:28, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4248658479209966\n",
      "train loss:2.3938487998858013\n",
      "train loss:2.330848497209502\n",
      "train loss:2.4188595410952374\n",
      "=== epoch:29, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.333783750706184\n",
      "train loss:2.419263554094142\n",
      "train loss:2.4915034183966474\n",
      "train loss:2.4888323626767233\n",
      "=== epoch:30, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4254209317591853\n",
      "train loss:2.35133125999048\n",
      "train loss:2.4113244160145357\n",
      "train loss:2.474248272746514\n",
      "=== epoch:31, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.2964788741970388\n",
      "train loss:2.388961154653201\n",
      "train loss:2.3950127327049007\n",
      "train loss:2.463639092002314\n",
      "=== epoch:32, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.5036552260168405\n",
      "train loss:2.437578445014314\n",
      "train loss:2.428977770769518\n",
      "train loss:2.454267944333135\n",
      "=== epoch:33, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4014008293746762\n",
      "train loss:2.4662695273518938\n",
      "train loss:2.47829105936754\n",
      "train loss:2.4183280967033522\n",
      "=== epoch:34, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4753001057844584\n",
      "train loss:2.325790195896292\n",
      "train loss:2.510198191073539\n",
      "train loss:2.379378592146767\n",
      "=== epoch:35, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.365260085013509\n",
      "train loss:2.4982216542893325\n",
      "train loss:2.3987171201224\n",
      "train loss:2.4894913996880517\n",
      "=== epoch:36, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.445178106947487\n",
      "train loss:2.505102656053722\n",
      "train loss:2.4125522613568484\n",
      "train loss:2.410903694521439\n",
      "=== epoch:37, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.416211360761799\n",
      "train loss:2.3545409767739427\n",
      "train loss:2.4407128589061884\n",
      "train loss:2.4028176798777787\n",
      "=== epoch:38, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.477725184044491\n",
      "train loss:2.430789795933293\n",
      "train loss:2.3577330558967304\n",
      "train loss:2.434934496472232\n",
      "=== epoch:39, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.426980682887507\n",
      "train loss:2.4582668432545036\n",
      "train loss:2.4685050318809636\n",
      "train loss:2.479431065755976\n",
      "=== epoch:40, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.489726577924461\n",
      "train loss:2.451427219442202\n",
      "train loss:2.462224987287074\n",
      "train loss:2.4164110625907833\n",
      "=== epoch:41, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.423419758491099\n",
      "train loss:2.4335235451633985\n",
      "train loss:2.398524601848564\n",
      "train loss:2.378703138815735\n",
      "=== epoch:42, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.375287668250973\n",
      "train loss:2.3656191984889006\n",
      "train loss:2.4932758671356376\n",
      "train loss:2.413760245329513\n",
      "=== epoch:43, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.3975932537055273\n",
      "train loss:2.4101611385487827\n",
      "train loss:2.3294182769379637\n",
      "train loss:2.3877576099530446\n",
      "=== epoch:44, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.409251969360153\n",
      "train loss:2.3839662277915368\n",
      "train loss:2.4509107256458655\n",
      "train loss:2.3678206903197516\n",
      "=== epoch:45, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4074345384091367\n",
      "train loss:2.5270257886397456\n",
      "train loss:2.4272468316143585\n",
      "train loss:2.4138344751016128\n",
      "=== epoch:46, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.500327160470849\n",
      "train loss:2.35855846090641\n",
      "train loss:2.417108664554078\n",
      "train loss:2.5202808751914016\n",
      "=== epoch:47, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4049707814232106\n",
      "train loss:2.5130359978867642\n",
      "train loss:2.449705743024869\n",
      "train loss:2.5568277300433535\n",
      "=== epoch:48, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4073678077071454\n",
      "train loss:2.490403878324838\n",
      "train loss:2.4377497658555813\n",
      "train loss:2.410848394422096\n",
      "=== epoch:49, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.410423730842477\n",
      "train loss:2.4699249398611807\n",
      "train loss:2.4769255034428985\n",
      "train loss:2.36666354511413\n",
      "=== epoch:50, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.376065401245329\n",
      "train loss:2.3573325118329844\n",
      "train loss:2.440190020412969\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.11\n",
      "val_acc: 0.1100 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3745195916118114\n",
      "=== epoch:1, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4311735399135315\n",
      "train loss:2.403516953766538\n",
      "train loss:2.425912431194894\n",
      "train loss:2.352965128627015\n",
      "=== epoch:2, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.287508415793057\n",
      "train loss:2.4189887034428494\n",
      "train loss:2.4401564325032554\n",
      "train loss:2.4218569767164717\n",
      "=== epoch:3, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.398581458921028\n",
      "train loss:2.3940034373861705\n",
      "train loss:2.3304491946475347\n",
      "train loss:2.3978640619215175\n",
      "=== epoch:4, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4442939094152765\n",
      "train loss:2.4452648488642392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4398656763489077\n",
      "train loss:2.3745901375394256\n",
      "=== epoch:5, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4067674097088094\n",
      "train loss:2.41681841390118\n",
      "train loss:2.4815865374163586\n",
      "train loss:2.4329443275663176\n",
      "=== epoch:6, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3757961353795625\n",
      "train loss:2.380798312276389\n",
      "train loss:2.444495861789589\n",
      "train loss:2.4449534074287693\n",
      "=== epoch:7, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4480941931009665\n",
      "train loss:2.3783616142944966\n",
      "train loss:2.37340568886327\n",
      "train loss:2.4136916106552375\n",
      "=== epoch:8, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4303833242425528\n",
      "train loss:2.383397710284476\n",
      "train loss:2.3281886180517146\n",
      "train loss:2.3833751552728466\n",
      "=== epoch:9, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.36855934775117\n",
      "train loss:2.417850966297029\n",
      "train loss:2.3524519619509707\n",
      "train loss:2.4013299950306064\n",
      "=== epoch:10, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3183423550155613\n",
      "train loss:2.3390885034986035\n",
      "train loss:2.3029334830032737\n",
      "train loss:2.411442030491188\n",
      "=== epoch:11, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4203594904462826\n",
      "train loss:2.4041036954417825\n",
      "train loss:2.4168144611744187\n",
      "train loss:2.272585869207696\n",
      "=== epoch:12, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.378922489012225\n",
      "train loss:2.362516144172688\n",
      "train loss:2.378018654807923\n",
      "train loss:2.368489581307802\n",
      "=== epoch:13, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3717338180257994\n",
      "train loss:2.4190256927622666\n",
      "train loss:2.440781278793377\n",
      "train loss:2.331537969271013\n",
      "=== epoch:14, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.473888995305701\n",
      "train loss:2.3139136341949276\n",
      "train loss:2.4027794955235358\n",
      "train loss:2.36839168083912\n",
      "=== epoch:15, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3376406258720666\n",
      "train loss:2.357020888006633\n",
      "train loss:2.350186705489404\n",
      "train loss:2.4733577142827925\n",
      "=== epoch:16, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4057127178715074\n",
      "train loss:2.4462074043339874\n",
      "train loss:2.454692813113473\n",
      "train loss:2.4507114231095377\n",
      "=== epoch:17, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.381999323549984\n",
      "train loss:2.3092895668768874\n",
      "train loss:2.3999849339488324\n",
      "train loss:2.3245679134404025\n",
      "=== epoch:18, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.408019944113048\n",
      "train loss:2.4048835337025154\n",
      "train loss:2.416394441919053\n",
      "train loss:2.382452686591281\n",
      "=== epoch:19, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3830483047536437\n",
      "train loss:2.402710783299769\n",
      "train loss:2.3533626732217074\n",
      "train loss:2.414603456858357\n",
      "=== epoch:20, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3629913415821355\n",
      "train loss:2.3717870049251486\n",
      "train loss:2.3515109004491137\n",
      "train loss:2.4735168240747507\n",
      "=== epoch:21, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4571956469335974\n",
      "train loss:2.4216869205605778\n",
      "train loss:2.2935298507453425\n",
      "train loss:2.355625845128893\n",
      "=== epoch:22, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.363068926043984\n",
      "train loss:2.3875139539029404\n",
      "train loss:2.388109175085207\n",
      "train loss:2.450282783201972\n",
      "=== epoch:23, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.435672613378755\n",
      "train loss:2.3583245893723395\n",
      "train loss:2.352506973308793\n",
      "train loss:2.4308873251252874\n",
      "=== epoch:24, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4079990190229856\n",
      "train loss:2.3272936530067208\n",
      "train loss:2.359379024089546\n",
      "train loss:2.340996393760515\n",
      "=== epoch:25, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.399549925193019\n",
      "train loss:2.4051260127211673\n",
      "train loss:2.3817897830504524\n",
      "train loss:2.3479416699624336\n",
      "=== epoch:26, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3159248498852825\n",
      "train loss:2.3882585868557524\n",
      "train loss:2.412348064669069\n",
      "train loss:2.3768709724748773\n",
      "=== epoch:27, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.326599175338764\n",
      "train loss:2.4282777109372007\n",
      "train loss:2.314797325325167\n",
      "train loss:2.3821308201649622\n",
      "=== epoch:28, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.375908150224173\n",
      "train loss:2.3263828927515764\n",
      "train loss:2.443146546852123\n",
      "train loss:2.394771041027195\n",
      "=== epoch:29, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3484813585094777\n",
      "train loss:2.3474119998048737\n",
      "train loss:2.375429851322291\n",
      "train loss:2.371883719316095\n",
      "=== epoch:30, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3740737610387543\n",
      "train loss:2.342008094568054\n",
      "train loss:2.476417481534462\n",
      "train loss:2.471021823644719\n",
      "=== epoch:31, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3372078525831355\n",
      "train loss:2.375320560974741\n",
      "train loss:2.4112192933959076\n",
      "train loss:2.3094264888254123\n",
      "=== epoch:32, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3687938306915517\n",
      "train loss:2.4322892634480096\n",
      "train loss:2.4245741757543846\n",
      "train loss:2.3785656927661813\n",
      "=== epoch:33, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3264990581908584\n",
      "train loss:2.4458908871259233\n",
      "train loss:2.3861462932615365\n",
      "train loss:2.3744605371165823\n",
      "=== epoch:34, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.347420897920381\n",
      "train loss:2.291744899226412\n",
      "train loss:2.3291572080763623\n",
      "train loss:2.460316099889758\n",
      "=== epoch:35, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.436251139874649\n",
      "train loss:2.394785919930775\n",
      "train loss:2.3131405857032945\n",
      "train loss:2.364629448936912\n",
      "=== epoch:36, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.451234505453556\n",
      "train loss:2.4076593496284273\n",
      "train loss:2.386041878452549\n",
      "train loss:2.423633177066129\n",
      "=== epoch:37, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3840123009770506\n",
      "train loss:2.3869000099909137\n",
      "train loss:2.368077165887537\n",
      "train loss:2.3963267747146637\n",
      "=== epoch:38, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.338422734208649\n",
      "train loss:2.37291063483383\n",
      "train loss:2.3793989894763263\n",
      "train loss:2.424192814934603\n",
      "=== epoch:39, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3967696062818\n",
      "train loss:2.369900760250433\n",
      "train loss:2.398510994185586\n",
      "train loss:2.353128942521891\n",
      "=== epoch:40, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4490859486716867\n",
      "train loss:2.361560671203017\n",
      "train loss:2.3635979371245854\n",
      "train loss:2.323882878210395\n",
      "=== epoch:41, train acc:0.125, test acc:0.12 ===\n",
      "train loss:2.5373100624634257\n",
      "train loss:2.3474468648609252\n",
      "train loss:2.347816060174353\n",
      "train loss:2.387327748772602\n",
      "=== epoch:42, train acc:0.125, test acc:0.12 ===\n",
      "train loss:2.4496318848779772\n",
      "train loss:2.4440097522338027\n",
      "train loss:2.4184064616892393\n",
      "train loss:2.367769822852326\n",
      "=== epoch:43, train acc:0.125, test acc:0.12 ===\n",
      "train loss:2.3828190607803093\n",
      "train loss:2.4898084196185355\n",
      "train loss:2.3650388565666316\n",
      "train loss:2.37221277083136\n",
      "=== epoch:44, train acc:0.125, test acc:0.12 ===\n",
      "train loss:2.357428419736701\n",
      "train loss:2.4226008326084028\n",
      "train loss:2.372297338270242\n",
      "train loss:2.307007313780161\n",
      "=== epoch:45, train acc:0.1275, test acc:0.12 ===\n",
      "train loss:2.4396721060385036\n",
      "train loss:2.3548791264272277\n",
      "train loss:2.3872323902853556\n",
      "train loss:2.291021931478881\n",
      "=== epoch:46, train acc:0.13, test acc:0.12 ===\n",
      "train loss:2.3241273904009283\n",
      "train loss:2.418532086422334\n",
      "train loss:2.40523191993412\n",
      "train loss:2.4882164165981404\n",
      "=== epoch:47, train acc:0.13, test acc:0.12 ===\n",
      "train loss:2.3189581510441877\n",
      "train loss:2.2976129768540745\n",
      "train loss:2.409671933459182\n",
      "train loss:2.39305924081807\n",
      "=== epoch:48, train acc:0.13, test acc:0.12 ===\n",
      "train loss:2.3666805597552334\n",
      "train loss:2.3967404601086137\n",
      "train loss:2.398677301030923\n",
      "train loss:2.378165710009567\n",
      "=== epoch:49, train acc:0.13, test acc:0.12 ===\n",
      "train loss:2.3453570904267984\n",
      "train loss:2.40461018861298\n",
      "train loss:2.4116795724095237\n",
      "train loss:2.4381545152613997\n",
      "=== epoch:50, train acc:0.13, test acc:0.12 ===\n",
      "train loss:2.4596779561148003\n",
      "train loss:2.3595535028120898\n",
      "train loss:2.304783538998837\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4042321636649224\n",
      "=== epoch:1, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4027460307836246\n",
      "train loss:2.4188810554157425\n",
      "train loss:2.3852695480237056\n",
      "train loss:2.446722800982692\n",
      "=== epoch:2, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.47084394392524\n",
      "train loss:2.3868549436894138\n",
      "train loss:2.4251921549143542\n",
      "train loss:2.3319944695007626\n",
      "=== epoch:3, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3473791302640454\n",
      "train loss:2.3619708030667144\n",
      "train loss:2.4139443164114924\n",
      "train loss:2.4667702283195885\n",
      "=== epoch:4, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3783944114588444\n",
      "train loss:2.373580504447692\n",
      "train loss:2.439692948570262\n",
      "train loss:2.424327885980413\n",
      "=== epoch:5, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.463710724000557\n",
      "train loss:2.4154049216544817\n",
      "train loss:2.3882036313319888\n",
      "train loss:2.361190820784598\n",
      "=== epoch:6, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3617585485429062\n",
      "train loss:2.383400020228337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4447516961390217\n",
      "train loss:2.418210202794632\n",
      "=== epoch:7, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4150795262942926\n",
      "train loss:2.4404216602635715\n",
      "train loss:2.4625485826237066\n",
      "train loss:2.392634503143891\n",
      "=== epoch:8, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.474277032025349\n",
      "train loss:2.433250967290338\n",
      "train loss:2.3585475013256687\n",
      "train loss:2.455588634546663\n",
      "=== epoch:9, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4428221046715706\n",
      "train loss:2.362630781684501\n",
      "train loss:2.4286838884198065\n",
      "train loss:2.3974869132508787\n",
      "=== epoch:10, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3704716261830217\n",
      "train loss:2.385683977052483\n",
      "train loss:2.5213483829825543\n",
      "train loss:2.417502218494842\n",
      "=== epoch:11, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.372301372743399\n",
      "train loss:2.44307096104118\n",
      "train loss:2.470280581846384\n",
      "train loss:2.4064765971731203\n",
      "=== epoch:12, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.364207460039753\n",
      "train loss:2.388827888371713\n",
      "train loss:2.467268778716512\n",
      "train loss:2.38855039940141\n",
      "=== epoch:13, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4361854879097993\n",
      "train loss:2.4282235115380146\n",
      "train loss:2.4090551097873845\n",
      "train loss:2.3852745781007902\n",
      "=== epoch:14, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3815617431012073\n",
      "train loss:2.3603700593676296\n",
      "train loss:2.408758749084727\n",
      "train loss:2.405481299678186\n",
      "=== epoch:15, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.425636606663696\n",
      "train loss:2.414286515951857\n",
      "train loss:2.411433679608384\n",
      "train loss:2.312032854116115\n",
      "=== epoch:16, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.449838606555721\n",
      "train loss:2.463122861660654\n",
      "train loss:2.399520120356724\n",
      "train loss:2.396160447921707\n",
      "=== epoch:17, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.402382485765528\n",
      "train loss:2.3810778866365063\n",
      "train loss:2.483231542666176\n",
      "train loss:2.462407577636476\n",
      "=== epoch:18, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3894521106659248\n",
      "train loss:2.420409656713048\n",
      "train loss:2.4188896302071483\n",
      "train loss:2.4090368093482617\n",
      "=== epoch:19, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4222902701365867\n",
      "train loss:2.399398551926001\n",
      "train loss:2.3123724679792574\n",
      "train loss:2.4238773816128765\n",
      "=== epoch:20, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.407165311687758\n",
      "train loss:2.45075790071396\n",
      "train loss:2.37554629294755\n",
      "train loss:2.4408199753651103\n",
      "=== epoch:21, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.418623425440841\n",
      "train loss:2.4211950071078823\n",
      "train loss:2.364108653798112\n",
      "train loss:2.4275536316221964\n",
      "=== epoch:22, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.391429628131801\n",
      "train loss:2.3261014256834756\n",
      "train loss:2.3609307391336873\n",
      "train loss:2.5039808812217186\n",
      "=== epoch:23, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4624592281456117\n",
      "train loss:2.4697806821910206\n",
      "train loss:2.3444880530566534\n",
      "train loss:2.44057755682539\n",
      "=== epoch:24, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4391892918279567\n",
      "train loss:2.397793865224258\n",
      "train loss:2.4205694669912967\n",
      "train loss:2.4609365747890415\n",
      "=== epoch:25, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.41243845085426\n",
      "train loss:2.423798764301306\n",
      "train loss:2.4504892309308457\n",
      "train loss:2.4789879512093993\n",
      "=== epoch:26, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.395392314577101\n",
      "train loss:2.375814755701774\n",
      "train loss:2.35184236163679\n",
      "train loss:2.422987353445407\n",
      "=== epoch:27, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4667013382281606\n",
      "train loss:2.3652503054641603\n",
      "train loss:2.395775702100418\n",
      "train loss:2.4243155704561947\n",
      "=== epoch:28, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.385156789882233\n",
      "train loss:2.3537088805803834\n",
      "train loss:2.49585601896388\n",
      "train loss:2.3517203915520195\n",
      "=== epoch:29, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.387220383716205\n",
      "train loss:2.3352477703436354\n",
      "train loss:2.3966200320676836\n",
      "train loss:2.475791045026844\n",
      "=== epoch:30, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4466304008015856\n",
      "train loss:2.3529321494619118\n",
      "train loss:2.3993253337390326\n",
      "train loss:2.3990068889852005\n",
      "=== epoch:31, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.514264886170232\n",
      "train loss:2.443556462001671\n",
      "train loss:2.4186683590937745\n",
      "train loss:2.329717736950836\n",
      "=== epoch:32, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4318978197866623\n",
      "train loss:2.4169069305233\n",
      "train loss:2.380033198013992\n",
      "train loss:2.4516883899543167\n",
      "=== epoch:33, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.431891424674071\n",
      "train loss:2.4254965241912707\n",
      "train loss:2.3423446406806465\n",
      "train loss:2.4650921325236674\n",
      "=== epoch:34, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.500978175878859\n",
      "train loss:2.433241782679182\n",
      "train loss:2.4273489775847965\n",
      "train loss:2.4513733191843983\n",
      "=== epoch:35, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.384019017269874\n",
      "train loss:2.397867569708242\n",
      "train loss:2.379463504358021\n",
      "train loss:2.408546125790125\n",
      "=== epoch:36, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4486749565189005\n",
      "train loss:2.3667481373236265\n",
      "train loss:2.388140222162365\n",
      "train loss:2.4381912621799633\n",
      "=== epoch:37, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.376200616480866\n",
      "train loss:2.430085435830307\n",
      "train loss:2.3197091284843534\n",
      "train loss:2.4893702935281365\n",
      "=== epoch:38, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3589739060216415\n",
      "train loss:2.375828527523778\n",
      "train loss:2.374161768192063\n",
      "train loss:2.4109120156981625\n",
      "=== epoch:39, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3192042096194685\n",
      "train loss:2.465173150431781\n",
      "train loss:2.3520318502077764\n",
      "train loss:2.4655730835169245\n",
      "=== epoch:40, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4135116796674314\n",
      "train loss:2.4216950257026406\n",
      "train loss:2.500730758093515\n",
      "train loss:2.403909892346031\n",
      "=== epoch:41, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4484259515234044\n",
      "train loss:2.3923013492151313\n",
      "train loss:2.4277071132262\n",
      "train loss:2.4026323116300463\n",
      "=== epoch:42, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.439620378099349\n",
      "train loss:2.387753376557697\n",
      "train loss:2.3341140739312607\n",
      "train loss:2.421518313536858\n",
      "=== epoch:43, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3752335595057494\n",
      "train loss:2.4190936803043024\n",
      "train loss:2.470675588393792\n",
      "train loss:2.3880455494538686\n",
      "=== epoch:44, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4812665135973115\n",
      "train loss:2.4436825749284288\n",
      "train loss:2.4355922639356353\n",
      "train loss:2.4715584415653176\n",
      "=== epoch:45, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.462321114837238\n",
      "train loss:2.500081841860892\n",
      "train loss:2.4731078633831336\n",
      "train loss:2.4335306302047535\n",
      "=== epoch:46, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.388548958637246\n",
      "train loss:2.402399423817539\n",
      "train loss:2.4808533711342253\n",
      "train loss:2.3186480533399867\n",
      "=== epoch:47, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4407727082088844\n",
      "train loss:2.499976620697979\n",
      "train loss:2.3557634703026276\n",
      "train loss:2.331523095360083\n",
      "=== epoch:48, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.4148778084391207\n",
      "train loss:2.421874336769253\n",
      "train loss:2.3519628508101293\n",
      "train loss:2.3995450803232945\n",
      "=== epoch:49, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3960023699303843\n",
      "train loss:2.350762616250846\n",
      "train loss:2.382194984939786\n",
      "train loss:2.4278135976855344\n",
      "=== epoch:50, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.419561842096181\n",
      "train loss:2.3999079324969483\n",
      "train loss:2.472894366839588\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4652309917454307\n",
      "=== epoch:1, train acc:0.1025, test acc:0.1 ===\n",
      "train loss:2.4716330012432177\n",
      "train loss:2.4809541890219142\n",
      "train loss:2.399985594679097\n",
      "train loss:2.352828285084102\n",
      "=== epoch:2, train acc:0.1125, test acc:0.1 ===\n",
      "train loss:2.4011267682543425\n",
      "train loss:2.4087100709105456\n",
      "train loss:2.427030993349987\n",
      "train loss:2.4504646523446594\n",
      "=== epoch:3, train acc:0.11, test acc:0.09 ===\n",
      "train loss:2.424391862400542\n",
      "train loss:2.3906630940113915\n",
      "train loss:2.3706706626510328\n",
      "train loss:2.399468084072829\n",
      "=== epoch:4, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.356967774224147\n",
      "train loss:2.37423896205918\n",
      "train loss:2.3752393265861054\n",
      "train loss:2.2829656125062243\n",
      "=== epoch:5, train acc:0.1225, test acc:0.13 ===\n",
      "train loss:2.415750173213994\n",
      "train loss:2.3413808999591543\n",
      "train loss:2.3797149340887414\n",
      "train loss:2.316975009474222\n",
      "=== epoch:6, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3210540349264135\n",
      "train loss:2.3858448917316193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3732524084883826\n",
      "train loss:2.2831501794094713\n",
      "=== epoch:7, train acc:0.13, test acc:0.13 ===\n",
      "train loss:2.265311491319009\n",
      "train loss:2.3047842465314323\n",
      "train loss:2.3081617652554924\n",
      "train loss:2.285449967147823\n",
      "=== epoch:8, train acc:0.1375, test acc:0.14 ===\n",
      "train loss:2.28866245735216\n",
      "train loss:2.3266140737392167\n",
      "train loss:2.300476684026489\n",
      "train loss:2.281073454673917\n",
      "=== epoch:9, train acc:0.145, test acc:0.14 ===\n",
      "train loss:2.324025281920033\n",
      "train loss:2.265668762475309\n",
      "train loss:2.265118410501337\n",
      "train loss:2.2402106579541794\n",
      "=== epoch:10, train acc:0.155, test acc:0.15 ===\n",
      "train loss:2.2514409234782438\n",
      "train loss:2.2977564328066786\n",
      "train loss:2.286974928979899\n",
      "train loss:2.2536724911695067\n",
      "=== epoch:11, train acc:0.1625, test acc:0.15 ===\n",
      "train loss:2.2542326840023104\n",
      "train loss:2.240003858794741\n",
      "train loss:2.2736202388706155\n",
      "train loss:2.219688184732269\n",
      "=== epoch:12, train acc:0.175, test acc:0.17 ===\n",
      "train loss:2.25749692419194\n",
      "train loss:2.2024473076688458\n",
      "train loss:2.2624394051745247\n",
      "train loss:2.293813016411392\n",
      "=== epoch:13, train acc:0.1975, test acc:0.18 ===\n",
      "train loss:2.2425357997830675\n",
      "train loss:2.234384098711244\n",
      "train loss:2.2119817777900823\n",
      "train loss:2.2714470206660575\n",
      "=== epoch:14, train acc:0.1925, test acc:0.19 ===\n",
      "train loss:2.223060499154068\n",
      "train loss:2.1940821450264303\n",
      "train loss:2.2239011379334848\n",
      "train loss:2.2017290820799458\n",
      "=== epoch:15, train acc:0.215, test acc:0.22 ===\n",
      "train loss:2.2215369495561874\n",
      "train loss:2.2259480659079824\n",
      "train loss:2.1473389683155233\n",
      "train loss:2.1710668786972454\n",
      "=== epoch:16, train acc:0.2525, test acc:0.26 ===\n",
      "train loss:2.1573110948729846\n",
      "train loss:2.1759768625803844\n",
      "train loss:2.2081330320698926\n",
      "train loss:2.202853051739799\n",
      "=== epoch:17, train acc:0.2675, test acc:0.27 ===\n",
      "train loss:2.206299444937074\n",
      "train loss:2.213197633396285\n",
      "train loss:2.187321290491239\n",
      "train loss:2.200204805499754\n",
      "=== epoch:18, train acc:0.2975, test acc:0.28 ===\n",
      "train loss:2.199099893032055\n",
      "train loss:2.1689747492432376\n",
      "train loss:2.186103811559555\n",
      "train loss:2.1800350305504206\n",
      "=== epoch:19, train acc:0.315, test acc:0.3 ===\n",
      "train loss:2.1527290797686667\n",
      "train loss:2.2199247360263503\n",
      "train loss:2.133447167744343\n",
      "train loss:2.144102334630462\n",
      "=== epoch:20, train acc:0.34, test acc:0.31 ===\n",
      "train loss:2.151689912237965\n",
      "train loss:2.134553865357044\n",
      "train loss:2.142194871594738\n",
      "train loss:2.1952613621222214\n",
      "=== epoch:21, train acc:0.3575, test acc:0.33 ===\n",
      "train loss:2.14231320909639\n",
      "train loss:2.141625271965138\n",
      "train loss:2.1484886048202365\n",
      "train loss:2.1258501056097585\n",
      "=== epoch:22, train acc:0.3775, test acc:0.33 ===\n",
      "train loss:2.159566188209248\n",
      "train loss:2.1704123236410817\n",
      "train loss:2.1044638723155207\n",
      "train loss:2.0982065727426833\n",
      "=== epoch:23, train acc:0.3875, test acc:0.33 ===\n",
      "train loss:2.1394096761484978\n",
      "train loss:2.092301658612778\n",
      "train loss:2.1320671390819053\n",
      "train loss:2.1196144214994823\n",
      "=== epoch:24, train acc:0.4025, test acc:0.31 ===\n",
      "train loss:2.1244416717080146\n",
      "train loss:2.1265956622725866\n",
      "train loss:2.0987101928545195\n",
      "train loss:2.0828580396229763\n",
      "=== epoch:25, train acc:0.405, test acc:0.31 ===\n",
      "train loss:2.079863936956529\n",
      "train loss:2.0958687233702755\n",
      "train loss:2.0727048307449225\n",
      "train loss:2.098440664322591\n",
      "=== epoch:26, train acc:0.425, test acc:0.35 ===\n",
      "train loss:2.1000467316608953\n",
      "train loss:2.092192964937135\n",
      "train loss:2.0263754468238298\n",
      "train loss:2.053151500542524\n",
      "=== epoch:27, train acc:0.4425, test acc:0.36 ===\n",
      "train loss:2.0198012017367355\n",
      "train loss:2.063242655748018\n",
      "train loss:2.0360830657974427\n",
      "train loss:2.078035260670343\n",
      "=== epoch:28, train acc:0.455, test acc:0.37 ===\n",
      "train loss:2.069783529117186\n",
      "train loss:2.0901469932752597\n",
      "train loss:2.0650448369918712\n",
      "train loss:2.005923243595231\n",
      "=== epoch:29, train acc:0.475, test acc:0.39 ===\n",
      "train loss:2.0577027429893797\n",
      "train loss:2.028843761393483\n",
      "train loss:2.0393652666720823\n",
      "train loss:1.9952833489218644\n",
      "=== epoch:30, train acc:0.485, test acc:0.43 ===\n",
      "train loss:1.9782950792477836\n",
      "train loss:2.0049095692919603\n",
      "train loss:2.03151356661029\n",
      "train loss:2.0214378298066884\n",
      "=== epoch:31, train acc:0.49, test acc:0.42 ===\n",
      "train loss:2.0215355290048054\n",
      "train loss:2.011936778098539\n",
      "train loss:1.9936707674031393\n",
      "train loss:2.034239306470554\n",
      "=== epoch:32, train acc:0.5125, test acc:0.44 ===\n",
      "train loss:2.022100780923016\n",
      "train loss:2.0368826463931025\n",
      "train loss:1.9876266437085521\n",
      "train loss:1.9968428374143012\n",
      "=== epoch:33, train acc:0.5275, test acc:0.45 ===\n",
      "train loss:2.044278823873718\n",
      "train loss:1.9940670643357459\n",
      "train loss:1.9751160573893358\n",
      "train loss:2.065056245047896\n",
      "=== epoch:34, train acc:0.5475, test acc:0.48 ===\n",
      "train loss:2.0134838540306115\n",
      "train loss:1.9414609224381714\n",
      "train loss:1.9892024082417887\n",
      "train loss:2.0090934071592934\n",
      "=== epoch:35, train acc:0.5725, test acc:0.49 ===\n",
      "train loss:2.0014171444700017\n",
      "train loss:1.9214020452520992\n",
      "train loss:1.9852929843834786\n",
      "train loss:1.966232374893056\n",
      "=== epoch:36, train acc:0.58, test acc:0.5 ===\n",
      "train loss:1.9078284187580166\n",
      "train loss:1.967486955220438\n",
      "train loss:1.9153556011999628\n",
      "train loss:1.9259374957546533\n",
      "=== epoch:37, train acc:0.59, test acc:0.55 ===\n",
      "train loss:1.9080029757482149\n",
      "train loss:1.9598316742385855\n",
      "train loss:1.924047822240214\n",
      "train loss:1.9527947760279427\n",
      "=== epoch:38, train acc:0.595, test acc:0.53 ===\n",
      "train loss:1.9306683320904527\n",
      "train loss:1.9220052267870036\n",
      "train loss:1.8868213537672425\n",
      "train loss:1.866653253998396\n",
      "=== epoch:39, train acc:0.6, test acc:0.58 ===\n",
      "train loss:1.8285702551601537\n",
      "train loss:1.9272248233165725\n",
      "train loss:1.9315748438542564\n",
      "train loss:1.8599101932327073\n",
      "=== epoch:40, train acc:0.6125, test acc:0.57 ===\n",
      "train loss:1.8112978333868108\n",
      "train loss:1.8411131203394793\n",
      "train loss:1.858696927682608\n",
      "train loss:1.791530057241944\n",
      "=== epoch:41, train acc:0.605, test acc:0.58 ===\n",
      "train loss:1.8618738570888491\n",
      "train loss:1.8554730579558345\n",
      "train loss:1.787042052476786\n",
      "train loss:1.8659300462597264\n",
      "=== epoch:42, train acc:0.62, test acc:0.58 ===\n",
      "train loss:1.8740435913343143\n",
      "train loss:1.8494308562189017\n",
      "train loss:1.8469871035493708\n",
      "train loss:1.719726083072661\n",
      "=== epoch:43, train acc:0.6325, test acc:0.6 ===\n",
      "train loss:1.778108880837183\n",
      "train loss:1.746190042740653\n",
      "train loss:1.8416880509763907\n",
      "train loss:1.708186610032798\n",
      "=== epoch:44, train acc:0.6425, test acc:0.6 ===\n",
      "train loss:1.6965934578749824\n",
      "train loss:1.820557926486958\n",
      "train loss:1.8293404359749288\n",
      "train loss:1.7893754346582902\n",
      "=== epoch:45, train acc:0.66, test acc:0.6 ===\n",
      "train loss:1.7787962855741488\n",
      "train loss:1.757558116594583\n",
      "train loss:1.742664984712766\n",
      "train loss:1.6859097135311216\n",
      "=== epoch:46, train acc:0.6625, test acc:0.63 ===\n",
      "train loss:1.7735723598178434\n",
      "train loss:1.7026754435963203\n",
      "train loss:1.7360041146177172\n",
      "train loss:1.7823848762534387\n",
      "=== epoch:47, train acc:0.665, test acc:0.62 ===\n",
      "train loss:1.7072371333607843\n",
      "train loss:1.819363267941073\n",
      "train loss:1.6423370498482233\n",
      "train loss:1.6781630348045298\n",
      "=== epoch:48, train acc:0.6775, test acc:0.63 ===\n",
      "train loss:1.7858294481241392\n",
      "train loss:1.6981353526860095\n",
      "train loss:1.6603315163871655\n",
      "train loss:1.68601798253516\n",
      "=== epoch:49, train acc:0.6775, test acc:0.62 ===\n",
      "train loss:1.6307642378068399\n",
      "train loss:1.6676940588851508\n",
      "train loss:1.6334794912725292\n",
      "train loss:1.7179760354451352\n",
      "=== epoch:50, train acc:0.675, test acc:0.62 ===\n",
      "train loss:1.6371930305524562\n",
      "train loss:1.6368107162872862\n",
      "train loss:1.7081240579908428\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.63\n",
      "val_acc: 0.6200 | lr: 0.0037, weight_decay: 0.0001\n",
      "train loss:2.47591233975597\n",
      "=== epoch:1, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.5189649751793413\n",
      "train loss:2.445261851227054\n",
      "train loss:2.3747975938251096\n",
      "train loss:2.484205657353801\n",
      "=== epoch:2, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.458302023442222\n",
      "train loss:2.3411963227835986\n",
      "train loss:2.4700041975792804\n",
      "train loss:2.478076282888797\n",
      "=== epoch:3, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4511406588454703\n",
      "train loss:2.3677183685506447\n",
      "train loss:2.5334269908224964\n",
      "train loss:2.454238813092781\n",
      "=== epoch:4, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4885673069161234\n",
      "train loss:2.424633922099838\n",
      "train loss:2.454980820239696\n",
      "train loss:2.5475915876854978\n",
      "=== epoch:5, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.390960494212005\n",
      "train loss:2.4276778988197236\n",
      "train loss:2.535259075882683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.469667157852281\n",
      "=== epoch:6, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4071697031989028\n",
      "train loss:2.524449757032842\n",
      "train loss:2.5234112713304695\n",
      "train loss:2.5160665748819593\n",
      "=== epoch:7, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4300603446577385\n",
      "train loss:2.431163743715303\n",
      "train loss:2.4509528893394097\n",
      "train loss:2.4186287885977564\n",
      "=== epoch:8, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4821876888487577\n",
      "train loss:2.3789019474305197\n",
      "train loss:2.5070151231766036\n",
      "train loss:2.4857188926448948\n",
      "=== epoch:9, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.551679708741379\n",
      "train loss:2.395896417268578\n",
      "train loss:2.4661834439111905\n",
      "train loss:2.5186505099529084\n",
      "=== epoch:10, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4210973129392146\n",
      "train loss:2.4567549976842207\n",
      "train loss:2.409347640815737\n",
      "train loss:2.3612135929927476\n",
      "=== epoch:11, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.3221110597135617\n",
      "train loss:2.3514563395956456\n",
      "train loss:2.557198711737124\n",
      "train loss:2.548674377088293\n",
      "=== epoch:12, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.5421055348119723\n",
      "train loss:2.3641820512933562\n",
      "train loss:2.393205733397042\n",
      "train loss:2.3295931470589473\n",
      "=== epoch:13, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4737278901468183\n",
      "train loss:2.4748082011140973\n",
      "train loss:2.4050617130182044\n",
      "train loss:2.397295731048379\n",
      "=== epoch:14, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4692201460110716\n",
      "train loss:2.4050451075226698\n",
      "train loss:2.4582595658233313\n",
      "train loss:2.425114615556119\n",
      "=== epoch:15, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.5068392187186532\n",
      "train loss:2.536952507855227\n",
      "train loss:2.4413865106807617\n",
      "train loss:2.3809130968998367\n",
      "=== epoch:16, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4466684372521277\n",
      "train loss:2.3845835826305684\n",
      "train loss:2.4425633221119356\n",
      "train loss:2.400097827153811\n",
      "=== epoch:17, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.6247169875891587\n",
      "train loss:2.5633293102075374\n",
      "train loss:2.3646085826726715\n",
      "train loss:2.4139573718488516\n",
      "=== epoch:18, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.495560443761573\n",
      "train loss:2.384026010079581\n",
      "train loss:2.4318874921566502\n",
      "train loss:2.3705864568075947\n",
      "=== epoch:19, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4953671139653286\n",
      "train loss:2.381725345193105\n",
      "train loss:2.393304614613439\n",
      "train loss:2.4053900083593898\n",
      "=== epoch:20, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.306618298008809\n",
      "train loss:2.3924007001758\n",
      "train loss:2.59045250238286\n",
      "train loss:2.4219478799115546\n",
      "=== epoch:21, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4330245003640276\n",
      "train loss:2.3899839956099274\n",
      "train loss:2.445794742363869\n",
      "train loss:2.412843729005314\n",
      "=== epoch:22, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.472392526357387\n",
      "train loss:2.392200267049773\n",
      "train loss:2.4677715652817627\n",
      "train loss:2.381006194178365\n",
      "=== epoch:23, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.494135938956968\n",
      "train loss:2.3892479719310384\n",
      "train loss:2.4950084838526516\n",
      "train loss:2.4177829592214475\n",
      "=== epoch:24, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.398803998249736\n",
      "train loss:2.3969111362461737\n",
      "train loss:2.4059392328977887\n",
      "train loss:2.540848587998804\n",
      "=== epoch:25, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4203445193440523\n",
      "train loss:2.553283762432565\n",
      "train loss:2.4557608967881452\n",
      "train loss:2.429882316431814\n",
      "=== epoch:26, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.428436177867899\n",
      "train loss:2.4006331726064345\n",
      "train loss:2.447535252078111\n",
      "train loss:2.6419369405749187\n",
      "=== epoch:27, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.511119740128523\n",
      "train loss:2.3486381891554733\n",
      "train loss:2.3961434488495494\n",
      "train loss:2.345870994872344\n",
      "=== epoch:28, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.428535125516273\n",
      "train loss:2.428935564883917\n",
      "train loss:2.408745849214408\n",
      "train loss:2.3969469877674205\n",
      "=== epoch:29, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.383857863447387\n",
      "train loss:2.5022294936795495\n",
      "train loss:2.4996717377974047\n",
      "train loss:2.4917591486948547\n",
      "=== epoch:30, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.426043637002372\n",
      "train loss:2.4068911298783298\n",
      "train loss:2.3636198812815254\n",
      "train loss:2.345469327755531\n",
      "=== epoch:31, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4395010187843886\n",
      "train loss:2.4151204616114956\n",
      "train loss:2.620760401817037\n",
      "train loss:2.437275994923912\n",
      "=== epoch:32, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.520807143145265\n",
      "train loss:2.372591530871935\n",
      "train loss:2.5381677672983676\n",
      "train loss:2.523164012778119\n",
      "=== epoch:33, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4446400913438846\n",
      "train loss:2.390657587017387\n",
      "train loss:2.3937213967874653\n",
      "train loss:2.389138967564374\n",
      "=== epoch:34, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.4076296897909786\n",
      "train loss:2.5161426780489875\n",
      "train loss:2.413493781722223\n",
      "train loss:2.4178891887523566\n",
      "=== epoch:35, train acc:0.115, test acc:0.1 ===\n",
      "train loss:2.5408463050124097\n",
      "train loss:2.428419175931308\n",
      "train loss:2.381165622108892\n",
      "train loss:2.440223296903031\n",
      "=== epoch:36, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.505821522290943\n",
      "train loss:2.362178489172802\n",
      "train loss:2.414888438223407\n",
      "train loss:2.4348284007270573\n",
      "=== epoch:37, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.4856485219936917\n",
      "train loss:2.3879235541148716\n",
      "train loss:2.4530889868887344\n",
      "train loss:2.480045753264803\n",
      "=== epoch:38, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.474554705268666\n",
      "train loss:2.5221568915966013\n",
      "train loss:2.380798986561696\n",
      "train loss:2.4146023715392797\n",
      "=== epoch:39, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.4150113034056786\n",
      "train loss:2.579495176612532\n",
      "train loss:2.4668398000478495\n",
      "train loss:2.467154525429061\n",
      "=== epoch:40, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.5064653239681305\n",
      "train loss:2.492915858164374\n",
      "train loss:2.375877595867891\n",
      "train loss:2.4440760243091018\n",
      "=== epoch:41, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.4417601365058523\n",
      "train loss:2.481114056545548\n",
      "train loss:2.4915982518701414\n",
      "train loss:2.311958061253909\n",
      "=== epoch:42, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.4765486257136056\n",
      "train loss:2.526718821384623\n",
      "train loss:2.419414743170269\n",
      "train loss:2.3973469990484166\n",
      "=== epoch:43, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.4910984306563653\n",
      "train loss:2.34843612809111\n",
      "train loss:2.3916358249218805\n",
      "train loss:2.5014520496114585\n",
      "=== epoch:44, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.439131350450768\n",
      "train loss:2.347459184665696\n",
      "train loss:2.458929763041774\n",
      "train loss:2.381732184315117\n",
      "=== epoch:45, train acc:0.115, test acc:0.11 ===\n",
      "train loss:2.362048190201884\n",
      "train loss:2.405268718558488\n",
      "train loss:2.4375801491894715\n",
      "train loss:2.442430845916477\n",
      "=== epoch:46, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.4057574366329355\n",
      "train loss:2.5581451276876144\n",
      "train loss:2.4204673573298026\n",
      "train loss:2.410509709566345\n",
      "=== epoch:47, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.5360035141750594\n",
      "train loss:2.4642631853863817\n",
      "train loss:2.391900660592646\n",
      "train loss:2.4315240580429855\n",
      "=== epoch:48, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.5101998711264795\n",
      "train loss:2.4768931016546882\n",
      "train loss:2.383665186606446\n",
      "train loss:2.413652594270211\n",
      "=== epoch:49, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.4320353720308407\n",
      "train loss:2.404235335120593\n",
      "train loss:2.3958357609063627\n",
      "train loss:2.348873993741235\n",
      "=== epoch:50, train acc:0.1175, test acc:0.11 ===\n",
      "train loss:2.481807297919997\n",
      "train loss:2.4631294876819614\n",
      "train loss:2.5372005836204816\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.11\n",
      "val_acc: 0.1100 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.503616905728391\n",
      "=== epoch:1, train acc:0.1525, test acc:0.12 ===\n",
      "train loss:2.3759438992890143\n",
      "train loss:2.4134575533664777\n",
      "train loss:2.43904900705507\n",
      "train loss:2.4695409706054416\n",
      "=== epoch:2, train acc:0.15, test acc:0.11 ===\n",
      "train loss:2.4461575526970725\n",
      "train loss:2.3567480985949176\n",
      "train loss:2.358908978952695\n",
      "train loss:2.3466861882798833\n",
      "=== epoch:3, train acc:0.155, test acc:0.13 ===\n",
      "train loss:2.3625571274102057\n",
      "train loss:2.284639086918334\n",
      "train loss:2.40861829846001\n",
      "train loss:2.317278734465704\n",
      "=== epoch:4, train acc:0.17, test acc:0.14 ===\n",
      "train loss:2.3919355518588996\n",
      "train loss:2.259879475487896\n",
      "train loss:2.3152289358954876\n",
      "train loss:2.3120880680709885\n",
      "=== epoch:5, train acc:0.16, test acc:0.15 ===\n",
      "train loss:2.2916909264310648\n",
      "train loss:2.2886331525248518\n",
      "train loss:2.297527124670933\n",
      "train loss:2.1863460441553957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:6, train acc:0.165, test acc:0.15 ===\n",
      "train loss:2.202365169519708\n",
      "train loss:2.2317657442579923\n",
      "train loss:2.2307652865004166\n",
      "train loss:2.278111735001671\n",
      "=== epoch:7, train acc:0.1725, test acc:0.15 ===\n",
      "train loss:2.237454328596717\n",
      "train loss:2.2130908099035205\n",
      "train loss:2.185976380330284\n",
      "train loss:2.2315458198408797\n",
      "=== epoch:8, train acc:0.1825, test acc:0.18 ===\n",
      "train loss:2.1881921485247378\n",
      "train loss:2.2324669382203535\n",
      "train loss:2.2022799054654763\n",
      "train loss:2.199565073738347\n",
      "=== epoch:9, train acc:0.195, test acc:0.18 ===\n",
      "train loss:2.230541663988998\n",
      "train loss:2.1552462618768806\n",
      "train loss:2.2517021785981424\n",
      "train loss:2.152812225931076\n",
      "=== epoch:10, train acc:0.1975, test acc:0.18 ===\n",
      "train loss:2.1424481732806786\n",
      "train loss:2.1845640021702146\n",
      "train loss:2.144410846662379\n",
      "train loss:2.1094539140942348\n",
      "=== epoch:11, train acc:0.205, test acc:0.19 ===\n",
      "train loss:2.1207609301146997\n",
      "train loss:2.145608771408564\n",
      "train loss:2.1396625986940196\n",
      "train loss:2.0882167695023495\n",
      "=== epoch:12, train acc:0.2075, test acc:0.19 ===\n",
      "train loss:2.0808696340083053\n",
      "train loss:2.1336483662220136\n",
      "train loss:2.102050392881563\n",
      "train loss:2.1416793817495052\n",
      "=== epoch:13, train acc:0.2175, test acc:0.18 ===\n",
      "train loss:2.1098388598751043\n",
      "train loss:2.0571768915081736\n",
      "train loss:2.097039602050224\n",
      "train loss:2.0672827608835744\n",
      "=== epoch:14, train acc:0.2275, test acc:0.2 ===\n",
      "train loss:2.1281168871240266\n",
      "train loss:2.1214597981580487\n",
      "train loss:2.0864609209695475\n",
      "train loss:2.0546123595241745\n",
      "=== epoch:15, train acc:0.2375, test acc:0.22 ===\n",
      "train loss:2.033930817093856\n",
      "train loss:2.104191101534273\n",
      "train loss:2.0414484519393943\n",
      "train loss:2.061453465621877\n",
      "=== epoch:16, train acc:0.2575, test acc:0.25 ===\n",
      "train loss:2.0700670320947006\n",
      "train loss:2.0627738033833385\n",
      "train loss:2.073121614162999\n",
      "train loss:2.0599297841619975\n",
      "=== epoch:17, train acc:0.3, test acc:0.25 ===\n",
      "train loss:2.02880189986728\n",
      "train loss:2.0358092372042806\n",
      "train loss:2.0091341642066185\n",
      "train loss:2.015100355549471\n",
      "=== epoch:18, train acc:0.3125, test acc:0.26 ===\n",
      "train loss:1.9803375724236696\n",
      "train loss:2.0278987742441568\n",
      "train loss:1.9855997303685071\n",
      "train loss:1.9523224751710055\n",
      "=== epoch:19, train acc:0.3425, test acc:0.29 ===\n",
      "train loss:1.999588854376862\n",
      "train loss:1.978686166857405\n",
      "train loss:1.9650020152230323\n",
      "train loss:1.9924590528330106\n",
      "=== epoch:20, train acc:0.36, test acc:0.31 ===\n",
      "train loss:1.9114034494253216\n",
      "train loss:1.9778669359941408\n",
      "train loss:1.9531488256878635\n",
      "train loss:1.9689475396923342\n",
      "=== epoch:21, train acc:0.3775, test acc:0.32 ===\n",
      "train loss:1.9987790042518467\n",
      "train loss:1.8727191130925716\n",
      "train loss:1.9018097470963482\n",
      "train loss:1.9331052165695541\n",
      "=== epoch:22, train acc:0.4225, test acc:0.33 ===\n",
      "train loss:1.7965316997625016\n",
      "train loss:1.9109284482951137\n",
      "train loss:1.8997960767586641\n",
      "train loss:1.8205092158647358\n",
      "=== epoch:23, train acc:0.4525, test acc:0.38 ===\n",
      "train loss:1.8590950234325427\n",
      "train loss:1.8991619666044723\n",
      "train loss:1.8737049835087871\n",
      "train loss:1.888282737453238\n",
      "=== epoch:24, train acc:0.4825, test acc:0.4 ===\n",
      "train loss:1.784227585510838\n",
      "train loss:1.8566436957579464\n",
      "train loss:1.8061776528532467\n",
      "train loss:1.8153952261503197\n",
      "=== epoch:25, train acc:0.5, test acc:0.44 ===\n",
      "train loss:1.8289230294552175\n",
      "train loss:1.81170816897512\n",
      "train loss:1.7175049212160227\n",
      "train loss:1.8209172983030748\n",
      "=== epoch:26, train acc:0.5275, test acc:0.46 ===\n",
      "train loss:1.7360568500179034\n",
      "train loss:1.8088349902133236\n",
      "train loss:1.7482124086581254\n",
      "train loss:1.6626498504784537\n",
      "=== epoch:27, train acc:0.5525, test acc:0.49 ===\n",
      "train loss:1.7643497608958645\n",
      "train loss:1.6714972448141336\n",
      "train loss:1.6941728451422584\n",
      "train loss:1.7383349404438455\n",
      "=== epoch:28, train acc:0.5775, test acc:0.52 ===\n",
      "train loss:1.7640938553106311\n",
      "train loss:1.7336317825796286\n",
      "train loss:1.7116851201624426\n",
      "train loss:1.6887956415943033\n",
      "=== epoch:29, train acc:0.5975, test acc:0.54 ===\n",
      "train loss:1.7401345372625505\n",
      "train loss:1.6886338929797473\n",
      "train loss:1.6789212574643955\n",
      "train loss:1.6606347500557186\n",
      "=== epoch:30, train acc:0.6025, test acc:0.57 ===\n",
      "train loss:1.6654895203646465\n",
      "train loss:1.6210760470463847\n",
      "train loss:1.4890167361194497\n",
      "train loss:1.6016222397613833\n",
      "=== epoch:31, train acc:0.625, test acc:0.58 ===\n",
      "train loss:1.6013420675560657\n",
      "train loss:1.4811329387843915\n",
      "train loss:1.5755506635422853\n",
      "train loss:1.5161493692893087\n",
      "=== epoch:32, train acc:0.635, test acc:0.62 ===\n",
      "train loss:1.5765822002822159\n",
      "train loss:1.473934309527571\n",
      "train loss:1.520991340871465\n",
      "train loss:1.5575277681758086\n",
      "=== epoch:33, train acc:0.64, test acc:0.64 ===\n",
      "train loss:1.4512604062377095\n",
      "train loss:1.560606302344075\n",
      "train loss:1.5731318243174697\n",
      "train loss:1.4834087435992789\n",
      "=== epoch:34, train acc:0.655, test acc:0.64 ===\n",
      "train loss:1.4173002194719648\n",
      "train loss:1.4714114554073967\n",
      "train loss:1.5333420940848776\n",
      "train loss:1.4363341311679148\n",
      "=== epoch:35, train acc:0.6925, test acc:0.66 ===\n",
      "train loss:1.3407522579642337\n",
      "train loss:1.4025408944338322\n",
      "train loss:1.5499852640437537\n",
      "train loss:1.3852317477166325\n",
      "=== epoch:36, train acc:0.7025, test acc:0.66 ===\n",
      "train loss:1.3290480501698803\n",
      "train loss:1.4203951089687659\n",
      "train loss:1.371054873421754\n",
      "train loss:1.3157506245184103\n",
      "=== epoch:37, train acc:0.7125, test acc:0.66 ===\n",
      "train loss:1.27966053018905\n",
      "train loss:1.3309417525877063\n",
      "train loss:1.3104891121533013\n",
      "train loss:1.3527910347637648\n",
      "=== epoch:38, train acc:0.71, test acc:0.66 ===\n",
      "train loss:1.274336522754868\n",
      "train loss:1.340281559186626\n",
      "train loss:1.2684450883032659\n",
      "train loss:1.3934567976829406\n",
      "=== epoch:39, train acc:0.7075, test acc:0.65 ===\n",
      "train loss:1.219609022458196\n",
      "train loss:1.2652201020776166\n",
      "train loss:1.34803940790021\n",
      "train loss:1.229334802520592\n",
      "=== epoch:40, train acc:0.715, test acc:0.65 ===\n",
      "train loss:1.2333047819451537\n",
      "train loss:1.2639468049659286\n",
      "train loss:1.280166256039206\n",
      "train loss:1.1811712241069263\n",
      "=== epoch:41, train acc:0.7075, test acc:0.64 ===\n",
      "train loss:1.2208075120551347\n",
      "train loss:1.234309443135615\n",
      "train loss:1.2531713128638469\n",
      "train loss:1.3152477626116932\n",
      "=== epoch:42, train acc:0.7325, test acc:0.69 ===\n",
      "train loss:1.128777969112937\n",
      "train loss:1.1418158171774329\n",
      "train loss:1.3695751047932578\n",
      "train loss:1.2189446409018412\n",
      "=== epoch:43, train acc:0.7375, test acc:0.68 ===\n",
      "train loss:1.1252165101489278\n",
      "train loss:1.0292633011988377\n",
      "train loss:1.1402306458589138\n",
      "train loss:1.1251724292303475\n",
      "=== epoch:44, train acc:0.7475, test acc:0.68 ===\n",
      "train loss:1.053566281708085\n",
      "train loss:1.0511074641892046\n",
      "train loss:1.0091251228259046\n",
      "train loss:0.9749768700471436\n",
      "=== epoch:45, train acc:0.7475, test acc:0.69 ===\n",
      "train loss:1.0574050176755343\n",
      "train loss:1.132569362475891\n",
      "train loss:1.030837255638145\n",
      "train loss:1.0758232386397788\n",
      "=== epoch:46, train acc:0.7625, test acc:0.69 ===\n",
      "train loss:0.9427232214903039\n",
      "train loss:1.0547548892960878\n",
      "train loss:1.0673495340827002\n",
      "train loss:1.0128541193241298\n",
      "=== epoch:47, train acc:0.775, test acc:0.69 ===\n",
      "train loss:1.1141258199115074\n",
      "train loss:0.9380050895087774\n",
      "train loss:1.1133778979792461\n",
      "train loss:1.0286843830604302\n",
      "=== epoch:48, train acc:0.7725, test acc:0.7 ===\n",
      "train loss:0.8853787697442536\n",
      "train loss:0.9651989463281374\n",
      "train loss:0.9513516171858158\n",
      "train loss:1.0092461817049578\n",
      "=== epoch:49, train acc:0.7825, test acc:0.74 ===\n",
      "train loss:1.049167444872111\n",
      "train loss:0.8755524539216201\n",
      "train loss:0.860478518447287\n",
      "train loss:1.0126595320206713\n",
      "=== epoch:50, train acc:0.7925, test acc:0.74 ===\n",
      "train loss:0.8978253915239673\n",
      "train loss:0.9013905856630189\n",
      "train loss:0.8907117330679954\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.74\n",
      "val_acc: 0.7400 | lr: 0.0058, weight_decay: 0.0000\n",
      "train loss:2.403347010234205\n",
      "=== epoch:1, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3697192816486488\n",
      "train loss:2.480967827595582\n",
      "train loss:2.4837431853602285\n",
      "train loss:2.4490899160359114\n",
      "=== epoch:2, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.340502197701483\n",
      "train loss:2.4088594275156403\n",
      "train loss:2.3787879746513467\n",
      "train loss:2.471512380672542\n",
      "=== epoch:3, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3844045431709766\n",
      "train loss:2.4219809100750838\n",
      "train loss:2.3943692260805727\n",
      "train loss:2.4209599304183977\n",
      "=== epoch:4, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4190352251184164\n",
      "train loss:2.47711534039183\n",
      "train loss:2.3878287523878003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.407262682913079\n",
      "=== epoch:5, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4607953491978853\n",
      "train loss:2.4120305511678524\n",
      "train loss:2.417735576335393\n",
      "train loss:2.3805190286627185\n",
      "=== epoch:6, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4325185193027083\n",
      "train loss:2.3537964102046\n",
      "train loss:2.464793113022622\n",
      "train loss:2.3777412851319784\n",
      "=== epoch:7, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.421339112947998\n",
      "train loss:2.4564960036384726\n",
      "train loss:2.4209167145378196\n",
      "train loss:2.3280102583428732\n",
      "=== epoch:8, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4274482166994837\n",
      "train loss:2.4322236083626447\n",
      "train loss:2.389770378674155\n",
      "train loss:2.409101730122103\n",
      "=== epoch:9, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.326035267046912\n",
      "train loss:2.275844971580916\n",
      "train loss:2.378589537612291\n",
      "train loss:2.3740944779033955\n",
      "=== epoch:10, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.402061969923015\n",
      "train loss:2.4186885278878925\n",
      "train loss:2.2750936520495335\n",
      "train loss:2.3131282108479954\n",
      "=== epoch:11, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3963148762798614\n",
      "train loss:2.4120754655005325\n",
      "train loss:2.4336895310878166\n",
      "train loss:2.416831149144464\n",
      "=== epoch:12, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.330263004948324\n",
      "train loss:2.359221775905671\n",
      "train loss:2.377186919315597\n",
      "train loss:2.427962912729776\n",
      "=== epoch:13, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3401623653615826\n",
      "train loss:2.4089337604788836\n",
      "train loss:2.3620659179979917\n",
      "train loss:2.3561493300910286\n",
      "=== epoch:14, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.39651970549754\n",
      "train loss:2.416708025495205\n",
      "train loss:2.3564044254094676\n",
      "train loss:2.4335289852891804\n",
      "=== epoch:15, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4096920815268246\n",
      "train loss:2.4009878666905893\n",
      "train loss:2.3414812120223276\n",
      "train loss:2.429670857030555\n",
      "=== epoch:16, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.36821409259019\n",
      "train loss:2.3379397435774325\n",
      "train loss:2.364229798210827\n",
      "train loss:2.426536711901043\n",
      "=== epoch:17, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4204241118878467\n",
      "train loss:2.4047476868924376\n",
      "train loss:2.342276409760638\n",
      "train loss:2.3228171308883017\n",
      "=== epoch:18, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3988191971484274\n",
      "train loss:2.446908451141478\n",
      "train loss:2.4112353285679866\n",
      "train loss:2.3222361706575256\n",
      "=== epoch:19, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3921291649437424\n",
      "train loss:2.4447356759305383\n",
      "train loss:2.4725163963476318\n",
      "train loss:2.363228692904494\n",
      "=== epoch:20, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.444212673173828\n",
      "train loss:2.4437742504323485\n",
      "train loss:2.4651486243279703\n",
      "train loss:2.4109364154653017\n",
      "=== epoch:21, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4729078181605537\n",
      "train loss:2.3949508084862936\n",
      "train loss:2.394429168592075\n",
      "train loss:2.389917178797059\n",
      "=== epoch:22, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.361274913968293\n",
      "train loss:2.3888123360883333\n",
      "train loss:2.283569036669483\n",
      "train loss:2.4051148954659243\n",
      "=== epoch:23, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.38281394829291\n",
      "train loss:2.373726079413561\n",
      "train loss:2.3997952399744724\n",
      "train loss:2.433926089820328\n",
      "=== epoch:24, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.406460572543488\n",
      "train loss:2.3341066160149566\n",
      "train loss:2.4143536253347566\n",
      "train loss:2.328249534354883\n",
      "=== epoch:25, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3190378042614737\n",
      "train loss:2.361485862986465\n",
      "train loss:2.450376389134649\n",
      "train loss:2.446289278292917\n",
      "=== epoch:26, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.419459642346268\n",
      "train loss:2.349073118619248\n",
      "train loss:2.4934690339358125\n",
      "train loss:2.410051212687151\n",
      "=== epoch:27, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3671654311823995\n",
      "train loss:2.4030961943774494\n",
      "train loss:2.446661458691478\n",
      "train loss:2.360796718786126\n",
      "=== epoch:28, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.42439448554064\n",
      "train loss:2.4559363971690926\n",
      "train loss:2.475253566200983\n",
      "train loss:2.376515121554923\n",
      "=== epoch:29, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.373809586344054\n",
      "train loss:2.3944155693521667\n",
      "train loss:2.406228562155154\n",
      "train loss:2.4354102257906947\n",
      "=== epoch:30, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4918141070435116\n",
      "train loss:2.414681335793833\n",
      "train loss:2.528939480381742\n",
      "train loss:2.4363773976966154\n",
      "=== epoch:31, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4410324565999786\n",
      "train loss:2.433728831497795\n",
      "train loss:2.3315760381942625\n",
      "train loss:2.46701778010092\n",
      "=== epoch:32, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3836271113377254\n",
      "train loss:2.452039948487489\n",
      "train loss:2.384920581252261\n",
      "train loss:2.4219645021104963\n",
      "=== epoch:33, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3909486034276752\n",
      "train loss:2.4089568608931904\n",
      "train loss:2.395599108363187\n",
      "train loss:2.3756642795056413\n",
      "=== epoch:34, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4074803229615016\n",
      "train loss:2.3982062405112625\n",
      "train loss:2.3771205149205543\n",
      "train loss:2.395610100652622\n",
      "=== epoch:35, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.443733494519201\n",
      "train loss:2.374239158302833\n",
      "train loss:2.3240305633888623\n",
      "train loss:2.3754185683163294\n",
      "=== epoch:36, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.399451862358496\n",
      "train loss:2.3867079192095586\n",
      "train loss:2.338285451129046\n",
      "train loss:2.4264890516305484\n",
      "=== epoch:37, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.340682283198431\n",
      "train loss:2.389568234002255\n",
      "train loss:2.451461850545519\n",
      "train loss:2.3904956236709443\n",
      "=== epoch:38, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4144954023068497\n",
      "train loss:2.418955648174616\n",
      "train loss:2.3744232335305964\n",
      "train loss:2.4238301637411315\n",
      "=== epoch:39, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4325098444518\n",
      "train loss:2.372261544043865\n",
      "train loss:2.414479855581766\n",
      "train loss:2.4262206901770687\n",
      "=== epoch:40, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.482819975924476\n",
      "train loss:2.422672825956925\n",
      "train loss:2.4117689794230315\n",
      "train loss:2.354780634440957\n",
      "=== epoch:41, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3544368703715284\n",
      "train loss:2.437397991401539\n",
      "train loss:2.3902534669044795\n",
      "train loss:2.3454491184924113\n",
      "=== epoch:42, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.340375268446711\n",
      "train loss:2.398178445958501\n",
      "train loss:2.5083289891106895\n",
      "train loss:2.4446144342206106\n",
      "=== epoch:43, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3978300979871285\n",
      "train loss:2.4126077079911794\n",
      "train loss:2.366909134541224\n",
      "train loss:2.3918431405056437\n",
      "=== epoch:44, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.3722883876699656\n",
      "train loss:2.441439664811085\n",
      "train loss:2.4143452203211893\n",
      "train loss:2.4188370679509936\n",
      "=== epoch:45, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.468079185806291\n",
      "train loss:2.3960561788658192\n",
      "train loss:2.455458184655909\n",
      "train loss:2.4326238782435485\n",
      "=== epoch:46, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4822315927576084\n",
      "train loss:2.3829449320799267\n",
      "train loss:2.4254002197569653\n",
      "train loss:2.3598369619600836\n",
      "=== epoch:47, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.386310385355285\n",
      "train loss:2.3566921361656767\n",
      "train loss:2.380595702302388\n",
      "train loss:2.407082044175283\n",
      "=== epoch:48, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.445531868313114\n",
      "train loss:2.4007311247058962\n",
      "train loss:2.4628140845525106\n",
      "train loss:2.3449089785989954\n",
      "=== epoch:49, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.4289400416061615\n",
      "train loss:2.4203246212104315\n",
      "train loss:2.4819754753179764\n",
      "train loss:2.2224931358693296\n",
      "=== epoch:50, train acc:0.1175, test acc:0.2 ===\n",
      "train loss:2.401369310079152\n",
      "train loss:2.3421602830699473\n",
      "train loss:2.356431176933483\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.2\n",
      "val_acc: 0.2000 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4795463670513604\n",
      "=== epoch:1, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.530912802104437\n",
      "train loss:2.5589240717294777\n",
      "train loss:2.5287934390599407\n",
      "train loss:2.6034034602274367\n",
      "=== epoch:2, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.535686344124657\n",
      "train loss:2.562048337662585\n",
      "train loss:2.512390853530435\n",
      "train loss:2.5447243429292907\n",
      "=== epoch:3, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.5572399263728247\n",
      "train loss:2.5665582868514867\n",
      "train loss:2.5116134070647917\n",
      "train loss:2.5490201600862474\n",
      "=== epoch:4, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.4889485869783825\n",
      "train loss:2.575474814426352\n",
      "train loss:2.5052646978227417\n",
      "train loss:2.556247353548994\n",
      "=== epoch:5, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.591465001590686\n",
      "train loss:2.5013160178851477\n",
      "train loss:2.5398408990440804\n",
      "train loss:2.586678482320908\n",
      "=== epoch:6, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.4963440460858366\n",
      "train loss:2.559627208084989\n",
      "train loss:2.5799112654291454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.560658666377005\n",
      "=== epoch:7, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.5484428977318045\n",
      "train loss:2.5269314555838434\n",
      "train loss:2.549907045874667\n",
      "train loss:2.5426507795131648\n",
      "=== epoch:8, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.517035163929942\n",
      "train loss:2.4683781777356777\n",
      "train loss:2.513447930157403\n",
      "train loss:2.5346046850662187\n",
      "=== epoch:9, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.514137488939422\n",
      "train loss:2.5408920899276755\n",
      "train loss:2.5304938415230245\n",
      "train loss:2.4565085435515166\n",
      "=== epoch:10, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.541283232169605\n",
      "train loss:2.496874025303313\n",
      "train loss:2.538776961461555\n",
      "train loss:2.5387373552609693\n",
      "=== epoch:11, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.4815421831859084\n",
      "train loss:2.4922390440177167\n",
      "train loss:2.5299902352075376\n",
      "train loss:2.4979100115545334\n",
      "=== epoch:12, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.502519148578338\n",
      "train loss:2.533853931720687\n",
      "train loss:2.5276288129073325\n",
      "train loss:2.515985026487179\n",
      "=== epoch:13, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.5192708516183497\n",
      "train loss:2.5472305606727352\n",
      "train loss:2.4777782738337213\n",
      "train loss:2.538591662612507\n",
      "=== epoch:14, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.5606946028025246\n",
      "train loss:2.523545774605287\n",
      "train loss:2.567622190206706\n",
      "train loss:2.517535451862453\n",
      "=== epoch:15, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.554614035038377\n",
      "train loss:2.497594665477125\n",
      "train loss:2.526824257830203\n",
      "train loss:2.4903289011247165\n",
      "=== epoch:16, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.536592501757891\n",
      "train loss:2.5127165394364566\n",
      "train loss:2.452360709350213\n",
      "train loss:2.569570563487341\n",
      "=== epoch:17, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.490327867473466\n",
      "train loss:2.5205082060765065\n",
      "train loss:2.530969168778382\n",
      "train loss:2.5108020307628784\n",
      "=== epoch:18, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.4629165316071138\n",
      "train loss:2.4911914650576845\n",
      "train loss:2.451036481522391\n",
      "train loss:2.4979842063500746\n",
      "=== epoch:19, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.4894201659543134\n",
      "train loss:2.47251606611449\n",
      "train loss:2.498038850482841\n",
      "train loss:2.5153493095389843\n",
      "=== epoch:20, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.4604244705317617\n",
      "train loss:2.465582990784843\n",
      "train loss:2.539327651301985\n",
      "train loss:2.5200832078093516\n",
      "=== epoch:21, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.485547773643575\n",
      "train loss:2.513550103810089\n",
      "train loss:2.581342457281596\n",
      "train loss:2.5194984748373632\n",
      "=== epoch:22, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.4872921405054615\n",
      "train loss:2.5025000149893977\n",
      "train loss:2.5258365321670535\n",
      "train loss:2.6122846234917554\n",
      "=== epoch:23, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.496517330801725\n",
      "train loss:2.5227544167836484\n",
      "train loss:2.4995791988761633\n",
      "train loss:2.5214226096749153\n",
      "=== epoch:24, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.569047417660009\n",
      "train loss:2.444506803195976\n",
      "train loss:2.547844855772225\n",
      "train loss:2.473700954235022\n",
      "=== epoch:25, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.528939488977185\n",
      "train loss:2.4377939802974784\n",
      "train loss:2.5234557331885386\n",
      "train loss:2.479321057361655\n",
      "=== epoch:26, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.5200391883902697\n",
      "train loss:2.4789236494673044\n",
      "train loss:2.516063555359686\n",
      "train loss:2.492186469900658\n",
      "=== epoch:27, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.5173683232759325\n",
      "train loss:2.505881930199114\n",
      "train loss:2.4909374368407735\n",
      "train loss:2.527177333341047\n",
      "=== epoch:28, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.4879228969435805\n",
      "train loss:2.5139612905724125\n",
      "train loss:2.526439168394611\n",
      "train loss:2.461463458476176\n",
      "=== epoch:29, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.5620460854317457\n",
      "train loss:2.5615885356689994\n",
      "train loss:2.505567873998455\n",
      "train loss:2.4743260591546505\n",
      "=== epoch:30, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.48764431309425\n",
      "train loss:2.527648200907799\n",
      "train loss:2.5514900187428524\n",
      "train loss:2.5877710104576863\n",
      "=== epoch:31, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.535092206015833\n",
      "train loss:2.5838890626658118\n",
      "train loss:2.476587064698298\n",
      "train loss:2.535239946180523\n",
      "=== epoch:32, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.5456939621580346\n",
      "train loss:2.5214596835116954\n",
      "train loss:2.5180482155113437\n",
      "train loss:2.5332760808056656\n",
      "=== epoch:33, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.521743104160839\n",
      "train loss:2.547543037503638\n",
      "train loss:2.5157665977800185\n",
      "train loss:2.5320083690439392\n",
      "=== epoch:34, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.534373848237556\n",
      "train loss:2.4688631998529464\n",
      "train loss:2.513906819657955\n",
      "train loss:2.494902563260295\n",
      "=== epoch:35, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.5126488332534422\n",
      "train loss:2.5075780878775316\n",
      "train loss:2.514093657411802\n",
      "train loss:2.502810572444902\n",
      "=== epoch:36, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.529483853986633\n",
      "train loss:2.479788601444575\n",
      "train loss:2.5519618618987345\n",
      "train loss:2.5179607529826065\n",
      "=== epoch:37, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.516888294150536\n",
      "train loss:2.52402019631997\n",
      "train loss:2.5224719318257756\n",
      "train loss:2.5176473780137587\n",
      "=== epoch:38, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.480616262734889\n",
      "train loss:2.465295366321432\n",
      "train loss:2.5239918814077127\n",
      "train loss:2.489113078406964\n",
      "=== epoch:39, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.5184478540066015\n",
      "train loss:2.540462670436911\n",
      "train loss:2.496261053711107\n",
      "train loss:2.4964522233551203\n",
      "=== epoch:40, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.516702629032666\n",
      "train loss:2.5228240485796616\n",
      "train loss:2.4677587555273317\n",
      "train loss:2.513987069069005\n",
      "=== epoch:41, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.4699773394724094\n",
      "train loss:2.53176444868189\n",
      "train loss:2.490243727479476\n",
      "train loss:2.4722099728387277\n",
      "=== epoch:42, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.5000104341604157\n",
      "train loss:2.5200888671687576\n",
      "train loss:2.5020526136124106\n",
      "train loss:2.4664649035048525\n",
      "=== epoch:43, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.507052189287295\n",
      "train loss:2.5304457609069146\n",
      "train loss:2.5096159775910802\n",
      "train loss:2.5029885651265715\n",
      "=== epoch:44, train acc:0.0325, test acc:0.04 ===\n",
      "train loss:2.5368912500998575\n",
      "train loss:2.529716641794462\n",
      "train loss:2.486585745578762\n",
      "train loss:2.519670581433205\n",
      "=== epoch:45, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.503156977989303\n",
      "train loss:2.506910171393436\n",
      "train loss:2.475605366097258\n",
      "train loss:2.489674197833898\n",
      "=== epoch:46, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.549958803348516\n",
      "train loss:2.4996478078882114\n",
      "train loss:2.51917389731166\n",
      "train loss:2.478495163702075\n",
      "=== epoch:47, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.51595370531106\n",
      "train loss:2.502413755759484\n",
      "train loss:2.502892206355422\n",
      "train loss:2.5141164675108487\n",
      "=== epoch:48, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.463354694871949\n",
      "train loss:2.4673095261508453\n",
      "train loss:2.487653995318044\n",
      "train loss:2.511865787135723\n",
      "=== epoch:49, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.4767983958191415\n",
      "train loss:2.5127625234340183\n",
      "train loss:2.496475790293864\n",
      "train loss:2.539079769448619\n",
      "=== epoch:50, train acc:0.035, test acc:0.04 ===\n",
      "train loss:2.51898471617091\n",
      "train loss:2.5447196130853844\n",
      "train loss:2.52333340613093\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.04\n",
      "val_acc: 0.0400 | lr: 0.0001, weight_decay: 0.0001\n",
      "train loss:2.375366555493494\n",
      "=== epoch:1, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.400150899206301\n",
      "train loss:2.4416272574397566\n",
      "train loss:2.3652745216222204\n",
      "train loss:2.424538903740599\n",
      "=== epoch:2, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.381308947703189\n",
      "train loss:2.4442530966248706\n",
      "train loss:2.4521267233584916\n",
      "train loss:2.412950054027581\n",
      "=== epoch:3, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3919547838031416\n",
      "train loss:2.352182572936287\n",
      "train loss:2.3999972178919275\n",
      "train loss:2.3824868779348343\n",
      "=== epoch:4, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3805246344411346\n",
      "train loss:2.4550805340408925\n",
      "train loss:2.3754279446218307\n",
      "train loss:2.4159641325374466\n",
      "=== epoch:5, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3670355720834975\n",
      "train loss:2.3044452036724508\n",
      "train loss:2.428105937412872\n",
      "train loss:2.3680046167929665\n",
      "=== epoch:6, train acc:0.095, test acc:0.09 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.342703380534981\n",
      "train loss:2.380835127550615\n",
      "train loss:2.3712956468759274\n",
      "train loss:2.376679189642081\n",
      "=== epoch:7, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.4129881214235804\n",
      "train loss:2.4213294401726984\n",
      "train loss:2.4027887451771983\n",
      "train loss:2.4275134767059967\n",
      "=== epoch:8, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.366363034836218\n",
      "train loss:2.358408071745258\n",
      "train loss:2.4009612519786048\n",
      "train loss:2.464614390229988\n",
      "=== epoch:9, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3507551426823854\n",
      "train loss:2.44514001747723\n",
      "train loss:2.3709670274025894\n",
      "train loss:2.442535046000972\n",
      "=== epoch:10, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3791170896737066\n",
      "train loss:2.363068471624195\n",
      "train loss:2.315405846424048\n",
      "train loss:2.3546456329106085\n",
      "=== epoch:11, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.4387311586326526\n",
      "train loss:2.3937611407764567\n",
      "train loss:2.359237520435745\n",
      "train loss:2.42455710673089\n",
      "=== epoch:12, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.371113991430478\n",
      "train loss:2.3941069404847517\n",
      "train loss:2.345452692251882\n",
      "train loss:2.364854734261528\n",
      "=== epoch:13, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3714811944156193\n",
      "train loss:2.3999659321895246\n",
      "train loss:2.352044749894025\n",
      "train loss:2.3547976298628748\n",
      "=== epoch:14, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.413069199901982\n",
      "train loss:2.378478758045438\n",
      "train loss:2.3717308357493696\n",
      "train loss:2.361011236756005\n",
      "=== epoch:15, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3485173727524162\n",
      "train loss:2.3177119087000646\n",
      "train loss:2.3502705494883815\n",
      "train loss:2.3989818050480456\n",
      "=== epoch:16, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3523875445214357\n",
      "train loss:2.379219803454541\n",
      "train loss:2.360416454661817\n",
      "train loss:2.4167191771748735\n",
      "=== epoch:17, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3729808295234585\n",
      "train loss:2.3882406603910313\n",
      "train loss:2.432987326366913\n",
      "train loss:2.377911013589321\n",
      "=== epoch:18, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.4103046006533133\n",
      "train loss:2.4302571141554905\n",
      "train loss:2.3497827452700006\n",
      "train loss:2.368621320974622\n",
      "=== epoch:19, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3643794051346987\n",
      "train loss:2.34659984920709\n",
      "train loss:2.439412904053581\n",
      "train loss:2.336999226564935\n",
      "=== epoch:20, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.426544787585898\n",
      "train loss:2.3619005613972393\n",
      "train loss:2.360010862017891\n",
      "train loss:2.3820449296792825\n",
      "=== epoch:21, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.390103283765334\n",
      "train loss:2.394349935814236\n",
      "train loss:2.426222686432336\n",
      "train loss:2.334631930514337\n",
      "=== epoch:22, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.379673801083649\n",
      "train loss:2.4169586345896157\n",
      "train loss:2.3832617429687724\n",
      "train loss:2.3008532022786343\n",
      "=== epoch:23, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.391631506067484\n",
      "train loss:2.427844204088793\n",
      "train loss:2.3989329544383637\n",
      "train loss:2.399713395414772\n",
      "=== epoch:24, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.344645158355196\n",
      "train loss:2.4091985419492503\n",
      "train loss:2.4112008574349892\n",
      "train loss:2.395388854986877\n",
      "=== epoch:25, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3728277492387035\n",
      "train loss:2.3412677969973075\n",
      "train loss:2.3630530502028306\n",
      "train loss:2.366408147385116\n",
      "=== epoch:26, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.427325641618891\n",
      "train loss:2.4194479682948864\n",
      "train loss:2.4349737668457125\n",
      "train loss:2.4100592934131684\n",
      "=== epoch:27, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.381367446486458\n",
      "train loss:2.316639217546909\n",
      "train loss:2.45647975030926\n",
      "train loss:2.388565229653368\n",
      "=== epoch:28, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3788659355784185\n",
      "train loss:2.3748688363619395\n",
      "train loss:2.4419125868382\n",
      "train loss:2.4066457219859143\n",
      "=== epoch:29, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3980025780938528\n",
      "train loss:2.3831240751785567\n",
      "train loss:2.294442229136307\n",
      "train loss:2.4194178487133606\n",
      "=== epoch:30, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.387826593330579\n",
      "train loss:2.4432106211914593\n",
      "train loss:2.3686891910325727\n",
      "train loss:2.3468340152694847\n",
      "=== epoch:31, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.394746695882618\n",
      "train loss:2.4511671640727712\n",
      "train loss:2.3958861549434136\n",
      "train loss:2.3639049563147694\n",
      "=== epoch:32, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.416552954693867\n",
      "train loss:2.4004028368195325\n",
      "train loss:2.3976323539000344\n",
      "train loss:2.339293521175779\n",
      "=== epoch:33, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3539865858820903\n",
      "train loss:2.42057868623924\n",
      "train loss:2.4675710402860553\n",
      "train loss:2.3773824283841134\n",
      "=== epoch:34, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.360226616997288\n",
      "train loss:2.366795397346842\n",
      "train loss:2.3259572702190234\n",
      "train loss:2.3738010028618644\n",
      "=== epoch:35, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3289068302106495\n",
      "train loss:2.4374373452199407\n",
      "train loss:2.3319939364379065\n",
      "train loss:2.4273799755496697\n",
      "=== epoch:36, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.423273856767617\n",
      "train loss:2.396097494150873\n",
      "train loss:2.3826527856290842\n",
      "train loss:2.3917791058913296\n",
      "=== epoch:37, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3186832502851096\n",
      "train loss:2.3722480391087286\n",
      "train loss:2.347133320605115\n",
      "train loss:2.335197660561569\n",
      "=== epoch:38, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3382364577818846\n",
      "train loss:2.3355654324597257\n",
      "train loss:2.3114854153802002\n",
      "train loss:2.3767035325222388\n",
      "=== epoch:39, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.440800335999716\n",
      "train loss:2.3551702480495873\n",
      "train loss:2.3876526243594856\n",
      "train loss:2.396594419038454\n",
      "=== epoch:40, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3391189675839037\n",
      "train loss:2.337781604769251\n",
      "train loss:2.340422993509137\n",
      "train loss:2.4277710918036797\n",
      "=== epoch:41, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.37494531542704\n",
      "train loss:2.3308737247979097\n",
      "train loss:2.3453538599167865\n",
      "train loss:2.3724753837653716\n",
      "=== epoch:42, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3819180494200256\n",
      "train loss:2.302296792476839\n",
      "train loss:2.400298519082835\n",
      "train loss:2.351440800567452\n",
      "=== epoch:43, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3776663092843853\n",
      "train loss:2.3875762618815677\n",
      "train loss:2.3907963819074474\n",
      "train loss:2.417706510363093\n",
      "=== epoch:44, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.411455069506909\n",
      "train loss:2.4289791212575316\n",
      "train loss:2.37538994622081\n",
      "train loss:2.3448203832532686\n",
      "=== epoch:45, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.4027783228077766\n",
      "train loss:2.3499099722404497\n",
      "train loss:2.426694516048073\n",
      "train loss:2.3777574805381207\n",
      "=== epoch:46, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.333802556028127\n",
      "train loss:2.389840878798209\n",
      "train loss:2.346380015885385\n",
      "train loss:2.4104531873556274\n",
      "=== epoch:47, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3490675828444694\n",
      "train loss:2.3584255889985704\n",
      "train loss:2.3525013809681092\n",
      "train loss:2.4167557112040248\n",
      "=== epoch:48, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.395587193853447\n",
      "train loss:2.3846167162257985\n",
      "train loss:2.4257327991352016\n",
      "train loss:2.3407971595987678\n",
      "=== epoch:49, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3344395168372776\n",
      "train loss:2.431452111073974\n",
      "train loss:2.3805901749899503\n",
      "train loss:2.4484431331760046\n",
      "=== epoch:50, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.385469728612404\n",
      "train loss:2.373477366139156\n",
      "train loss:2.34349988972254\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.300902423015034\n",
      "=== epoch:1, train acc:0.0925, test acc:0.07 ===\n",
      "train loss:2.343554135204418\n",
      "train loss:2.3002196849624013\n",
      "train loss:2.3344040262624937\n",
      "train loss:2.332489917423742\n",
      "=== epoch:2, train acc:0.095, test acc:0.06 ===\n",
      "train loss:2.345896610662404\n",
      "train loss:2.3951292620364244\n",
      "train loss:2.331368403131541\n",
      "train loss:2.3561751445945345\n",
      "=== epoch:3, train acc:0.0975, test acc:0.06 ===\n",
      "train loss:2.3383721087875324\n",
      "train loss:2.3429547896854994\n",
      "train loss:2.3347651799250344\n",
      "train loss:2.399228944274983\n",
      "=== epoch:4, train acc:0.1, test acc:0.06 ===\n",
      "train loss:2.33720371599474\n",
      "train loss:2.3251192324519834\n",
      "train loss:2.3147478879347108\n",
      "train loss:2.3058849609306673\n",
      "=== epoch:5, train acc:0.1, test acc:0.06 ===\n",
      "train loss:2.341758655756776\n",
      "train loss:2.298478257784425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2968168500660453\n",
      "train loss:2.3351530009660326\n",
      "=== epoch:6, train acc:0.1, test acc:0.06 ===\n",
      "train loss:2.3029096053466955\n",
      "train loss:2.292786066798926\n",
      "train loss:2.305329260916673\n",
      "train loss:2.3123077095992572\n",
      "=== epoch:7, train acc:0.1, test acc:0.04 ===\n",
      "train loss:2.355403754008028\n",
      "train loss:2.3429360719230403\n",
      "train loss:2.309998414451135\n",
      "train loss:2.3285248357695525\n",
      "=== epoch:8, train acc:0.105, test acc:0.04 ===\n",
      "train loss:2.339665320931476\n",
      "train loss:2.3396937281341046\n",
      "train loss:2.3051897981722567\n",
      "train loss:2.3533097256554587\n",
      "=== epoch:9, train acc:0.105, test acc:0.04 ===\n",
      "train loss:2.337891639536693\n",
      "train loss:2.245651049429092\n",
      "train loss:2.3619942526641227\n",
      "train loss:2.3457223000029894\n",
      "=== epoch:10, train acc:0.105, test acc:0.04 ===\n",
      "train loss:2.323232517366138\n",
      "train loss:2.326494643952617\n",
      "train loss:2.24841284536974\n",
      "train loss:2.2900451756056093\n",
      "=== epoch:11, train acc:0.1025, test acc:0.04 ===\n",
      "train loss:2.2682185180416674\n",
      "train loss:2.298322633453175\n",
      "train loss:2.2801961008982827\n",
      "train loss:2.3019693051866317\n",
      "=== epoch:12, train acc:0.1025, test acc:0.04 ===\n",
      "train loss:2.303323275220368\n",
      "train loss:2.2839907012022636\n",
      "train loss:2.2774073409045874\n",
      "train loss:2.34712064933994\n",
      "=== epoch:13, train acc:0.105, test acc:0.04 ===\n",
      "train loss:2.338808097746609\n",
      "train loss:2.307303161847209\n",
      "train loss:2.2636897486843193\n",
      "train loss:2.3292789017279394\n",
      "=== epoch:14, train acc:0.1075, test acc:0.05 ===\n",
      "train loss:2.3203535385244574\n",
      "train loss:2.278089350887807\n",
      "train loss:2.3682986740281136\n",
      "train loss:2.292151104534707\n",
      "=== epoch:15, train acc:0.1125, test acc:0.05 ===\n",
      "train loss:2.33189998045316\n",
      "train loss:2.319924323408158\n",
      "train loss:2.2869247289890566\n",
      "train loss:2.279643678802309\n",
      "=== epoch:16, train acc:0.1125, test acc:0.05 ===\n",
      "train loss:2.3062085720227294\n",
      "train loss:2.293527842503937\n",
      "train loss:2.3019897077064155\n",
      "train loss:2.298890767041198\n",
      "=== epoch:17, train acc:0.115, test acc:0.07 ===\n",
      "train loss:2.2772000863943087\n",
      "train loss:2.3487399600892256\n",
      "train loss:2.2989436359188935\n",
      "train loss:2.29434110500924\n",
      "=== epoch:18, train acc:0.1175, test acc:0.07 ===\n",
      "train loss:2.289667611106613\n",
      "train loss:2.2674976270697758\n",
      "train loss:2.3102124749569266\n",
      "train loss:2.2608301595719027\n",
      "=== epoch:19, train acc:0.1175, test acc:0.08 ===\n",
      "train loss:2.272630641469838\n",
      "train loss:2.273104563308483\n",
      "train loss:2.2905794794005536\n",
      "train loss:2.28104485438628\n",
      "=== epoch:20, train acc:0.1175, test acc:0.08 ===\n",
      "train loss:2.305553693828102\n",
      "train loss:2.291561525830732\n",
      "train loss:2.2819158114365554\n",
      "train loss:2.2775684511623515\n",
      "=== epoch:21, train acc:0.12, test acc:0.08 ===\n",
      "train loss:2.293231679691077\n",
      "train loss:2.280609351390773\n",
      "train loss:2.2751086491595762\n",
      "train loss:2.285835938842299\n",
      "=== epoch:22, train acc:0.12, test acc:0.08 ===\n",
      "train loss:2.290830745934894\n",
      "train loss:2.3004913021877558\n",
      "train loss:2.320290527289894\n",
      "train loss:2.286684243350462\n",
      "=== epoch:23, train acc:0.1225, test acc:0.08 ===\n",
      "train loss:2.300747009755089\n",
      "train loss:2.3087721373487673\n",
      "train loss:2.2856172697243338\n",
      "train loss:2.2541321918823414\n",
      "=== epoch:24, train acc:0.125, test acc:0.08 ===\n",
      "train loss:2.263107688002744\n",
      "train loss:2.286065005947217\n",
      "train loss:2.278591183322068\n",
      "train loss:2.26495623130582\n",
      "=== epoch:25, train acc:0.125, test acc:0.08 ===\n",
      "train loss:2.27586535886467\n",
      "train loss:2.33174806686618\n",
      "train loss:2.291564989325918\n",
      "train loss:2.289801597921654\n",
      "=== epoch:26, train acc:0.1325, test acc:0.08 ===\n",
      "train loss:2.291533098490536\n",
      "train loss:2.332806794184243\n",
      "train loss:2.2875554006245866\n",
      "train loss:2.2809118999665445\n",
      "=== epoch:27, train acc:0.135, test acc:0.08 ===\n",
      "train loss:2.316406021969546\n",
      "train loss:2.2751376692486804\n",
      "train loss:2.261277997590219\n",
      "train loss:2.267479080229292\n",
      "=== epoch:28, train acc:0.14, test acc:0.08 ===\n",
      "train loss:2.2742270883566538\n",
      "train loss:2.240009314555679\n",
      "train loss:2.2673595841785636\n",
      "train loss:2.252917790839465\n",
      "=== epoch:29, train acc:0.1425, test acc:0.08 ===\n",
      "train loss:2.324122262130669\n",
      "train loss:2.235359653066575\n",
      "train loss:2.2712065285747567\n",
      "train loss:2.2873584220293073\n",
      "=== epoch:30, train acc:0.1425, test acc:0.08 ===\n",
      "train loss:2.2805009188134897\n",
      "train loss:2.3039716285175693\n",
      "train loss:2.2827490742018606\n",
      "train loss:2.2901618127161147\n",
      "=== epoch:31, train acc:0.145, test acc:0.09 ===\n",
      "train loss:2.289831364432335\n",
      "train loss:2.2765977276439373\n",
      "train loss:2.2921114873164727\n",
      "train loss:2.24248524983983\n",
      "=== epoch:32, train acc:0.15, test acc:0.1 ===\n",
      "train loss:2.254338980367116\n",
      "train loss:2.282764736576108\n",
      "train loss:2.257380681446634\n",
      "train loss:2.3120192580349603\n",
      "=== epoch:33, train acc:0.1525, test acc:0.1 ===\n",
      "train loss:2.266420364435024\n",
      "train loss:2.2754781254008107\n",
      "train loss:2.2963343011473625\n",
      "train loss:2.273199007389503\n",
      "=== epoch:34, train acc:0.1525, test acc:0.1 ===\n",
      "train loss:2.2781488858922265\n",
      "train loss:2.252802099137326\n",
      "train loss:2.2816220650102164\n",
      "train loss:2.2461096153592757\n",
      "=== epoch:35, train acc:0.155, test acc:0.1 ===\n",
      "train loss:2.260382431049393\n",
      "train loss:2.235676174387062\n",
      "train loss:2.257218962310563\n",
      "train loss:2.2546363445164603\n",
      "=== epoch:36, train acc:0.155, test acc:0.1 ===\n",
      "train loss:2.265578660005473\n",
      "train loss:2.253382006924127\n",
      "train loss:2.292140785384429\n",
      "train loss:2.238385005052589\n",
      "=== epoch:37, train acc:0.155, test acc:0.1 ===\n",
      "train loss:2.237702084785972\n",
      "train loss:2.2758348641850183\n",
      "train loss:2.281307989164196\n",
      "train loss:2.2215332676514508\n",
      "=== epoch:38, train acc:0.1575, test acc:0.1 ===\n",
      "train loss:2.2736355925707423\n",
      "train loss:2.301912287344719\n",
      "train loss:2.2604793644896155\n",
      "train loss:2.2847022269460906\n",
      "=== epoch:39, train acc:0.16, test acc:0.1 ===\n",
      "train loss:2.239183424941307\n",
      "train loss:2.2291464213393044\n",
      "train loss:2.296348018540172\n",
      "train loss:2.2751378773771154\n",
      "=== epoch:40, train acc:0.16, test acc:0.1 ===\n",
      "train loss:2.285339214148619\n",
      "train loss:2.2469796474374357\n",
      "train loss:2.27758746284729\n",
      "train loss:2.2834545349004474\n",
      "=== epoch:41, train acc:0.16, test acc:0.1 ===\n",
      "train loss:2.261601631828172\n",
      "train loss:2.281870666833869\n",
      "train loss:2.2576862817725645\n",
      "train loss:2.2741434118896\n",
      "=== epoch:42, train acc:0.16, test acc:0.1 ===\n",
      "train loss:2.245358447224869\n",
      "train loss:2.2523000260557025\n",
      "train loss:2.245030037326468\n",
      "train loss:2.2429570086435\n",
      "=== epoch:43, train acc:0.165, test acc:0.1 ===\n",
      "train loss:2.232240462345465\n",
      "train loss:2.2916972348565254\n",
      "train loss:2.2427247789784044\n",
      "train loss:2.2810277248626156\n",
      "=== epoch:44, train acc:0.1675, test acc:0.1 ===\n",
      "train loss:2.2525770744520544\n",
      "train loss:2.244538827819566\n",
      "train loss:2.269606846318801\n",
      "train loss:2.2345717873274005\n",
      "=== epoch:45, train acc:0.1675, test acc:0.1 ===\n",
      "train loss:2.277548423746737\n",
      "train loss:2.2631409031487864\n",
      "train loss:2.2772806141137174\n",
      "train loss:2.2296816978598075\n",
      "=== epoch:46, train acc:0.1675, test acc:0.1 ===\n",
      "train loss:2.248766135127093\n",
      "train loss:2.2551556644036164\n",
      "train loss:2.252481654182146\n",
      "train loss:2.2621564092093513\n",
      "=== epoch:47, train acc:0.1775, test acc:0.09 ===\n",
      "train loss:2.2606738179125725\n",
      "train loss:2.2883275697611474\n",
      "train loss:2.2311101349682847\n",
      "train loss:2.234749978051568\n",
      "=== epoch:48, train acc:0.1775, test acc:0.09 ===\n",
      "train loss:2.254315238848785\n",
      "train loss:2.2601506563931055\n",
      "train loss:2.2593333230073234\n",
      "train loss:2.2423003745311747\n",
      "=== epoch:49, train acc:0.18, test acc:0.09 ===\n",
      "train loss:2.2563247894835547\n",
      "train loss:2.2493903315872683\n",
      "train loss:2.288548542857971\n",
      "train loss:2.276792938047738\n",
      "=== epoch:50, train acc:0.1775, test acc:0.09 ===\n",
      "train loss:2.222107957876244\n",
      "train loss:2.2578788426484193\n",
      "train loss:2.278394282298165\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0005, weight_decay: 0.0000\n",
      "train loss:2.4172135883960166\n",
      "=== epoch:1, train acc:0.07, test acc:0.03 ===\n",
      "train loss:2.3948533027643264\n",
      "train loss:2.315534629841379\n",
      "train loss:2.426711211442543\n",
      "train loss:2.349089772056769\n",
      "=== epoch:2, train acc:0.0675, test acc:0.03 ===\n",
      "train loss:2.39182260621607\n",
      "train loss:2.3965449903070843\n",
      "train loss:2.378578451800818\n",
      "train loss:2.3700289562745174\n",
      "=== epoch:3, train acc:0.0675, test acc:0.03 ===\n",
      "train loss:2.384467587289056\n",
      "train loss:2.3832115255124617\n",
      "train loss:2.34156317403171\n",
      "train loss:2.392115774275046\n",
      "=== epoch:4, train acc:0.0675, test acc:0.03 ===\n",
      "train loss:2.4559279760792707\n",
      "train loss:2.3274316291932102\n",
      "train loss:2.3889957493242235\n",
      "train loss:2.3719489597088166\n",
      "=== epoch:5, train acc:0.0675, test acc:0.03 ===\n",
      "train loss:2.421612790087111\n",
      "train loss:2.365973561891683\n",
      "train loss:2.440761690243078\n",
      "train loss:2.395947341468754\n",
      "=== epoch:6, train acc:0.0675, test acc:0.03 ===\n",
      "train loss:2.43247216748286\n",
      "train loss:2.379053106867244\n",
      "train loss:2.3529591629279185\n",
      "train loss:2.4096680983166365\n",
      "=== epoch:7, train acc:0.0675, test acc:0.03 ===\n",
      "train loss:2.3391810763475798\n",
      "train loss:2.3993083793531342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3423465725263295\n",
      "train loss:2.3513829521223344\n",
      "=== epoch:8, train acc:0.0675, test acc:0.03 ===\n",
      "train loss:2.484076432347116\n",
      "train loss:2.41587143389337\n",
      "train loss:2.367610825472223\n",
      "train loss:2.3641028017637393\n",
      "=== epoch:9, train acc:0.07, test acc:0.04 ===\n",
      "train loss:2.3658525373392076\n",
      "train loss:2.341225055467948\n",
      "train loss:2.3814991245950785\n",
      "train loss:2.3514610913684684\n",
      "=== epoch:10, train acc:0.0675, test acc:0.04 ===\n",
      "train loss:2.2985017873829374\n",
      "train loss:2.3025566172344636\n",
      "train loss:2.3643074318542934\n",
      "train loss:2.428569649705557\n",
      "=== epoch:11, train acc:0.0675, test acc:0.04 ===\n",
      "train loss:2.348421759989573\n",
      "train loss:2.4077694102680804\n",
      "train loss:2.3556683712638327\n",
      "train loss:2.394486284954819\n",
      "=== epoch:12, train acc:0.0675, test acc:0.04 ===\n",
      "train loss:2.3877669791074787\n",
      "train loss:2.3266618262700676\n",
      "train loss:2.3847734063096593\n",
      "train loss:2.3483150020617467\n",
      "=== epoch:13, train acc:0.0675, test acc:0.04 ===\n",
      "train loss:2.3420210404484747\n",
      "train loss:2.251356569922827\n",
      "train loss:2.378212649909496\n",
      "train loss:2.4281316996409124\n",
      "=== epoch:14, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.3835238895136697\n",
      "train loss:2.388995606706956\n",
      "train loss:2.3489061168653658\n",
      "train loss:2.3518898129146297\n",
      "=== epoch:15, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.3285647601218478\n",
      "train loss:2.3096311400011333\n",
      "train loss:2.3331208881318166\n",
      "train loss:2.3846924531009512\n",
      "=== epoch:16, train acc:0.0625, test acc:0.04 ===\n",
      "train loss:2.2966324106811364\n",
      "train loss:2.4393767478352313\n",
      "train loss:2.37028467134577\n",
      "train loss:2.399355161330437\n",
      "=== epoch:17, train acc:0.0625, test acc:0.04 ===\n",
      "train loss:2.380366697159838\n",
      "train loss:2.3222556003109163\n",
      "train loss:2.307538041887771\n",
      "train loss:2.3168213774212423\n",
      "=== epoch:18, train acc:0.0625, test acc:0.04 ===\n",
      "train loss:2.303249627432852\n",
      "train loss:2.3172754959013235\n",
      "train loss:2.3657831095959336\n",
      "train loss:2.341825709297573\n",
      "=== epoch:19, train acc:0.0625, test acc:0.04 ===\n",
      "train loss:2.3488580998650024\n",
      "train loss:2.31010090879335\n",
      "train loss:2.3575371592660987\n",
      "train loss:2.3741139562796887\n",
      "=== epoch:20, train acc:0.0625, test acc:0.04 ===\n",
      "train loss:2.287918300069311\n",
      "train loss:2.3257864508571235\n",
      "train loss:2.3550346630929524\n",
      "train loss:2.3548946739189853\n",
      "=== epoch:21, train acc:0.0625, test acc:0.04 ===\n",
      "train loss:2.3522852213593115\n",
      "train loss:2.3102491303571404\n",
      "train loss:2.349064660187489\n",
      "train loss:2.3308258915388174\n",
      "=== epoch:22, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.4198937802080844\n",
      "train loss:2.333446324217886\n",
      "train loss:2.2928302071583158\n",
      "train loss:2.320389455891837\n",
      "=== epoch:23, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.339715852427345\n",
      "train loss:2.314416391780709\n",
      "train loss:2.3662402433154606\n",
      "train loss:2.375144625811547\n",
      "=== epoch:24, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.3049096765492587\n",
      "train loss:2.3523372677954324\n",
      "train loss:2.2952576959556192\n",
      "train loss:2.3026860224712786\n",
      "=== epoch:25, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.3441594236541237\n",
      "train loss:2.3650981456921514\n",
      "train loss:2.318846753028875\n",
      "train loss:2.3145737303919405\n",
      "=== epoch:26, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.35511035829828\n",
      "train loss:2.325429659796722\n",
      "train loss:2.3190194448864228\n",
      "train loss:2.385687717401407\n",
      "=== epoch:27, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.358970790148514\n",
      "train loss:2.3329049377743662\n",
      "train loss:2.3226176526865374\n",
      "train loss:2.30434446661896\n",
      "=== epoch:28, train acc:0.065, test acc:0.04 ===\n",
      "train loss:2.301679994947642\n",
      "train loss:2.306565652548098\n",
      "train loss:2.333930299534392\n",
      "train loss:2.3317904361578603\n",
      "=== epoch:29, train acc:0.0675, test acc:0.04 ===\n",
      "train loss:2.306894439775336\n",
      "train loss:2.2643749990970132\n",
      "train loss:2.3453532867942415\n",
      "train loss:2.2822278035443437\n",
      "=== epoch:30, train acc:0.0675, test acc:0.04 ===\n",
      "train loss:2.329567994759391\n",
      "train loss:2.2860534258250165\n",
      "train loss:2.299684659517086\n",
      "train loss:2.3225924294393065\n",
      "=== epoch:31, train acc:0.07, test acc:0.04 ===\n",
      "train loss:2.313280214981015\n",
      "train loss:2.3404490472723234\n",
      "train loss:2.3265329714358365\n",
      "train loss:2.281847609031808\n",
      "=== epoch:32, train acc:0.07, test acc:0.04 ===\n",
      "train loss:2.3225188814809825\n",
      "train loss:2.330659761822164\n",
      "train loss:2.2626061878132506\n",
      "train loss:2.2651818898462532\n",
      "=== epoch:33, train acc:0.07, test acc:0.04 ===\n",
      "train loss:2.3066403278965906\n",
      "train loss:2.299951857144354\n",
      "train loss:2.315672139624634\n",
      "train loss:2.2954483340522702\n",
      "=== epoch:34, train acc:0.07, test acc:0.04 ===\n",
      "train loss:2.251524753901262\n",
      "train loss:2.3115950027515946\n",
      "train loss:2.3590569927792577\n",
      "train loss:2.3556274705208105\n",
      "=== epoch:35, train acc:0.07, test acc:0.04 ===\n",
      "train loss:2.3347836767158974\n",
      "train loss:2.3429075942414888\n",
      "train loss:2.308696242158473\n",
      "train loss:2.2555160716120324\n",
      "=== epoch:36, train acc:0.0725, test acc:0.04 ===\n",
      "train loss:2.233173428708562\n",
      "train loss:2.2763306717735126\n",
      "train loss:2.3401293863883637\n",
      "train loss:2.317020787421048\n",
      "=== epoch:37, train acc:0.0725, test acc:0.04 ===\n",
      "train loss:2.340580595989447\n",
      "train loss:2.333024903087539\n",
      "train loss:2.2335708143591546\n",
      "train loss:2.3332150830189673\n",
      "=== epoch:38, train acc:0.075, test acc:0.04 ===\n",
      "train loss:2.327973298133403\n",
      "train loss:2.282531155932599\n",
      "train loss:2.299396333065162\n",
      "train loss:2.2766295228608233\n",
      "=== epoch:39, train acc:0.075, test acc:0.04 ===\n",
      "train loss:2.349186321536197\n",
      "train loss:2.2686255148252035\n",
      "train loss:2.2931775219327837\n",
      "train loss:2.3085411796521433\n",
      "=== epoch:40, train acc:0.075, test acc:0.04 ===\n",
      "train loss:2.3088283415995847\n",
      "train loss:2.2716371401687994\n",
      "train loss:2.347856079849931\n",
      "train loss:2.280043532881634\n",
      "=== epoch:41, train acc:0.0775, test acc:0.04 ===\n",
      "train loss:2.296123144647629\n",
      "train loss:2.2977672221382117\n",
      "train loss:2.287665985310419\n",
      "train loss:2.2870305543544096\n",
      "=== epoch:42, train acc:0.0775, test acc:0.04 ===\n",
      "train loss:2.320070782831728\n",
      "train loss:2.3302791917212415\n",
      "train loss:2.306919003743836\n",
      "train loss:2.3478222106067492\n",
      "=== epoch:43, train acc:0.075, test acc:0.04 ===\n",
      "train loss:2.3086523327252952\n",
      "train loss:2.316696173405805\n",
      "train loss:2.266119056178782\n",
      "train loss:2.284342196161058\n",
      "=== epoch:44, train acc:0.0775, test acc:0.04 ===\n",
      "train loss:2.309079902917728\n",
      "train loss:2.343099600612951\n",
      "train loss:2.3094563924794373\n",
      "train loss:2.2749265200283078\n",
      "=== epoch:45, train acc:0.0775, test acc:0.05 ===\n",
      "train loss:2.30255356467953\n",
      "train loss:2.2726784299284857\n",
      "train loss:2.309899368256175\n",
      "train loss:2.2777660385096095\n",
      "=== epoch:46, train acc:0.0775, test acc:0.06 ===\n",
      "train loss:2.3041363464206843\n",
      "train loss:2.328299898308229\n",
      "train loss:2.284995169959627\n",
      "train loss:2.305475498977208\n",
      "=== epoch:47, train acc:0.0775, test acc:0.06 ===\n",
      "train loss:2.2540225529492557\n",
      "train loss:2.3075011948688084\n",
      "train loss:2.2590325946429743\n",
      "train loss:2.288834488353233\n",
      "=== epoch:48, train acc:0.0775, test acc:0.06 ===\n",
      "train loss:2.299795628415555\n",
      "train loss:2.3011448236844894\n",
      "train loss:2.2988417161833556\n",
      "train loss:2.272218408879856\n",
      "=== epoch:49, train acc:0.0775, test acc:0.06 ===\n",
      "train loss:2.260983626316376\n",
      "train loss:2.2768716044633095\n",
      "train loss:2.2936537370309744\n",
      "train loss:2.3067726116014393\n",
      "=== epoch:50, train acc:0.08, test acc:0.06 ===\n",
      "train loss:2.3008652768735516\n",
      "train loss:2.287437839514526\n",
      "train loss:2.332249131212018\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.06\n",
      "val_acc: 0.0600 | lr: 0.0003, weight_decay: 0.0000\n",
      "train loss:2.537487985472239\n",
      "=== epoch:1, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4607404563819033\n",
      "train loss:2.5129497106988548\n",
      "train loss:2.523985063833098\n",
      "train loss:2.4722426886032367\n",
      "=== epoch:2, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4354297071238125\n",
      "train loss:2.5272783693026737\n",
      "train loss:2.5040630275613536\n",
      "train loss:2.4601819112775605\n",
      "=== epoch:3, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.42327996628945\n",
      "train loss:2.4747263977669767\n",
      "train loss:2.4409247148031508\n",
      "train loss:2.4413090637781303\n",
      "=== epoch:4, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.5431928655632063\n",
      "train loss:2.5129266599989704\n",
      "train loss:2.466769086936024\n",
      "train loss:2.5294602086113045\n",
      "=== epoch:5, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.5601993186844147\n",
      "train loss:2.429456653730998\n",
      "train loss:2.4346491363842993\n",
      "train loss:2.5029478649876733\n",
      "=== epoch:6, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.445527856148846\n",
      "train loss:2.478865426476752\n",
      "train loss:2.476243957036731\n",
      "train loss:2.5012432711289136\n",
      "=== epoch:7, train acc:0.105, test acc:0.11 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.5611834932716753\n",
      "train loss:2.433860345904333\n",
      "train loss:2.549215317198408\n",
      "train loss:2.4684302588278046\n",
      "=== epoch:8, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4603186905548244\n",
      "train loss:2.4721930002776844\n",
      "train loss:2.460717776752303\n",
      "train loss:2.5174877286454076\n",
      "=== epoch:9, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4823687466159003\n",
      "train loss:2.4999093782332764\n",
      "train loss:2.456744614811756\n",
      "train loss:2.4275249420183114\n",
      "=== epoch:10, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4236517945334755\n",
      "train loss:2.551622498520117\n",
      "train loss:2.4551784894902657\n",
      "train loss:2.4860487034234806\n",
      "=== epoch:11, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.3717307276216473\n",
      "train loss:2.5013009679137492\n",
      "train loss:2.4824304021738803\n",
      "train loss:2.4710787552641653\n",
      "=== epoch:12, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4957465493758404\n",
      "train loss:2.40514971519541\n",
      "train loss:2.431721392234616\n",
      "train loss:2.422639636399068\n",
      "=== epoch:13, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.580504417476114\n",
      "train loss:2.478737421494495\n",
      "train loss:2.5224615090904843\n",
      "train loss:2.4476998884211887\n",
      "=== epoch:14, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4905230190124112\n",
      "train loss:2.4367733557969977\n",
      "train loss:2.4035435880229916\n",
      "train loss:2.427099958593971\n",
      "=== epoch:15, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4946802828768013\n",
      "train loss:2.4816478306630034\n",
      "train loss:2.5090008754727786\n",
      "train loss:2.457211763219616\n",
      "=== epoch:16, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.545248371461753\n",
      "train loss:2.426057044122887\n",
      "train loss:2.522713550209177\n",
      "train loss:2.420430308312863\n",
      "=== epoch:17, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.504108843574537\n",
      "train loss:2.4573053443634647\n",
      "train loss:2.5229835469291375\n",
      "train loss:2.5425661856954234\n",
      "=== epoch:18, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.437234913417276\n",
      "train loss:2.5090056611483087\n",
      "train loss:2.4818951079272917\n",
      "train loss:2.445005906781418\n",
      "=== epoch:19, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4559108581126807\n",
      "train loss:2.461448795829681\n",
      "train loss:2.4662445110253177\n",
      "train loss:2.3800445159797197\n",
      "=== epoch:20, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.498844123691447\n",
      "train loss:2.4518108746417187\n",
      "train loss:2.5195726012367654\n",
      "train loss:2.495816155467936\n",
      "=== epoch:21, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4316329167471316\n",
      "train loss:2.4597335899144546\n",
      "train loss:2.5343677297654934\n",
      "train loss:2.4386257385381476\n",
      "=== epoch:22, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.537302982891926\n",
      "train loss:2.4309958394693925\n",
      "train loss:2.4773726458966845\n",
      "train loss:2.4637904019693018\n",
      "=== epoch:23, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.457365029340683\n",
      "train loss:2.463665066031619\n",
      "train loss:2.5205994122686444\n",
      "train loss:2.5154291523072256\n",
      "=== epoch:24, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.518609771455408\n",
      "train loss:2.4851878952473214\n",
      "train loss:2.441722554422353\n",
      "train loss:2.4345115114648874\n",
      "=== epoch:25, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.465863860046325\n",
      "train loss:2.4961270524227697\n",
      "train loss:2.4294854751686623\n",
      "train loss:2.411345228466573\n",
      "=== epoch:26, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.5028554270165415\n",
      "train loss:2.442084316615174\n",
      "train loss:2.455951438597349\n",
      "train loss:2.4625525446830454\n",
      "=== epoch:27, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4154159965301916\n",
      "train loss:2.4791803473880782\n",
      "train loss:2.4215232031841967\n",
      "train loss:2.4947923127311706\n",
      "=== epoch:28, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.5000558631930363\n",
      "train loss:2.391299134305713\n",
      "train loss:2.3703463078962232\n",
      "train loss:2.5194377631416685\n",
      "=== epoch:29, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.3558921303867013\n",
      "train loss:2.4573115942096964\n",
      "train loss:2.4795791192319028\n",
      "train loss:2.45514816988323\n",
      "=== epoch:30, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4517156869750507\n",
      "train loss:2.4469101027357407\n",
      "train loss:2.495717758704894\n",
      "train loss:2.3808851322135487\n",
      "=== epoch:31, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.48487582373527\n",
      "train loss:2.4991415173826983\n",
      "train loss:2.5147357075549768\n",
      "train loss:2.4402321077689964\n",
      "=== epoch:32, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4223828106352396\n",
      "train loss:2.5346376119131477\n",
      "train loss:2.4119877412007167\n",
      "train loss:2.4426459136006056\n",
      "=== epoch:33, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4151610597036477\n",
      "train loss:2.5298808160760067\n",
      "train loss:2.5111677097555187\n",
      "train loss:2.547129058882252\n",
      "=== epoch:34, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4843801134707455\n",
      "train loss:2.437312386242946\n",
      "train loss:2.486626201195295\n",
      "train loss:2.53793940822905\n",
      "=== epoch:35, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4950864185152186\n",
      "train loss:2.4217172096582718\n",
      "train loss:2.4486825118080393\n",
      "train loss:2.448828685370588\n",
      "=== epoch:36, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.456863038886275\n",
      "train loss:2.4545059082149066\n",
      "train loss:2.5473302197185697\n",
      "train loss:2.4151914197448967\n",
      "=== epoch:37, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.476007797521811\n",
      "train loss:2.4390243259359834\n",
      "train loss:2.4674091840748065\n",
      "train loss:2.5327380638253816\n",
      "=== epoch:38, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.467553078022175\n",
      "train loss:2.5116847586541273\n",
      "train loss:2.451961960919483\n",
      "train loss:2.520955950524151\n",
      "=== epoch:39, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.477450410227974\n",
      "train loss:2.5313620742965184\n",
      "train loss:2.4970170864277925\n",
      "train loss:2.5175997278385993\n",
      "=== epoch:40, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4628393816155927\n",
      "train loss:2.462833178409567\n",
      "train loss:2.453196379557971\n",
      "train loss:2.4930834389308156\n",
      "=== epoch:41, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.423456743998399\n",
      "train loss:2.4819741008424003\n",
      "train loss:2.464662518303737\n",
      "train loss:2.4384307002457017\n",
      "=== epoch:42, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.5526026310857253\n",
      "train loss:2.384452738753222\n",
      "train loss:2.417244484592437\n",
      "train loss:2.4408478242628457\n",
      "=== epoch:43, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.472092611113576\n",
      "train loss:2.508352977796865\n",
      "train loss:2.562966668457085\n",
      "train loss:2.436226507334296\n",
      "=== epoch:44, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.456084280734758\n",
      "train loss:2.4892581331367873\n",
      "train loss:2.47212276217494\n",
      "train loss:2.372494151426739\n",
      "=== epoch:45, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4369194764284323\n",
      "train loss:2.4494540054949443\n",
      "train loss:2.4645597284951917\n",
      "train loss:2.4458351873081963\n",
      "=== epoch:46, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.456374505367329\n",
      "train loss:2.468022783523366\n",
      "train loss:2.5129185801732654\n",
      "train loss:2.439381803819696\n",
      "=== epoch:47, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4885357109390256\n",
      "train loss:2.443886980292954\n",
      "train loss:2.406370852965318\n",
      "train loss:2.5105090174492197\n",
      "=== epoch:48, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.448501610774158\n",
      "train loss:2.423446416873268\n",
      "train loss:2.5222024994434054\n",
      "train loss:2.49573585287547\n",
      "=== epoch:49, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.4704164674999487\n",
      "train loss:2.5052483512937065\n",
      "train loss:2.489492560056426\n",
      "train loss:2.4236467263775148\n",
      "=== epoch:50, train acc:0.105, test acc:0.11 ===\n",
      "train loss:2.476460106746836\n",
      "train loss:2.4762846664766744\n",
      "train loss:2.496211262978486\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.11\n",
      "val_acc: 0.1100 | lr: 0.0000, weight_decay: 0.0001\n",
      "train loss:2.377990848294276\n",
      "=== epoch:1, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.382605063350397\n",
      "train loss:2.3872593160839317\n",
      "train loss:2.323415725152016\n",
      "train loss:2.364526351647783\n",
      "=== epoch:2, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.356332769062752\n",
      "train loss:2.381950384742482\n",
      "train loss:2.4251749174455406\n",
      "train loss:2.3348263928109354\n",
      "=== epoch:3, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.2953456818435094\n",
      "train loss:2.4102337335797572\n",
      "train loss:2.328461027697205\n",
      "train loss:2.3891981929113975\n",
      "=== epoch:4, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.3169695541645576\n",
      "train loss:2.3140177856651816\n",
      "train loss:2.345163682234667\n",
      "train loss:2.3373620247949614\n",
      "=== epoch:5, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.3756359646890273\n",
      "train loss:2.36769237793608\n",
      "train loss:2.344660861995108\n",
      "train loss:2.293685301010191\n",
      "=== epoch:6, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.286139034211502\n",
      "train loss:2.3251467128948002\n",
      "train loss:2.3262685557266427\n",
      "train loss:2.3755662191888014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:7, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.272901681640896\n",
      "train loss:2.231909397341234\n",
      "train loss:2.3458773084350346\n",
      "train loss:2.3595722710014853\n",
      "=== epoch:8, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.339712385282295\n",
      "train loss:2.3435749633975513\n",
      "train loss:2.3005135448193186\n",
      "train loss:2.3077232998409083\n",
      "=== epoch:9, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.2804925058863463\n",
      "train loss:2.370327219897403\n",
      "train loss:2.321572296004429\n",
      "train loss:2.352332668780672\n",
      "=== epoch:10, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.376503449945668\n",
      "train loss:2.3379251527253957\n",
      "train loss:2.355802478498976\n",
      "train loss:2.4435479921164194\n",
      "=== epoch:11, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.282736710076216\n",
      "train loss:2.3330875608972983\n",
      "train loss:2.3715222978298485\n",
      "train loss:2.2924778580683385\n",
      "=== epoch:12, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.2657762991550143\n",
      "train loss:2.3642436877819946\n",
      "train loss:2.322188560593622\n",
      "train loss:2.2818504971947937\n",
      "=== epoch:13, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.303964925100382\n",
      "train loss:2.3578122312434817\n",
      "train loss:2.324886357985066\n",
      "train loss:2.302054727338045\n",
      "=== epoch:14, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.3499862001233356\n",
      "train loss:2.317711572519814\n",
      "train loss:2.288117479576773\n",
      "train loss:2.2787926312521973\n",
      "=== epoch:15, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.3064944268647274\n",
      "train loss:2.2887334229142473\n",
      "train loss:2.3200415394070903\n",
      "train loss:2.3120942386130565\n",
      "=== epoch:16, train acc:0.1225, test acc:0.19 ===\n",
      "train loss:2.281934544144342\n",
      "train loss:2.315441011619548\n",
      "train loss:2.344817477072104\n",
      "train loss:2.342873456585554\n",
      "=== epoch:17, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.299936053626865\n",
      "train loss:2.3466156849057738\n",
      "train loss:2.3594272897231456\n",
      "train loss:2.4171330315931194\n",
      "=== epoch:18, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.276688608085677\n",
      "train loss:2.309667169054143\n",
      "train loss:2.2970179664605004\n",
      "train loss:2.2777540428627576\n",
      "=== epoch:19, train acc:0.1275, test acc:0.19 ===\n",
      "train loss:2.2954346824211327\n",
      "train loss:2.3477476066615304\n",
      "train loss:2.273446818125568\n",
      "train loss:2.314742427479908\n",
      "=== epoch:20, train acc:0.1275, test acc:0.19 ===\n",
      "train loss:2.246571294787757\n",
      "train loss:2.366545062046811\n",
      "train loss:2.35267809669612\n",
      "train loss:2.317081481382144\n",
      "=== epoch:21, train acc:0.125, test acc:0.19 ===\n",
      "train loss:2.390767089585656\n",
      "train loss:2.2509184621089373\n",
      "train loss:2.2672388377582746\n",
      "train loss:2.34879075043536\n",
      "=== epoch:22, train acc:0.1275, test acc:0.19 ===\n",
      "train loss:2.3381022694387386\n",
      "train loss:2.301414853395309\n",
      "train loss:2.351420223275741\n",
      "train loss:2.2201659038995105\n",
      "=== epoch:23, train acc:0.13, test acc:0.19 ===\n",
      "train loss:2.307711854449943\n",
      "train loss:2.2426195224053895\n",
      "train loss:2.383924169190941\n",
      "train loss:2.3008664332754383\n",
      "=== epoch:24, train acc:0.13, test acc:0.19 ===\n",
      "train loss:2.261393981210533\n",
      "train loss:2.2564014007756032\n",
      "train loss:2.338084220924927\n",
      "train loss:2.3229609909306346\n",
      "=== epoch:25, train acc:0.13, test acc:0.19 ===\n",
      "train loss:2.290004185975411\n",
      "train loss:2.2601316591665492\n",
      "train loss:2.255300174879113\n",
      "train loss:2.2873711222725253\n",
      "=== epoch:26, train acc:0.13, test acc:0.19 ===\n",
      "train loss:2.2395899005110382\n",
      "train loss:2.2944685415567383\n",
      "train loss:2.2923738439151067\n",
      "train loss:2.243114971829883\n",
      "=== epoch:27, train acc:0.13, test acc:0.19 ===\n",
      "train loss:2.225216672592853\n",
      "train loss:2.3013594492008744\n",
      "train loss:2.278804753335775\n",
      "train loss:2.220761539080536\n",
      "=== epoch:28, train acc:0.13, test acc:0.19 ===\n",
      "train loss:2.273322533213215\n",
      "train loss:2.308952277884916\n",
      "train loss:2.2428503154298745\n",
      "train loss:2.3023204659175844\n",
      "=== epoch:29, train acc:0.1325, test acc:0.19 ===\n",
      "train loss:2.281423230852696\n",
      "train loss:2.2889839089404482\n",
      "train loss:2.2640641355549613\n",
      "train loss:2.2790724694572333\n",
      "=== epoch:30, train acc:0.135, test acc:0.19 ===\n",
      "train loss:2.31172281087724\n",
      "train loss:2.3046977464088143\n",
      "train loss:2.2167588323521343\n",
      "train loss:2.3444937875918486\n",
      "=== epoch:31, train acc:0.135, test acc:0.19 ===\n",
      "train loss:2.281509791623247\n",
      "train loss:2.299266143651163\n",
      "train loss:2.2507534347654485\n",
      "train loss:2.3704049805770944\n",
      "=== epoch:32, train acc:0.14, test acc:0.19 ===\n",
      "train loss:2.2786483392477597\n",
      "train loss:2.293003530201831\n",
      "train loss:2.299615467563966\n",
      "train loss:2.2790001859090565\n",
      "=== epoch:33, train acc:0.145, test acc:0.19 ===\n",
      "train loss:2.268036811208067\n",
      "train loss:2.3460631768590856\n",
      "train loss:2.3081087878611344\n",
      "train loss:2.30665163765492\n",
      "=== epoch:34, train acc:0.1425, test acc:0.19 ===\n",
      "train loss:2.2265821109881085\n",
      "train loss:2.3434243061439117\n",
      "train loss:2.2815343950014046\n",
      "train loss:2.253769265352574\n",
      "=== epoch:35, train acc:0.145, test acc:0.19 ===\n",
      "train loss:2.2179970391863097\n",
      "train loss:2.25030725051858\n",
      "train loss:2.3036465429130306\n",
      "train loss:2.384529207548283\n",
      "=== epoch:36, train acc:0.145, test acc:0.19 ===\n",
      "train loss:2.27868875714475\n",
      "train loss:2.321315956072601\n",
      "train loss:2.2944573189970425\n",
      "train loss:2.275632601154544\n",
      "=== epoch:37, train acc:0.145, test acc:0.19 ===\n",
      "train loss:2.2400880637641043\n",
      "train loss:2.293482024298946\n",
      "train loss:2.238249325846003\n",
      "train loss:2.239300078648826\n",
      "=== epoch:38, train acc:0.15, test acc:0.19 ===\n",
      "train loss:2.2616000449819227\n",
      "train loss:2.28306455693727\n",
      "train loss:2.254338021406147\n",
      "train loss:2.2269781499457206\n",
      "=== epoch:39, train acc:0.15, test acc:0.19 ===\n",
      "train loss:2.2757935290139404\n",
      "train loss:2.3167163499359233\n",
      "train loss:2.2551277126660274\n",
      "train loss:2.185630052687192\n",
      "=== epoch:40, train acc:0.15, test acc:0.2 ===\n",
      "train loss:2.2873729731623578\n",
      "train loss:2.241541568662198\n",
      "train loss:2.3147120492814226\n",
      "train loss:2.271270572781225\n",
      "=== epoch:41, train acc:0.1525, test acc:0.19 ===\n",
      "train loss:2.306135884698881\n",
      "train loss:2.275141191905598\n",
      "train loss:2.291377567330895\n",
      "train loss:2.2642277486459794\n",
      "=== epoch:42, train acc:0.16, test acc:0.19 ===\n",
      "train loss:2.2466569622523016\n",
      "train loss:2.270846371983716\n",
      "train loss:2.2587368882720615\n",
      "train loss:2.25637640523686\n",
      "=== epoch:43, train acc:0.1625, test acc:0.19 ===\n",
      "train loss:2.272768677647417\n",
      "train loss:2.3048289191757036\n",
      "train loss:2.229832365138637\n",
      "train loss:2.2817661267169753\n",
      "=== epoch:44, train acc:0.1625, test acc:0.2 ===\n",
      "train loss:2.2961711844871657\n",
      "train loss:2.251593287775022\n",
      "train loss:2.2745591514259345\n",
      "train loss:2.2433000423968195\n",
      "=== epoch:45, train acc:0.1625, test acc:0.2 ===\n",
      "train loss:2.2126545070739443\n",
      "train loss:2.2622690175508495\n",
      "train loss:2.2365273391806\n",
      "train loss:2.228022709948352\n",
      "=== epoch:46, train acc:0.165, test acc:0.2 ===\n",
      "train loss:2.2948638697018198\n",
      "train loss:2.2784353338936496\n",
      "train loss:2.2647545477405915\n",
      "train loss:2.284589011962661\n",
      "=== epoch:47, train acc:0.165, test acc:0.2 ===\n",
      "train loss:2.258581652430807\n",
      "train loss:2.244399562017401\n",
      "train loss:2.2943462942000985\n",
      "train loss:2.24212597987998\n",
      "=== epoch:48, train acc:0.165, test acc:0.2 ===\n",
      "train loss:2.3009912120636518\n",
      "train loss:2.217136195083707\n",
      "train loss:2.21165636829795\n",
      "train loss:2.228487479313829\n",
      "=== epoch:49, train acc:0.1625, test acc:0.2 ===\n",
      "train loss:2.2656696442861572\n",
      "train loss:2.266790359644735\n",
      "train loss:2.2256296040622905\n",
      "train loss:2.192006348841295\n",
      "=== epoch:50, train acc:0.1675, test acc:0.2 ===\n",
      "train loss:2.268766689911325\n",
      "train loss:2.232366250907264\n",
      "train loss:2.27734583214403\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.2\n",
      "val_acc: 0.2000 | lr: 0.0006, weight_decay: 0.0000\n",
      "train loss:2.539266482757591\n",
      "=== epoch:1, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.46976700696185\n",
      "train loss:2.5755281654556557\n",
      "train loss:2.5518777922812745\n",
      "train loss:2.560953816231454\n",
      "=== epoch:2, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4975370870949294\n",
      "train loss:2.4953366819802802\n",
      "train loss:2.542678709010054\n",
      "train loss:2.533099386879714\n",
      "=== epoch:3, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.548595486951683\n",
      "train loss:2.455696591751056\n",
      "train loss:2.443087441582284\n",
      "train loss:2.4431888516049565\n",
      "=== epoch:4, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.579933619694525\n",
      "train loss:2.579599001477242\n",
      "train loss:2.3600797278730083\n",
      "train loss:2.5221615100304526\n",
      "=== epoch:5, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5779986597316022\n",
      "train loss:2.5809035540043204\n",
      "train loss:2.4911737459989176\n",
      "train loss:2.524072647618188\n",
      "=== epoch:6, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4566342514686186\n",
      "train loss:2.5551947677861877\n",
      "train loss:2.5438232929293276\n",
      "train loss:2.6322773292349533\n",
      "=== epoch:7, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.3899214456518254\n",
      "train loss:2.5991153291280096\n",
      "train loss:2.4026315871124986\n",
      "train loss:2.4274372032261335\n",
      "=== epoch:8, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4634531019909387\n",
      "train loss:2.501411699827847\n",
      "train loss:2.4247179421725087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.514968385364944\n",
      "=== epoch:9, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.624877449017531\n",
      "train loss:2.5135589432574106\n",
      "train loss:2.381161829501582\n",
      "train loss:2.492725140039221\n",
      "=== epoch:10, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.495025083506465\n",
      "train loss:2.626715100695072\n",
      "train loss:2.5416988252734973\n",
      "train loss:2.48261086884452\n",
      "=== epoch:11, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.512140713899485\n",
      "train loss:2.389341581626579\n",
      "train loss:2.584327920684682\n",
      "train loss:2.507902168579359\n",
      "=== epoch:12, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4474905955414603\n",
      "train loss:2.602500329579376\n",
      "train loss:2.5344696145244585\n",
      "train loss:2.394376600660637\n",
      "=== epoch:13, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5464299516855022\n",
      "train loss:2.542126189727588\n",
      "train loss:2.520412616749662\n",
      "train loss:2.550226110332142\n",
      "=== epoch:14, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4889312964177313\n",
      "train loss:2.46713127123773\n",
      "train loss:2.537816226326605\n",
      "train loss:2.3986715402246896\n",
      "=== epoch:15, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5052323078352092\n",
      "train loss:2.527938658926853\n",
      "train loss:2.485700553278238\n",
      "train loss:2.521549511830525\n",
      "=== epoch:16, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4936859669838887\n",
      "train loss:2.4366354627864424\n",
      "train loss:2.4451180845362197\n",
      "train loss:2.4892745333959514\n",
      "=== epoch:17, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.518126355373779\n",
      "train loss:2.566827549256915\n",
      "train loss:2.522635149570358\n",
      "train loss:2.5865865116982434\n",
      "=== epoch:18, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4680109248318116\n",
      "train loss:2.5573590351211593\n",
      "train loss:2.451675500071184\n",
      "train loss:2.50600742928446\n",
      "=== epoch:19, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.523696934645839\n",
      "train loss:2.6069605876421167\n",
      "train loss:2.4184832865677586\n",
      "train loss:2.4465637679132772\n",
      "=== epoch:20, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4092561058612696\n",
      "train loss:2.5825034945167\n",
      "train loss:2.492695952445125\n",
      "train loss:2.5133121654984043\n",
      "=== epoch:21, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5473013288806023\n",
      "train loss:2.4693550425352164\n",
      "train loss:2.553882742732743\n",
      "train loss:2.454373711450746\n",
      "=== epoch:22, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.471728374449715\n",
      "train loss:2.5023516394888774\n",
      "train loss:2.5713042398439883\n",
      "train loss:2.500740163284158\n",
      "=== epoch:23, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5754935454753096\n",
      "train loss:2.4799537550932422\n",
      "train loss:2.466095218403714\n",
      "train loss:2.428421480048046\n",
      "=== epoch:24, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.47619395758417\n",
      "train loss:2.491095768838333\n",
      "train loss:2.4902636074356863\n",
      "train loss:2.498305775015265\n",
      "=== epoch:25, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.584213232787238\n",
      "train loss:2.396663902718381\n",
      "train loss:2.5612516434620405\n",
      "train loss:2.3175048271685466\n",
      "=== epoch:26, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.534817232165276\n",
      "train loss:2.540943692032263\n",
      "train loss:2.429316722872305\n",
      "train loss:2.459904332068782\n",
      "=== epoch:27, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4718269589490087\n",
      "train loss:2.452028111872276\n",
      "train loss:2.462681225164945\n",
      "train loss:2.4979480462175108\n",
      "=== epoch:28, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.593532101512466\n",
      "train loss:2.5608006696821772\n",
      "train loss:2.5749261775614283\n",
      "train loss:2.5007026393787055\n",
      "=== epoch:29, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5400461647237127\n",
      "train loss:2.4994958791647095\n",
      "train loss:2.49262577204481\n",
      "train loss:2.5232471192474097\n",
      "=== epoch:30, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4557714405506323\n",
      "train loss:2.540980502845334\n",
      "train loss:2.448031667156849\n",
      "train loss:2.515147564502052\n",
      "=== epoch:31, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5376115401540376\n",
      "train loss:2.5624355595567847\n",
      "train loss:2.4958486682023326\n",
      "train loss:2.4966846870457338\n",
      "=== epoch:32, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.475310229695695\n",
      "train loss:2.5491302812234347\n",
      "train loss:2.4739638626929463\n",
      "train loss:2.6055481296492315\n",
      "=== epoch:33, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4799198557494733\n",
      "train loss:2.587756875517823\n",
      "train loss:2.469454776799072\n",
      "train loss:2.4889408709243037\n",
      "=== epoch:34, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4123845759734484\n",
      "train loss:2.5724363847421317\n",
      "train loss:2.531285292417735\n",
      "train loss:2.504858771630961\n",
      "=== epoch:35, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.52324592635556\n",
      "train loss:2.519170225940652\n",
      "train loss:2.4495673694662026\n",
      "train loss:2.5286672754446746\n",
      "=== epoch:36, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.422707046747161\n",
      "train loss:2.5980588773287376\n",
      "train loss:2.5168814959756487\n",
      "train loss:2.35461727292752\n",
      "=== epoch:37, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5395453660798775\n",
      "train loss:2.4830193822620354\n",
      "train loss:2.49552826973283\n",
      "train loss:2.4985490640900405\n",
      "=== epoch:38, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4836954722515947\n",
      "train loss:2.510753334746637\n",
      "train loss:2.469637240964122\n",
      "train loss:2.488363614276117\n",
      "=== epoch:39, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4453124842542495\n",
      "train loss:2.4591135179561663\n",
      "train loss:2.4363775488427706\n",
      "train loss:2.478357014413535\n",
      "=== epoch:40, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4652822591217944\n",
      "train loss:2.5347546855363645\n",
      "train loss:2.5384582558820847\n",
      "train loss:2.492598309032116\n",
      "=== epoch:41, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.484227540647492\n",
      "train loss:2.5847118611146156\n",
      "train loss:2.5560804056183666\n",
      "train loss:2.506595920107276\n",
      "=== epoch:42, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5199205571980605\n",
      "train loss:2.500862445928511\n",
      "train loss:2.521363183945984\n",
      "train loss:2.40867869212059\n",
      "=== epoch:43, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5478727450075382\n",
      "train loss:2.5226902360958827\n",
      "train loss:2.639933244398224\n",
      "train loss:2.482385418701426\n",
      "=== epoch:44, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.4802121161491217\n",
      "train loss:2.4981250398296364\n",
      "train loss:2.4077432277717365\n",
      "train loss:2.4901291003494306\n",
      "=== epoch:45, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.516092457988235\n",
      "train loss:2.4555688580776405\n",
      "train loss:2.662783158039626\n",
      "train loss:2.521854969594192\n",
      "=== epoch:46, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.5425197731597464\n",
      "train loss:2.4052995570714604\n",
      "train loss:2.386956252692737\n",
      "train loss:2.579097270721304\n",
      "=== epoch:47, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.3515072307814293\n",
      "train loss:2.4467815102850787\n",
      "train loss:2.4319181776047336\n",
      "train loss:2.4461734575208176\n",
      "=== epoch:48, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.52456426809975\n",
      "train loss:2.629939128372779\n",
      "train loss:2.5012766327251197\n",
      "train loss:2.3351119052333655\n",
      "=== epoch:49, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.485140439408975\n",
      "train loss:2.477163895895613\n",
      "train loss:2.4362979409883905\n",
      "train loss:2.5150912062464026\n",
      "=== epoch:50, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.53149291083498\n",
      "train loss:2.428258071881725\n",
      "train loss:2.4482638077080456\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.13\n",
      "val_acc: 0.1300 | lr: 0.0000, weight_decay: 0.0001\n",
      "train loss:2.371901809159134\n",
      "=== epoch:1, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.4139127205040554\n",
      "train loss:2.389392842137788\n",
      "train loss:2.379664285244777\n",
      "train loss:2.3764440008429975\n",
      "=== epoch:2, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.3494787829377484\n",
      "train loss:2.3230522210319555\n",
      "train loss:2.380392353939028\n",
      "train loss:2.362126365787364\n",
      "=== epoch:3, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.343828568909282\n",
      "train loss:2.3723530253133602\n",
      "train loss:2.4037489821279863\n",
      "train loss:2.3771635428412354\n",
      "=== epoch:4, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.427920024147675\n",
      "train loss:2.3788971930841467\n",
      "train loss:2.4048527387413157\n",
      "train loss:2.3717705981621218\n",
      "=== epoch:5, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.422983081708117\n",
      "train loss:2.3494379131346097\n",
      "train loss:2.3928157908734566\n",
      "train loss:2.382532619566693\n",
      "=== epoch:6, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.3671009444183237\n",
      "train loss:2.3610429951001555\n",
      "train loss:2.4026252744190653\n",
      "train loss:2.3580598951645144\n",
      "=== epoch:7, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.337546782024762\n",
      "train loss:2.3288994460048773\n",
      "train loss:2.372650024883101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4105637302771603\n",
      "=== epoch:8, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.3746887353683417\n",
      "train loss:2.322685345536702\n",
      "train loss:2.3156660820868415\n",
      "train loss:2.333714485772617\n",
      "=== epoch:9, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.3329455007308666\n",
      "train loss:2.3411834887471845\n",
      "train loss:2.275674304307248\n",
      "train loss:2.3438101098077926\n",
      "=== epoch:10, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.3657901842983535\n",
      "train loss:2.337582263391357\n",
      "train loss:2.3641608081718943\n",
      "train loss:2.372026109388463\n",
      "=== epoch:11, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.36232853815572\n",
      "train loss:2.355867364948754\n",
      "train loss:2.3586403117190966\n",
      "train loss:2.387130311547717\n",
      "=== epoch:12, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.347291134688076\n",
      "train loss:2.381054125457179\n",
      "train loss:2.3969556733724127\n",
      "train loss:2.3621741642141703\n",
      "=== epoch:13, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.4004392513759014\n",
      "train loss:2.4101306974523675\n",
      "train loss:2.395778307282478\n",
      "train loss:2.331554660957329\n",
      "=== epoch:14, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.3963729677753265\n",
      "train loss:2.3691685728819762\n",
      "train loss:2.377288695550404\n",
      "train loss:2.382793544324232\n",
      "=== epoch:15, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.3688154877339067\n",
      "train loss:2.342080064911523\n",
      "train loss:2.356295931763396\n",
      "train loss:2.3942783959502227\n",
      "=== epoch:16, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.38931581017636\n",
      "train loss:2.3640008850198733\n",
      "train loss:2.2755468333291065\n",
      "train loss:2.349478232143374\n",
      "=== epoch:17, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.2997402383578307\n",
      "train loss:2.3227695721524495\n",
      "train loss:2.361319850588556\n",
      "train loss:2.3393685102979975\n",
      "=== epoch:18, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.380580214915287\n",
      "train loss:2.3979718904901275\n",
      "train loss:2.32846493703871\n",
      "train loss:2.3555566446225926\n",
      "=== epoch:19, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.335603797714251\n",
      "train loss:2.351874977854202\n",
      "train loss:2.3601133828587213\n",
      "train loss:2.3600536986138345\n",
      "=== epoch:20, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.3304444653191982\n",
      "train loss:2.381830851985329\n",
      "train loss:2.381110980369118\n",
      "train loss:2.3264576682379463\n",
      "=== epoch:21, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.334786521031459\n",
      "train loss:2.386174435363136\n",
      "train loss:2.342828383459011\n",
      "train loss:2.4106174274072774\n",
      "=== epoch:22, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.358355657923325\n",
      "train loss:2.360582173791787\n",
      "train loss:2.3448357289959065\n",
      "train loss:2.3297004823008027\n",
      "=== epoch:23, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.314820437473245\n",
      "train loss:2.3646149129310876\n",
      "train loss:2.3211593689682872\n",
      "train loss:2.40150094476399\n",
      "=== epoch:24, train acc:0.1, test acc:0.09 ===\n",
      "train loss:2.32908305933338\n",
      "train loss:2.296486390019489\n",
      "train loss:2.4346513230895086\n",
      "train loss:2.3647416248285396\n",
      "=== epoch:25, train acc:0.1025, test acc:0.09 ===\n",
      "train loss:2.295726774226345\n",
      "train loss:2.3551973616270483\n",
      "train loss:2.352782593887849\n",
      "train loss:2.3553179277432474\n",
      "=== epoch:26, train acc:0.1025, test acc:0.09 ===\n",
      "train loss:2.3244813629438528\n",
      "train loss:2.3516952835778606\n",
      "train loss:2.3399044159853783\n",
      "train loss:2.311358443575858\n",
      "=== epoch:27, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.3710612089885807\n",
      "train loss:2.3071711219342173\n",
      "train loss:2.3421709033699756\n",
      "train loss:2.399107103024669\n",
      "=== epoch:28, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.3002997376426477\n",
      "train loss:2.2858636722435492\n",
      "train loss:2.3446028145918643\n",
      "train loss:2.2924329612304715\n",
      "=== epoch:29, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.309909139399608\n",
      "train loss:2.358215521677236\n",
      "train loss:2.3675074105662888\n",
      "train loss:2.34505612288652\n",
      "=== epoch:30, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.3219076664957887\n",
      "train loss:2.3188796964396885\n",
      "train loss:2.3154253806169653\n",
      "train loss:2.3273846172273887\n",
      "=== epoch:31, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.355201706709181\n",
      "train loss:2.306246676521143\n",
      "train loss:2.290907656804454\n",
      "train loss:2.3012120559011975\n",
      "=== epoch:32, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3451934677543003\n",
      "train loss:2.3898313509539175\n",
      "train loss:2.3086493606404446\n",
      "train loss:2.3515862317166567\n",
      "=== epoch:33, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3369395560648294\n",
      "train loss:2.335588855420377\n",
      "train loss:2.3732381306912353\n",
      "train loss:2.336202350845313\n",
      "=== epoch:34, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.344430489919146\n",
      "train loss:2.356524016576817\n",
      "train loss:2.365552556648726\n",
      "train loss:2.3269775405404016\n",
      "=== epoch:35, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3079850586503445\n",
      "train loss:2.337182564101737\n",
      "train loss:2.3128317843278645\n",
      "train loss:2.3024319648668965\n",
      "=== epoch:36, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3245128254513836\n",
      "train loss:2.3311097359796733\n",
      "train loss:2.2854187534257187\n",
      "train loss:2.340359281542673\n",
      "=== epoch:37, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.344656520086679\n",
      "train loss:2.3625352332046643\n",
      "train loss:2.3424140277202126\n",
      "train loss:2.381193993960248\n",
      "=== epoch:38, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3080402312462467\n",
      "train loss:2.328605883929043\n",
      "train loss:2.3213520217796244\n",
      "train loss:2.341721987332276\n",
      "=== epoch:39, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.358396467661088\n",
      "train loss:2.351327085786358\n",
      "train loss:2.3348280351924493\n",
      "train loss:2.327518481318142\n",
      "=== epoch:40, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.31681325335319\n",
      "train loss:2.3675256153637396\n",
      "train loss:2.338986104054284\n",
      "train loss:2.338873987747664\n",
      "=== epoch:41, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.3702378383542655\n",
      "train loss:2.3182104716695315\n",
      "train loss:2.317093916177306\n",
      "train loss:2.2981816528734496\n",
      "=== epoch:42, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.3571258660930416\n",
      "train loss:2.357748935451612\n",
      "train loss:2.349627953501436\n",
      "train loss:2.2740000667294393\n",
      "=== epoch:43, train acc:0.1175, test acc:0.09 ===\n",
      "train loss:2.360813467480859\n",
      "train loss:2.2995815950979805\n",
      "train loss:2.3600244378379873\n",
      "train loss:2.2563776282423973\n",
      "=== epoch:44, train acc:0.1175, test acc:0.1 ===\n",
      "train loss:2.3541301160128207\n",
      "train loss:2.3345467492337297\n",
      "train loss:2.3517828448820874\n",
      "train loss:2.3363453628568274\n",
      "=== epoch:45, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.270576584947296\n",
      "train loss:2.306559731437144\n",
      "train loss:2.2430082903567152\n",
      "train loss:2.3610508919640494\n",
      "=== epoch:46, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.2848666117413887\n",
      "train loss:2.3640830141329188\n",
      "train loss:2.2682906963319347\n",
      "train loss:2.301880332224362\n",
      "=== epoch:47, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.393276517296856\n",
      "train loss:2.3545414165641607\n",
      "train loss:2.3365697155376655\n",
      "train loss:2.301412952253741\n",
      "=== epoch:48, train acc:0.12, test acc:0.1 ===\n",
      "train loss:2.3677352929923066\n",
      "train loss:2.339277357928953\n",
      "train loss:2.3313285401089185\n",
      "train loss:2.308479442410954\n",
      "=== epoch:49, train acc:0.1225, test acc:0.1 ===\n",
      "train loss:2.2673620885558647\n",
      "train loss:2.3441621670411927\n",
      "train loss:2.3313010441926205\n",
      "train loss:2.295732529036683\n",
      "=== epoch:50, train acc:0.1225, test acc:0.1 ===\n",
      "train loss:2.3282688493565677\n",
      "train loss:2.298089663373932\n",
      "train loss:2.265682902229742\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.1\n",
      "val_acc: 0.1000 | lr: 0.0002, weight_decay: 0.0000\n",
      "train loss:2.333558363142854\n",
      "=== epoch:1, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.350903142443941\n",
      "train loss:2.3652343923000068\n",
      "train loss:2.341414430243503\n",
      "train loss:2.343205060392128\n",
      "=== epoch:2, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3192740204325695\n",
      "train loss:2.326964335675909\n",
      "train loss:2.29969707131991\n",
      "train loss:2.3248329787015862\n",
      "=== epoch:3, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3978024249607026\n",
      "train loss:2.367803167567972\n",
      "train loss:2.398501912168402\n",
      "train loss:2.3250034091621012\n",
      "=== epoch:4, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3801479489697788\n",
      "train loss:2.3663138527384078\n",
      "train loss:2.3385894425389386\n",
      "train loss:2.3195888271312897\n",
      "=== epoch:5, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.2965496297665524\n",
      "train loss:2.349374087446378\n",
      "train loss:2.308221648851787\n",
      "train loss:2.3137117866467767\n",
      "=== epoch:6, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.2984667667284624\n",
      "train loss:2.344848325788797\n",
      "train loss:2.338757114250894\n",
      "train loss:2.3405779166752487\n",
      "=== epoch:7, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.365813826269356\n",
      "train loss:2.335735788491772\n",
      "train loss:2.3361365469255215\n",
      "train loss:2.3555379075910015\n",
      "=== epoch:8, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.340945618797645\n",
      "train loss:2.325902946115021\n",
      "train loss:2.3660016997216964\n",
      "train loss:2.344770127389617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:9, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.355498376915837\n",
      "train loss:2.3051500709218016\n",
      "train loss:2.3018301980306495\n",
      "train loss:2.350555871299914\n",
      "=== epoch:10, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.358254790114055\n",
      "train loss:2.3456994205708415\n",
      "train loss:2.3259528827601947\n",
      "train loss:2.303254843300183\n",
      "=== epoch:11, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3462168255337508\n",
      "train loss:2.3260544666924523\n",
      "train loss:2.336775634180918\n",
      "train loss:2.3173333009722232\n",
      "=== epoch:12, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3338258968130527\n",
      "train loss:2.3608755929552303\n",
      "train loss:2.3355427612063138\n",
      "train loss:2.369536877641902\n",
      "=== epoch:13, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.326725977522005\n",
      "train loss:2.335245605121342\n",
      "train loss:2.3440383506673896\n",
      "train loss:2.3792939334998318\n",
      "=== epoch:14, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3162249324920716\n",
      "train loss:2.3425793968976194\n",
      "train loss:2.3369693605064383\n",
      "train loss:2.324143890768497\n",
      "=== epoch:15, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.336230963634511\n",
      "train loss:2.304678569798882\n",
      "train loss:2.3427090275128157\n",
      "train loss:2.362604335395903\n",
      "=== epoch:16, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3578897657947735\n",
      "train loss:2.352902349201688\n",
      "train loss:2.300461033154138\n",
      "train loss:2.308497654879693\n",
      "=== epoch:17, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3146622465364053\n",
      "train loss:2.3238554144998806\n",
      "train loss:2.3539465696076265\n",
      "train loss:2.337072110884036\n",
      "=== epoch:18, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3061177126129215\n",
      "train loss:2.379407445732095\n",
      "train loss:2.3355837630388487\n",
      "train loss:2.3101715916482974\n",
      "=== epoch:19, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3862839804064957\n",
      "train loss:2.3180138876384504\n",
      "train loss:2.3097800811659988\n",
      "train loss:2.300062764418787\n",
      "=== epoch:20, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.2936127119251175\n",
      "train loss:2.3426230844649525\n",
      "train loss:2.332356078614323\n",
      "train loss:2.3155297578668437\n",
      "=== epoch:21, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3288673560402953\n",
      "train loss:2.2986098278206484\n",
      "train loss:2.3696253773072353\n",
      "train loss:2.333942655267733\n",
      "=== epoch:22, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.332573087988133\n",
      "train loss:2.313376939912684\n",
      "train loss:2.3665198466363737\n",
      "train loss:2.3346774775287815\n",
      "=== epoch:23, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.334374200463743\n",
      "train loss:2.2903938988681585\n",
      "train loss:2.3529251885537903\n",
      "train loss:2.3086523925052638\n",
      "=== epoch:24, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.343189937887839\n",
      "train loss:2.328142821059468\n",
      "train loss:2.339447783173444\n",
      "train loss:2.3215122345214607\n",
      "=== epoch:25, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.324044746380207\n",
      "train loss:2.373871432257549\n",
      "train loss:2.326377803675184\n",
      "train loss:2.340867978022618\n",
      "=== epoch:26, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3444284533654547\n",
      "train loss:2.2953923635913096\n",
      "train loss:2.335936731164658\n",
      "train loss:2.3256394760951395\n",
      "=== epoch:27, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.2865260689720657\n",
      "train loss:2.321935499229183\n",
      "train loss:2.3425311891789633\n",
      "train loss:2.353255959208167\n",
      "=== epoch:28, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3303111727385266\n",
      "train loss:2.30050928202233\n",
      "train loss:2.3386107247125127\n",
      "train loss:2.3406248400394865\n",
      "=== epoch:29, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3345806058658263\n",
      "train loss:2.3478409810030367\n",
      "train loss:2.314780789698234\n",
      "train loss:2.354928817267018\n",
      "=== epoch:30, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3308101593680948\n",
      "train loss:2.301666023840584\n",
      "train loss:2.3783181015219936\n",
      "train loss:2.3071580203086834\n",
      "=== epoch:31, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.375645722222734\n",
      "train loss:2.346693472808053\n",
      "train loss:2.307599104683133\n",
      "train loss:2.3302788902194296\n",
      "=== epoch:32, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3368511166004744\n",
      "train loss:2.3197884748884188\n",
      "train loss:2.3072498422014243\n",
      "train loss:2.350577187110575\n",
      "=== epoch:33, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3328098171018503\n",
      "train loss:2.293211917187074\n",
      "train loss:2.35175173585944\n",
      "train loss:2.3420014636168407\n",
      "=== epoch:34, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.372416639712068\n",
      "train loss:2.335145751318794\n",
      "train loss:2.358954713998725\n",
      "train loss:2.37668953109369\n",
      "=== epoch:35, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.342351931508693\n",
      "train loss:2.35143669907664\n",
      "train loss:2.355308784662283\n",
      "train loss:2.317373937293701\n",
      "=== epoch:36, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3467873367801357\n",
      "train loss:2.3496266312934764\n",
      "train loss:2.386505683279687\n",
      "train loss:2.343639220799869\n",
      "=== epoch:37, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3410633798210405\n",
      "train loss:2.425210037235472\n",
      "train loss:2.328648669827108\n",
      "train loss:2.333633898999072\n",
      "=== epoch:38, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.340545183253413\n",
      "train loss:2.2943487213155858\n",
      "train loss:2.355906072333167\n",
      "train loss:2.33469806213199\n",
      "=== epoch:39, train acc:0.065, test acc:0.09 ===\n",
      "train loss:2.3523859769149555\n",
      "train loss:2.343219794056303\n",
      "train loss:2.2970960646926994\n",
      "train loss:2.3621579127704018\n",
      "=== epoch:40, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3291741816297313\n",
      "train loss:2.2872934504003837\n",
      "train loss:2.298693458157777\n",
      "train loss:2.311397260034532\n",
      "=== epoch:41, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.352724373102692\n",
      "train loss:2.339616253217807\n",
      "train loss:2.3357702342823505\n",
      "train loss:2.3088224522186587\n",
      "=== epoch:42, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3505070570988256\n",
      "train loss:2.322519587894957\n",
      "train loss:2.2974217168586217\n",
      "train loss:2.3105335023681253\n",
      "=== epoch:43, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3439128263217444\n",
      "train loss:2.3579934257760136\n",
      "train loss:2.3748315024034623\n",
      "train loss:2.3391375077221452\n",
      "=== epoch:44, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3085962034329426\n",
      "train loss:2.3211604521847846\n",
      "train loss:2.3904534511125015\n",
      "train loss:2.356378719340454\n",
      "=== epoch:45, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.331471609103097\n",
      "train loss:2.334613147334646\n",
      "train loss:2.338025708332702\n",
      "train loss:2.315473367730354\n",
      "=== epoch:46, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.3234947365275866\n",
      "train loss:2.306192756714534\n",
      "train loss:2.27710123514247\n",
      "train loss:2.2988487025928013\n",
      "=== epoch:47, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.308046576777354\n",
      "train loss:2.34523530592702\n",
      "train loss:2.321268139823051\n",
      "train loss:2.3194369586598613\n",
      "=== epoch:48, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.340569491396246\n",
      "train loss:2.3370884963367464\n",
      "train loss:2.3589370517867088\n",
      "train loss:2.332876808581701\n",
      "=== epoch:49, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.346338484398304\n",
      "train loss:2.3480604872204798\n",
      "train loss:2.358457076094768\n",
      "train loss:2.356983443644789\n",
      "=== epoch:50, train acc:0.0625, test acc:0.09 ===\n",
      "train loss:2.279503317287481\n",
      "train loss:2.3161145093905664\n",
      "train loss:2.3576205424379424\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.09\n",
      "val_acc: 0.0900 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.408376209011552\n",
      "=== epoch:1, train acc:0.1225, test acc:0.21 ===\n",
      "train loss:2.3916652589011798\n",
      "train loss:2.3921686290697406\n",
      "train loss:2.377551252005148\n",
      "train loss:2.4092218731443125\n",
      "=== epoch:2, train acc:0.13, test acc:0.21 ===\n",
      "train loss:2.4041831500369337\n",
      "train loss:2.351402413561063\n",
      "train loss:2.4216965780881\n",
      "train loss:2.3917747242131595\n",
      "=== epoch:3, train acc:0.1325, test acc:0.22 ===\n",
      "train loss:2.3082007986147945\n",
      "train loss:2.285514217907317\n",
      "train loss:2.3596462545804107\n",
      "train loss:2.369975952807094\n",
      "=== epoch:4, train acc:0.1425, test acc:0.21 ===\n",
      "train loss:2.3540284677847185\n",
      "train loss:2.316843067053619\n",
      "train loss:2.3465535197451395\n",
      "train loss:2.331150520288729\n",
      "=== epoch:5, train acc:0.1525, test acc:0.22 ===\n",
      "train loss:2.333604780437451\n",
      "train loss:2.292765207369658\n",
      "train loss:2.319296655896131\n",
      "train loss:2.3056357100961216\n",
      "=== epoch:6, train acc:0.16, test acc:0.22 ===\n",
      "train loss:2.338324813935804\n",
      "train loss:2.308185846404461\n",
      "train loss:2.3047776116305796\n",
      "train loss:2.2737949188498408\n",
      "=== epoch:7, train acc:0.16, test acc:0.22 ===\n",
      "train loss:2.3500185870243953\n",
      "train loss:2.3199535654252257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2910829262726997\n",
      "train loss:2.3007063143116997\n",
      "=== epoch:8, train acc:0.1625, test acc:0.22 ===\n",
      "train loss:2.3288091868911414\n",
      "train loss:2.3000883147904716\n",
      "train loss:2.2370386799891855\n",
      "train loss:2.3281944203103686\n",
      "=== epoch:9, train acc:0.1625, test acc:0.22 ===\n",
      "train loss:2.2487655846106107\n",
      "train loss:2.321344423206906\n",
      "train loss:2.3192016502057036\n",
      "train loss:2.2976160873978206\n",
      "=== epoch:10, train acc:0.17, test acc:0.21 ===\n",
      "train loss:2.3193426247409836\n",
      "train loss:2.2551756943345693\n",
      "train loss:2.2587862777173537\n",
      "train loss:2.273204247208576\n",
      "=== epoch:11, train acc:0.1725, test acc:0.22 ===\n",
      "train loss:2.233773258371159\n",
      "train loss:2.3044861126109883\n",
      "train loss:2.269433324503876\n",
      "train loss:2.2698717979459526\n",
      "=== epoch:12, train acc:0.1725, test acc:0.23 ===\n",
      "train loss:2.2349878535606913\n",
      "train loss:2.2508551529457526\n",
      "train loss:2.2428689432441287\n",
      "train loss:2.2415986932472793\n",
      "=== epoch:13, train acc:0.175, test acc:0.23 ===\n",
      "train loss:2.224682024052698\n",
      "train loss:2.2222303038095244\n",
      "train loss:2.2186342930561556\n",
      "train loss:2.2388571889468625\n",
      "=== epoch:14, train acc:0.1775, test acc:0.22 ===\n",
      "train loss:2.2652959090279103\n",
      "train loss:2.2648165814105647\n",
      "train loss:2.208631294846449\n",
      "train loss:2.255045038134963\n",
      "=== epoch:15, train acc:0.1825, test acc:0.23 ===\n",
      "train loss:2.2754390547400125\n",
      "train loss:2.2561397302586332\n",
      "train loss:2.250804884193791\n",
      "train loss:2.2182745771217864\n",
      "=== epoch:16, train acc:0.1875, test acc:0.23 ===\n",
      "train loss:2.239546028443039\n",
      "train loss:2.2541135081092674\n",
      "train loss:2.2217964744799406\n",
      "train loss:2.2035939974669634\n",
      "=== epoch:17, train acc:0.1975, test acc:0.24 ===\n",
      "train loss:2.2189158471992068\n",
      "train loss:2.2258687749629047\n",
      "train loss:2.2592715733501096\n",
      "train loss:2.2904263891868326\n",
      "=== epoch:18, train acc:0.1975, test acc:0.24 ===\n",
      "train loss:2.2457600245124043\n",
      "train loss:2.2490465844094083\n",
      "train loss:2.2238279049510843\n",
      "train loss:2.200686053951638\n",
      "=== epoch:19, train acc:0.21, test acc:0.24 ===\n",
      "train loss:2.2390413575884507\n",
      "train loss:2.2076437793216663\n",
      "train loss:2.246776855846759\n",
      "train loss:2.214476367465539\n",
      "=== epoch:20, train acc:0.215, test acc:0.24 ===\n",
      "train loss:2.18692496871473\n",
      "train loss:2.2228058794240235\n",
      "train loss:2.2277785547411915\n",
      "train loss:2.199727333464228\n",
      "=== epoch:21, train acc:0.235, test acc:0.25 ===\n",
      "train loss:2.195461072893084\n",
      "train loss:2.182924872708817\n",
      "train loss:2.1824828209414275\n",
      "train loss:2.224960520631301\n",
      "=== epoch:22, train acc:0.2425, test acc:0.25 ===\n",
      "train loss:2.1815131411858393\n",
      "train loss:2.187044144183925\n",
      "train loss:2.161659944302345\n",
      "train loss:2.217063426821955\n",
      "=== epoch:23, train acc:0.255, test acc:0.25 ===\n",
      "train loss:2.1463586476163825\n",
      "train loss:2.187764760205667\n",
      "train loss:2.2076733334297725\n",
      "train loss:2.1707655968551136\n",
      "=== epoch:24, train acc:0.26, test acc:0.25 ===\n",
      "train loss:2.1733968459717117\n",
      "train loss:2.15581307057613\n",
      "train loss:2.1533565725513015\n",
      "train loss:2.216203084018234\n",
      "=== epoch:25, train acc:0.2725, test acc:0.25 ===\n",
      "train loss:2.187891410155348\n",
      "train loss:2.1826233490440394\n",
      "train loss:2.2174778494020337\n",
      "train loss:2.145728152170209\n",
      "=== epoch:26, train acc:0.275, test acc:0.25 ===\n",
      "train loss:2.136559166173041\n",
      "train loss:2.163775184094939\n",
      "train loss:2.1431133874974857\n",
      "train loss:2.1608813988804956\n",
      "=== epoch:27, train acc:0.28, test acc:0.25 ===\n",
      "train loss:2.121755450588052\n",
      "train loss:2.148878743955549\n",
      "train loss:2.1811882857017344\n",
      "train loss:2.166191350891408\n",
      "=== epoch:28, train acc:0.29, test acc:0.28 ===\n",
      "train loss:2.1751308768948405\n",
      "train loss:2.1723839723051084\n",
      "train loss:2.1467182460222243\n",
      "train loss:2.137611641881345\n",
      "=== epoch:29, train acc:0.295, test acc:0.29 ===\n",
      "train loss:2.113027169759051\n",
      "train loss:2.1652395216289646\n",
      "train loss:2.1320440763799624\n",
      "train loss:2.1209382753623616\n",
      "=== epoch:30, train acc:0.3075, test acc:0.31 ===\n",
      "train loss:2.1737873057603823\n",
      "train loss:2.112924943317035\n",
      "train loss:2.122143067454331\n",
      "train loss:2.1297975592776903\n",
      "=== epoch:31, train acc:0.315, test acc:0.32 ===\n",
      "train loss:2.0705077542245647\n",
      "train loss:2.1228219302172344\n",
      "train loss:2.1684676213046066\n",
      "train loss:2.152384074749608\n",
      "=== epoch:32, train acc:0.3225, test acc:0.32 ===\n",
      "train loss:2.0983442658562153\n",
      "train loss:2.132934096191339\n",
      "train loss:2.101746527937922\n",
      "train loss:2.1486935952187918\n",
      "=== epoch:33, train acc:0.35, test acc:0.34 ===\n",
      "train loss:2.0964799770333262\n",
      "train loss:2.117500838058988\n",
      "train loss:2.114618803283392\n",
      "train loss:2.0798747318083235\n",
      "=== epoch:34, train acc:0.3475, test acc:0.34 ===\n",
      "train loss:2.1173972742628315\n",
      "train loss:2.109151963423269\n",
      "train loss:2.063028303541019\n",
      "train loss:2.0928011913444218\n",
      "=== epoch:35, train acc:0.3675, test acc:0.35 ===\n",
      "train loss:2.1409523299722717\n",
      "train loss:2.1252710217262063\n",
      "train loss:2.1225381693606025\n",
      "train loss:2.106534041503904\n",
      "=== epoch:36, train acc:0.365, test acc:0.36 ===\n",
      "train loss:2.110167120182439\n",
      "train loss:2.1347266457291725\n",
      "train loss:2.0329689200200014\n",
      "train loss:2.103011305089141\n",
      "=== epoch:37, train acc:0.3775, test acc:0.39 ===\n",
      "train loss:2.1077811597297575\n",
      "train loss:2.0650183277219525\n",
      "train loss:2.0625894816430086\n",
      "train loss:2.069030445111357\n",
      "=== epoch:38, train acc:0.3875, test acc:0.42 ===\n",
      "train loss:2.0581775511577716\n",
      "train loss:2.061771471315784\n",
      "train loss:2.0752587692031734\n",
      "train loss:2.050171192450036\n",
      "=== epoch:39, train acc:0.39, test acc:0.43 ===\n",
      "train loss:2.032919878854093\n",
      "train loss:2.074340000104777\n",
      "train loss:2.0919751721900286\n",
      "train loss:2.0785113468696346\n",
      "=== epoch:40, train acc:0.3925, test acc:0.43 ===\n",
      "train loss:2.012068337788008\n",
      "train loss:2.02246920791447\n",
      "train loss:2.003296544892655\n",
      "train loss:2.0494400978668774\n",
      "=== epoch:41, train acc:0.4025, test acc:0.44 ===\n",
      "train loss:2.045822319602259\n",
      "train loss:1.9998005893909925\n",
      "train loss:2.0215444641880476\n",
      "train loss:2.00105710585611\n",
      "=== epoch:42, train acc:0.41, test acc:0.44 ===\n",
      "train loss:2.0361659874327533\n",
      "train loss:2.0181718544815928\n",
      "train loss:1.9847625854526525\n",
      "train loss:2.0553834329032217\n",
      "=== epoch:43, train acc:0.425, test acc:0.44 ===\n",
      "train loss:2.023042629204816\n",
      "train loss:2.0075471105508456\n",
      "train loss:1.9966991745112443\n",
      "train loss:2.031505505949138\n",
      "=== epoch:44, train acc:0.4275, test acc:0.45 ===\n",
      "train loss:1.9926919576269881\n",
      "train loss:2.00808764818304\n",
      "train loss:2.0320701921562874\n",
      "train loss:2.0308168556788955\n",
      "=== epoch:45, train acc:0.4275, test acc:0.45 ===\n",
      "train loss:2.0589035982856236\n",
      "train loss:1.9865094307440894\n",
      "train loss:2.0044346456272515\n",
      "train loss:2.0188143673848034\n",
      "=== epoch:46, train acc:0.4325, test acc:0.46 ===\n",
      "train loss:1.9741613991828393\n",
      "train loss:1.993252753538708\n",
      "train loss:1.993595239966743\n",
      "train loss:2.0158938270487288\n",
      "=== epoch:47, train acc:0.435, test acc:0.46 ===\n",
      "train loss:1.947225056252811\n",
      "train loss:2.045554973351631\n",
      "train loss:1.9929828648173977\n",
      "train loss:1.9400979686015787\n",
      "=== epoch:48, train acc:0.45, test acc:0.46 ===\n",
      "train loss:2.0013084955866955\n",
      "train loss:1.9689217150570784\n",
      "train loss:1.8903446215767858\n",
      "train loss:1.9310995194495597\n",
      "=== epoch:49, train acc:0.465, test acc:0.47 ===\n",
      "train loss:1.984446728175441\n",
      "train loss:1.8992718159416815\n",
      "train loss:1.998039615687737\n",
      "train loss:1.9720540194655247\n",
      "=== epoch:50, train acc:0.465, test acc:0.47 ===\n",
      "train loss:1.9784728909860296\n",
      "train loss:1.9450600661831905\n",
      "train loss:1.954917005710211\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.51\n",
      "val_acc: 0.4700 | lr: 0.0031, weight_decay: 0.0000\n"
     ]
    }
   ],
   "source": [
    "optimization_trial = 100\n",
    "results_val = {}\n",
    "results_train = {}\n",
    "for _ in range(optimization_trial): # 탐색한 하이퍼파라미터의 범위 지정===============\n",
    "    weight_decay = 10 ** np.random.uniform(-8, -4)\n",
    "    lr = 10 ** np.random.uniform(-6, -2)\n",
    "    \n",
    "    val_acc_list, train_acc_list = __train(lr, weight_decay)\n",
    "    print('val_acc: %.4f | lr: %.4f, weight_decay: %.4f' %\n",
    "              (val_acc_list[-1], lr, weight_decay)\n",
    "    )\n",
    "    \n",
    "    key = 'lr: %.4f, weight_decay: %.4f' % (lr, weight_decay)\n",
    "    results_val[key] = val_acc_list\n",
    "    results_train[key] = train_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Hyper-Parameter Optimization Result ==========\n",
      "Best-1(val acc:0.85) | lr: 0.0073, weight_decay: 0.0000\n",
      "Best-2(val acc:0.83) | lr: 0.0094, weight_decay: 0.0000\n",
      "Best-3(val acc:0.79) | lr: 0.0057, weight_decay: 0.0000\n",
      "Best-4(val acc:0.74) | lr: 0.0058, weight_decay: 0.0000\n",
      "Best-5(val acc:0.69) | lr: 0.0045, weight_decay: 0.0000\n",
      "Best-6(val acc:0.62) | lr: 0.0037, weight_decay: 0.0001\n",
      "Best-7(val acc:0.6) | lr: 0.0033, weight_decay: 0.0000\n",
      "Best-8(val acc:0.57) | lr: 0.0026, weight_decay: 0.0000\n",
      "Best-9(val acc:0.52) | lr: 0.0027, weight_decay: 0.0000\n",
      "Best-10(val acc:0.47) | lr: 0.0031, weight_decay: 0.0000\n",
      "Best-11(val acc:0.47) | lr: 0.0018, weight_decay: 0.0000\n",
      "Best-12(val acc:0.43) | lr: 0.0017, weight_decay: 0.0000\n",
      "Best-13(val acc:0.4) | lr: 0.0024, weight_decay: 0.0000\n",
      "Best-14(val acc:0.38) | lr: 0.0025, weight_decay: 0.0000\n",
      "Best-15(val acc:0.37) | lr: 0.0019, weight_decay: 0.0000\n",
      "Best-16(val acc:0.27) | lr: 0.0008, weight_decay: 0.0000\n",
      "Best-17(val acc:0.26) | lr: 0.0015, weight_decay: 0.0000\n",
      "Best-18(val acc:0.25) | lr: 0.0011, weight_decay: 0.0000\n",
      "Best-19(val acc:0.24) | lr: 0.0009, weight_decay: 0.0000\n",
      "Best-20(val acc:0.21) | lr: 0.0014, weight_decay: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('========== Hyper-Parameter Optimization Result ==========')\n",
    "graph_draw_num = 20\n",
    "col_num = 5\n",
    "row_num = int(np.ceil(graph_draw_num / col_num))\n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for key, val_acc_list in sorted(results_val.items(), key=lambda x: x[1][-1], reverse=True):\n",
    "    print('Best-' + str(i+1) + '(val acc:' + str(val_acc_list[-1]) + ') | ' + key)\n",
    "    \n",
    "    plt.subplot(row_num, col_num, i+1)\n",
    "    plt.title('Best-' + str(i+1))\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    if i % 5:\n",
    "        plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    x = np.arange(len(val_acc_list))\n",
    "    plt.plot(x, val_acc_list)\n",
    "    plt.plot(x, results_train[key], '--')\n",
    "    i += 1\n",
    "    \n",
    "    if i >= graph_draw_num:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 불러와서 테스트용으로 데이터 양을 줄인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 128\n",
    "max_iterations = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비교할 4가지 방법을 정의한다.\n",
    "### 확률적 경사하강법 복습\n",
    "> SGD는 손실함수의 기울기를 계산하여서 이 기울기 값에 학습률(Learning Rate)를 계산하여 이 결과 값으로 기존의 가중치 값을 갱신한다.\n",
    "### 모멘텀 Momentum\n",
    ">  속도가 크게 나올수록 기울기가 크게 업데이트 되어 확률적 경사하강법이 가지는 단점을 보완할 수 있다.\n",
    "### AdaGrad\n",
    "> 신경망 학습에서의 학습률 learning rate의 값은 일종의 보폭으로 생각할 수 있는데 한 번 갱신하는 가중치의 값을 양을 결정한다. \n",
    "### Adam\n",
    "> Momentum과 AdaGrad를 섞은 기법이라고 보면 된다.\n",
    "따라서 하이퍼파라미터도 그만큼 많다. 모멘텀에서 사용하는 계수와 학습률에 대한 계수가 사용된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.util import smooth_curve\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    'SGD': SGD(),\n",
    "    'Momentum': Momentum(),\n",
    "    'AdaGrad': AdaGrad(),\n",
    "    'Adam': Adam(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 층이 100개의 뉴런으로 구성된 5층 신경망에서 ReLU를 활성화 함수로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = {}\n",
    "train_loss = {}\n",
    "for key in optimizers.keys():\n",
    "    networks[key] = MultiLayerNet(\n",
    "        input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
    "        output_size=10,\n",
    "    )\n",
    "    train_loss[key] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인식률은 AdaGrad > Adam > Momentum >> SGD 순서였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== iteration: 0 ==========\n",
      "SGD:2.3083815106545824\n",
      "Adam:2.1793509245662497\n",
      "AdaGrad:2.2038791658482206\n",
      "Momentum:2.3924964832690403\n",
      "========== iteration: 100 ==========\n",
      "SGD:1.3525754089334479\n",
      "Adam:0.15629034281251913\n",
      "AdaGrad:0.08555175716287061\n",
      "Momentum:0.2573192868351295\n",
      "========== iteration: 200 ==========\n",
      "SGD:0.8256919055751185\n",
      "Adam:0.2877176821154616\n",
      "AdaGrad:0.15401780116578279\n",
      "Momentum:0.3930400176929182\n",
      "========== iteration: 300 ==========\n",
      "SGD:0.45059402040724533\n",
      "Adam:0.1422206141242559\n",
      "AdaGrad:0.12026976095730049\n",
      "Momentum:0.1772373915699958\n",
      "========== iteration: 400 ==========\n",
      "SGD:0.35707416872263775\n",
      "Adam:0.07804369799833927\n",
      "AdaGrad:0.0853482380646906\n",
      "Momentum:0.16387721807510994\n",
      "========== iteration: 500 ==========\n",
      "SGD:0.4228321790437184\n",
      "Adam:0.18265202425442517\n",
      "AdaGrad:0.10310430072425081\n",
      "Momentum:0.23729653581008422\n",
      "========== iteration: 600 ==========\n",
      "SGD:0.36356353845598743\n",
      "Adam:0.1311267958330596\n",
      "AdaGrad:0.06184940786711124\n",
      "Momentum:0.16409075695565284\n",
      "========== iteration: 700 ==========\n",
      "SGD:0.302360692514966\n",
      "Adam:0.07832887752444503\n",
      "AdaGrad:0.059416665830514095\n",
      "Momentum:0.13858213527458763\n",
      "========== iteration: 800 ==========\n",
      "SGD:0.32550058071998705\n",
      "Adam:0.080619660481908\n",
      "AdaGrad:0.06971988752439848\n",
      "Momentum:0.13201403633714967\n",
      "========== iteration: 900 ==========\n",
      "SGD:0.3358934468615753\n",
      "Adam:0.0688868884982242\n",
      "AdaGrad:0.06886229683868343\n",
      "Momentum:0.12585056793615856\n",
      "========== iteration: 1000 ==========\n",
      "SGD:0.2895058440861322\n",
      "Adam:0.130143126285866\n",
      "AdaGrad:0.06335071250287239\n",
      "Momentum:0.16456738817864627\n",
      "========== iteration: 1100 ==========\n",
      "SGD:0.24353657921046223\n",
      "Adam:0.03461988011302791\n",
      "AdaGrad:0.03068146474810474\n",
      "Momentum:0.07358252336014148\n",
      "========== iteration: 1200 ==========\n",
      "SGD:0.19206022636148956\n",
      "Adam:0.036383497699574864\n",
      "AdaGrad:0.021619526626424884\n",
      "Momentum:0.056619279597371605\n",
      "========== iteration: 1300 ==========\n",
      "SGD:0.24935801981899736\n",
      "Adam:0.03160374425790129\n",
      "AdaGrad:0.04144447044979696\n",
      "Momentum:0.06284242079989172\n",
      "========== iteration: 1400 ==========\n",
      "SGD:0.2589682141264771\n",
      "Adam:0.07965480455180177\n",
      "AdaGrad:0.07482270852126945\n",
      "Momentum:0.11520632876363633\n",
      "========== iteration: 1500 ==========\n",
      "SGD:0.2053303392253476\n",
      "Adam:0.055442031661918134\n",
      "AdaGrad:0.025191220207055134\n",
      "Momentum:0.0582796883241556\n",
      "========== iteration: 1600 ==========\n",
      "SGD:0.3960837701309505\n",
      "Adam:0.14239140417234813\n",
      "AdaGrad:0.11401753764142852\n",
      "Momentum:0.15317022031597083\n",
      "========== iteration: 1700 ==========\n",
      "SGD:0.23643031552700544\n",
      "Adam:0.027935887075973272\n",
      "AdaGrad:0.03289548187759607\n",
      "Momentum:0.05935508096093521\n",
      "========== iteration: 1800 ==========\n",
      "SGD:0.2688563909393567\n",
      "Adam:0.036891510198114416\n",
      "AdaGrad:0.0302251791130079\n",
      "Momentum:0.058937164867566505\n",
      "========== iteration: 1900 ==========\n",
      "SGD:0.1332264751422077\n",
      "Adam:0.016396612315172865\n",
      "AdaGrad:0.01773463551575176\n",
      "Momentum:0.04408147815425384\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_iterations):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    for key in optimizers.keys():\n",
    "        grads = networks[key].gradient(x_batch, t_batch)\n",
    "        optimizers[key].update(networks[key].params, grads)\n",
    "        \n",
    "        loss = networks[key].loss(x_batch, t_batch)\n",
    "        train_loss[key].append(loss)\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print('========== iteration: %d ==========' % i)\n",
    "        for key in optimizers.keys():\n",
    "            loss = networks[key].loss(x_batch, t_batch)\n",
    "            print(key + ':' + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {\n",
    "    'SGD': 'o',\n",
    "    'Momentum': 'x',\n",
    "    'AdaGrad': 's',\n",
    "    'Adam': 'D',\n",
    "}\n",
    "x = np.arange(max_iterations)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for key in optimizers.keys():\n",
    "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 갱신 방법 결정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minist 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from common.optimizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return x**2 / 20.0 + y**2\n",
    "\n",
    "def df(x, y):\n",
    "    return x / 10.0, 2.0 * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pos = (-7.0, 2.0)\n",
    "params = {\n",
    "    'x': init_pos[0],\n",
    "    'y': init_pos[1],\n",
    "}\n",
    "grads = {\n",
    "    'x': 0,\n",
    "    'y': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비교할 4가지 방법을 정의한다.\n",
    "### 확률적 경사하강법 복습\n",
    "> SGD는 손실함수의 기울기를 계산하여서 이 기울기 값에 학습률(Learning Rate)를 계산하여 이 결과 값으로 기존의 가중치 값을 갱신한다.\n",
    "### 모멘텀 Momentum\n",
    ">  속도가 크게 나올수록 기울기가 크게 업데이트 되어 확률적 경사하강법이 가지는 단점을 보완할 수 있다.\n",
    "### AdaGrad\n",
    "> 신경망 학습에서의 학습률 learning rate의 값은 일종의 보폭으로 생각할 수 있는데 한 번 갱신하는 가중치의 값을 양을 결정한다. \n",
    "### Adam\n",
    "> Momentum과 AdaGrad를 섞은 기법이라고 보면 된다.\n",
    "따라서 하이퍼파라미터도 그만큼 많다. 모멘텀에서 사용하는 계수와 학습률에 대한 계수가 사용된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = OrderedDict()\n",
    "optimizers['SGD'] = SGD(lr=0.95)\n",
    "optimizers['Momentum'] = Momentum(lr=0.1)\n",
    "optimizers['AdaGrad'] = AdaGrad(lr=1.5)\n",
    "optimizers['Adam'] = Adam(lr=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터를 어떻게 설정하느냐에 따라서 결과가 달라진다 \n",
    "> 문제에 따라 기법을 다르게 써야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "plt.figure(figsize=(15,15))\n",
    "for key in optimizers:\n",
    "    optimizer = optimizers[key]\n",
    "    x_history = []\n",
    "    y_history = []\n",
    "    params['x'], params['y'] = init_pos[0], init_pos[1]\n",
    "    \n",
    "    for i in range(30):\n",
    "        x_history.append(params['x'])\n",
    "        y_history.append(params['y'])\n",
    "        \n",
    "        grads['x'], grads['y'] = df(params['x'], params['y'])\n",
    "        optimizer.update(params, grads)\n",
    "        \n",
    "    x = np.arange(-10, 10, 0.01)\n",
    "    y = np.arange(-5, 5, 0.01)\n",
    "        \n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = f(X, Y)\n",
    "    \n",
    "    mask = Z > 7\n",
    "    Z[mask] = 0\n",
    "    \n",
    "    plt.subplot(2, 2, idx)\n",
    "    idx += 1\n",
    "    plt.plot(x_history, y_history, 'o-', color='red')\n",
    "    plt.contour(X, Y, Z)\n",
    "    plt.ylim(-10, 10)\n",
    "    plt.xlim(-10, 10)\n",
    "    plt.plot(0, 0, '+')\n",
    "    \n",
    "    plt.title(key)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src ='최적화.png'  > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layer_naive import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend # common 패키지에 있는 다중 퍼셉트론 넷 구현 위한 함수 불러오기\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버피팅재현위해 학습데이터수 줄이기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist()\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.319638933801686\n",
      "=== epoch:1, train acc:0.14, test acc:0.1282 ===\n",
      "train loss:2.3056278727398416\n",
      "train loss:2.3051466711308435\n",
      "train loss:2.3095865277064704\n",
      "=== epoch:2, train acc:0.15, test acc:0.1351 ===\n",
      "train loss:2.2931091550450087\n",
      "train loss:2.3014704303997884\n",
      "train loss:2.3101429066590313\n",
      "=== epoch:3, train acc:0.15333333333333332, test acc:0.1404 ===\n",
      "train loss:2.2989443132356104\n",
      "train loss:2.297113843800268\n",
      "train loss:2.302671911314375\n",
      "=== epoch:4, train acc:0.15666666666666668, test acc:0.147 ===\n",
      "train loss:2.32515257313899\n",
      "train loss:2.2960222460655695\n",
      "train loss:2.3006369506699684\n",
      "=== epoch:5, train acc:0.15666666666666668, test acc:0.1494 ===\n",
      "train loss:2.297166618772762\n",
      "train loss:2.3186176927613658\n",
      "train loss:2.299913254179164\n",
      "=== epoch:6, train acc:0.15333333333333332, test acc:0.1518 ===\n",
      "train loss:2.2991826208312864\n",
      "train loss:2.2983822070573656\n",
      "train loss:2.2906172297324976\n",
      "=== epoch:7, train acc:0.15333333333333332, test acc:0.1541 ===\n",
      "train loss:2.30031941034571\n",
      "train loss:2.3044291435822455\n",
      "train loss:2.3044563637117026\n",
      "=== epoch:8, train acc:0.15666666666666668, test acc:0.1602 ===\n",
      "train loss:2.3003180495600373\n",
      "train loss:2.3017950233320836\n",
      "train loss:2.3110572891148338\n",
      "=== epoch:9, train acc:0.17333333333333334, test acc:0.1635 ===\n",
      "train loss:2.3027196325700534\n",
      "train loss:2.3041738864183787\n",
      "train loss:2.29918465063621\n",
      "=== epoch:10, train acc:0.17666666666666667, test acc:0.1656 ===\n",
      "train loss:2.3064736052657766\n",
      "train loss:2.2931438518427942\n",
      "train loss:2.2941237902083236\n",
      "=== epoch:11, train acc:0.18333333333333332, test acc:0.1673 ===\n",
      "train loss:2.2890237117787473\n",
      "train loss:2.2966390695419374\n",
      "train loss:2.306079989408138\n",
      "=== epoch:12, train acc:0.18333333333333332, test acc:0.1704 ===\n",
      "train loss:2.2943800868503303\n",
      "train loss:2.2877906155636243\n",
      "train loss:2.3059055492476257\n",
      "=== epoch:13, train acc:0.18333333333333332, test acc:0.1707 ===\n",
      "train loss:2.2881847306961483\n",
      "train loss:2.295116287542477\n",
      "train loss:2.2914598526940058\n",
      "=== epoch:14, train acc:0.18, test acc:0.1732 ===\n",
      "train loss:2.291525831809032\n",
      "train loss:2.2973260359074374\n",
      "train loss:2.2780322262198176\n",
      "=== epoch:15, train acc:0.18666666666666668, test acc:0.1728 ===\n",
      "train loss:2.2849419577818555\n",
      "train loss:2.288200968170921\n",
      "train loss:2.2789887291452273\n",
      "=== epoch:16, train acc:0.18333333333333332, test acc:0.1748 ===\n",
      "train loss:2.284119893942627\n",
      "train loss:2.299791234203295\n",
      "train loss:2.289957707341765\n",
      "=== epoch:17, train acc:0.18666666666666668, test acc:0.175 ===\n",
      "train loss:2.2906034817922762\n",
      "train loss:2.2920120462188653\n",
      "train loss:2.2901579365082916\n",
      "=== epoch:18, train acc:0.18333333333333332, test acc:0.1771 ===\n",
      "train loss:2.295892672389459\n",
      "train loss:2.2911715875638974\n",
      "train loss:2.3042570742537065\n",
      "=== epoch:19, train acc:0.18, test acc:0.179 ===\n",
      "train loss:2.2912251388863556\n",
      "train loss:2.2707609695328452\n",
      "train loss:2.287705989392319\n",
      "=== epoch:20, train acc:0.18666666666666668, test acc:0.1807 ===\n",
      "train loss:2.2957178295970575\n",
      "train loss:2.28092643102618\n",
      "train loss:2.278429984642129\n",
      "=== epoch:21, train acc:0.18666666666666668, test acc:0.1819 ===\n",
      "train loss:2.2849905840368017\n",
      "train loss:2.29649933806413\n",
      "train loss:2.296831517996374\n",
      "=== epoch:22, train acc:0.19, test acc:0.1818 ===\n",
      "train loss:2.2902794735574203\n",
      "train loss:2.2778414381962806\n",
      "train loss:2.2921441509861493\n",
      "=== epoch:23, train acc:0.19333333333333333, test acc:0.1829 ===\n",
      "train loss:2.282737885418669\n",
      "train loss:2.286480230355081\n",
      "train loss:2.280079224157724\n",
      "=== epoch:24, train acc:0.19333333333333333, test acc:0.1824 ===\n",
      "train loss:2.286920726102366\n",
      "train loss:2.2867544519592546\n",
      "train loss:2.2771906989842066\n",
      "=== epoch:25, train acc:0.19666666666666666, test acc:0.1816 ===\n",
      "train loss:2.287339481860453\n",
      "train loss:2.2969538746382874\n",
      "train loss:2.283415597076635\n",
      "=== epoch:26, train acc:0.19666666666666666, test acc:0.181 ===\n",
      "train loss:2.2841930553926426\n",
      "train loss:2.280869585849336\n",
      "train loss:2.2812059279710386\n",
      "=== epoch:27, train acc:0.19666666666666666, test acc:0.1842 ===\n",
      "train loss:2.296691853138529\n",
      "train loss:2.2907561382545856\n",
      "train loss:2.2880502786916783\n",
      "=== epoch:28, train acc:0.19666666666666666, test acc:0.1845 ===\n",
      "train loss:2.29365627398016\n",
      "train loss:2.284630188055472\n",
      "train loss:2.288947587020073\n",
      "=== epoch:29, train acc:0.2, test acc:0.1872 ===\n",
      "train loss:2.2848794144767566\n",
      "train loss:2.2756008079906107\n",
      "train loss:2.274200761646575\n",
      "=== epoch:30, train acc:0.2, test acc:0.1876 ===\n",
      "train loss:2.292934244085217\n",
      "train loss:2.2813373313693392\n",
      "train loss:2.2846373681205603\n",
      "=== epoch:31, train acc:0.2, test acc:0.1872 ===\n",
      "train loss:2.2814803974302467\n",
      "train loss:2.2719323302398826\n",
      "train loss:2.2765233970276597\n",
      "=== epoch:32, train acc:0.19333333333333333, test acc:0.1837 ===\n",
      "train loss:2.27916232629118\n",
      "train loss:2.27287904341925\n",
      "train loss:2.274134275051957\n",
      "=== epoch:33, train acc:0.19666666666666666, test acc:0.1849 ===\n",
      "train loss:2.282570606829359\n",
      "train loss:2.279130247784528\n",
      "train loss:2.278237519670091\n",
      "=== epoch:34, train acc:0.19333333333333333, test acc:0.1835 ===\n",
      "train loss:2.269670751777896\n",
      "train loss:2.281275429309446\n",
      "train loss:2.266106818382433\n",
      "=== epoch:35, train acc:0.20333333333333334, test acc:0.1844 ===\n",
      "train loss:2.267575032755528\n",
      "train loss:2.287140454296112\n",
      "train loss:2.2754815216439694\n",
      "=== epoch:36, train acc:0.20333333333333334, test acc:0.1859 ===\n",
      "train loss:2.274363241716855\n",
      "train loss:2.2760241189769848\n",
      "train loss:2.275825027937522\n",
      "=== epoch:37, train acc:0.2, test acc:0.1855 ===\n",
      "train loss:2.2778764850429907\n",
      "train loss:2.2727970921442324\n",
      "train loss:2.275180704756147\n",
      "=== epoch:38, train acc:0.2, test acc:0.1861 ===\n",
      "train loss:2.2877975613373773\n",
      "train loss:2.270647977037322\n",
      "train loss:2.274915199451136\n",
      "=== epoch:39, train acc:0.19666666666666666, test acc:0.1868 ===\n",
      "train loss:2.288697509677902\n",
      "train loss:2.278139705649279\n",
      "train loss:2.2752005936615243\n",
      "=== epoch:40, train acc:0.2, test acc:0.1872 ===\n",
      "train loss:2.2612934141674996\n",
      "train loss:2.274563470330385\n",
      "train loss:2.264465504718928\n",
      "=== epoch:41, train acc:0.19666666666666666, test acc:0.1861 ===\n",
      "train loss:2.2702870469314487\n",
      "train loss:2.2673956617013302\n",
      "train loss:2.270175928458077\n",
      "=== epoch:42, train acc:0.2, test acc:0.1879 ===\n",
      "train loss:2.282357970078377\n",
      "train loss:2.272928112720301\n",
      "train loss:2.2712063248916996\n",
      "=== epoch:43, train acc:0.2, test acc:0.188 ===\n",
      "train loss:2.275478242929276\n",
      "train loss:2.271737775537824\n",
      "train loss:2.2630244585156056\n",
      "=== epoch:44, train acc:0.2, test acc:0.1884 ===\n",
      "train loss:2.266479188469724\n",
      "train loss:2.277424463217538\n",
      "train loss:2.2796866314212223\n",
      "=== epoch:45, train acc:0.19, test acc:0.1864 ===\n",
      "train loss:2.258948238744223\n",
      "train loss:2.2720981935980493\n",
      "train loss:2.2773982885186808\n",
      "=== epoch:46, train acc:0.19666666666666666, test acc:0.1871 ===\n",
      "train loss:2.265370053413446\n",
      "train loss:2.262319361158722\n",
      "train loss:2.2568283001802576\n",
      "=== epoch:47, train acc:0.2, test acc:0.19 ===\n",
      "train loss:2.2688110435743543\n",
      "train loss:2.2820136292329267\n",
      "train loss:2.260812776638843\n",
      "=== epoch:48, train acc:0.20666666666666667, test acc:0.1911 ===\n",
      "train loss:2.2406645238595884\n",
      "train loss:2.271311546571172\n",
      "train loss:2.274963034585374\n",
      "=== epoch:49, train acc:0.20333333333333334, test acc:0.1918 ===\n",
      "train loss:2.2671240094067255\n",
      "train loss:2.2764433490464504\n",
      "train loss:2.275935724539393\n",
      "=== epoch:50, train acc:0.20666666666666667, test acc:0.1944 ===\n",
      "train loss:2.2567219301551105\n",
      "train loss:2.2684030697697786\n",
      "train loss:2.2665835735926745\n",
      "=== epoch:51, train acc:0.20666666666666667, test acc:0.1941 ===\n",
      "train loss:2.2616595993450526\n",
      "train loss:2.2560738682044525\n",
      "train loss:2.263288259573222\n",
      "=== epoch:52, train acc:0.20333333333333334, test acc:0.1958 ===\n",
      "train loss:2.2747935075989583\n",
      "train loss:2.2617638796609407\n",
      "train loss:2.2594866722161164\n",
      "=== epoch:53, train acc:0.20333333333333334, test acc:0.195 ===\n",
      "train loss:2.265199393570567\n",
      "train loss:2.2730108451327147\n",
      "train loss:2.2650421048967257\n",
      "=== epoch:54, train acc:0.21333333333333335, test acc:0.1955 ===\n",
      "train loss:2.2771106479793404\n",
      "train loss:2.2686358575713\n",
      "train loss:2.277034568730158\n",
      "=== epoch:55, train acc:0.21333333333333335, test acc:0.1971 ===\n",
      "train loss:2.247730893868474\n",
      "train loss:2.261806344336786\n",
      "train loss:2.265884146090986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:56, train acc:0.22, test acc:0.1968 ===\n",
      "train loss:2.2612599818960657\n",
      "train loss:2.2554005753070014\n",
      "train loss:2.267009643068259\n",
      "=== epoch:57, train acc:0.21666666666666667, test acc:0.1982 ===\n",
      "train loss:2.277545811350096\n",
      "train loss:2.2552444574573904\n",
      "train loss:2.254788487166295\n",
      "=== epoch:58, train acc:0.22, test acc:0.202 ===\n",
      "train loss:2.2623686042639806\n",
      "train loss:2.2516991506654676\n",
      "train loss:2.2596376640773728\n",
      "=== epoch:59, train acc:0.22, test acc:0.2 ===\n",
      "train loss:2.2706329901662325\n",
      "train loss:2.263251402944814\n",
      "train loss:2.265766010133602\n",
      "=== epoch:60, train acc:0.22, test acc:0.2004 ===\n",
      "train loss:2.252350661990139\n",
      "train loss:2.250492796873967\n",
      "train loss:2.2365585479095307\n",
      "=== epoch:61, train acc:0.22, test acc:0.2026 ===\n",
      "train loss:2.263420925732718\n",
      "train loss:2.249602131826319\n",
      "train loss:2.253457398953135\n",
      "=== epoch:62, train acc:0.22, test acc:0.2062 ===\n",
      "train loss:2.2467915103943024\n",
      "train loss:2.2457576752256294\n",
      "train loss:2.2598572651287174\n",
      "=== epoch:63, train acc:0.22, test acc:0.2045 ===\n",
      "train loss:2.2619142244253108\n",
      "train loss:2.2731162174816344\n",
      "train loss:2.2468606062239114\n",
      "=== epoch:64, train acc:0.22666666666666666, test acc:0.2088 ===\n",
      "train loss:2.2420225054749583\n",
      "train loss:2.24410986699107\n",
      "train loss:2.2567240058505873\n",
      "=== epoch:65, train acc:0.22666666666666666, test acc:0.207 ===\n",
      "train loss:2.262719130520278\n",
      "train loss:2.258502113641703\n",
      "train loss:2.242723294859703\n",
      "=== epoch:66, train acc:0.23666666666666666, test acc:0.2112 ===\n",
      "train loss:2.2567670578256864\n",
      "train loss:2.2530013117940086\n",
      "train loss:2.2583117678031686\n",
      "=== epoch:67, train acc:0.24666666666666667, test acc:0.2155 ===\n",
      "train loss:2.250390957688349\n",
      "train loss:2.2626581492485767\n",
      "train loss:2.2594561060267364\n",
      "=== epoch:68, train acc:0.25333333333333335, test acc:0.2171 ===\n",
      "train loss:2.2586095546950418\n",
      "train loss:2.2653249705733507\n",
      "train loss:2.2482933583862894\n",
      "=== epoch:69, train acc:0.26, test acc:0.2187 ===\n",
      "train loss:2.231341034423727\n",
      "train loss:2.242640716157742\n",
      "train loss:2.250692190809457\n",
      "=== epoch:70, train acc:0.25, test acc:0.2161 ===\n",
      "train loss:2.258522038114378\n",
      "train loss:2.249872913871381\n",
      "train loss:2.2488550116371098\n",
      "=== epoch:71, train acc:0.25333333333333335, test acc:0.2165 ===\n",
      "train loss:2.2508849103165454\n",
      "train loss:2.22770991445599\n",
      "train loss:2.250271874199874\n",
      "=== epoch:72, train acc:0.25333333333333335, test acc:0.2171 ===\n",
      "train loss:2.241785934596332\n",
      "train loss:2.262464304283713\n",
      "train loss:2.2280296948691025\n",
      "=== epoch:73, train acc:0.25333333333333335, test acc:0.218 ===\n",
      "train loss:2.2354468559048093\n",
      "train loss:2.2272222749556905\n",
      "train loss:2.2343898641764706\n",
      "=== epoch:74, train acc:0.25333333333333335, test acc:0.2167 ===\n",
      "train loss:2.2524692938027377\n",
      "train loss:2.228687973080942\n",
      "train loss:2.2406000425412596\n",
      "=== epoch:75, train acc:0.25333333333333335, test acc:0.216 ===\n",
      "train loss:2.24502519897706\n",
      "train loss:2.242422521524549\n",
      "train loss:2.225229752376854\n",
      "=== epoch:76, train acc:0.25, test acc:0.2173 ===\n",
      "train loss:2.2587579765435324\n",
      "train loss:2.239654745568798\n",
      "train loss:2.2458394058953357\n",
      "=== epoch:77, train acc:0.25333333333333335, test acc:0.2195 ===\n",
      "train loss:2.2303031523632972\n",
      "train loss:2.2374879997796384\n",
      "train loss:2.2494236693685106\n",
      "=== epoch:78, train acc:0.26, test acc:0.2227 ===\n",
      "train loss:2.2311780455774217\n",
      "train loss:2.2427473611708795\n",
      "train loss:2.242692852939218\n",
      "=== epoch:79, train acc:0.2633333333333333, test acc:0.2207 ===\n",
      "train loss:2.2420836268758646\n",
      "train loss:2.242410931389592\n",
      "train loss:2.1988916646795342\n",
      "=== epoch:80, train acc:0.2633333333333333, test acc:0.2208 ===\n",
      "train loss:2.2507452835007307\n",
      "train loss:2.227697754937389\n",
      "train loss:2.2307898565551336\n",
      "=== epoch:81, train acc:0.2633333333333333, test acc:0.2227 ===\n",
      "train loss:2.227227930177644\n",
      "train loss:2.227910966000493\n",
      "train loss:2.2507904180835085\n",
      "=== epoch:82, train acc:0.2633333333333333, test acc:0.2216 ===\n",
      "train loss:2.235515405865052\n",
      "train loss:2.2550522484232816\n",
      "train loss:2.2260000169729315\n",
      "=== epoch:83, train acc:0.26666666666666666, test acc:0.225 ===\n",
      "train loss:2.2316725059257654\n",
      "train loss:2.2110664184260065\n",
      "train loss:2.2322557516025117\n",
      "=== epoch:84, train acc:0.2733333333333333, test acc:0.2272 ===\n",
      "train loss:2.217268262042493\n",
      "train loss:2.2219628676435312\n",
      "train loss:2.227789896244847\n",
      "=== epoch:85, train acc:0.27, test acc:0.2281 ===\n",
      "train loss:2.247197079961933\n",
      "train loss:2.2201668152610843\n",
      "train loss:2.225791030197492\n",
      "=== epoch:86, train acc:0.2733333333333333, test acc:0.2309 ===\n",
      "train loss:2.2221394477473173\n",
      "train loss:2.227427635816943\n",
      "train loss:2.2136937812453668\n",
      "=== epoch:87, train acc:0.27666666666666667, test acc:0.2328 ===\n",
      "train loss:2.224025185742491\n",
      "train loss:2.2249955295049006\n",
      "train loss:2.2267490182531944\n",
      "=== epoch:88, train acc:0.27666666666666667, test acc:0.2345 ===\n",
      "train loss:2.240720102964606\n",
      "train loss:2.1996653727276185\n",
      "train loss:2.232382394335642\n",
      "=== epoch:89, train acc:0.28, test acc:0.2346 ===\n",
      "train loss:2.2334465102152032\n",
      "train loss:2.2485316239574606\n",
      "train loss:2.201370481546652\n",
      "=== epoch:90, train acc:0.2833333333333333, test acc:0.2362 ===\n",
      "train loss:2.2398425206658077\n",
      "train loss:2.2194258927793613\n",
      "train loss:2.205066850918686\n",
      "=== epoch:91, train acc:0.2866666666666667, test acc:0.2366 ===\n",
      "train loss:2.226980382159086\n",
      "train loss:2.2130365788617508\n",
      "train loss:2.2167193664935088\n",
      "=== epoch:92, train acc:0.2866666666666667, test acc:0.238 ===\n",
      "train loss:2.218288970306123\n",
      "train loss:2.2208723945093083\n",
      "train loss:2.217304606277362\n",
      "=== epoch:93, train acc:0.2866666666666667, test acc:0.2382 ===\n",
      "train loss:2.2435500848286085\n",
      "train loss:2.2015544418852633\n",
      "train loss:2.2367932241802326\n",
      "=== epoch:94, train acc:0.29, test acc:0.2385 ===\n",
      "train loss:2.2379335714702253\n",
      "train loss:2.205305399752348\n",
      "train loss:2.2173154701418194\n",
      "=== epoch:95, train acc:0.2866666666666667, test acc:0.2376 ===\n",
      "train loss:2.2018719262811364\n",
      "train loss:2.2136758305752022\n",
      "train loss:2.2031802002804493\n",
      "=== epoch:96, train acc:0.29, test acc:0.241 ===\n",
      "train loss:2.2137878633911923\n",
      "train loss:2.1726339817168467\n",
      "train loss:2.2127148671699595\n",
      "=== epoch:97, train acc:0.29333333333333333, test acc:0.2388 ===\n",
      "train loss:2.2142320074762853\n",
      "train loss:2.2113456737214943\n",
      "train loss:2.203313085350493\n",
      "=== epoch:98, train acc:0.29333333333333333, test acc:0.2396 ===\n",
      "train loss:2.1980497442653135\n",
      "train loss:2.207778647124756\n",
      "train loss:2.2098564160154464\n",
      "=== epoch:99, train acc:0.2966666666666667, test acc:0.2433 ===\n",
      "train loss:2.1951159515339826\n",
      "train loss:2.20682368312596\n",
      "train loss:2.2014711727302947\n",
      "=== epoch:100, train acc:0.3, test acc:0.2445 ===\n",
      "train loss:2.2076408204348055\n",
      "train loss:2.209442346431414\n",
      "train loss:2.18796110534478\n",
      "=== epoch:101, train acc:0.3, test acc:0.2461 ===\n",
      "train loss:2.1590266766784043\n",
      "train loss:2.212566217396249\n",
      "train loss:2.189018110977608\n",
      "=== epoch:102, train acc:0.30666666666666664, test acc:0.2469 ===\n",
      "train loss:2.1816677034623995\n",
      "train loss:2.204377234140163\n",
      "train loss:2.188665626397164\n",
      "=== epoch:103, train acc:0.3, test acc:0.246 ===\n",
      "train loss:2.201424098221406\n",
      "train loss:2.1975089498366325\n",
      "train loss:2.21221281234589\n",
      "=== epoch:104, train acc:0.30666666666666664, test acc:0.2468 ===\n",
      "train loss:2.1711978268952787\n",
      "train loss:2.182353392484545\n",
      "train loss:2.210762905179569\n",
      "=== epoch:105, train acc:0.2966666666666667, test acc:0.2464 ===\n",
      "train loss:2.1794298605128124\n",
      "train loss:2.2157041865416307\n",
      "train loss:2.1697543447584384\n",
      "=== epoch:106, train acc:0.2966666666666667, test acc:0.2463 ===\n",
      "train loss:2.185000702330379\n",
      "train loss:2.152485932713306\n",
      "train loss:2.1772546889024222\n",
      "=== epoch:107, train acc:0.3, test acc:0.2446 ===\n",
      "train loss:2.1671313705462265\n",
      "train loss:2.1710182690642608\n",
      "train loss:2.1681821702579267\n",
      "=== epoch:108, train acc:0.3, test acc:0.2462 ===\n",
      "train loss:2.193725160407636\n",
      "train loss:2.199438935942425\n",
      "train loss:2.2046959384361404\n",
      "=== epoch:109, train acc:0.30666666666666664, test acc:0.2457 ===\n",
      "train loss:2.180876603435281\n",
      "train loss:2.19015752387286\n",
      "train loss:2.1859261273356925\n",
      "=== epoch:110, train acc:0.30666666666666664, test acc:0.248 ===\n",
      "train loss:2.1816178280106824\n",
      "train loss:2.1856020694834473\n",
      "train loss:2.136575751365314\n",
      "=== epoch:111, train acc:0.30333333333333334, test acc:0.2468 ===\n",
      "train loss:2.164385543357297\n",
      "train loss:2.1899404855656073\n",
      "train loss:2.156380463826875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:112, train acc:0.3, test acc:0.2437 ===\n",
      "train loss:2.173895150124206\n",
      "train loss:2.1645825295875984\n",
      "train loss:2.1359191755108484\n",
      "=== epoch:113, train acc:0.3, test acc:0.2433 ===\n",
      "train loss:2.1874646931079784\n",
      "train loss:2.1666651614654064\n",
      "train loss:2.1265115938600725\n",
      "=== epoch:114, train acc:0.3, test acc:0.2433 ===\n",
      "train loss:2.1499701023029028\n",
      "train loss:2.17010160910101\n",
      "train loss:2.161027568524866\n",
      "=== epoch:115, train acc:0.30333333333333334, test acc:0.2454 ===\n",
      "train loss:2.1777219558834804\n",
      "train loss:2.168885699893163\n",
      "train loss:2.1454640603254265\n",
      "=== epoch:116, train acc:0.3, test acc:0.2454 ===\n",
      "train loss:2.1671559641921276\n",
      "train loss:2.164625111407375\n",
      "train loss:2.1544196894891874\n",
      "=== epoch:117, train acc:0.3, test acc:0.2464 ===\n",
      "train loss:2.11341511086777\n",
      "train loss:2.1817078992261694\n",
      "train loss:2.1819514602222374\n",
      "=== epoch:118, train acc:0.3, test acc:0.2466 ===\n",
      "train loss:2.1881663131443982\n",
      "train loss:2.1246687115215948\n",
      "train loss:2.1842712098910324\n",
      "=== epoch:119, train acc:0.29333333333333333, test acc:0.2453 ===\n",
      "train loss:2.129201039764888\n",
      "train loss:2.117051426899764\n",
      "train loss:2.133203416215109\n",
      "=== epoch:120, train acc:0.3, test acc:0.2457 ===\n",
      "train loss:2.1828278711835907\n",
      "train loss:2.108094437485403\n",
      "train loss:2.1435545894570436\n",
      "=== epoch:121, train acc:0.2966666666666667, test acc:0.2489 ===\n",
      "train loss:2.144989782000869\n",
      "train loss:2.171110269146925\n",
      "train loss:2.138401013536972\n",
      "=== epoch:122, train acc:0.30333333333333334, test acc:0.2501 ===\n",
      "train loss:2.133194850232201\n",
      "train loss:2.111633384196709\n",
      "train loss:2.1420138498970953\n",
      "=== epoch:123, train acc:0.31, test acc:0.2517 ===\n",
      "train loss:2.0914824738084623\n",
      "train loss:2.118368878038766\n",
      "train loss:2.140240440963388\n",
      "=== epoch:124, train acc:0.31, test acc:0.2514 ===\n",
      "train loss:2.1672908508798\n",
      "train loss:2.148426088062788\n",
      "train loss:2.146810235806912\n",
      "=== epoch:125, train acc:0.31, test acc:0.2541 ===\n",
      "train loss:2.16312657662544\n",
      "train loss:2.133560026944151\n",
      "train loss:2.104375906279899\n",
      "=== epoch:126, train acc:0.31, test acc:0.2575 ===\n",
      "train loss:2.1394441886883357\n",
      "train loss:2.0993925099622466\n",
      "train loss:2.1559817555429546\n",
      "=== epoch:127, train acc:0.31666666666666665, test acc:0.2627 ===\n",
      "train loss:2.1112437190824016\n",
      "train loss:2.1491168612749014\n",
      "train loss:2.129566104535557\n",
      "=== epoch:128, train acc:0.31333333333333335, test acc:0.2624 ===\n",
      "train loss:2.12597764613412\n",
      "train loss:2.125656807253792\n",
      "train loss:2.1004478090164076\n",
      "=== epoch:129, train acc:0.31666666666666665, test acc:0.2622 ===\n",
      "train loss:2.1210297442351065\n",
      "train loss:2.121373276253548\n",
      "train loss:2.1443718090958614\n",
      "=== epoch:130, train acc:0.34, test acc:0.2652 ===\n",
      "train loss:2.1669521699413106\n",
      "train loss:2.115613775854589\n",
      "train loss:2.124555959186427\n",
      "=== epoch:131, train acc:0.34, test acc:0.2674 ===\n",
      "train loss:2.135425700448646\n",
      "train loss:2.1620338920895366\n",
      "train loss:2.1472550372478905\n",
      "=== epoch:132, train acc:0.3466666666666667, test acc:0.272 ===\n",
      "train loss:2.1461366531714736\n",
      "train loss:2.0776878784046344\n",
      "train loss:2.087566333527778\n",
      "=== epoch:133, train acc:0.35, test acc:0.2724 ===\n",
      "train loss:2.1418049288986456\n",
      "train loss:2.1271421623089855\n",
      "train loss:2.1352973790168206\n",
      "=== epoch:134, train acc:0.3566666666666667, test acc:0.2783 ===\n",
      "train loss:2.115753897325616\n",
      "train loss:2.0842821215176683\n",
      "train loss:2.1012323666884747\n",
      "=== epoch:135, train acc:0.3566666666666667, test acc:0.2768 ===\n",
      "train loss:2.0425451953376923\n",
      "train loss:2.1342674484584903\n",
      "train loss:2.075033379673937\n",
      "=== epoch:136, train acc:0.35, test acc:0.2761 ===\n",
      "train loss:2.0952321967838063\n",
      "train loss:2.062231906291961\n",
      "train loss:2.1175790195247313\n",
      "=== epoch:137, train acc:0.3566666666666667, test acc:0.2792 ===\n",
      "train loss:2.111856680453932\n",
      "train loss:2.159724883058511\n",
      "train loss:2.1390072807333724\n",
      "=== epoch:138, train acc:0.3566666666666667, test acc:0.2817 ===\n",
      "train loss:2.0869771824234284\n",
      "train loss:2.152453573723484\n",
      "train loss:2.1056115826293382\n",
      "=== epoch:139, train acc:0.35333333333333333, test acc:0.2806 ===\n",
      "train loss:2.1308565211978854\n",
      "train loss:2.1026409594277586\n",
      "train loss:2.047523272986388\n",
      "=== epoch:140, train acc:0.35333333333333333, test acc:0.2818 ===\n",
      "train loss:2.098729382019442\n",
      "train loss:2.118288768331119\n",
      "train loss:2.006297429793441\n",
      "=== epoch:141, train acc:0.35333333333333333, test acc:0.2822 ===\n",
      "train loss:2.0701422639362\n",
      "train loss:2.1048332515321584\n",
      "train loss:2.0634900592867567\n",
      "=== epoch:142, train acc:0.35333333333333333, test acc:0.2836 ===\n",
      "train loss:2.029217352798288\n",
      "train loss:2.0881878381437278\n",
      "train loss:2.101465267355407\n",
      "=== epoch:143, train acc:0.35, test acc:0.2814 ===\n",
      "train loss:2.0997003111535197\n",
      "train loss:2.1205808786368916\n",
      "train loss:2.054339200095963\n",
      "=== epoch:144, train acc:0.35, test acc:0.2829 ===\n",
      "train loss:2.1111544883184745\n",
      "train loss:2.071596573790878\n",
      "train loss:2.0329529045802337\n",
      "=== epoch:145, train acc:0.3566666666666667, test acc:0.2811 ===\n",
      "train loss:2.086964905737057\n",
      "train loss:2.043234713543982\n",
      "train loss:2.04966446406023\n",
      "=== epoch:146, train acc:0.35333333333333333, test acc:0.284 ===\n",
      "train loss:2.062929505858823\n",
      "train loss:2.0496028461936295\n",
      "train loss:2.114486328456159\n",
      "=== epoch:147, train acc:0.3566666666666667, test acc:0.2821 ===\n",
      "train loss:2.1072277893721445\n",
      "train loss:2.0830165213778002\n",
      "train loss:2.0619775633665998\n",
      "=== epoch:148, train acc:0.3566666666666667, test acc:0.2832 ===\n",
      "train loss:2.053121117018613\n",
      "train loss:2.095595257414236\n",
      "train loss:2.0678303890250813\n",
      "=== epoch:149, train acc:0.36, test acc:0.2881 ===\n",
      "train loss:2.007214829927263\n",
      "train loss:2.0581745051018006\n",
      "train loss:1.998120968064719\n",
      "=== epoch:150, train acc:0.35333333333333333, test acc:0.2841 ===\n",
      "train loss:2.094550140085122\n",
      "train loss:2.093705864159406\n",
      "train loss:2.015271029563846\n",
      "=== epoch:151, train acc:0.36666666666666664, test acc:0.2941 ===\n",
      "train loss:2.0114461298313473\n",
      "train loss:1.9542810187681736\n",
      "train loss:2.0413932657152167\n",
      "=== epoch:152, train acc:0.36, test acc:0.2905 ===\n",
      "train loss:2.0100917220473\n",
      "train loss:1.9888208241799143\n",
      "train loss:2.056282099361433\n",
      "=== epoch:153, train acc:0.36333333333333334, test acc:0.2948 ===\n",
      "train loss:2.065467109850418\n",
      "train loss:1.9915685609787501\n",
      "train loss:2.005163063338331\n",
      "=== epoch:154, train acc:0.3566666666666667, test acc:0.2945 ===\n",
      "train loss:2.037268473459916\n",
      "train loss:2.059580216120432\n",
      "train loss:1.9876578512370515\n",
      "=== epoch:155, train acc:0.37, test acc:0.3002 ===\n",
      "train loss:1.9589525613313306\n",
      "train loss:1.996143032851931\n",
      "train loss:2.0545870561742188\n",
      "=== epoch:156, train acc:0.37333333333333335, test acc:0.3003 ===\n",
      "train loss:2.005640432026025\n",
      "train loss:1.9778032939524173\n",
      "train loss:1.9819353980514123\n",
      "=== epoch:157, train acc:0.37, test acc:0.3019 ===\n",
      "train loss:2.0607193028129682\n",
      "train loss:2.0235244061515605\n",
      "train loss:2.0554863530058887\n",
      "=== epoch:158, train acc:0.38, test acc:0.306 ===\n",
      "train loss:1.9773592756764016\n",
      "train loss:2.020016913193286\n",
      "train loss:2.0176566492468915\n",
      "=== epoch:159, train acc:0.37666666666666665, test acc:0.3061 ===\n",
      "train loss:2.0239719151038087\n",
      "train loss:1.9759789362906903\n",
      "train loss:1.9440729932883087\n",
      "=== epoch:160, train acc:0.37666666666666665, test acc:0.3054 ===\n",
      "train loss:1.9671016315010883\n",
      "train loss:2.038506482702412\n",
      "train loss:1.9451001361265206\n",
      "=== epoch:161, train acc:0.38666666666666666, test acc:0.3074 ===\n",
      "train loss:1.9934776641837777\n",
      "train loss:2.022011812075921\n",
      "train loss:1.9413842536154908\n",
      "=== epoch:162, train acc:0.39, test acc:0.31 ===\n",
      "train loss:1.9240318289003873\n",
      "train loss:2.01424590968202\n",
      "train loss:1.9858060226541718\n",
      "=== epoch:163, train acc:0.38, test acc:0.3108 ===\n",
      "train loss:2.064455592556003\n",
      "train loss:1.9864047079796248\n",
      "train loss:1.995488622238557\n",
      "=== epoch:164, train acc:0.37, test acc:0.3096 ===\n",
      "train loss:1.9386996186939751\n",
      "train loss:1.8758106049055954\n",
      "train loss:2.0098127095149594\n",
      "=== epoch:165, train acc:0.36333333333333334, test acc:0.308 ===\n",
      "train loss:2.0444824058161974\n",
      "train loss:1.9884484543476786\n",
      "train loss:1.9673215417210184\n",
      "=== epoch:166, train acc:0.36333333333333334, test acc:0.3032 ===\n",
      "train loss:1.9123872440983434\n",
      "train loss:2.0649551181214214\n",
      "train loss:1.9503040825942926\n",
      "=== epoch:167, train acc:0.37, test acc:0.3071 ===\n",
      "train loss:1.9900817554169656\n",
      "train loss:1.9374054408923476\n",
      "train loss:1.9852870938938625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:168, train acc:0.36, test acc:0.3069 ===\n",
      "train loss:1.8331320391357522\n",
      "train loss:1.8078065476399785\n",
      "train loss:1.927704527926406\n",
      "=== epoch:169, train acc:0.36, test acc:0.3031 ===\n",
      "train loss:1.9428144284775248\n",
      "train loss:1.959069361778944\n",
      "train loss:1.909590577546212\n",
      "=== epoch:170, train acc:0.36, test acc:0.2988 ===\n",
      "train loss:2.0117233471773037\n",
      "train loss:1.9623822553925065\n",
      "train loss:1.9956654027590772\n",
      "=== epoch:171, train acc:0.36, test acc:0.3038 ===\n",
      "train loss:1.9652065609444338\n",
      "train loss:1.9366628093510259\n",
      "train loss:1.9539750028458847\n",
      "=== epoch:172, train acc:0.36, test acc:0.3048 ===\n",
      "train loss:2.015255758120801\n",
      "train loss:1.9418419810129537\n",
      "train loss:1.997285656599931\n",
      "=== epoch:173, train acc:0.37666666666666665, test acc:0.3105 ===\n",
      "train loss:1.9125157358239064\n",
      "train loss:1.974610903860015\n",
      "train loss:1.9772517110742145\n",
      "=== epoch:174, train acc:0.37666666666666665, test acc:0.3135 ===\n",
      "train loss:1.9328532972033765\n",
      "train loss:2.0075416783670206\n",
      "train loss:1.8982495378181854\n",
      "=== epoch:175, train acc:0.37, test acc:0.3143 ===\n",
      "train loss:1.8604503723457015\n",
      "train loss:1.9302872869896475\n",
      "train loss:1.8804755539149314\n",
      "=== epoch:176, train acc:0.38333333333333336, test acc:0.3176 ===\n",
      "train loss:1.932622336088306\n",
      "train loss:1.960337397060507\n",
      "train loss:1.895960589671408\n",
      "=== epoch:177, train acc:0.37333333333333335, test acc:0.3168 ===\n",
      "train loss:1.9789524152969675\n",
      "train loss:1.8787021077561021\n",
      "train loss:1.9566887200827265\n",
      "=== epoch:178, train acc:0.37, test acc:0.3173 ===\n",
      "train loss:1.8412242247737667\n",
      "train loss:1.855184415109652\n",
      "train loss:2.02785956450769\n",
      "=== epoch:179, train acc:0.38666666666666666, test acc:0.3237 ===\n",
      "train loss:1.9357422264436928\n",
      "train loss:2.008922563233116\n",
      "train loss:1.8927686294071622\n",
      "=== epoch:180, train acc:0.3933333333333333, test acc:0.3306 ===\n",
      "train loss:1.9108634019397224\n",
      "train loss:1.9617509264493205\n",
      "train loss:1.7995372589713412\n",
      "=== epoch:181, train acc:0.4, test acc:0.3292 ===\n",
      "train loss:1.8879990142560492\n",
      "train loss:1.8788632572951756\n",
      "train loss:1.909416654315084\n",
      "=== epoch:182, train acc:0.39, test acc:0.33 ===\n",
      "train loss:1.9585733841869974\n",
      "train loss:1.9400528170398477\n",
      "train loss:1.9082995765132962\n",
      "=== epoch:183, train acc:0.4, test acc:0.3338 ===\n",
      "train loss:1.7731283101790833\n",
      "train loss:1.914318709793655\n",
      "train loss:1.8856408288812876\n",
      "=== epoch:184, train acc:0.39, test acc:0.3348 ===\n",
      "train loss:1.9450239258279955\n",
      "train loss:1.8960923995625356\n",
      "train loss:1.9372701381206054\n",
      "=== epoch:185, train acc:0.4033333333333333, test acc:0.3369 ===\n",
      "train loss:1.8496267710517116\n",
      "train loss:1.8934011349594007\n",
      "train loss:1.9154575556108855\n",
      "=== epoch:186, train acc:0.4, test acc:0.34 ===\n",
      "train loss:1.8484286467528557\n",
      "train loss:1.8270392524065397\n",
      "train loss:1.9072818540426633\n",
      "=== epoch:187, train acc:0.4, test acc:0.3395 ===\n",
      "train loss:1.8541024390753582\n",
      "train loss:1.8353646813497426\n",
      "train loss:1.7712536136168993\n",
      "=== epoch:188, train acc:0.3933333333333333, test acc:0.3354 ===\n",
      "train loss:1.754635428744597\n",
      "train loss:1.7290144238604137\n",
      "train loss:1.9094985065725003\n",
      "=== epoch:189, train acc:0.3933333333333333, test acc:0.3346 ===\n",
      "train loss:1.8884974823565706\n",
      "train loss:1.8626435048000578\n",
      "train loss:1.831594820752704\n",
      "=== epoch:190, train acc:0.39666666666666667, test acc:0.338 ===\n",
      "train loss:1.8714770524686741\n",
      "train loss:1.8308641876058454\n",
      "train loss:1.9589367329486622\n",
      "=== epoch:191, train acc:0.41, test acc:0.3393 ===\n",
      "train loss:1.9157670908386353\n",
      "train loss:1.8857288547824549\n",
      "train loss:1.864801248307512\n",
      "=== epoch:192, train acc:0.41, test acc:0.3398 ===\n",
      "train loss:1.8801108983627488\n",
      "train loss:1.849504271556164\n",
      "train loss:1.8228483216769686\n",
      "=== epoch:193, train acc:0.42, test acc:0.3456 ===\n",
      "train loss:1.894180644159504\n",
      "train loss:1.8623645565144604\n",
      "train loss:1.7723538706845252\n",
      "=== epoch:194, train acc:0.4166666666666667, test acc:0.3459 ===\n",
      "train loss:1.8629583351922514\n",
      "train loss:1.8208183282601973\n",
      "train loss:1.869491832596578\n",
      "=== epoch:195, train acc:0.4066666666666667, test acc:0.3439 ===\n",
      "train loss:1.848239410836245\n",
      "train loss:1.8801557415051748\n",
      "train loss:1.8883718362038762\n",
      "=== epoch:196, train acc:0.41333333333333333, test acc:0.3427 ===\n",
      "train loss:1.8870959515851389\n",
      "train loss:1.7584882691020272\n",
      "train loss:1.8167134828987974\n",
      "=== epoch:197, train acc:0.41, test acc:0.3423 ===\n",
      "train loss:1.6983040923766959\n",
      "train loss:1.8157355778323687\n",
      "train loss:1.9845761699555202\n",
      "=== epoch:198, train acc:0.41, test acc:0.3421 ===\n",
      "train loss:1.8776284160729242\n",
      "train loss:1.8400184929127272\n",
      "train loss:1.9082006343854505\n",
      "=== epoch:199, train acc:0.42, test acc:0.3537 ===\n",
      "train loss:1.7413730546982822\n",
      "train loss:1.83224052371877\n",
      "train loss:1.8200619932162025\n",
      "=== epoch:200, train acc:0.4166666666666667, test acc:0.3512 ===\n",
      "train loss:1.8167659204024265\n",
      "train loss:1.879955205843804\n",
      "train loss:1.8424842833790722\n",
      "=== epoch:201, train acc:0.4166666666666667, test acc:0.3544 ===\n",
      "train loss:1.8265666397365221\n",
      "train loss:1.7946385305885695\n",
      "train loss:1.8473300632208327\n",
      "=== epoch:202, train acc:0.41333333333333333, test acc:0.3562 ===\n",
      "train loss:1.750582055188075\n",
      "train loss:1.8044046553483415\n",
      "train loss:1.7690542793848438\n",
      "=== epoch:203, train acc:0.4166666666666667, test acc:0.3548 ===\n",
      "train loss:1.7419676332185074\n",
      "train loss:1.8331424601859132\n",
      "train loss:1.8343227806724562\n",
      "=== epoch:204, train acc:0.41333333333333333, test acc:0.3552 ===\n",
      "train loss:1.6609090107517601\n",
      "train loss:1.7756027210841605\n",
      "train loss:1.927208836924197\n",
      "=== epoch:205, train acc:0.4266666666666667, test acc:0.3635 ===\n",
      "train loss:1.8204413535367214\n",
      "train loss:1.7892988647166923\n",
      "train loss:1.7578442057615755\n",
      "=== epoch:206, train acc:0.43666666666666665, test acc:0.3659 ===\n",
      "train loss:1.924690374203562\n",
      "train loss:1.7228610646347737\n",
      "train loss:1.860921409485168\n",
      "=== epoch:207, train acc:0.43666666666666665, test acc:0.3707 ===\n",
      "train loss:1.7347471381148214\n",
      "train loss:1.688552975415752\n",
      "train loss:1.8264360692181705\n",
      "=== epoch:208, train acc:0.43666666666666665, test acc:0.3718 ===\n",
      "train loss:1.7366112131986362\n",
      "train loss:1.8354262124094638\n",
      "train loss:1.8589015515345673\n",
      "=== epoch:209, train acc:0.44, test acc:0.3767 ===\n",
      "train loss:1.676167061925614\n",
      "train loss:1.8531332768243454\n",
      "train loss:1.7394587567168471\n",
      "=== epoch:210, train acc:0.44333333333333336, test acc:0.3798 ===\n",
      "train loss:1.75176485703683\n",
      "train loss:1.7032785712708236\n",
      "train loss:1.7463773347548333\n",
      "=== epoch:211, train acc:0.44333333333333336, test acc:0.3805 ===\n",
      "train loss:1.7312488156690136\n",
      "train loss:1.882031207904874\n",
      "train loss:1.8311407916544449\n",
      "=== epoch:212, train acc:0.44, test acc:0.3857 ===\n",
      "train loss:1.6793322113210873\n",
      "train loss:1.7711528445272746\n",
      "train loss:1.7786921264168092\n",
      "=== epoch:213, train acc:0.44666666666666666, test acc:0.3863 ===\n",
      "train loss:1.6071845737091994\n",
      "train loss:1.7426014936505048\n",
      "train loss:1.6963918760797325\n",
      "=== epoch:214, train acc:0.4633333333333333, test acc:0.39 ===\n",
      "train loss:1.5835026793095819\n",
      "train loss:1.8197835688450075\n",
      "train loss:1.6705831377477673\n",
      "=== epoch:215, train acc:0.46, test acc:0.3879 ===\n",
      "train loss:1.7674901452828775\n",
      "train loss:1.7553860531461474\n",
      "train loss:1.664824862478162\n",
      "=== epoch:216, train acc:0.46, test acc:0.3871 ===\n",
      "train loss:1.6311402707056153\n",
      "train loss:1.7233639151534306\n",
      "train loss:1.745988017842845\n",
      "=== epoch:217, train acc:0.46, test acc:0.3871 ===\n",
      "train loss:1.7420943871680936\n",
      "train loss:1.7459227762821359\n",
      "train loss:1.706953996543767\n",
      "=== epoch:218, train acc:0.4666666666666667, test acc:0.3903 ===\n",
      "train loss:1.7208573736959625\n",
      "train loss:1.6903928541632502\n",
      "train loss:1.6418010608557287\n",
      "=== epoch:219, train acc:0.45666666666666667, test acc:0.3917 ===\n",
      "train loss:1.6322132082435785\n",
      "train loss:1.769875585729008\n",
      "train loss:1.614915897544939\n",
      "=== epoch:220, train acc:0.45, test acc:0.3881 ===\n",
      "train loss:1.558788073655459\n",
      "train loss:1.5625258250479817\n",
      "train loss:1.67721915603071\n",
      "=== epoch:221, train acc:0.4633333333333333, test acc:0.3835 ===\n",
      "train loss:1.6939091844010512\n",
      "train loss:1.783533102666555\n",
      "train loss:1.7772927071659779\n",
      "=== epoch:222, train acc:0.45666666666666667, test acc:0.3877 ===\n",
      "train loss:1.7354677039020734\n",
      "train loss:1.6897407910648914\n",
      "train loss:1.7212326721057951\n",
      "=== epoch:223, train acc:0.47333333333333333, test acc:0.392 ===\n",
      "train loss:1.8200141320220764\n",
      "train loss:1.7836600466481674\n",
      "train loss:1.6473786748423047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:224, train acc:0.48333333333333334, test acc:0.3968 ===\n",
      "train loss:1.5607939674693767\n",
      "train loss:1.713911481981213\n",
      "train loss:1.5538772921200212\n",
      "=== epoch:225, train acc:0.49, test acc:0.4002 ===\n",
      "train loss:1.668243261619074\n",
      "train loss:1.6467999483312952\n",
      "train loss:1.568137398198326\n",
      "=== epoch:226, train acc:0.48333333333333334, test acc:0.3965 ===\n",
      "train loss:1.727018665560233\n",
      "train loss:1.8233137840431624\n",
      "train loss:1.6983713019184652\n",
      "=== epoch:227, train acc:0.4866666666666667, test acc:0.4083 ===\n",
      "train loss:1.745829467729416\n",
      "train loss:1.7015511321634846\n",
      "train loss:1.7183026760317264\n",
      "=== epoch:228, train acc:0.49, test acc:0.4161 ===\n",
      "train loss:1.662533344863727\n",
      "train loss:1.7597938587739081\n",
      "train loss:1.5951399893327183\n",
      "=== epoch:229, train acc:0.5033333333333333, test acc:0.415 ===\n",
      "train loss:1.705903042188372\n",
      "train loss:1.7276243889366816\n",
      "train loss:1.7366115771575465\n",
      "=== epoch:230, train acc:0.5066666666666667, test acc:0.4183 ===\n",
      "train loss:1.7283541885449925\n",
      "train loss:1.7001716261581823\n",
      "train loss:1.5688919065293812\n",
      "=== epoch:231, train acc:0.5166666666666667, test acc:0.4215 ===\n",
      "train loss:1.7296475008447925\n",
      "train loss:1.6588576399751704\n",
      "train loss:1.7520789196613986\n",
      "=== epoch:232, train acc:0.5233333333333333, test acc:0.4223 ===\n",
      "train loss:1.6955625251984674\n",
      "train loss:1.721122514910742\n",
      "train loss:1.6490140006458534\n",
      "=== epoch:233, train acc:0.53, test acc:0.4256 ===\n",
      "train loss:1.6645066184135273\n",
      "train loss:1.5386954756084856\n",
      "train loss:1.5463775291989932\n",
      "=== epoch:234, train acc:0.5233333333333333, test acc:0.4217 ===\n",
      "train loss:1.6218360762471733\n",
      "train loss:1.6698857974351924\n",
      "train loss:1.7445797593065833\n",
      "=== epoch:235, train acc:0.5333333333333333, test acc:0.4261 ===\n",
      "train loss:1.659940794724276\n",
      "train loss:1.7080322053129589\n",
      "train loss:1.620689319735008\n",
      "=== epoch:236, train acc:0.55, test acc:0.428 ===\n",
      "train loss:1.6246946989282163\n",
      "train loss:1.5723625284712066\n",
      "train loss:1.64794098274714\n",
      "=== epoch:237, train acc:0.54, test acc:0.4249 ===\n",
      "train loss:1.7384230655188497\n",
      "train loss:1.6670908778540139\n",
      "train loss:1.5660312508057683\n",
      "=== epoch:238, train acc:0.5466666666666666, test acc:0.4291 ===\n",
      "train loss:1.5477848702862484\n",
      "train loss:1.6124170341479231\n",
      "train loss:1.592531362472355\n",
      "=== epoch:239, train acc:0.55, test acc:0.4344 ===\n",
      "train loss:1.630416543681602\n",
      "train loss:1.4841728808934425\n",
      "train loss:1.5128926754274206\n",
      "=== epoch:240, train acc:0.5433333333333333, test acc:0.43 ===\n",
      "train loss:1.64676430870992\n",
      "train loss:1.626673053127879\n",
      "train loss:1.4772285590988004\n",
      "=== epoch:241, train acc:0.5266666666666666, test acc:0.4266 ===\n",
      "train loss:1.7441592505670354\n",
      "train loss:1.6444249679129208\n",
      "train loss:1.704357470713592\n",
      "=== epoch:242, train acc:0.53, test acc:0.4324 ===\n",
      "train loss:1.5511740506982812\n",
      "train loss:1.57643475981639\n",
      "train loss:1.5828292507346975\n",
      "=== epoch:243, train acc:0.5266666666666666, test acc:0.4301 ===\n",
      "train loss:1.6008365900720747\n",
      "train loss:1.6486777856376542\n",
      "train loss:1.5938632059442766\n",
      "=== epoch:244, train acc:0.52, test acc:0.4296 ===\n",
      "train loss:1.5870448855127206\n",
      "train loss:1.5295059788896763\n",
      "train loss:1.4764384423534422\n",
      "=== epoch:245, train acc:0.53, test acc:0.4451 ===\n",
      "train loss:1.5703246721442203\n",
      "train loss:1.5424149064873465\n",
      "train loss:1.5693712266744546\n",
      "=== epoch:246, train acc:0.5233333333333333, test acc:0.4457 ===\n",
      "train loss:1.559955340355523\n",
      "train loss:1.4944525278445673\n",
      "train loss:1.6627860927682503\n",
      "=== epoch:247, train acc:0.5266666666666666, test acc:0.4447 ===\n",
      "train loss:1.3918177856067049\n",
      "train loss:1.5490844540195612\n",
      "train loss:1.6564047376040414\n",
      "=== epoch:248, train acc:0.5433333333333333, test acc:0.4508 ===\n",
      "train loss:1.6314891415788373\n",
      "train loss:1.4929266411218234\n",
      "train loss:1.5970303613928605\n",
      "=== epoch:249, train acc:0.55, test acc:0.4529 ===\n",
      "train loss:1.5738258942935122\n",
      "train loss:1.47445981737429\n",
      "train loss:1.4897485743567247\n",
      "=== epoch:250, train acc:0.55, test acc:0.4522 ===\n",
      "train loss:1.6261542568317886\n",
      "train loss:1.7313407357193276\n",
      "train loss:1.554585035313105\n",
      "=== epoch:251, train acc:0.56, test acc:0.449 ===\n",
      "train loss:1.5503386445693912\n",
      "train loss:1.4765303267785503\n",
      "train loss:1.509665390112395\n",
      "=== epoch:252, train acc:0.5566666666666666, test acc:0.4528 ===\n",
      "train loss:1.4569795931052305\n",
      "train loss:1.5738324652381102\n",
      "train loss:1.6023810238660063\n",
      "=== epoch:253, train acc:0.5533333333333333, test acc:0.4526 ===\n",
      "train loss:1.4298429585002754\n",
      "train loss:1.5029619836200843\n",
      "train loss:1.5513610857661713\n",
      "=== epoch:254, train acc:0.5633333333333334, test acc:0.4526 ===\n",
      "train loss:1.3894012516249787\n",
      "train loss:1.5044518200602082\n",
      "train loss:1.4770205889489174\n",
      "=== epoch:255, train acc:0.5733333333333334, test acc:0.4547 ===\n",
      "train loss:1.5139325060449855\n",
      "train loss:1.4566014005663164\n",
      "train loss:1.4500032473091315\n",
      "=== epoch:256, train acc:0.5833333333333334, test acc:0.4555 ===\n",
      "train loss:1.5166901868476657\n",
      "train loss:1.5088828308278874\n",
      "train loss:1.4705702699412135\n",
      "=== epoch:257, train acc:0.5866666666666667, test acc:0.4577 ===\n",
      "train loss:1.520929744759779\n",
      "train loss:1.49411993881096\n",
      "train loss:1.428247454343908\n",
      "=== epoch:258, train acc:0.5766666666666667, test acc:0.4556 ===\n",
      "train loss:1.3889565065211409\n",
      "train loss:1.532715416100848\n",
      "train loss:1.4688299683911132\n",
      "=== epoch:259, train acc:0.59, test acc:0.4645 ===\n",
      "train loss:1.531685494926136\n",
      "train loss:1.563509121781828\n",
      "train loss:1.3998862667798633\n",
      "=== epoch:260, train acc:0.6, test acc:0.4675 ===\n",
      "train loss:1.4973475777802616\n",
      "train loss:1.5344510204764061\n",
      "train loss:1.422062338363829\n",
      "=== epoch:261, train acc:0.61, test acc:0.4725 ===\n",
      "train loss:1.3872846919715753\n",
      "train loss:1.4651884707564198\n",
      "train loss:1.4436021035660398\n",
      "=== epoch:262, train acc:0.61, test acc:0.4763 ===\n",
      "train loss:1.6372723419348338\n",
      "train loss:1.3975807240793834\n",
      "train loss:1.407946712482312\n",
      "=== epoch:263, train acc:0.59, test acc:0.4727 ===\n",
      "train loss:1.2906760267992834\n",
      "train loss:1.5630673774656247\n",
      "train loss:1.2943131808180568\n",
      "=== epoch:264, train acc:0.57, test acc:0.4718 ===\n",
      "train loss:1.4882109375976995\n",
      "train loss:1.5746511127582847\n",
      "train loss:1.4624043159417224\n",
      "=== epoch:265, train acc:0.5833333333333334, test acc:0.4754 ===\n",
      "train loss:1.5402274633142918\n",
      "train loss:1.417108556695584\n",
      "train loss:1.4187338993187435\n",
      "=== epoch:266, train acc:0.59, test acc:0.4792 ===\n",
      "train loss:1.4388473748644903\n",
      "train loss:1.344944330950019\n",
      "train loss:1.4144959242601265\n",
      "=== epoch:267, train acc:0.5933333333333334, test acc:0.4847 ===\n",
      "train loss:1.4753368575146915\n",
      "train loss:1.3270931358404356\n",
      "train loss:1.5130981039955642\n",
      "=== epoch:268, train acc:0.6, test acc:0.4872 ===\n",
      "train loss:1.5188189079663903\n",
      "train loss:1.459128653270335\n",
      "train loss:1.3497643126384296\n",
      "=== epoch:269, train acc:0.6066666666666667, test acc:0.4905 ===\n",
      "train loss:1.5514657359805537\n",
      "train loss:1.4454082405975661\n",
      "train loss:1.549669215739103\n",
      "=== epoch:270, train acc:0.6166666666666667, test acc:0.4915 ===\n",
      "train loss:1.5147405893149049\n",
      "train loss:1.4188945019986017\n",
      "train loss:1.490036721233861\n",
      "=== epoch:271, train acc:0.6266666666666667, test acc:0.4944 ===\n",
      "train loss:1.3764914560019137\n",
      "train loss:1.316940756748844\n",
      "train loss:1.550204204941902\n",
      "=== epoch:272, train acc:0.63, test acc:0.5002 ===\n",
      "train loss:1.3562043403258115\n",
      "train loss:1.4573529766928188\n",
      "train loss:1.4007244903706026\n",
      "=== epoch:273, train acc:0.6266666666666667, test acc:0.4982 ===\n",
      "train loss:1.402748728011786\n",
      "train loss:1.4239157376734541\n",
      "train loss:1.3253331475095793\n",
      "=== epoch:274, train acc:0.6366666666666667, test acc:0.4952 ===\n",
      "train loss:1.5786006910537482\n",
      "train loss:1.5123286843351706\n",
      "train loss:1.3904606233772734\n",
      "=== epoch:275, train acc:0.6433333333333333, test acc:0.5047 ===\n",
      "train loss:1.4178481161934988\n",
      "train loss:1.3265683238626667\n",
      "train loss:1.5436872117756442\n",
      "=== epoch:276, train acc:0.63, test acc:0.5068 ===\n",
      "train loss:1.2608545634564514\n",
      "train loss:1.2695071056107845\n",
      "train loss:1.384059319895468\n",
      "=== epoch:277, train acc:0.6333333333333333, test acc:0.5057 ===\n",
      "train loss:1.3562775239417622\n",
      "train loss:1.3455407673258803\n",
      "train loss:1.3670291735111137\n",
      "=== epoch:278, train acc:0.6333333333333333, test acc:0.5084 ===\n",
      "train loss:1.3742487042667555\n",
      "train loss:1.3543473692382464\n",
      "train loss:1.34766047483015\n",
      "=== epoch:279, train acc:0.63, test acc:0.5064 ===\n",
      "train loss:1.5146768090274523\n",
      "train loss:1.3011892177483135\n",
      "train loss:1.3332253067374495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:280, train acc:0.64, test acc:0.5137 ===\n",
      "train loss:1.4045167965298466\n",
      "train loss:1.255477547417165\n",
      "train loss:1.313619422563444\n",
      "=== epoch:281, train acc:0.6333333333333333, test acc:0.5146 ===\n",
      "train loss:1.3463939199366646\n",
      "train loss:1.3182601657917734\n",
      "train loss:1.3165470846804295\n",
      "=== epoch:282, train acc:0.63, test acc:0.5149 ===\n",
      "train loss:1.328250948302331\n",
      "train loss:1.3165822818649042\n",
      "train loss:1.3826605109721817\n",
      "=== epoch:283, train acc:0.6366666666666667, test acc:0.519 ===\n",
      "train loss:1.353221014924375\n",
      "train loss:1.4411044446697736\n",
      "train loss:1.2639700075391274\n",
      "=== epoch:284, train acc:0.6333333333333333, test acc:0.52 ===\n",
      "train loss:1.387344999443546\n",
      "train loss:1.4938971319878973\n",
      "train loss:1.26003842724445\n",
      "=== epoch:285, train acc:0.63, test acc:0.521 ===\n",
      "train loss:1.393804217148063\n",
      "train loss:1.266466841373156\n",
      "train loss:1.253837329981044\n",
      "=== epoch:286, train acc:0.64, test acc:0.5141 ===\n",
      "train loss:1.3016401915602651\n",
      "train loss:1.3094154122717958\n",
      "train loss:1.3023816121864698\n",
      "=== epoch:287, train acc:0.63, test acc:0.5116 ===\n",
      "train loss:1.3431406994923978\n",
      "train loss:1.3871583624059454\n",
      "train loss:1.3619129812296384\n",
      "=== epoch:288, train acc:0.6733333333333333, test acc:0.5156 ===\n",
      "train loss:1.294942565794093\n",
      "train loss:1.1832856914483938\n",
      "train loss:1.2963902364762785\n",
      "=== epoch:289, train acc:0.6766666666666666, test acc:0.5139 ===\n",
      "train loss:1.315727284208622\n",
      "train loss:1.2187173313996253\n",
      "train loss:1.4843776956069874\n",
      "=== epoch:290, train acc:0.6566666666666666, test acc:0.5191 ===\n",
      "train loss:1.3326895650034032\n",
      "train loss:1.3856758867312033\n",
      "train loss:1.2994023054563548\n",
      "=== epoch:291, train acc:0.6433333333333333, test acc:0.5221 ===\n",
      "train loss:1.3037155053479297\n",
      "train loss:1.3675222624893917\n",
      "train loss:1.2421809894019484\n",
      "=== epoch:292, train acc:0.6633333333333333, test acc:0.515 ===\n",
      "train loss:1.3354759596350854\n",
      "train loss:1.287015682437137\n",
      "train loss:1.3125302365855833\n",
      "=== epoch:293, train acc:0.66, test acc:0.5229 ===\n",
      "train loss:1.3453097684396613\n",
      "train loss:1.2867024725007852\n",
      "train loss:1.1564274582154304\n",
      "=== epoch:294, train acc:0.6533333333333333, test acc:0.5268 ===\n",
      "train loss:1.2770858781063792\n",
      "train loss:1.2057673035882301\n",
      "train loss:1.2840189589017532\n",
      "=== epoch:295, train acc:0.6466666666666666, test acc:0.5303 ===\n",
      "train loss:1.3315473171679282\n",
      "train loss:1.2474934717570492\n",
      "train loss:1.2512584639491582\n",
      "=== epoch:296, train acc:0.65, test acc:0.5318 ===\n",
      "train loss:1.1561893435612178\n",
      "train loss:1.266600354431981\n",
      "train loss:1.3867942158170026\n",
      "=== epoch:297, train acc:0.66, test acc:0.533 ===\n",
      "train loss:1.223834672828232\n",
      "train loss:1.3220303435116776\n",
      "train loss:1.22047302303243\n",
      "=== epoch:298, train acc:0.6766666666666666, test acc:0.5401 ===\n",
      "train loss:1.2431352836236647\n",
      "train loss:1.256259493497147\n",
      "train loss:1.1931514162734458\n",
      "=== epoch:299, train acc:0.6833333333333333, test acc:0.5324 ===\n",
      "train loss:1.1936103552343\n",
      "train loss:1.3358046973173507\n",
      "train loss:1.1616739426242777\n",
      "=== epoch:300, train acc:0.6866666666666666, test acc:0.5344 ===\n",
      "train loss:1.190860276473392\n",
      "train loss:1.0900351973291926\n",
      "train loss:1.2182224749008719\n",
      "=== epoch:301, train acc:0.6833333333333333, test acc:0.5349 ===\n",
      "train loss:1.289062126481359\n",
      "train loss:1.2726194013198233\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5368\n"
     ]
    }
   ],
   "source": [
    "# 드롭아웃 사용할지 안할지 유무 적용\n",
    "use_dropout = True\n",
    "\n",
    "# 0.2 \n",
    "dropout_ratio = 0.2\n",
    "\n",
    "# 네트워크~ 사이즈 조정 후 히든 사이즈를 주고 아웃풋도 줌\n",
    "\n",
    "# 여러가지의 파라미터가 있는데 드랍 아웃 사용 하고 \n",
    "# 죽여버릴 비율을 한 iteration 당 0.2로 줌\n",
    "network = MultiLayerNetExtend(input_size=784,\n",
    "                              hidden_size_list=[100 for _ in range(6)],\n",
    "                              output_size=10,\n",
    "                              use_dropout=use_dropout,\n",
    "                              dropout_ration=dropout_ratio,\n",
    ")\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4lNX5//H3Pclkg5CwyZKABEQUFUERteC+IFoVrT9camutFmtduonC113bq3y12pavW621i9Zd2RQLqLigssqOIsiasC8JW9bJ+f3xTIZJMpMMkMn6eV1Xrsw8c56Z82Rg7jnbfcw5h4iICICvoSsgIiKNh4KCiIiEKCiIiEiIgoKIiIQoKIiISIiCgoiIhMQtKJjZi2a21cyWRnnczGycma0ys8VmdlK86iIiIrGJZ0vhn8BFNTw+DOgd/BkJPBvHuoiISAziFhScc58CO2socjnwb+eZBWSaWZd41UdERGqX2ICvnQVsCLufGzy2qWpBMxuJ15qgVatWJx9zzDH1UkERkeZi/vz5251zHWsr15BBwSIci5hzwzn3PPA8wMCBA928efPiWS8RkWbHzNbFUq4hZx/lAt3C7mcDGxuoLiIiQsMGhUnAj4OzkE4DCpxz1bqORESk/sSt+8jMXgXOBjqYWS7wIOAHcM49B0wBLgZWAfuBG+NVFxERiU3cgoJz7tpaHnfAbfF6fREROXha0SwiIiEKCiIiEqKgICIiIQoKIiISoqAgIiIhCgoiIhKioCAiIiEKCiIiEqKgICIiIQoKIiISoqAgIiIhCgoiIhKioCAiIiEKCiIiEqKgICIiIQoKIiISoqAgIiIhCgoiIhKioCAiIiEKCiIiEqKgICIiIQoKIiISoqAgIiIhCgoiIhKioCAiIiEKCiIiEqKgICIiIQoKIiISoqAgIiIhCgoiIhKioCAiIiEKCiIiEqKgICIiIQoKIiISoqAgIiIhcQ0KZnaRma0ws1VmNjrC493NbIaZLTCzxWZ2cTzrIyIiNYtbUDCzBOBpYBjQF7jWzPpWKXYf8IZzbgBwDfBMvOojIiK1i2dLYRCwyjm32jlXArwGXF6ljAPaBG9nABvjWB8REalFPINCFrAh7H5u8Fi4h4DrzSwXmALcEemJzGykmc0zs3nbtm2LR11FRIT4BgWLcMxVuX8t8E/nXDZwMfCSmVWrk3PueefcQOfcwI4dO8ahqiIiAvENCrlAt7D72VTvHroJeAPAOfclkAJ0iGOdRESkBvEMCnOB3maWY2ZJeAPJk6qUWQ+cB2Bmx+IFBfUPiYg0kLgFBedcGXA7MBX4Gm+W0TIze8TMLgsW+y3wMzNbBLwK/MQ5V7WLSURE6kliPJ/cOTcFbwA5/NgDYbeXA4PjWQcREYmdVjSLiEiIgoKIiIQoKIiISIiCgoiIhCgoiIhIiIKCiIiEKCiIiEiIgoKIiIQoKIiISIiCgoiIhCgoiIhIiIKCiIiEKCiIiEiIgoKIiIQoKIiISIiCgoiIhMR1kx0RETl8Exbk8fjUFWzML6RrZiqjhvZh+ICsuLyWgoKISCM2YUEe97y9mOKycgDy8gsZ884SgLgEBnUfiYg0UmWBcv5n/JJQQKhQWBrg8akr4vKaCgoiIg2gvNzVWubpGd+xvyQQ8bGN+YV1XSVAQUFEpF4Fyh33T1jKsQ/8l5Vb9kQttzG/kHEfrSTVnxDx8a6ZqXGpn4KCiEg9mrlqOy/NWkdxWTmffLstarkZK7YSKHf86vze1QJDqj+BUUP7xKV+CgoiIvVo/c79ACQn+pi7dicAu/aV4Fzl7qRPv91GVmYqI8/syR+uPIGszFQMyMpM5Q9XnqDZRyIizcGWgiISfMaw4zszc9V2luYV8P3/m8nZfTryzA9PIi0pkdJAOZ+v2sGlJ3bFzBg+ICtuQaAqtRREROrRpoIijkhP5tSe7dm+t4R/f7kWgI9XbOORycsBmL58C3uLyzjvmCPqvX5qKYiI1KMtu4vonJHCkKM6APDGvFwAWicn8trcDZx7zBE8+/F35HRoxTkKCiIizdumgkKO7pTO/HW7MIOKoYS9xWUYcMtL83HA//7gBBJ8Vu/1U/eRiMghmrZsMzf/ax5lgQOLyyYsyON7f/iQnNHvMXjsR0xYkBd6rLAkwJbdxXTOSOHxqSuoMraMAxJ8xn2XHMuIgd3q6SoqU0tBROQQbMwv5LdvLmJPURmff7eDs47uyIQFeYx6axGlAe/TPi+/kLvfWkx5uaNNqp+b/z0PgM5tUqIuPguUO24+o2e9XUdVCgoiIjGompSuS0YypYFy0pMTueetxQzKaceHX28JBYQKJYFyRr+zhJ4dW4WOdc5IoWtmKnkRAkO8FqXFSt1HIiK1mLAgjzHvLCEvvxCH1wKYty6fQT3aceFxndm8u4gvvtvOvigpKUoC5Xyz+cDq5Y6tkxk1tE+9LkqLlVoKIiK1eHzqCgpLq3/gr9iyh/+9qh99u7bhukHdOevxGWzdU1ytXKc2yfzsjJ5ceVI2b83fwKCcdiQm+ELPXR8psWNlVVfRNXYDBw508+bNa+hqiEgzEcteBTmj3yPSJ6UBa8ZeUum5xryzpFIASfUnxHUFcqzMbL5zbmBt5dRSEJEWq+qHeLS9CmLt/684p7F9+z8YcQ0KZnYR8BcgAXjBOTc2QpkRwEN4s7EWOeeui2edREQqROoWqtirIPyD/I5zezH6naWVykXr/6/PlBTxELegYGYJwNPABUAuMNfMJjnnloeV6Q2MAQY753aZWf0v3xORFivatNCqx7ftKQGgY3oy2/cUN8kWQKzi2VIYBKxyzq0GMLPXgMuB5WFlfgY87ZzbBeCc2xrH+oiIVBJLt9DyjbsZ99FKLj6hM8/88OT6rF6DiOeU1CxgQ9j93OCxcEcDR5vZ52Y2K9jdVI2ZjTSzeWY2b9u26PnHRUQOxl0XHE3VRBL+BAt1CxWVBvjV6wvITEvid8NPqP8KNoB4BoVISTuqDuAnAr2Bs4FrgRfMLLPaSc4975wb6Jwb2LFjxzqvqIi0TGkpiTigbZofA3wGJ2ZnMHxAFgX7S7nj1QV8u2Uvj1/Vj3atkhq6uvUipu4jM3sbeBF43zlXXlv5oFwgPHlHNrAxQplZzrlSYI2ZrcALEnNjfA0RkYP26bfbSPEn8I/P19CtXSozfns2iQk+bn15PkvyCgiUO0a+NI/563Zx//f7cnafljPcGWtL4VngOmClmY01s2NiOGcu0NvMcswsCbgGmFSlzATgHAAz64DXnbQ6xjqJiBy0J6d/y49fnMNN/5rL7DU7ueqkbqGFZAN7tCN3VyGPTf2G2Wt2MvYH/bhpSE4D17h+xRQUnHMfOOd+CJwErAWmm9kXZnajmfmjnFMG3A5MBb4G3nDOLTOzR8zssmCxqcAOM1sOzABGOed2HN4liYhEtrmgiGc/XsXJR7ZlT1EZzsFl/buGHh94ZFsAnv90NYN6tOMHJzW/2UW1iXn2kZm1B64HfgQsAP4DDAFuwBsTqMY5NwWYUuXYA2G3HfCb4I+ISFz9feZqyh38+er+jH5nMSVl5eR0OJCorm/XNqT6EygsDXDlSVmY1f9+Bg0t1jGFd4BjgJeAS51zm4IPvW5myjkhIo1O1fQVt53Ti1dmr+f7/brQrV0af7/hlGr7GfgTfAzonsnctTsZdnyXhql4A4u1pfCUc+6jSA/EkktDRKQ+RUpf8cDEZZSVO35+Vi8AUqpkKK3wmwuOZv3O/WSkRewZb/ZiHWg+NnyqqJm1NbNfxKlOIiKHJVL6irJyR3Kij2O7tKnx3IE92nHlSdnxrF6jFmtQ+JlzLr/iTnAF8s/iUyURkcMTLX1FSVmsM+pbrliDgs/CRlyCeY1axkoOEWkwzjlenbOevPxCSsrKeenLtazZvq/W89pGWWjWNTOljmvY/MQ6pjAVeMPMnsNblfxz4L9xq5WICLB6+z7GvLOEc/p0ZNf+UhZuyKdXx1a8e8cZpCZFHhOYs2YnO/eVVDue4vcxamgsS6waocVvwIePQEEuZGTDeQ9AvxFxealYWwr3AB8BtwK3AR8Cd8elRiIiQZ+s8HKdzVixjYUb8rnlrJ58t20ff58ZfY3rfROW0L1dGmOvPIGszFQMyMpMZeyV/ZpWVlPnYM1nsPAVmHwnFGwAnPd78p1eoIgD7bwmIo3WT/4xhxWb91BUGmDEKd0YM+xYznrsIzYWFFEWcNVSWK/fsZ8zH5/Bg5f25cbBTXwl8oL/wMRfQFJrKNlb/fGMbvDrpdWPR1GnO68F9z34A9AXCHXKOed6xlwjEZEY7dpXgj/Rx6zVO7jmlO6MHnYMKf4EJizIIy+/iLJy78tsxU5phaVljBjYnU9Wei2Ls45uIokzI3ULte4EK96HBS9DQnLkgADeOXEQ65jCP4AHgT/h5Sq6kchZUEVEDkn4YjMHHJGeRFFpOcMHZIXWFDw+dUUoIFQoLA1w7/ilTFu2BQd0a5daaZVyo7X4Da8bqDQ4U6pgA4z/ObgAJKZAzplekHjhAiiLMJsqIz7TZmMNCqnOuQ/NzJxz64CHzOwzvEAhInJYIm14v3VPCb06tqJ/twPZ9KNNNS133rgDwM/P6tWw6SkiffvvfSHs3QIdw7bv/PCRAwGhggtAchv47QpISvOOXTaucvAA8Kd6zxsHsQaFIjPz4WVJvR3IA1pOLlkRiatIi80AdheVVbofbae0pAQfN3zvSI5IT+GnDZnVNNK3/3dGEtpKZsRL0PcybxA5WvdP8Z4DAQEOzDKqp9lHsQaFXwFpwJ3Ao3hdSDfEpUYi0uJEawFs31Nc6f6ooX2qtSiSEnyMufiYxjGwHOnbPw6SM6DtkfDur2DdF/DVv6I/R6RuoX4j4hYEqqp1SmpwodoI59xe51yuc+5G59wPnHOz6qF+ItIChO+JXNPx4QOy+EOVqaaPXdWvYQNCeQD2boNtK4LTRiMo3g0/eAH8rWD2s5B9CnTo440dhItjt1Csam0pOOcCZnZycDyhac1fFZFGzznHidkZ1bqFUv0Job2Sww0fkNUw6w0ijRW0Pwre+insWlPzuRnZ3njCHfNg4wLodiqY1euitFjF2n20AJhoZm8CoTXmzrl34lIrEWkx5q3bxZSlm+nfLYMtu4vZXFBUbf1Bg4s0VjDxdkjv6s0MOu9BCJQCDj57AgJhK6rDv/0nJkP30w48Vo/dQrGKNSi0A3YA54Ydc4CCgogclokL80jx+/jPzafRKjnmfb/qV6SxgkAx5K+BS56EU246cLxdz0b37f9gxPQOOOdujHdFRKRlKCkrZ/KijVx0fGcA3lu8ifOP7dR4AwLUvFBswPWV7zfCb/8HI9YVzf8gNKfqAOfcT+u8RiLSrD0xbQV//XQ1kxdvZP2O/eQXlnLtoO4NXa3I9myG6Q8S4ePPk9HN6xJqRmINze+G3U4BrgA21n11RKQ5W5pXwPOfraZbu1Q+XrGNzm1SeOXm0zi9V/uGq1S0wd7CfPjXpbBrHRx9Eaz+pPLK4kYwUygeYu0+ejv8vpm9CnwQlxqJSLP1zMeraJ2cyOTbh/Dpyu2c2bsDmWkNuDVLpAHkyXfCvm2w6FXYuQZ+PBF6DG6UM4Xi4VA78XoDjbS9JyKNRXg+oyPaJLNldzG/OLsXmWlJXHZi14auXuQB5NJCmHYfJKXDta96AQGa/FhBrGIdU9hD5U61zXh7LIiIVFNcFuDJ6d/y7y/WUljqbYG5Zbe3Orl960a0aWO0AWRXDiNnQPte9VufRiCmTXacc+nOuTZhP0dX7VISkZZrY34h901Ywvod+wF4ZPJy/vrJ6lBACPfizLX1XLsahOcYCpfRrUUGBIi9pXAF8JFzriB4PxM42zk3IZ6VE5Gm4T+z1/HyrPW8PGs9SQk+SgLVg0GFaHmO6ly0MYDyclj1AeSvg5J94EuE8rDEe810ADlWsY4pPOicG19xxzmXb2YPAgoKIi1Q+FhB12Aeoq4ZKVw1sBulgXLat0riqY9WkV9YWu3caHmO6kx5AKY/AHOeP7CyuGCDt4vZrGdh11oo3OkdT86ACx72ViE38wHkWMUaFCJ1MzXilSYiEi9V9z6oyFl08fGd+c0FR4fKtUtL4q63FhG+J06q3xcxn1GdKS2Ef14CefOrPxYo9fIODbgeep0DiamQ2haOPB0Gan1uhVg/2OeZ2ZPA03gDzncAEf7qItLcRdv7YO66XZXuX3lyNgVFpV75kkB88xlNfwBWfuCtI9i5uuaylz9V96/fjMQaFO4A7gdeD96fBtwXlxqJSKMW694HADcOzol/Wus9m+Hzv0CX/t54wAU/gTl/i5zGOk5bWDYnsS5e2weMjnNdRKSRmrJkE49MXk65c9ESPsR/rAC8VcXbv/WCQMUYQM+zvccufxo6H+/dTu9Sr1tYNiexzj6aDvw/51x+8H5b4DXn3NB4Vk5EGl6g3PH41BX4E40hR3Vkx95iPl25naKw6abR9j44KLWtGP7q3zDpDsAILZsq2AALX4bUdtDpuANl63kLy+Yk1u6jDhUBAcA5t8vMtEezSDNTdVbRqKF9SPH7WLN9H09fdxKX9OsStdxhjRVESjcx6Q5Y9DpsXgyd+sKaTyEhqfJeBeDtd1xe6m1aE66FrECua7EGhXIz6+6cWw9gZj2ImjZQRBqzgv2l7Cspq9bd88bc9dw/cRnFZV4LIC+/kDHvLCGnQxpdMlJCqa4hDrufRUo3UVYE330AR10Aq2fAUefDyumRzy/eW3d1aeFiDQr3AjPN7JPg/TOBkfGpkojUtfBv9v5EH4FAOb+74oRKKasfnHQgIFQoLA2wfNMebjmzJwk+q/q0h6+8HJaPj763McD1b8H+nZCSCX/ppwHkOIt1oPm/ZjYQLxAsBCYC9bQsUUQOR9V1BSXBD/77xi9hc0ER323byzWndI+YkqLCZf3jlLxu4cvBcYIoMrp5v9Paeb/Pe0ADyHEW60DzzcAvgWy8oHAa8CWVt+eMdN5FwF+ABOAF59zYKOWuAt4ETnHOzYu59iItXCx9+9HWFQQc/OXDlQC8u3hT1NdIT0mkb5c2dVtxgKIC+OAh6HYa9DgDvnyq9v0KNIAcd7F2H/0SOAWY5Zw7x8yOAR6u6QQzS8Bb7HYBkAvMNbNJzrnlVcqlA3cCsw+28iItWaSVxWPeWcL89bs4pnM6157SHZ/Pasw11KN9Gv937UksyStgU0EhL3y2plIASfUn8Ojlx2NVB3HrwqLXYf8OuO5NyD4ZOh4d24e9BpDjKtagUOScKzIzzCzZOfeNmdU2/2wQsMo5txrAzF4DLgeWVyn3KPAYcNfBVFykpYvUAigsDfDSl+sAGDvlG75/Yle6ZqaQl19U7fyumSlM+/VZJCX6OCE7A4BeHVvX7ayiqpyDBS/Dx2O9je+7nOgFBNCHfSMRa1DIDWZGnQBMN7Nd1L4dZxYQPiKUC5waXsDMBgDdnHPvmlnUoGBmIwkObHfvrr19pOmqy6mcNbUArhyQxb6SMl6ds57TctpVCwqp/gTuHnoMSYmV05rV6awi52Dhf7wAUPHtv+sA+HoStO7k7W52zr1181pSZ2IdaL4iePMhM5sBZAD/reW0SO3N0DRWM/MBfwJ+EsPrPw88DzBw4EBNhZUmKVp3D3BIH8Qd0pPZFiG1hM/gsav64TPjlpfnM335Frq0SSbgYNue4rpbVxDe1XP8VbBjJRx3hffBv2khTLkb9m8/cE7BBu+n2+nwk3dh41eQNfDQ6yBxcdCZTp1zn9ReCvBaBt3C7mdTuXWRDhwPfBzsr+wMTDKzyzTYLM1RtO6ex6euiPkDes32fbRrlURGqp/khOrfuxJ9xlUDs0lM8FoAz//oZEoDDn+C1d24QKSFZp//CSwBvnn3QDmfP/L5uzdAQiJ0G1Q39ZE6Fc/013OB3maWA+QB1wDXVTwY3LCnQ8V9M/sYuEsBQZqb4rIA//x8bdTunlg3nSkqDXD5UzM5tWd7Hry0L7n5RQzv35W5a3dF7Y4yM5IS63iQONJCM4D0znDVP2Dnd+BPgzd/Evn8gry6rY/UqbgFBedcmZndDkzFm5L6onNumZk9Asxzzk2K12uL1Keaxgn2FJUyceFG/vD+N1HPrymRnHOOW1/+im+37qFvlzbsLipj+vItZLf1zrntnKPo3Sm9bi+oNtEWmu3eCN1P9X4ApmVroVkTFNeNcpxzU4ApVY5FXGXinDs7nnURiYdo4wSu3LFs025emLmGFL+Pvl3akJmWyOzVuwi4ysNiN5/hpZaes2Ynx2e1IS3pwH/L1dv38d9lm2mb5ufdxZto3yqJ/SUB/vH5WtqkJHLUEa3r72K3fQszn4z+eNUPey00a5Ii7agmIjGKNk7w6JSveWHmGk7v2Z5AuWPU0D688rPTeWLEiWQFt6/s1CaZBIMvv9vBf5duYsRfv+SRyd6M7QkL8hg89iPOe8IbwrtxcA+6ZKRw9SndePb6k0hPSeTaQd3js34gkg1zvR3NvnnPGyhOrNK6ibbQ7NJxwVXJ5v2+dJymnTZy5lzTmswzcOBAN2+ehh0k/mKZPpoz+r2omSE7tE5i1pjzcIA/IfL3r799uprfT/mairRCiT4fPx3Sg398vrZSHiJvEdlx/ODkbMyM8uAel766zkcUKX11UQFMuQtad4YbJnuLzGpLcy2NjpnNd87VOt1L+yxLi7dh537e+SqPHh3SGJTTjjfn5bJ+537eXbwxtGdARbfQ/pIyHDC4VwfeW7KJpERftSRyFS45oUtoFlA0Nw3JwZ9gbN1TzFlHd+SHL8zmuU+qbydZWBrgTx+s5KqB3oS+Og8GECV99e3gzNvI5uqXITk4fqGFZs2WgoK0aEWlAW7851xWbfVSLx+RnszWCHP/wftgfnjy8kpBIDnBwrd8ASAp0UdygjHilG7VnqMqn8/4Sdh2le/eOYSL/vxZxLKxzlI6ZO/fEyF9dfBvMeyxAwFBmjUFBWlxwruFKr7p/+PGU/jzBytZtCGf5390MiNfmh/x3OKycn54anf2lwS4/dyj6NWxNX+fuZo/Tv2WotLD35z+mM5tyMpMJS9CADis7S4rdfdkwWm/gP7XQWpb7/HyABTujHKyQcfD3FVNmgwFBWlRqs4WKi4rx59gFOwv5e83DGRpXgFn9zki6gdz2zQ/j15+fKXum5uG9OSmIT3rrI6jhvapVEc4zO0uq3UL5cLU/4Fp98Ox3/dWFRflRz9fU0hbFAUFaVEizRYqDbjQquKz+3i7zEb7YH7w0uPi058fpqKVEVOOpEgDvkd+D/47xtvgvs8wWPJm5MVm/lTYMAeWT/TuJ2dCebGmkLZwCgrSosS6qvigPpjjIKbEdJEGhsf/3LudmOylkZj5p+jnl+yDMblQvBsK8yGljbfdpWYVtWgKCtKiRE8jXb2/vs73Ia5rHz5cvQXgApDUGm79AtoeCQtfgXd/7e13XFVGtrfZfUqG9wOaVSRavCYty0+H5FQ7dlj99Q2pIDfy8ZJ9XkAAbzD5sv/zuoHCqVtIolBQkBala4b34dixdTIGZGWm8ocrT2jcLYJItlTdqypM1YFhrSyWg6DuI2kRXpm9nrlrd1JcFiDRZ3x2zzmk+BPqvyKHuhK4qADWzoRp90HRbm/9QFI6lJdW7hqK1gJQt5DESEFBGr1D2a1sy+4ivvxuB+BlKn148nLKgqkhbh6S03ABoerA8MTbvA/4k35UvWxF8EjNhJL93vaV7Xp6M4rMByf/BHas0sCw1CkFBWkwExbk8djUb9iYX0TH9GQG92rPyDN70bdrm1CZu95YyPgFG0OZRWvarSw8ePjMKmUjzW6byrhrB1BYEmDwUR2oV6VFMP+fMOP31QeGAyVeKonCXbDtG28WUMc+MPvZA2ULd3lB4Hu/hHPGVB4fyDpJQUDqlBLiSYOYsCCP0W8vpqhK3qDszFQ+u+ccdu4rYdryLaEAUFVyoo/z+3bi52f2IsFnLNtYwP0Tl4ZyFQEkJfgYNbQP5/ftROc2KaQmxal1EK1LaOvXsHMNfP5n2DC79udJTIHUdrAnyvbnGd3g10vrtu7SYsSaEE9BQepcbd09gXLHgEemsbuoLOL5Vw/sxsRFeZU+4CNJSvBREvDKJPos1D0ULiszlc9Hn3sYV1OLql1C4H2T7zscFr3q3U/OgEv/BNMfiDxjKCMb+l8PRw+F9kfB2Gg5kwweqmHlsUgNlCVVGkTkTWcWAzCwR1sen7qCbzbtiRoQAF6ft4Gzju7Idad256FJy9hUUH2Ofac2ybw28nRWbN7DpoJCHp4ceTbOYSWRi2VQONLWlKWFXkDoPRSG/NrbyN6f4uUXirjpzIOVnzcjO3rwEIkzBQWpU5E3nSlnzDtLSEzw9gE4rmsGbdP87NpfWu38rpkpfPibs0NdPYUlgYjpJsYMO5acDq3I6dAKgD9/8C0FhdUDzSEnkYs0KDz5Tu92+Ad4tLUCAFf9vXJm0Yrzags05z2oHcukwSgoSJ2K9s28sDTAgC6Z/OXqAXRvn1atRQHeh/3dQ4+p1Pcfa7qJhy87vu6SyAVKva6eSC2A9+/2UkisnO61AHwJUB6h1ZPRLXKq6VimhsYaPETiQGMKUify95ewcEM+P/3nXCJ07dOpTTKf33NupU1nDmWqaU0O+fl2rYM1n0LOmbBrDUwZ5SWTq4nP760RSEz1gkJ5WKvHn6rFYdLoaKBZ4qosUM5nq7ZzSo92/N+HK3n+s9U4Bx1bJ7G7qKzaVpKNatVw+FhBemevr3/f1gOPt+3hTQ2NlE66dSdvw5neF3rnt8uBZeP1rV4aPQ00S52q+i38uK7pTFu+lRS/j6LSckYMzOb0Xu0Zelxnpi3b0mDZRWtVdaxgzybv98CboFNf73b/6+HrSZH79S/8HRw33Lvf8Wjvt1YLSzOiloLUavz8XEaPX1JtL+LeR7QiMy2Jm8/oydDjOjdQ7WLknJco7plTo8zsibAGQJvTSzOiloLUauueIv76yWr+u3Rz1G/1BftLIwYEgL3FAab/5nv1WeVDEyiFN26AFe9FLxMpUKgFIC2QgkILVRoo5wfPfsGGnQe6R/LyCxn9zmJKA+VcMSCLBJ8x+p3FEQMCwOZqgdDsAAAUfklEQVQI6wcOSqzfxA+n3FHne/mFVkyBU2+Fhf/xNpWpSmsARAAFhRbrqY9WVQoIFYpKyxn11mIemrSMIb07MHXZFtqkJEZcbHbYG8nHsg7gcMqN/7mXOiJQ7A0On3qLlytIawBEolJQaIEWbsjnqRmraizTv3smU5dt4cbBPTihawb3Tlga+xqAw1kJ/O6vvZxBWSfB/p3R1wtMux/8aZC/DgryYOHLkXchc2XwsxnQpZ93TGsARGqkoNACPT71G9q1SiLRZxFTSGRlpvLST09l655iOmekAODzWewbyUf7Zt82x5vuWZTvHY+kZC98MS7ygrBwezfD6z/0bvtbQem+yOXKSg4EhAoaKxCJSkGhhVmcm8/nq3YwZtgxdGqTEnUVsM9noYAAB7Ff8QcR9g0uLfT69QMlwUVfZV4qaBdhrCKjG9y5ANZ9Dmkd4JX/B7sjZA1NyYAfT4L0LpDeCZ44NnJ2UY0ViBwUBYUW5rlPviM9JZHrTu1OeoofqD2FBFBzl9DGBfDVv+HrybBvW+QXDpTAOfd6O4glp0NKW/jwwch9+wl+6Hm2d+z8hyOPAVz8R+ja/8CxC6KU01iByEFRUGimqi42+80FvclMS+L9pZu59axeoYAQUwsgUpfQpDth/SxvJfDXk70B3T4Xw6rpULyn+nNkdIOz7q58LK1t7X37sY4BaKxApE5o8VozFCnZnM+g3EGK38dnd59Lx/Rk74HaBoWL98K4/tFbAEnpMPhOGDTS2zYy2v4CygUk0qC0eK2FeXnWOpZtLKBjegrPfryK0kDlYF/uID05kQm3D/YCQqAUPnwUZj/j3YYDewYX74X+13mLvT58JHpAwGD0Oi9TaAV9Yxdp0hQUmpiq3UI3n5GDP8HHg5OWEYiUnjTM3uIyenVsDV+95E31LNxZvVCgBN77Nbw/yhsQ7nC0t0VkpLIZ2ZUDQgXN7hFpsuIaFMzsIuAvQALwgnNubJXHfwPcDJQB24CfOufWxbNO9a0u00NH2tXskcnLcUD3dmk8MeJEikoDjH57CSfvns7diW/Q1baz0XXgmbJL2duqB3z6OHz0OzhyCKybGf3FTr8NepwBvc6FpW9rEFekhYjbmIKZJQDfAhcAucBc4Frn3PKwMucAs51z+83sVuBs59zVNT1vUxpTiLaRzL2XHMtpPdvRo32r0P4CNQUP5xz3TljK+K/yqu1qBtAmJZHZ/3N+aHOauZP+yvHz7yPVSkJlyp03rgBAv6vh8qdh3IDI6wWUHE6k2WkMYwqDgFXOudXBCr0GXA6EgoJzbkZY+VnA9XGsT70KlDsenrwswtaUAe6fuBTn4Ngubbjq5GzKAuU8Me3b0Cb0efmFjHprEZsLCvn52Ufxypz1vDJ7PQCX+WZWagE8VjaCyUVDvIBQVgLTH+CURS9CWECAYEBIbQvn3g8n3wg+n/fBHmsLQF1CIi1CPINCFhD+NTQXOLWG8jcB70d6wMxGAiMBunfvXlf1OyxVv9n/dEgPluQWhPYd3rK7iF37SyN+iE8qH8JdFx7NP79Yy6PvejHyMt9M7k6qXO6P07xMpE/NWMWQozqQs/E9/ifwQqgFkG3b+aP/r9xsH8LfnvDSPezdHL3Shflwyk0H7mtQWESqiGdQsAjHIvZVmdn1wEDgrEiPO+eeB54Hr/uoripYVaz9/xMW5DFz/DO8zmt0Td7Oxv0deGzKCKbaGRzTNQOAVsmJXJsyi/vdC6SFfYiP9b+Av9zH7edewi1n9WJzQRGP//FRxvqrl6MUnprhuPn4RO7p8w1s+hv+Ki2AJAtwAish+Uw48nQ48Vp477dRuoUirO5VC0BEwsQzKOQC3cLuZwPV8hCY2fnAvcBZzrniONanRpEGcce8s4Si0gD7SgKc0bsDM77ZyhUDsljw7vM8Ys9X+xDPSPTz6G2PQHk55K+j9OkX8Acqf4inWQkPp70J356Jv6yIbsV7+H3SP0mjernH/H9jWPJ3XLTmY2xV9D+N4eDHEw8cKCrQwLCIHJJ4DjQn4g00nwfk4Q00X+ecWxZWZgDwFnCRc25lLM8br4HmwWM/Ii+/eirp5ERfpf0E2qb5mVx2K9m+7dXKFrg0Mi4cAzOfhMJdMb+2o4ZmVVJrrM8wOHMUvHyldg0TkUPS4APNzrkyM7sdmIo3JfVF59wyM3sEmOecmwQ8DrQG3jQzgPXOucviVaeabMwvjNz/XzaEqwd2wwyG9vCR+8EzZAWqBwSADNsP0++HbqdC3+Fets+KPYDDJafDiJcgrT0kt8b+dWnED3vL6Aa/WgIWDBnnPaiBYRGJq7iuU3DOTQGmVDn2QNjt8+P5+gfjR63mMLqscr/+Y/6/cY3N5DRfX3zfvg9LCgAo9SXhdyXVnmN/amfSbp7ipYf2JUCrDpE/xC95Enqdc+BYTR/2FtaG0MCwiMSZVjQH/dJeCQWECilWyuksxr5dB0cPgw5HQd/h+DcuoGziHSQGDuxFUJaQQtqwR6F9rwNPEI9kbmoBiByS0tJScnNzKSo6zG1kG7mUlBSys7Px+/2HdL4S4gW5hzIi9uuDwUP51Q+rz16kSVmzZg3p6em0b98es8j/25s65xw7duxgz5495OTkVHqswccUGrtAucPwdhTb+91sUp2RYBECZLRNWvSNXaRJKSoqokePHs02IACYGe3bt2fbtmhJLGvX4oJCYUmA3723nFfnrKd1ciIPDmnFebNvJN+1pm1iCb5A2NRPTeMUaVaac0CocLjX2CKCQviitASfUVbuuOXEJAau/ztnfzaNUhJ5qe+zjOwbUJeQiLRozT4oVF2UVlbuuDRxDvd8+xTm87HzuOvZe8od3JLT2ztBQUBEqNsMxwD5+fm88sor/OIXvzio8y6++GJeeeUVMjMzD/m1D4avXl6lAT0+dUWlpHRZbOP3Cc/zNTnYHV/RfsQ4jqwICCIiHPgymZdfiONAhoMJC/IO+Tnz8/N55plnqh0PBKpnPg43ZcqUegsI0AJaClUXpQVIoBQftxb9gk8zu9X+BCLS7Dw8eRnLN+6O+viC9fmhrMUVCksD3P3WYl6dsz7iOX27tuHBS4+L+pyjR4/mu+++o3///vj9flq3bk2XLl1YuHAhy5cvZ/jw4WzYsIGioiJ++ctfMnLkSAB69OjBvHnz2Lt3L8OGDWPIkCF88cUXZGVlMXHiRFJTUw/hLxBds28p3NB6DmP9L5Dt247PwG8BEnCc26pZ7eUjInWoakCo7Xgsxo4dS69evVi4cCGPP/44c+bM4fe//z3Ll3uZkl988UXmz5/PvHnzGDduHDt27Kj2HCtXruS2225j2bJlZGZm8vbbbx9yfaJp9i2Fu/2vk1ZWeVFaspVxt/914OGGqZSINKiavtFD9FxoWZmpvH7L6XVSh0GDBlVaSzBu3DjGjx8PwIYNG1i5ciXt27evdE5OTg79+/cH4OSTT2bt2rV1Updwzb6lkFYYeX+BaMdFREYN7UOqv/L+46n+BEYN7VNnr9GqVavQ7Y8//pgPPviAL7/8kkWLFjFgwICIK6+Tk5NDtxMSEigrK6uz+lRo9i0FMrJj31tARARCs4zqcvZReno6e/bsifhYQUEBbdu2JS0tjW+++YZZs2Yd8uscruYfFA5my0kRkaDhA7IOKwhU1b59ewYPHszxxx9PamoqnTp1Cj120UUX8dxzz9GvXz/69OnDaaedVmeve7BaRu4j5SkSafG+/vprjj322IauRr2IdK3KfRROeYpERGLS7AeaRUQkdgoKIiISoqAgIiIhCgoiIhKioCAiIiEKCiIikSx+A/50PDyU6f1e/MZhPV20LKmx+POf/8z+/fsP6/VjpaAgIlLV4je8Ra8FGwDn/Z5852EFhqYSFFrGOgURkXDvj4bNS6I/njsXwrfmBS8rwsTbYf6/Ip/T+QQYNjbqU4anzr7gggs44ogjeOONNyguLuaKK67g4YcfZt++fYwYMYLc3FwCgQD3338/W7ZsYePGjZxzzjl06NCBGTNmHMIFx05BQUSkqqoBobbjMRg7dixLly5l4cKFTJs2jbfeeos5c+bgnOOyyy7j008/Zdu2bXTt2pX33nsP8HIiZWRk8OSTTzJjxgw6dOhwyK8fKwUFEWl5avhGD3hjCBETaXaDG9877JefNm0a06ZNY8CAAQDs3buXlStXcsYZZ3DXXXdxzz338P3vf58zzjjjsF/rYCkoiIhUFedEms45xowZwy233FLtsfnz5zNlyhTGjBnDhRdeyAMP1G/yTg00i4hU1W8EXDrOaxlg3u9Lxx1WDrXw1NlDhw7lxRdfZO/evQDk5eWxdetWNm7cSFpaGtdffz133XUXX331VbVz400tBRGRSOo4kWZ46uxhw4Zx3XXXcfrp3i5urVu35uWXX2bVqlWMGjUKn8+H3+/n2WefBWDkyJEMGzaMLl26xH2guWWkzhaRFk+ps2NLna3uIxERCVFQEBGREAUFEWkxmlp3+aE43GtUUBCRFiElJYUdO3Y068DgnGPHjh2kpKQc8nNo9pGItAjZ2dnk5uaybdu2hq5KXKWkpJCdnX3I5ysoiEiL4Pf7ycnJaehqNHpx7T4ys4vMbIWZrTKz0REeTzaz14OPzzazHvGsj4iI1CxuQcHMEoCngWFAX+BaM+tbpdhNwC7n3FHAn4D/jVd9RESkdvFsKQwCVjnnVjvnSoDXgMurlLkcqMhD+xZwnplZHOskIiI1iOeYQhYQnmYwFzg1WhnnXJmZFQDtge3hhcxsJDAyeHevma04xDp1qPrcTZiupfFpLtcBupbG6nCu5chYCsUzKET6xl91LlgsZXDOPQ88f9gVMpsXyzLvpkDX0vg0l+sAXUtjVR/XEs/uo1ygW9j9bGBjtDJmlghkADvjWCcREalBPIPCXKC3meWYWRJwDTCpSplJwA3B21cBH7nmvLJERKSRi1v3UXCM4HZgKpAAvOicW2ZmjwDznHOTgL8DL5nZKrwWwjXxqk/QYXdBNSK6lsanuVwH6Foaq7hfS5NLnS0iIvGj3EciIhKioCAiIiEtJijUlnKjsTOztWa2xMwWmtm84LF2ZjbdzFYGf7dt6HpWZWYvmtlWM1sadixivc0zLvgeLTazkxqu5tVFuZaHzCwv+L4sNLOLwx4bE7yWFWY2tGFqHZmZdTOzGWb2tZktM7NfBo83qfemhutocu+LmaWY2RwzWxS8loeDx3OCaYBWBtMCJQWPxydNkHOu2f/gDXR/B/QEkoBFQN+GrtdBXsNaoEOVY48Bo4O3RwP/29D1jFDvM4GTgKW11Ru4GHgfb/3KacDshq5/DNfyEHBXhLJ9g//OkoGc4L+/hIa+hrD6dQFOCt5OB74N1rlJvTc1XEeTe1+Cf9vWwdt+YHbwb/0GcE3w+HPArcHbvwCeC96+Bni9LurRUloKsaTcaIrC04T8CxjegHWJyDn3KdXXnkSr9+XAv51nFpBpZl3qp6a1i3It0VwOvOacK3bOrQFW4f07bBScc5ucc18Fb+8BvsbLMNCk3psariOaRvu+BP+2e4N3/cEfB5yLlwYIqr8ndZ4mqKUEhUgpN2r6h9MYOWCamc0Ppv0A6OSc2wTefw7giAar3cGJVu+m+j7dHuxSeTGsC6/JXEuw22EA3jfTJvveVLkOaILvi5klmNlCYCswHa8lk++cKwsWCa9vpTRBQEWaoMPSUoJCTOk0GrnBzrmT8LLO3mZmZzZ0heKgKb5PzwK9gP7AJuCJ4PEmcS1m1hp4G/iVc253TUUjHGs01xPhOprk++KcCzjn+uNlgBgEHBupWPB3XK6lpQSFWFJuNGrOuY3B31uB8Xj/YLZUNOGDv7c2XA0PSrR6N7n3yTm3JfgfuRz4Gwe6Ihr9tZiZH++D9D/OuXeCh5vcexPpOpry+wLgnMsHPsYbU8gMpgGCyvWNS5qglhIUYkm50WiZWSszS6+4DVwILKVympAbgIkNU8ODFq3ek4AfB2e6nAYUVHRlNFZV+tWvwHtfwLuWa4IzRHKA3sCc+q5fNMG+578DXzvnngx7qEm9N9Guoym+L2bW0cwyg7dTgfPxxkhm4KUBgurvSd2nCWroEff6+sGbPfEtXh/dvQ1dn4Ose0+8GROLgGUV9cfrP/wQWBn83a6h6xqh7q/iNd9L8b7Z3BSt3njN4aeD79ESYGBD1z+Ga3kpWNfFwf+kXcLK3xu8lhXAsIauf5VrGYLX1bAYWBj8ubipvTc1XEeTe1+AfsCCYJ2XAg8Ej/fEC1yrgDeB5ODxlOD9VcHHe9ZFPZTmQkREQlpK95GIiMRAQUFEREIUFEREJERBQUREQhQUREQkREFBJM7M7Gwze7eh6yESCwUFEREJUVAQCTKz64P57Bea2V+Dycn2mtkTZvaVmX1oZh2DZfub2axgwrXxYfsOHGVmHwRz4n9lZr2CT9/azN4ys2/M7D8V2SzNbKyZLQ8+zx8b6NJFQhQURAAzOxa4Gi/xYH8gAPwQaAV85bxkhJ8ADwZP+Tdwj3OuH97K2Yrj/wGeds6dCHwPbwU0eNk7f4WXz78nMNjM2uGlYDgu+Dy/i+9VitROQUHEcx5wMjA3mLr4PLwP73Lg9WCZl4EhZpYBZDrnPgke/xdwZjA/VZZzbjyAc67IObc/WGaOcy7XeQnaFgI9gN1AEfCCmV0JVJQVaTAKCiIeA/7lnOsf/OnjnHsoQrma8sLUtMFJcdjtAJDovBz4g/AyfA4H/nuQdRapcwoKIp4PgavM7AgI7VV8JN7/kYoMldcBM51zBcAuMzsjePxHwCfOy+Ofa2bDg8+RbGZp0V4wuAdAhnNuCl7XUv94XJjIwUisvYhI8+ecW25m9+HtbufDy4R6G7APOM7M5uPtbHV18JQbgOeCH/qrgRuDx38E/NXMHgk+x/+r4WXTgYlmloLXyvh1HV+WyEFTllSRGpjZXudc64auh0h9UfeRiIiEqKUgIiIhaimIiEiIgoKIiIQoKIiISIiCgoiIhCgoiIhIyP8Hp3xZYsEyY/oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='o', label='test', markevery=10)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 활성화 함수 + weight initialization 다르게 적용해보기!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.random.uniform(1000, 100) #1000개의 input data\n",
    "node_num = 100 # 각 은닉층의 노드 개수\n",
    "hidden_layer_size = 5 # 히든 레이어 5개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src ='시그모이드.png'  > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "activations = {}\n",
    "x = input_data\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    # 초깃값을 다양하게 바꿔가며 실험해보자！\n",
    "    \n",
    "    w = np.random.randn(node_num, node_num) * 1\n",
    "    #w = np.random.randn(node_num, node_num) * 0.01\n",
    "    #w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
    "    #w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
    "    \n",
    "    a = np.dot(x, w)\n",
    "    \n",
    "    # 활성화 함수를 다르게 해보면서 실험해보기\n",
    "    #z = sigmoid(a)\n",
    "    z = sigmoid(a)\n",
    "    #z = tanh(a)\n",
    "    \n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + '-layer')\n",
    "    if i != 0:\n",
    "        plt.yticks([], [])\n",
    "        # plt.xlim(0.1, 1)\n",
    "        # plt.ylim(0, 7000)\n",
    "    plt.hist(a.flatten(), 30, range=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "x = input_data\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    # 초깃값을 다양하게 바꿔가며 실험해보자！\n",
    "    \n",
    "    #w = np.random.randn(node_num, node_num) * 1\n",
    "    w = np.random.randn(node_num, node_num) * 0.01\n",
    "    #w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
    "    #w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
    "    \n",
    "    a = np.dot(x, w)\n",
    "    \n",
    "    # 활성화 함수를 다르게 해보면서 실험해보기\n",
    "    z = sigmoid(a)\n",
    "    #z = ReLU(a)\n",
    "    #z = tanh(a)\n",
    "    \n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + '-layer')\n",
    "    if i != 0:\n",
    "        plt.yticks([], [])\n",
    "        # plt.xlim(0.1, 1)\n",
    "        # plt.ylim(0, 7000)\n",
    "    plt.hist(a.flatten(), 30, range=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "x = input_data\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    # 초깃값을 다양하게 바꿔가며 실험해보자！\n",
    "    \n",
    "    #w = np.random.randn(node_num, node_num) * 1\n",
    "    #w = np.random.randn(node_num, node_num) * 0.01\n",
    "    w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
    "    #w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
    "    \n",
    "    a = np.dot(x, w)\n",
    "    \n",
    "    # 활성화 함수를 다르게 해보면서 실험해보기\n",
    "    z = sigmoid(a)\n",
    "    #z = ReLU(a)\n",
    "    #z = tanh(a)\n",
    "    \n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + '-layer')\n",
    "    if i != 0:\n",
    "        plt.yticks([], [])\n",
    "        # plt.xlim(0.1, 1)\n",
    "        # plt.ylim(0, 7000)\n",
    "    plt.hist(a.flatten(), 30, range=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "x = input_data\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    # 초깃값을 다양하게 바꿔가며 실험해보자！\n",
    "    \n",
    "    #w = np.random.randn(node_num, node_num) * 1\n",
    "    #w = np.random.randn(node_num, node_num) * 0.01\n",
    "    w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
    "    #w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
    "    \n",
    "    a = np.dot(x, w)\n",
    "    \n",
    "    # 활성화 함수를 다르게 해보면서 실험해보기\n",
    "    #z = sigmoid(a)\n",
    "    #z = ReLU(a)\n",
    "    z = tanh(a)\n",
    "    \n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + '-layer')\n",
    "    if i != 0:\n",
    "        plt.yticks([], [])\n",
    "        # plt.xlim(0.1, 1)\n",
    "        # plt.ylim(0, 7000)\n",
    "    plt.hist(a.flatten(), 30, range=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "x = input_data\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    # 초깃값을 다양하게 바꿔가며 실험해보자！\n",
    "    \n",
    "    #w = np.random.randn(node_num, node_num) * 1\n",
    "    #w = np.random.randn(node_num, node_num) * 0.01\n",
    "    #w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
    "    w = np.random.randn(node_num, node_num) * np.sqrt(2/ node_num)\n",
    "    \n",
    "    a = np.dot(x, w)\n",
    "    \n",
    "    # 활성화 함수를 다르게 해보면서 실험해보기\n",
    "    #z = sigmoid(a)\n",
    "    z = ReLU(a)\n",
    "    #z = tanh(a)\n",
    "    \n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i, a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + '-layer')\n",
    "    if i != 0:\n",
    "        plt.yticks([], [])\n",
    "        # plt.xlim(0.1, 1)\n",
    "        # plt.ylim(0, 7000)\n",
    "    plt.hist(a.flatten(), 30, range=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.util import smooth_curve\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 128\n",
    "max_iterations = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_init_types = {\n",
    "    'std=0.01': 0.01,\n",
    "    'Xavier': 'sigmoid',\n",
    "    'He': 'relu',\n",
    "}\n",
    "optimizer = SGD(lr=0.01)\n",
    "\n",
    "networks = {}\n",
    "train_loss = {}\n",
    "for key, weight_type in weight_init_types.items():\n",
    "    networks[key] = MultiLayerNet(\n",
    "                        input_size=784,\n",
    "                        hidden_size_list=[100, 100, 100, 100],\n",
    "                        output_size=10,\n",
    "                        weight_init_std=weight_type,\n",
    "    )\n",
    "    train_loss[key] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== iter: 0 =========\n",
      "Xavier:2.2954103751575854\n",
      "std=0.01:2.3025523093938287\n",
      "He:2.284520186290723\n",
      "========== iter: 100 =========\n",
      "Xavier:2.2303209439793426\n",
      "std=0.01:2.3020537844016475\n",
      "He:1.345364462954699\n",
      "========== iter: 200 =========\n",
      "Xavier:2.101103067838998\n",
      "std=0.01:2.3026426848798054\n",
      "He:0.6951853311051747\n",
      "========== iter: 300 =========\n",
      "Xavier:1.8168758669199883\n",
      "std=0.01:2.299922253621169\n",
      "He:0.5640056025948628\n",
      "========== iter: 400 =========\n",
      "Xavier:1.3736411788094667\n",
      "std=0.01:2.3015235077782408\n",
      "He:0.6038383896481493\n",
      "========== iter: 500 =========\n",
      "Xavier:0.7839813075486677\n",
      "std=0.01:2.299177668138453\n",
      "He:0.3707355374582248\n",
      "========== iter: 600 =========\n",
      "Xavier:0.6888121263147219\n",
      "std=0.01:2.3043082430554516\n",
      "He:0.33288903792613445\n",
      "========== iter: 700 =========\n",
      "Xavier:0.6053179899313239\n",
      "std=0.01:2.297802490088687\n",
      "He:0.3853106506309364\n",
      "========== iter: 800 =========\n",
      "Xavier:0.4314219302459198\n",
      "std=0.01:2.3023299264159904\n",
      "He:0.21400270498139104\n",
      "========== iter: 900 =========\n",
      "Xavier:0.4583522532214262\n",
      "std=0.01:2.302769131149672\n",
      "He:0.3534920149568282\n",
      "========== iter: 1000 =========\n",
      "Xavier:0.4085010693369197\n",
      "std=0.01:2.3007141172941132\n",
      "He:0.28256614902560073\n",
      "========== iter: 1100 =========\n",
      "Xavier:0.4155527370500871\n",
      "std=0.01:2.2990208736632862\n",
      "He:0.3058510915979629\n",
      "========== iter: 1200 =========\n",
      "Xavier:0.2287335832213081\n",
      "std=0.01:2.295522550477191\n",
      "He:0.1704488403645082\n",
      "========== iter: 1300 =========\n",
      "Xavier:0.27344712711465824\n",
      "std=0.01:2.3038440705751153\n",
      "He:0.20136586015300695\n",
      "========== iter: 1400 =========\n",
      "Xavier:0.308011181885425\n",
      "std=0.01:2.3034656526667954\n",
      "He:0.16801507200706375\n",
      "========== iter: 1500 =========\n",
      "Xavier:0.3085572672693737\n",
      "std=0.01:2.296725348896771\n",
      "He:0.24745434583052295\n",
      "========== iter: 1600 =========\n",
      "Xavier:0.3821299843192701\n",
      "std=0.01:2.300510397776541\n",
      "He:0.24357371174664363\n",
      "========== iter: 1700 =========\n",
      "Xavier:0.2177145488641633\n",
      "std=0.01:2.2967673933270927\n",
      "He:0.14521205225716102\n",
      "========== iter: 1800 =========\n",
      "Xavier:0.2838977787399063\n",
      "std=0.01:2.300458379511916\n",
      "He:0.21681490600606088\n",
      "========== iter: 1900 =========\n",
      "Xavier:0.37156726740129487\n",
      "std=0.01:2.29934263206769\n",
      "He:0.27005345339892234\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_iterations):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    for key in weight_init_types.keys():\n",
    "        grads = networks[key].gradient(x_batch, t_batch)\n",
    "        optimizer.update(networks[key].params, grads)\n",
    "        \n",
    "        loss = networks[key].loss(x_batch, t_batch)\n",
    "        train_loss[key].append(loss)\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print('========== iter: %d =========' % i)\n",
    "        for key in weight_init_types.keys():\n",
    "            loss = networks[key].loss(x_batch, t_batch)\n",
    "            print(key + ':' + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {'std=0.01': 'o', 'Xavier': 's', 'He': 'D'}\n",
    "x = np.arange(max_iterations)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for key in weight_init_types.keys():\n",
    "    plt.plot(\n",
    "        x,\n",
    "        smooth_curve(train_loss[key]),\n",
    "        marker=markers[key],\n",
    "        markevery=100,\n",
    "        label=key,\n",
    "    )\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정리!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴럴넷 아키텍쳐 구성할시 주의해야할 점!\n",
    "\n",
    "## 신경망 구성 단계\n",
    "\n",
    "* 최대한 각 layer에 속한 유닛이 다양한 값을 갖게 해야 한다! \n",
    "> 기존의 sigmoid로 활성화를 주면 은닉층이 깊어질 수록 유닛 값의 분포가 점점 동일해짐\n",
    "> weight 초기값을 동일하게 0으로 주는건 절대안됨! 따라서 weight 초기값과 batch normalization이 중요!\n",
    "> batch normalization은 affine 계층과 활성화 계층의 중간단계에 구성 해야함.\n",
    "\n",
    "## 오버피팅 문제\n",
    "\n",
    "* 신경망의 깊이가 깊어지고 유닛의 수가 많아 질수록 오버피팅 될 가능성이 높음.\n",
    "\n",
    "> dropout으로 데이터가 mini_batch로 들어갈 때마다 유닛들을 무작위로 죽여 오버피팅 방지! \n",
    "\n",
    "## 이후 역전파 단계에서 최적해 찾는 속도 문제\n",
    "\n",
    "* 전체 데이터를 한번 학습할때마다 weight를 갱신하게 되면 전체 데이터를 고려할 수 있으나 학습속도가 현저하게 떨어짐. learning rate를 크게 주자니 코스트가 발산할 우려가 생김\n",
    "\n",
    "> 그로 인해 mini batch를 주어 데이터의 일부만으로 weight를 업데이트 하는 최적화 알고리즘이 개발됨 - SGD \n",
    "\n",
    "> SGD 알고리즘이 갖고 있는 문제점을 해결하기 위해 다양한 알고리즘이 나오게 됨 - Mometum, Adam "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
