{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 최적화 구하기\n",
    "> 최적화의 핵심은 하이퍼파라미터의 '최적값'이 존재하는 범위를 조금씩 줄여간다는 것.<br>\n",
    "대략적인 범위를 설정하고 그 범위에서 무작위로 값을 샘플링 후 그 값으로 정확도를 평가한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋을 사용하여 학습진도 차이를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.util import shuffle_dataset\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 불러와서 테스트용으로 데이터 양을 줄인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:500]\n",
    "t_train = t_train[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST는 검증 데이터가 따로 없다. 훈련 데이터에서 20% 정도를 분리해서 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rate = 0.20\n",
    "validation_num = int(x_train.shape[0] * validation_rate)\n",
    "x_train, t_train = shuffle_dataset(x_train, t_train)\n",
    "x_val = x_train[:validation_num]\n",
    "t_val = t_train[:validation_num]\n",
    "x_train = x_train[validation_num:]\n",
    "t_train = t_train[validation_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __train(lr, weight_decay, epochs=50):\n",
    "    network = MultiLayerNet(input_size=784,\n",
    "                            hidden_size_list=[100 for _ in range(6)],\n",
    "                            output_size=10,\n",
    "                            weight_decay_lambda=weight_decay,\n",
    "    )\n",
    "    trainer = Trainer(network, x_train, t_train, x_val, t_val,\n",
    "                      epochs=epochs, mini_batch_size=100,\n",
    "                      optimizer='sgd', optimizer_param={'lr': lr}, verbose=True,\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer.test_acc_list, trainer.train_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST에서 최적화를 수행한다\n",
    "* 0단계 <br>\n",
    "하이퍼파라미터 값의 범위를 설정한다.<br>\n",
    "* 1단계<br>\n",
    "설정된 범위에서 하이퍼파라미터 값을 무작위로 추출한다.<br>\n",
    "* 2단계<br>\n",
    "1단계에서 샘플링한 값을 사용하여 학습하고, 검증 데이터로 평가한다.(단, 에폭은 작게 설정한다.)<br>\n",
    "* 3단계<br>\n",
    "1~2단계를 특정 횟수(100회 등) 반복하여 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힌다.<br>\n",
    ">여기서는 가중치 감소 계수를 10^-8 ~ 10^-4\n",
    " 학습률을 10^-6 ~ 10^-2 범위부터 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.441405167007871\n",
      "=== epoch:1, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.34039124991242\n",
      "train loss:2.3645331720427736\n",
      "train loss:2.3303205118034276\n",
      "train loss:2.3957628546069816\n",
      "=== epoch:2, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.331848487822984\n",
      "train loss:2.3672437440095258\n",
      "train loss:2.3497970512441984\n",
      "train loss:2.4331754320529386\n",
      "=== epoch:3, train acc:0.1125, test acc:0.12 ===\n",
      "train loss:2.389852994353768\n",
      "train loss:2.361001341031925\n",
      "train loss:2.331481273325349\n",
      "train loss:2.3585746154666904\n",
      "=== epoch:4, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.3656132443220956\n",
      "train loss:2.3504051956676335\n",
      "train loss:2.364523241271452\n",
      "train loss:2.384411679577989\n",
      "=== epoch:5, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.3786803202962328\n",
      "train loss:2.3004162324568043\n",
      "train loss:2.33414063054572\n",
      "train loss:2.3599064859380317\n",
      "=== epoch:6, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.321370001550645\n",
      "train loss:2.3283492787137874\n",
      "train loss:2.331806340287281\n",
      "train loss:2.341043976216104\n",
      "=== epoch:7, train acc:0.115, test acc:0.13 ===\n",
      "train loss:2.3752843999711137\n",
      "train loss:2.338671961636644\n",
      "train loss:2.355040681802969\n",
      "train loss:2.369235042685761\n",
      "=== epoch:8, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.3518062585481605\n",
      "train loss:2.3518570573739477\n",
      "train loss:2.3899133137553576\n",
      "train loss:2.340340889689934\n",
      "=== epoch:9, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.3154007267642656\n",
      "train loss:2.339565219595315\n",
      "train loss:2.3500540707259074\n",
      "train loss:2.339315221771049\n",
      "=== epoch:10, train acc:0.1175, test acc:0.13 ===\n",
      "train loss:2.2997285668976444\n",
      "train loss:2.316834445354487\n",
      "train loss:2.310876017243227\n",
      "train loss:2.3439646489045503\n",
      "=== epoch:11, train acc:0.12, test acc:0.14 ===\n",
      "train loss:2.304084933489631\n",
      "train loss:2.297945541852088\n",
      "train loss:2.3183862527127856\n",
      "train loss:2.2848238159270964\n",
      "=== epoch:12, train acc:0.12, test acc:0.14 ===\n",
      "train loss:2.323095949939836\n",
      "train loss:2.293116459083384\n",
      "train loss:2.324504036977736\n",
      "train loss:2.304570077945257\n",
      "=== epoch:13, train acc:0.12, test acc:0.15 ===\n",
      "train loss:2.3245288026064506\n",
      "train loss:2.3056659046580226\n",
      "train loss:2.3537232003571256\n",
      "train loss:2.2676460954898747\n",
      "=== epoch:14, train acc:0.12, test acc:0.15 ===\n",
      "train loss:2.3153791909887764\n",
      "train loss:2.3250827984233897\n",
      "train loss:2.3643442757304247\n",
      "train loss:2.2919856049356504\n",
      "=== epoch:15, train acc:0.125, test acc:0.15 ===\n",
      "train loss:2.3114434448049965\n",
      "train loss:2.3013437991336625\n",
      "train loss:2.33141031683415\n",
      "train loss:2.3362353036881625\n",
      "=== epoch:16, train acc:0.125, test acc:0.15 ===\n",
      "train loss:2.3106921539901597\n",
      "train loss:2.3065925674154064\n",
      "train loss:2.2962139839408504\n",
      "train loss:2.3047244160106373\n",
      "=== epoch:17, train acc:0.125, test acc:0.15 ===\n",
      "train loss:2.3244114901764252\n",
      "train loss:2.3155558397685168\n",
      "train loss:2.2934689417427925\n",
      "train loss:2.3631851025065034\n",
      "=== epoch:18, train acc:0.125, test acc:0.15 ===\n",
      "train loss:2.349822319558215\n",
      "train loss:2.2834830234737438\n",
      "train loss:2.258710187637437\n",
      "train loss:2.3768097292886456\n",
      "=== epoch:19, train acc:0.125, test acc:0.15 ===\n",
      "train loss:2.353495471573716\n",
      "train loss:2.3382216605154102\n",
      "train loss:2.2857892894997858\n",
      "train loss:2.330717341808944\n",
      "=== epoch:20, train acc:0.1275, test acc:0.15 ===\n",
      "train loss:2.3274534134264036\n",
      "train loss:2.322549686479037\n",
      "train loss:2.3275114951199742\n",
      "train loss:2.327102878564157\n",
      "=== epoch:21, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.292481367896501\n",
      "train loss:2.305830652030771\n",
      "train loss:2.3328094427906514\n",
      "train loss:2.3012386716750846\n",
      "=== epoch:22, train acc:0.1325, test acc:0.16 ===\n",
      "train loss:2.3071067702283985\n",
      "train loss:2.2452780478010665\n",
      "train loss:2.306867155159186\n",
      "train loss:2.3331009662101647\n",
      "=== epoch:23, train acc:0.1325, test acc:0.16 ===\n",
      "train loss:2.317479508573335\n",
      "train loss:2.300079922340849\n",
      "train loss:2.258302537485904\n",
      "train loss:2.3481653963702387\n",
      "=== epoch:24, train acc:0.1325, test acc:0.16 ===\n",
      "train loss:2.311973009151452\n",
      "train loss:2.354028086193507\n",
      "train loss:2.260292738141696\n",
      "train loss:2.3054836522508593\n",
      "=== epoch:25, train acc:0.135, test acc:0.17 ===\n",
      "train loss:2.335243398663716\n",
      "train loss:2.22594321803793\n",
      "train loss:2.279032717170272\n",
      "train loss:2.31947628658969\n",
      "=== epoch:26, train acc:0.135, test acc:0.17 ===\n",
      "train loss:2.298372516881449\n",
      "train loss:2.3013950128622946\n",
      "train loss:2.285562937088815\n",
      "train loss:2.2896559825290757\n",
      "=== epoch:27, train acc:0.1325, test acc:0.17 ===\n",
      "train loss:2.3002531874768546\n",
      "train loss:2.302677203366348\n",
      "train loss:2.2815695120248622\n",
      "train loss:2.3172180662083766\n",
      "=== epoch:28, train acc:0.13, test acc:0.17 ===\n",
      "train loss:2.295444232319151\n",
      "train loss:2.2874710002090164\n",
      "train loss:2.286824077537827\n",
      "train loss:2.301676939381329\n",
      "=== epoch:29, train acc:0.135, test acc:0.17 ===\n",
      "train loss:2.316387501162639\n",
      "train loss:2.2477390072983465\n",
      "train loss:2.288259461054252\n",
      "train loss:2.2778246428450575\n",
      "=== epoch:30, train acc:0.14, test acc:0.17 ===\n",
      "train loss:2.282762298146727\n",
      "train loss:2.288410127951226\n",
      "train loss:2.314536943165242\n",
      "train loss:2.278352951434402\n",
      "=== epoch:31, train acc:0.145, test acc:0.17 ===\n",
      "train loss:2.3002656369001273\n",
      "train loss:2.308917939999226\n",
      "train loss:2.3018248962535393\n",
      "train loss:2.2772050603494525\n",
      "=== epoch:32, train acc:0.15, test acc:0.17 ===\n",
      "train loss:2.2570630439278556\n",
      "train loss:2.309657791164971\n",
      "train loss:2.316412842015793\n",
      "train loss:2.2827911167146313\n",
      "=== epoch:33, train acc:0.1525, test acc:0.17 ===\n",
      "train loss:2.2681601900996595\n",
      "train loss:2.2897234397567474\n",
      "train loss:2.2895450117249094\n",
      "train loss:2.27740846249107\n",
      "=== epoch:34, train acc:0.1525, test acc:0.17 ===\n",
      "train loss:2.299964840957146\n",
      "train loss:2.280025453299538\n",
      "train loss:2.316252118542295\n",
      "train loss:2.2718077802572383\n",
      "=== epoch:35, train acc:0.1525, test acc:0.17 ===\n",
      "train loss:2.2820195068600118\n",
      "train loss:2.2656342544523316\n",
      "train loss:2.271561201804781\n",
      "train loss:2.2947771388032097\n",
      "=== epoch:36, train acc:0.15, test acc:0.17 ===\n",
      "train loss:2.240656194221779\n",
      "train loss:2.235146504887435\n",
      "train loss:2.277635348400831\n",
      "train loss:2.326468570742147\n",
      "=== epoch:37, train acc:0.155, test acc:0.16 ===\n",
      "train loss:2.3182679572608946\n",
      "train loss:2.2890534875640354\n",
      "train loss:2.2301496719201723\n",
      "train loss:2.2402708007856247\n",
      "=== epoch:38, train acc:0.155, test acc:0.16 ===\n",
      "train loss:2.2981966627661703\n",
      "train loss:2.3137208759007004\n",
      "train loss:2.2809775417330704\n",
      "train loss:2.251754286856466\n",
      "=== epoch:39, train acc:0.155, test acc:0.17 ===\n",
      "train loss:2.2389881770961493\n",
      "train loss:2.2528117832356997\n",
      "train loss:2.283711700052904\n",
      "train loss:2.261967487786484\n",
      "=== epoch:40, train acc:0.155, test acc:0.17 ===\n",
      "train loss:2.2450734027480634\n",
      "train loss:2.2695737622430787\n",
      "train loss:2.272430216812087\n",
      "train loss:2.259128661611564\n",
      "=== epoch:41, train acc:0.155, test acc:0.19 ===\n",
      "train loss:2.250167391007789\n",
      "train loss:2.2678472048090454\n",
      "train loss:2.2677378825467165\n",
      "train loss:2.2495934484689784\n",
      "=== epoch:42, train acc:0.16, test acc:0.19 ===\n",
      "train loss:2.2858058083842248\n",
      "train loss:2.2634007849024216\n",
      "train loss:2.3028838131800984\n",
      "train loss:2.270262880893632\n",
      "=== epoch:43, train acc:0.16, test acc:0.19 ===\n",
      "train loss:2.2623604624970954\n",
      "train loss:2.2501658986785045\n",
      "train loss:2.2806771998694275\n",
      "train loss:2.2468212215583017\n",
      "=== epoch:44, train acc:0.16, test acc:0.19 ===\n",
      "train loss:2.2691978434533606\n",
      "train loss:2.2510491176789653\n",
      "train loss:2.234467389223005\n",
      "train loss:2.2530634303031576\n",
      "=== epoch:45, train acc:0.1625, test acc:0.19 ===\n",
      "train loss:2.245570951131995\n",
      "train loss:2.300161056496843\n",
      "train loss:2.284440883506454\n",
      "train loss:2.2571988299496906\n",
      "=== epoch:46, train acc:0.1675, test acc:0.2 ===\n",
      "train loss:2.272518805004715\n",
      "train loss:2.2802950052945734\n",
      "train loss:2.27924594548662\n",
      "train loss:2.2537448305250147\n",
      "=== epoch:47, train acc:0.1675, test acc:0.2 ===\n",
      "train loss:2.240022617702856\n",
      "train loss:2.2875977876313702\n",
      "train loss:2.2557283503425283\n",
      "train loss:2.2448332873672228\n",
      "=== epoch:48, train acc:0.1675, test acc:0.2 ===\n",
      "train loss:2.2239484346969975\n",
      "train loss:2.2487203476687885\n",
      "train loss:2.2832494780944472\n",
      "train loss:2.2746944864561556\n",
      "=== epoch:49, train acc:0.17, test acc:0.2 ===\n",
      "train loss:2.247296890706703\n",
      "train loss:2.2791300602959934\n",
      "train loss:2.283183037693125\n",
      "train loss:2.2485510299972717\n",
      "=== epoch:50, train acc:0.17, test acc:0.2 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.277080249433984\n",
      "train loss:2.2542420879090828\n",
      "train loss:2.231222122412932\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.2\n",
      "val_acc: 0.2000 | lr: 0.0008, weight_decay: 0.0000\n",
      "train loss:2.5392308003295865\n",
      "=== epoch:1, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.4121209685267893\n",
      "train loss:2.382163643844161\n",
      "train loss:2.525737733580568\n",
      "train loss:2.4394648007694717\n",
      "=== epoch:2, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.497268255771305\n",
      "train loss:2.3323879973561024\n",
      "train loss:2.409925714742341\n",
      "train loss:2.3944397400738207\n",
      "=== epoch:3, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.4853254145829635\n",
      "train loss:2.4871554633885995\n",
      "train loss:2.435315201326443\n",
      "train loss:2.384260338701149\n",
      "=== epoch:4, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.344076297431933\n",
      "train loss:2.3199997307156552\n",
      "train loss:2.424022066938594\n",
      "train loss:2.3558644294084257\n",
      "=== epoch:5, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.4027126773815075\n",
      "train loss:2.4452813334512618\n",
      "train loss:2.4176418313795742\n",
      "train loss:2.2695881394087203\n",
      "=== epoch:6, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.3539442562020083\n",
      "train loss:2.3111071227944953\n",
      "train loss:2.3906411955414226\n",
      "train loss:2.500132611091089\n",
      "=== epoch:7, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.292145129715706\n",
      "train loss:2.4228548701356463\n",
      "train loss:2.2978518641442887\n",
      "train loss:2.3700672079162013\n",
      "=== epoch:8, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.319187909476183\n",
      "train loss:2.4541617163492098\n",
      "train loss:2.314664688542572\n",
      "train loss:2.3812309750964866\n",
      "=== epoch:9, train acc:0.1, test acc:0.08 ===\n",
      "train loss:2.3883217370791794\n",
      "train loss:2.348660595206912\n",
      "train loss:2.4004299823854454\n",
      "train loss:2.3480261457251883\n",
      "=== epoch:10, train acc:0.105, test acc:0.08 ===\n",
      "train loss:2.312736829948536\n",
      "train loss:2.2967270645788376\n",
      "train loss:2.367770613694159\n",
      "train loss:2.4032569928450926\n",
      "=== epoch:11, train acc:0.1075, test acc:0.08 ===\n",
      "train loss:2.3754623429647324\n",
      "train loss:2.3496582334181206\n",
      "train loss:2.442135079426466\n",
      "train loss:2.4021905186884656\n",
      "=== epoch:12, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.3460131334029155\n",
      "train loss:2.3699578598922457\n",
      "train loss:2.2291560322811725\n",
      "train loss:2.2768424880050775\n",
      "=== epoch:13, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.419039493754668\n",
      "train loss:2.299838519842642\n",
      "train loss:2.392591883834552\n",
      "train loss:2.3717788433426734\n",
      "=== epoch:14, train acc:0.1075, test acc:0.09 ===\n",
      "train loss:2.377672373845396\n",
      "train loss:2.2048747858297153\n",
      "train loss:2.3801515756068365\n",
      "train loss:2.3015294341550185\n",
      "=== epoch:15, train acc:0.11, test acc:0.09 ===\n",
      "train loss:2.297607135578599\n",
      "train loss:2.2986725762651394\n",
      "train loss:2.388051437760166\n",
      "train loss:2.3196565680251044\n",
      "=== epoch:16, train acc:0.11, test acc:0.09 ===\n",
      "train loss:2.3486601877606827\n",
      "train loss:2.3199539081060916\n",
      "train loss:2.2914229732536087\n",
      "train loss:2.3911837726384406\n",
      "=== epoch:17, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.3205868477270633\n",
      "train loss:2.299117750635167\n",
      "train loss:2.362724706634197\n",
      "train loss:2.252448609146801\n",
      "=== epoch:18, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3311785690578697\n",
      "train loss:2.416709189011328\n",
      "train loss:2.3264064685774635\n",
      "train loss:2.3550196429113597\n",
      "=== epoch:19, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.270785433737006\n",
      "train loss:2.3510299576025226\n",
      "train loss:2.158191208755119\n",
      "train loss:2.2680722464731304\n",
      "=== epoch:20, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3258453321809323\n",
      "train loss:2.356531070868751\n",
      "train loss:2.3088792300560703\n",
      "train loss:2.304137168999435\n",
      "=== epoch:21, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.4194435472291675\n",
      "train loss:2.2544757050478865\n",
      "train loss:2.3050588778230643\n",
      "train loss:2.2760600007478797\n",
      "=== epoch:22, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.3157903887037476\n",
      "train loss:2.2719824573399436\n",
      "train loss:2.248362625410779\n",
      "train loss:2.3533698033624577\n",
      "=== epoch:23, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.3369415689831734\n",
      "train loss:2.282029648567132\n",
      "train loss:2.26155155613906\n",
      "train loss:2.3257732148108006\n",
      "=== epoch:24, train acc:0.125, test acc:0.11 ===\n",
      "train loss:2.3178128773082194\n",
      "train loss:2.277705996602445\n",
      "train loss:2.2896010825595647\n",
      "train loss:2.348528210088049\n",
      "=== epoch:25, train acc:0.13, test acc:0.11 ===\n",
      "train loss:2.213644836211923\n",
      "train loss:2.329848166695726\n",
      "train loss:2.2277662197897783\n",
      "train loss:2.2815149525358787\n",
      "=== epoch:26, train acc:0.13, test acc:0.11 ===\n",
      "train loss:2.3216588001642675\n",
      "train loss:2.282883963719326\n",
      "train loss:2.32105197684523\n",
      "train loss:2.2696834168658673\n",
      "=== epoch:27, train acc:0.135, test acc:0.11 ===\n",
      "train loss:2.1999966883880764\n",
      "train loss:2.2302475900812686\n",
      "train loss:2.3079970090509456\n",
      "train loss:2.2540913186755422\n",
      "=== epoch:28, train acc:0.135, test acc:0.11 ===\n",
      "train loss:2.3648956563935646\n",
      "train loss:2.2699200349675124\n",
      "train loss:2.313520051376701\n",
      "train loss:2.2820139615715602\n",
      "=== epoch:29, train acc:0.135, test acc:0.11 ===\n",
      "train loss:2.264798187513555\n",
      "train loss:2.415889724375573\n",
      "train loss:2.343490563307244\n",
      "train loss:2.232537394543506\n",
      "=== epoch:30, train acc:0.1375, test acc:0.11 ===\n",
      "train loss:2.3031598421970076\n",
      "train loss:2.1875741836341445\n",
      "train loss:2.35959132594644\n",
      "train loss:2.278083144313541\n",
      "=== epoch:31, train acc:0.1425, test acc:0.11 ===\n",
      "train loss:2.318531774542815\n",
      "train loss:2.1320783212143968\n",
      "train loss:2.315600632343971\n",
      "train loss:2.2974691411473143\n",
      "=== epoch:32, train acc:0.1475, test acc:0.11 ===\n",
      "train loss:2.3018214152839285\n",
      "train loss:2.327923464906965\n",
      "train loss:2.35682397200835\n",
      "train loss:2.288187953758605\n",
      "=== epoch:33, train acc:0.145, test acc:0.11 ===\n",
      "train loss:2.349532256996649\n",
      "train loss:2.157517874287154\n",
      "train loss:2.360852535437029\n",
      "train loss:2.266352489242114\n",
      "=== epoch:34, train acc:0.1475, test acc:0.11 ===\n",
      "train loss:2.249044216767056\n",
      "train loss:2.2940939219987255\n",
      "train loss:2.1981760560035704\n",
      "train loss:2.274956707826565\n",
      "=== epoch:35, train acc:0.15, test acc:0.11 ===\n",
      "train loss:2.27257617257409\n",
      "train loss:2.235553352431443\n",
      "train loss:2.2872909591126214\n",
      "train loss:2.2069104033063955\n",
      "=== epoch:36, train acc:0.1475, test acc:0.11 ===\n",
      "train loss:2.2390518895208187\n",
      "train loss:2.1826955710620832\n",
      "train loss:2.323405106965731\n",
      "train loss:2.3040470418236962\n",
      "=== epoch:37, train acc:0.15, test acc:0.1 ===\n",
      "train loss:2.3591566220249245\n",
      "train loss:2.285842957000055\n",
      "train loss:2.3496189453038645\n",
      "train loss:2.2732311300183037\n",
      "=== epoch:38, train acc:0.155, test acc:0.1 ===\n",
      "train loss:2.2225962457533397\n",
      "train loss:2.25637006041857\n",
      "train loss:2.3200860248154473\n",
      "train loss:2.2165865115305805\n",
      "=== epoch:39, train acc:0.1525, test acc:0.1 ===\n",
      "train loss:2.3225833653319183\n",
      "train loss:2.280476942661105\n",
      "train loss:2.2761821799512747\n",
      "train loss:2.2723101494963656\n",
      "=== epoch:40, train acc:0.155, test acc:0.1 ===\n",
      "train loss:2.1857506044944093\n",
      "train loss:2.2538902263882163\n",
      "train loss:2.3647425154882935\n",
      "train loss:2.318384635942992\n",
      "=== epoch:41, train acc:0.1575, test acc:0.1 ===\n",
      "train loss:2.2313530337443908\n",
      "train loss:2.342200316008689\n",
      "train loss:2.2214316968295615\n",
      "train loss:2.2530491562955666\n",
      "=== epoch:42, train acc:0.1575, test acc:0.1 ===\n",
      "train loss:2.146643007696501\n",
      "train loss:2.165175500206298\n",
      "train loss:2.269473769571908\n",
      "train loss:2.151382296020759\n",
      "=== epoch:43, train acc:0.1575, test acc:0.11 ===\n",
      "train loss:2.192996022825135\n",
      "train loss:2.2716657860661393\n",
      "train loss:2.332632107379403\n",
      "train loss:2.331667500102929\n",
      "=== epoch:44, train acc:0.16, test acc:0.11 ===\n",
      "train loss:2.2492328722839385\n",
      "train loss:2.2092696853466762\n",
      "train loss:2.166887170625424\n",
      "train loss:2.270475700239678\n",
      "=== epoch:45, train acc:0.1625, test acc:0.11 ===\n",
      "train loss:2.2483073775577678\n",
      "train loss:2.3044278045695106\n",
      "train loss:2.1235337300872716\n",
      "train loss:2.242397152903255\n",
      "=== epoch:46, train acc:0.165, test acc:0.11 ===\n",
      "train loss:2.2129981516104005\n",
      "train loss:2.2265604099244025\n",
      "train loss:2.215330407174058\n",
      "train loss:2.280838570054935\n",
      "=== epoch:47, train acc:0.1725, test acc:0.11 ===\n",
      "train loss:2.3330797062017044\n",
      "train loss:2.2500720922511817\n",
      "train loss:2.3242977128595754\n",
      "train loss:2.29260015515302\n",
      "=== epoch:48, train acc:0.1725, test acc:0.11 ===\n",
      "train loss:2.197770965030752\n",
      "train loss:2.2717139634234256\n",
      "train loss:2.295929353057215\n",
      "train loss:2.2107727777511115\n",
      "=== epoch:49, train acc:0.175, test acc:0.11 ===\n",
      "train loss:2.2184800460388616\n",
      "train loss:2.2593377216332553\n",
      "train loss:2.256046076593924\n",
      "train loss:2.1567521634936635\n",
      "=== epoch:50, train acc:0.1775, test acc:0.11 ===\n",
      "train loss:2.300433101705327\n",
      "train loss:2.271298761923828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2473272471035695\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.11\n",
      "val_acc: 0.1100 | lr: 0.0004, weight_decay: 0.0000\n",
      "train loss:2.3996644524904274\n",
      "=== epoch:1, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.2832050942633044\n",
      "train loss:2.3364656771042926\n",
      "train loss:2.4187621120142415\n",
      "train loss:2.3495323770776224\n",
      "=== epoch:2, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.3591545750883713\n",
      "train loss:2.481784782414105\n",
      "train loss:2.3941177628982975\n",
      "train loss:2.274843651572842\n",
      "=== epoch:3, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.389142089586045\n",
      "train loss:2.365573805038577\n",
      "train loss:2.2986923866421365\n",
      "train loss:2.3509205878444726\n",
      "=== epoch:4, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.429191044978637\n",
      "train loss:2.393732978222097\n",
      "train loss:2.368841348510115\n",
      "train loss:2.413531012064153\n",
      "=== epoch:5, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.4113229123827615\n",
      "train loss:2.3809753803464906\n",
      "train loss:2.3354496315399476\n",
      "train loss:2.3789270401716993\n",
      "=== epoch:6, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.382497796358393\n",
      "train loss:2.476423781423817\n",
      "train loss:2.3532508160125976\n",
      "train loss:2.398638142506662\n",
      "=== epoch:7, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.2841021923316367\n",
      "train loss:2.403696160145992\n",
      "train loss:2.4739535348433286\n",
      "train loss:2.3663827255043737\n",
      "=== epoch:8, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.4852658235090055\n",
      "train loss:2.416747473048894\n",
      "train loss:2.432135521497183\n",
      "train loss:2.294207884682141\n",
      "=== epoch:9, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.384886729723178\n",
      "train loss:2.3750279731397046\n",
      "train loss:2.381543197659677\n",
      "train loss:2.3747983169909275\n",
      "=== epoch:10, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.3879193995066483\n",
      "train loss:2.429146025966067\n",
      "train loss:2.3854364696257555\n",
      "train loss:2.4228858628539487\n",
      "=== epoch:11, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.3777915538773544\n",
      "train loss:2.316979096238302\n",
      "train loss:2.352343505530182\n",
      "train loss:2.3868552374606553\n",
      "=== epoch:12, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.383080682501592\n",
      "train loss:2.443319944151633\n",
      "train loss:2.3530594203921584\n",
      "train loss:2.380614564832601\n",
      "=== epoch:13, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.4615880650324473\n",
      "train loss:2.4124465248928657\n",
      "train loss:2.410755830012611\n",
      "train loss:2.3633837563741213\n",
      "=== epoch:14, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.3834322087978435\n",
      "train loss:2.3295163491181663\n",
      "train loss:2.3820823046112443\n",
      "train loss:2.350938190756836\n",
      "=== epoch:15, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.3653784936474653\n",
      "train loss:2.2983236178127706\n",
      "train loss:2.3296755371684115\n",
      "train loss:2.431691566725559\n",
      "=== epoch:16, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.4045697102654824\n",
      "train loss:2.444421028945059\n",
      "train loss:2.464391004778963\n",
      "train loss:2.432476485897104\n",
      "=== epoch:17, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.334811346344161\n",
      "train loss:2.3317503368743218\n",
      "train loss:2.342495858725208\n",
      "train loss:2.4524735598245964\n",
      "=== epoch:18, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.4658950000920807\n",
      "train loss:2.3731553061136688\n",
      "train loss:2.3629159297671194\n",
      "train loss:2.3839884197919643\n",
      "=== epoch:19, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.3575746757352367\n",
      "train loss:2.437152641765016\n",
      "train loss:2.2774785223516756\n",
      "train loss:2.3632406319046524\n",
      "=== epoch:20, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.425105129800494\n",
      "train loss:2.3798083755335666\n",
      "train loss:2.3997239460131117\n",
      "train loss:2.384201967824645\n",
      "=== epoch:21, train acc:0.1225, test acc:0.11 ===\n",
      "train loss:2.373419228804823\n",
      "train loss:2.413832163955787\n",
      "train loss:2.421553522615878\n",
      "train loss:2.403902809108448\n",
      "=== epoch:22, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.375250317033234\n",
      "train loss:2.4379761092680776\n",
      "train loss:2.438147233031209\n",
      "train loss:2.346354476155831\n",
      "=== epoch:23, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4244683751376583\n",
      "train loss:2.4130612500553155\n",
      "train loss:2.4006101962070163\n",
      "train loss:2.367839803942079\n",
      "=== epoch:24, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4143466676330343\n",
      "train loss:2.286564371395154\n",
      "train loss:2.3791330530004826\n",
      "train loss:2.35179891427791\n",
      "=== epoch:25, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4241347133562705\n",
      "train loss:2.441780550880575\n",
      "train loss:2.368097779493977\n",
      "train loss:2.441945864819696\n",
      "=== epoch:26, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.399959901975961\n",
      "train loss:2.341719608909197\n",
      "train loss:2.344236462201821\n",
      "train loss:2.4036726617074216\n",
      "=== epoch:27, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.319073280473858\n",
      "train loss:2.474908823395794\n",
      "train loss:2.419206880553528\n",
      "train loss:2.3503109892169984\n",
      "=== epoch:28, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.457801482060915\n",
      "train loss:2.3686043375191406\n",
      "train loss:2.3800304965113708\n",
      "train loss:2.357090297940506\n",
      "=== epoch:29, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.425146042143106\n",
      "train loss:2.335897152470936\n",
      "train loss:2.3961869376135003\n",
      "train loss:2.3960336994771416\n",
      "=== epoch:30, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.341460171814387\n",
      "train loss:2.3139808760607816\n",
      "train loss:2.4082993751010457\n",
      "train loss:2.3948990189282586\n",
      "=== epoch:31, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4406834399305786\n",
      "train loss:2.4425106051929024\n",
      "train loss:2.3399944851926957\n",
      "train loss:2.4152617542286\n",
      "=== epoch:32, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3700802232732223\n",
      "train loss:2.394140451770785\n",
      "train loss:2.3888927983132326\n",
      "train loss:2.4316721774079935\n",
      "=== epoch:33, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.368223491497379\n",
      "train loss:2.471569944684132\n",
      "train loss:2.4731455065268677\n",
      "train loss:2.4169518953151514\n",
      "=== epoch:34, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.2978166740488346\n",
      "train loss:2.409675137703939\n",
      "train loss:2.4345721719993243\n",
      "train loss:2.3924113008934333\n",
      "=== epoch:35, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4620384571318286\n",
      "train loss:2.3784868800984293\n",
      "train loss:2.3369781517242756\n",
      "train loss:2.4017350008848726\n",
      "=== epoch:36, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3388280142063245\n",
      "train loss:2.326695468236418\n",
      "train loss:2.32183577527086\n",
      "train loss:2.3651513670869706\n",
      "=== epoch:37, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4487868834342295\n",
      "train loss:2.4547166876410675\n",
      "train loss:2.33095413431935\n",
      "train loss:2.369487328080221\n",
      "=== epoch:38, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3285151829367665\n",
      "train loss:2.3014534933176263\n",
      "train loss:2.524415169156288\n",
      "train loss:2.338638289887163\n",
      "=== epoch:39, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3646360228616468\n",
      "train loss:2.3462915746870014\n",
      "train loss:2.3515273846290894\n",
      "train loss:2.4631261448879895\n",
      "=== epoch:40, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3151135726688112\n",
      "train loss:2.3580170131130833\n",
      "train loss:2.448313797777887\n",
      "train loss:2.4778494873570867\n",
      "=== epoch:41, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3931224537750864\n",
      "train loss:2.34049938164546\n",
      "train loss:2.4061629940543305\n",
      "train loss:2.38645817723162\n",
      "=== epoch:42, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3746921504170646\n",
      "train loss:2.3493081044764463\n",
      "train loss:2.3428055727566246\n",
      "train loss:2.409910779055941\n",
      "=== epoch:43, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.3715558969520334\n",
      "train loss:2.4219217875970855\n",
      "train loss:2.3179264351951043\n",
      "train loss:2.3530294452033913\n",
      "=== epoch:44, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.283362465768397\n",
      "train loss:2.4595142287403284\n",
      "train loss:2.387027917419343\n",
      "train loss:2.381408329771062\n",
      "=== epoch:45, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.386743333395611\n",
      "train loss:2.3241236029977257\n",
      "train loss:2.3675650878227716\n",
      "train loss:2.322923422520407\n",
      "=== epoch:46, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4039185139265826\n",
      "train loss:2.319456781870336\n",
      "train loss:2.3634638490583786\n",
      "train loss:2.359581127591568\n",
      "=== epoch:47, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.429977634595497\n",
      "train loss:2.4021575876820958\n",
      "train loss:2.4296405587775056\n",
      "train loss:2.414294551336081\n",
      "=== epoch:48, train acc:0.1225, test acc:0.12 ===\n",
      "train loss:2.4644390037143937\n",
      "train loss:2.455116290875098\n",
      "train loss:2.2932651320744615\n",
      "train loss:2.3824617966453787\n",
      "=== epoch:49, train acc:0.125, test acc:0.12 ===\n",
      "train loss:2.291898023905081\n",
      "train loss:2.4168161621724424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.4256358970742546\n",
      "train loss:2.4153830612814415\n",
      "=== epoch:50, train acc:0.125, test acc:0.12 ===\n",
      "train loss:2.3973686170104185\n",
      "train loss:2.341257139161864\n",
      "train loss:2.380709221318996\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4613773761873765\n",
      "=== epoch:1, train acc:0.09, test acc:0.09 ===\n",
      "train loss:2.419806097531866\n",
      "train loss:2.432146103479212\n",
      "train loss:2.4577524473846295\n",
      "train loss:2.390376360348364\n",
      "=== epoch:2, train acc:0.0975, test acc:0.09 ===\n",
      "train loss:2.4180746715179735\n",
      "train loss:2.376687810558542\n",
      "train loss:2.388753580955138\n",
      "train loss:2.3994890480537663\n",
      "=== epoch:3, train acc:0.1, test acc:0.1 ===\n",
      "train loss:2.462497479646004\n",
      "train loss:2.376843710362843\n",
      "train loss:2.308807115498635\n",
      "train loss:2.3095963105214654\n",
      "=== epoch:4, train acc:0.105, test acc:0.13 ===\n",
      "train loss:2.3444981644299054\n",
      "train loss:2.289980984901535\n",
      "train loss:2.3900263567581237\n",
      "train loss:2.3770783884588806\n",
      "=== epoch:5, train acc:0.1025, test acc:0.13 ===\n",
      "train loss:2.4002427751978317\n",
      "train loss:2.4320989846261383\n",
      "train loss:2.389677434654432\n",
      "train loss:2.4073742960882885\n",
      "=== epoch:6, train acc:0.1025, test acc:0.13 ===\n",
      "train loss:2.338220547642681\n",
      "train loss:2.3756829908589108\n",
      "train loss:2.362863911440655\n",
      "train loss:2.384773290740512\n",
      "=== epoch:7, train acc:0.1075, test acc:0.14 ===\n",
      "train loss:2.369328240188239\n",
      "train loss:2.34079534899875\n",
      "train loss:2.40542022646948\n",
      "train loss:2.3149760643625226\n",
      "=== epoch:8, train acc:0.1125, test acc:0.15 ===\n",
      "train loss:2.330777729402273\n",
      "train loss:2.3798149530121298\n",
      "train loss:2.3350586845125907\n",
      "train loss:2.32755392746426\n",
      "=== epoch:9, train acc:0.1225, test acc:0.14 ===\n",
      "train loss:2.2884333377750714\n",
      "train loss:2.3394796738925048\n",
      "train loss:2.403188899220124\n",
      "train loss:2.2976564738916347\n",
      "=== epoch:10, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.295112522419037\n",
      "train loss:2.333109435071611\n",
      "train loss:2.2825915389526017\n",
      "train loss:2.3199652928081607\n",
      "=== epoch:11, train acc:0.14, test acc:0.17 ===\n",
      "train loss:2.3009580618639722\n",
      "train loss:2.334692060788913\n",
      "train loss:2.3042735227934714\n",
      "train loss:2.323612398749344\n",
      "=== epoch:12, train acc:0.1425, test acc:0.17 ===\n",
      "train loss:2.34829571780739\n",
      "train loss:2.2659614559475982\n",
      "train loss:2.3304286093887296\n",
      "train loss:2.2743639885528792\n",
      "=== epoch:13, train acc:0.155, test acc:0.18 ===\n",
      "train loss:2.316204366172321\n",
      "train loss:2.3011439376762186\n",
      "train loss:2.264097536724153\n",
      "train loss:2.247749787492788\n",
      "=== epoch:14, train acc:0.1575, test acc:0.19 ===\n",
      "train loss:2.2571833685242595\n",
      "train loss:2.2767548288761974\n",
      "train loss:2.2407130564161934\n",
      "train loss:2.311318760559308\n",
      "=== epoch:15, train acc:0.1725, test acc:0.19 ===\n",
      "train loss:2.2700203321211454\n",
      "train loss:2.335239448287671\n",
      "train loss:2.219519329533584\n",
      "train loss:2.2486165161090885\n",
      "=== epoch:16, train acc:0.1725, test acc:0.2 ===\n",
      "train loss:2.2499593672493763\n",
      "train loss:2.284533322190927\n",
      "train loss:2.2677613529192553\n",
      "train loss:2.287621621216723\n",
      "=== epoch:17, train acc:0.18, test acc:0.21 ===\n",
      "train loss:2.261387580254361\n",
      "train loss:2.2942137179709876\n",
      "train loss:2.242011926975603\n",
      "train loss:2.2459938004570623\n",
      "=== epoch:18, train acc:0.1775, test acc:0.21 ===\n",
      "train loss:2.3044650165689577\n",
      "train loss:2.2650494458856922\n",
      "train loss:2.281444906450065\n",
      "train loss:2.2722887966310097\n",
      "=== epoch:19, train acc:0.185, test acc:0.23 ===\n",
      "train loss:2.2345119793259878\n",
      "train loss:2.2602006691660974\n",
      "train loss:2.267490926755364\n",
      "train loss:2.2557499711117837\n",
      "=== epoch:20, train acc:0.1875, test acc:0.23 ===\n",
      "train loss:2.2395646990187434\n",
      "train loss:2.260572981686599\n",
      "train loss:2.3158785382815696\n",
      "train loss:2.2650692365532903\n",
      "=== epoch:21, train acc:0.195, test acc:0.24 ===\n",
      "train loss:2.2674945568447287\n",
      "train loss:2.273184155070302\n",
      "train loss:2.209600491726966\n",
      "train loss:2.2778000747022276\n",
      "=== epoch:22, train acc:0.21, test acc:0.23 ===\n",
      "train loss:2.2422060133380235\n",
      "train loss:2.2443065723651165\n",
      "train loss:2.2451067007565197\n",
      "train loss:2.21657087223955\n",
      "=== epoch:23, train acc:0.21, test acc:0.23 ===\n",
      "train loss:2.2321281476849526\n",
      "train loss:2.2436782073377413\n",
      "train loss:2.230953615795407\n",
      "train loss:2.250496928545181\n",
      "=== epoch:24, train acc:0.21, test acc:0.23 ===\n",
      "train loss:2.1610906550310665\n",
      "train loss:2.252807661041939\n",
      "train loss:2.2129776780100405\n",
      "train loss:2.197842154801296\n",
      "=== epoch:25, train acc:0.2125, test acc:0.23 ===\n",
      "train loss:2.2129012641733117\n",
      "train loss:2.216750567515097\n",
      "train loss:2.1882451788779087\n",
      "train loss:2.1976189947000533\n",
      "=== epoch:26, train acc:0.22, test acc:0.24 ===\n",
      "train loss:2.1847031919607014\n",
      "train loss:2.2378144031159106\n",
      "train loss:2.1877761752514724\n",
      "train loss:2.2285482635427365\n",
      "=== epoch:27, train acc:0.2225, test acc:0.26 ===\n",
      "train loss:2.2665161316972724\n",
      "train loss:2.1873579483404666\n",
      "train loss:2.26635775480176\n",
      "train loss:2.1637800322307026\n",
      "=== epoch:28, train acc:0.225, test acc:0.26 ===\n",
      "train loss:2.2002551339847214\n",
      "train loss:2.2051553089467815\n",
      "train loss:2.213944872457759\n",
      "train loss:2.2068483169836837\n",
      "=== epoch:29, train acc:0.2375, test acc:0.27 ===\n",
      "train loss:2.208157123595231\n",
      "train loss:2.167233069558446\n",
      "train loss:2.2075340926674767\n",
      "train loss:2.1950077374312267\n",
      "=== epoch:30, train acc:0.2375, test acc:0.27 ===\n",
      "train loss:2.2452600422108646\n",
      "train loss:2.180412124429313\n",
      "train loss:2.2003763674738956\n",
      "train loss:2.1761989001448527\n",
      "=== epoch:31, train acc:0.245, test acc:0.27 ===\n",
      "train loss:2.186834085074142\n",
      "train loss:2.157399944228585\n",
      "train loss:2.218945661312071\n",
      "train loss:2.1852289687133912\n",
      "=== epoch:32, train acc:0.245, test acc:0.26 ===\n",
      "train loss:2.196477046236393\n",
      "train loss:2.195721838676285\n",
      "train loss:2.1883091130384154\n",
      "train loss:2.21637872634795\n",
      "=== epoch:33, train acc:0.25, test acc:0.27 ===\n",
      "train loss:2.21369279382731\n",
      "train loss:2.119621822468821\n",
      "train loss:2.1772194187538614\n",
      "train loss:2.2181670195609295\n",
      "=== epoch:34, train acc:0.2675, test acc:0.28 ===\n",
      "train loss:2.181700189841414\n",
      "train loss:2.1773203090927846\n",
      "train loss:2.1368095345105496\n",
      "train loss:2.1359756073138145\n",
      "=== epoch:35, train acc:0.27, test acc:0.28 ===\n",
      "train loss:2.1524412138760693\n",
      "train loss:2.135357073025608\n",
      "train loss:2.1272635563126423\n",
      "train loss:2.155507690029392\n",
      "=== epoch:36, train acc:0.275, test acc:0.29 ===\n",
      "train loss:2.098472526289585\n",
      "train loss:2.1327803767854676\n",
      "train loss:2.1544432781114056\n",
      "train loss:2.1426696018174898\n",
      "=== epoch:37, train acc:0.2775, test acc:0.29 ===\n",
      "train loss:2.1253230615553687\n",
      "train loss:2.1438080805625725\n",
      "train loss:2.133134653562467\n",
      "train loss:2.161582009875228\n",
      "=== epoch:38, train acc:0.2825, test acc:0.29 ===\n",
      "train loss:2.1367370648239596\n",
      "train loss:2.1252986734303208\n",
      "train loss:2.175663891627749\n",
      "train loss:2.163582686225224\n",
      "=== epoch:39, train acc:0.2925, test acc:0.29 ===\n",
      "train loss:2.1608417485933336\n",
      "train loss:2.130888566341025\n",
      "train loss:2.144108731775815\n",
      "train loss:2.1104976691961075\n",
      "=== epoch:40, train acc:0.2925, test acc:0.3 ===\n",
      "train loss:2.1508100288071064\n",
      "train loss:2.1024216679122443\n",
      "train loss:2.129902773198262\n",
      "train loss:2.1002043201310117\n",
      "=== epoch:41, train acc:0.2925, test acc:0.29 ===\n",
      "train loss:2.194177401662781\n",
      "train loss:2.137341924258341\n",
      "train loss:2.0807266159654123\n",
      "train loss:2.1205476624922417\n",
      "=== epoch:42, train acc:0.295, test acc:0.3 ===\n",
      "train loss:2.1358254036028157\n",
      "train loss:2.1620485065009984\n",
      "train loss:2.1656647877415467\n",
      "train loss:2.111471619453903\n",
      "=== epoch:43, train acc:0.3, test acc:0.29 ===\n",
      "train loss:2.126245306543199\n",
      "train loss:2.0893739411535517\n",
      "train loss:2.1295552448029684\n",
      "train loss:2.0939240408800015\n",
      "=== epoch:44, train acc:0.3025, test acc:0.29 ===\n",
      "train loss:2.1667255800017995\n",
      "train loss:2.128730129180749\n",
      "train loss:2.149051873071904\n",
      "train loss:2.084353296068572\n",
      "=== epoch:45, train acc:0.3025, test acc:0.29 ===\n",
      "train loss:2.102944557975909\n",
      "train loss:2.1052919183421017\n",
      "train loss:2.076868181338811\n",
      "train loss:2.1105237439970974\n",
      "=== epoch:46, train acc:0.305, test acc:0.3 ===\n",
      "train loss:2.0894946995165897\n",
      "train loss:2.128604868661626\n",
      "train loss:2.1232329295364067\n",
      "train loss:2.073987058619729\n",
      "=== epoch:47, train acc:0.3125, test acc:0.3 ===\n",
      "train loss:2.088448000395719\n",
      "train loss:2.16376493859476\n",
      "train loss:2.108200977377514\n",
      "train loss:2.0605161808120362\n",
      "=== epoch:48, train acc:0.3175, test acc:0.31 ===\n",
      "train loss:2.095365034244226\n",
      "train loss:2.09470258608642\n",
      "train loss:2.0841673938997225\n",
      "train loss:2.1131833920527323\n",
      "=== epoch:49, train acc:0.3175, test acc:0.32 ===\n",
      "train loss:2.0585823646805483\n",
      "train loss:2.1019992444206403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.0808573932208887\n",
      "train loss:2.0876296126950895\n",
      "=== epoch:50, train acc:0.32, test acc:0.33 ===\n",
      "train loss:2.0457959990890835\n",
      "train loss:2.0675729070986266\n",
      "train loss:2.0486340599319606\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.33\n",
      "val_acc: 0.3300 | lr: 0.0013, weight_decay: 0.0000\n",
      "train loss:2.3318461692031196\n",
      "=== epoch:1, train acc:0.095, test acc:0.11 ===\n",
      "train loss:2.344605250102151\n",
      "train loss:2.3576237976691075\n",
      "train loss:2.322827537537823\n",
      "train loss:2.3286264221953767\n",
      "=== epoch:2, train acc:0.1325, test acc:0.1 ===\n",
      "train loss:2.2569997978646006\n",
      "train loss:2.2849998528140643\n",
      "train loss:2.3112446318480604\n",
      "train loss:2.2397917704587935\n",
      "=== epoch:3, train acc:0.1475, test acc:0.13 ===\n",
      "train loss:2.2244303849219\n",
      "train loss:2.2705425270005586\n",
      "train loss:2.2559799896677637\n",
      "train loss:2.2062527571283126\n",
      "=== epoch:4, train acc:0.17, test acc:0.15 ===\n",
      "train loss:2.2506424253862285\n",
      "train loss:2.198040286653836\n",
      "train loss:2.1915461326200965\n",
      "train loss:2.197123321264949\n",
      "=== epoch:5, train acc:0.205, test acc:0.15 ===\n",
      "train loss:2.209367883382725\n",
      "train loss:2.2000689790272796\n",
      "train loss:2.1353566485367876\n",
      "train loss:2.194385829947348\n",
      "=== epoch:6, train acc:0.24, test acc:0.17 ===\n",
      "train loss:2.1614619087862184\n",
      "train loss:2.1426347353828605\n",
      "train loss:2.1256977246214817\n",
      "train loss:2.1587793793426586\n",
      "=== epoch:7, train acc:0.2875, test acc:0.23 ===\n",
      "train loss:2.174789808788964\n",
      "train loss:2.1027578756262617\n",
      "train loss:2.1094757503425385\n",
      "train loss:2.135913279074156\n",
      "=== epoch:8, train acc:0.305, test acc:0.27 ===\n",
      "train loss:2.1335002345234386\n",
      "train loss:2.1008785751823438\n",
      "train loss:2.1017858484578666\n",
      "train loss:2.142424078958046\n",
      "=== epoch:9, train acc:0.345, test acc:0.29 ===\n",
      "train loss:2.1026280426828663\n",
      "train loss:2.080766319989141\n",
      "train loss:2.0784203389768736\n",
      "train loss:2.074777186938685\n",
      "=== epoch:10, train acc:0.3875, test acc:0.33 ===\n",
      "train loss:2.052031505310539\n",
      "train loss:2.0601122339497757\n",
      "train loss:2.0536763632549833\n",
      "train loss:2.0635140947583124\n",
      "=== epoch:11, train acc:0.4, test acc:0.38 ===\n",
      "train loss:2.0811811428731515\n",
      "train loss:2.0055580553128975\n",
      "train loss:1.9788572181566941\n",
      "train loss:2.0116634334794496\n",
      "=== epoch:12, train acc:0.445, test acc:0.41 ===\n",
      "train loss:1.9571115777234573\n",
      "train loss:2.025524700906804\n",
      "train loss:1.973551077693524\n",
      "train loss:1.9802915629010682\n",
      "=== epoch:13, train acc:0.4675, test acc:0.44 ===\n",
      "train loss:1.9154056927141692\n",
      "train loss:1.9144933008052258\n",
      "train loss:1.9457130161349308\n",
      "train loss:1.9202250175688784\n",
      "=== epoch:14, train acc:0.495, test acc:0.46 ===\n",
      "train loss:1.8731593018392456\n",
      "train loss:1.8985130448020469\n",
      "train loss:1.9298051014015682\n",
      "train loss:1.9937403638194338\n",
      "=== epoch:15, train acc:0.5125, test acc:0.42 ===\n",
      "train loss:1.9218167084814746\n",
      "train loss:1.8794050043069825\n",
      "train loss:1.9094519389496252\n",
      "train loss:1.8712979523450228\n",
      "=== epoch:16, train acc:0.54, test acc:0.45 ===\n",
      "train loss:1.8938104643836873\n",
      "train loss:1.916646988445598\n",
      "train loss:1.8009722512598791\n",
      "train loss:1.7957164372730918\n",
      "=== epoch:17, train acc:0.5725, test acc:0.49 ===\n",
      "train loss:1.86744180660887\n",
      "train loss:1.804737986237631\n",
      "train loss:1.7730966479194241\n",
      "train loss:1.8043463202511625\n",
      "=== epoch:18, train acc:0.5775, test acc:0.49 ===\n",
      "train loss:1.7261313389755273\n",
      "train loss:1.7798326153596336\n",
      "train loss:1.8191466206338522\n",
      "train loss:1.7174421558123942\n",
      "=== epoch:19, train acc:0.5825, test acc:0.49 ===\n",
      "train loss:1.719912510856042\n",
      "train loss:1.7464209778219564\n",
      "train loss:1.7691081770036219\n",
      "train loss:1.7143891271570832\n",
      "=== epoch:20, train acc:0.615, test acc:0.52 ===\n",
      "train loss:1.719985888563187\n",
      "train loss:1.7679674123191764\n",
      "train loss:1.707358133116209\n",
      "train loss:1.6201297766429208\n",
      "=== epoch:21, train acc:0.655, test acc:0.53 ===\n",
      "train loss:1.622484059283102\n",
      "train loss:1.6516870131538646\n",
      "train loss:1.6422200000387435\n",
      "train loss:1.607575665776903\n",
      "=== epoch:22, train acc:0.6625, test acc:0.55 ===\n",
      "train loss:1.589295416233998\n",
      "train loss:1.5507277215034998\n",
      "train loss:1.5501027422079081\n",
      "train loss:1.5323697781269865\n",
      "=== epoch:23, train acc:0.665, test acc:0.55 ===\n",
      "train loss:1.5397179444716653\n",
      "train loss:1.469839507240525\n",
      "train loss:1.53977380402948\n",
      "train loss:1.627891876752171\n",
      "=== epoch:24, train acc:0.6725, test acc:0.59 ===\n",
      "train loss:1.4264143715561206\n",
      "train loss:1.3759546822598117\n",
      "train loss:1.5012809725400964\n",
      "train loss:1.440481991793155\n",
      "=== epoch:25, train acc:0.67, test acc:0.57 ===\n",
      "train loss:1.4013278328240846\n",
      "train loss:1.3874905302208402\n",
      "train loss:1.5008175186855095\n",
      "train loss:1.448545622388776\n",
      "=== epoch:26, train acc:0.685, test acc:0.57 ===\n",
      "train loss:1.351817655636173\n",
      "train loss:1.2720466895090745\n",
      "train loss:1.4137545571337033\n",
      "train loss:1.289344662427158\n",
      "=== epoch:27, train acc:0.695, test acc:0.61 ===\n",
      "train loss:1.3476846035978916\n",
      "train loss:1.2590914017285002\n",
      "train loss:1.3527342273091194\n",
      "train loss:1.212753848286267\n",
      "=== epoch:28, train acc:0.695, test acc:0.61 ===\n",
      "train loss:1.2333817188404879\n",
      "train loss:1.159207806986431\n",
      "train loss:1.2057531027539221\n",
      "train loss:1.2055720599429551\n",
      "=== epoch:29, train acc:0.7025, test acc:0.61 ===\n",
      "train loss:1.1461961662620577\n",
      "train loss:1.2823883412595232\n",
      "train loss:1.2104993014249847\n",
      "train loss:1.2352972846620458\n",
      "=== epoch:30, train acc:0.725, test acc:0.62 ===\n",
      "train loss:1.0324641393210963\n",
      "train loss:1.202798777381718\n",
      "train loss:1.1497632188495006\n",
      "train loss:1.0307429269533488\n",
      "=== epoch:31, train acc:0.735, test acc:0.66 ===\n",
      "train loss:1.1673470306266749\n",
      "train loss:1.1210772200339258\n",
      "train loss:1.131586618474539\n",
      "train loss:1.0486485852683072\n",
      "=== epoch:32, train acc:0.76, test acc:0.65 ===\n",
      "train loss:0.9427799875869152\n",
      "train loss:1.0384923600330922\n",
      "train loss:0.9232888381291401\n",
      "train loss:1.0101650559568969\n",
      "=== epoch:33, train acc:0.765, test acc:0.65 ===\n",
      "train loss:0.8439614838423282\n",
      "train loss:1.018600122062783\n",
      "train loss:0.921496799239744\n",
      "train loss:0.8613772084112263\n",
      "=== epoch:34, train acc:0.76, test acc:0.65 ===\n",
      "train loss:1.008709220806489\n",
      "train loss:0.8599305535262128\n",
      "train loss:0.899528547218197\n",
      "train loss:0.8897736533582181\n",
      "=== epoch:35, train acc:0.7675, test acc:0.66 ===\n",
      "train loss:0.7981518213942873\n",
      "train loss:0.9020555226500883\n",
      "train loss:0.8610559689367603\n",
      "train loss:0.8112060940331117\n",
      "=== epoch:36, train acc:0.78, test acc:0.68 ===\n",
      "train loss:0.9253886232855062\n",
      "train loss:0.9008934967048275\n",
      "train loss:0.880061610793081\n",
      "train loss:0.8330408699317742\n",
      "=== epoch:37, train acc:0.7925, test acc:0.69 ===\n",
      "train loss:0.8166398107768003\n",
      "train loss:0.8610194858061416\n",
      "train loss:0.8863254622157724\n",
      "train loss:0.7552278255494016\n",
      "=== epoch:38, train acc:0.7875, test acc:0.69 ===\n",
      "train loss:0.8109863251282914\n",
      "train loss:0.7434675436269866\n",
      "train loss:0.8579154998065621\n",
      "train loss:0.7989125679641949\n",
      "=== epoch:39, train acc:0.79, test acc:0.72 ===\n",
      "train loss:0.7360013043182143\n",
      "train loss:0.7622873189508652\n",
      "train loss:0.7610012104361823\n",
      "train loss:0.8419747402367237\n",
      "=== epoch:40, train acc:0.805, test acc:0.73 ===\n",
      "train loss:0.7235625514082121\n",
      "train loss:0.8105944810154677\n",
      "train loss:0.7259408689177587\n",
      "train loss:0.7057518320305619\n",
      "=== epoch:41, train acc:0.8175, test acc:0.73 ===\n",
      "train loss:0.6527089707163068\n",
      "train loss:0.6961418185724421\n",
      "train loss:0.783627070190254\n",
      "train loss:0.6856476309149483\n",
      "=== epoch:42, train acc:0.8275, test acc:0.75 ===\n",
      "train loss:0.695087721483204\n",
      "train loss:0.5485207750001299\n",
      "train loss:0.613652228810342\n",
      "train loss:0.6403827262880672\n",
      "=== epoch:43, train acc:0.8375, test acc:0.74 ===\n",
      "train loss:0.576145494569417\n",
      "train loss:0.733598114248191\n",
      "train loss:0.6133324395534906\n",
      "train loss:0.6632763446061853\n",
      "=== epoch:44, train acc:0.8425, test acc:0.75 ===\n",
      "train loss:0.6081597491363857\n",
      "train loss:0.7355344358980362\n",
      "train loss:0.6581932914965148\n",
      "train loss:0.635821635690369\n",
      "=== epoch:45, train acc:0.8625, test acc:0.76 ===\n",
      "train loss:0.5940489460709992\n",
      "train loss:0.5462836249547658\n",
      "train loss:0.5151986814033602\n",
      "train loss:0.5955015416633231\n",
      "=== epoch:46, train acc:0.8525, test acc:0.77 ===\n",
      "train loss:0.5615705533481282\n",
      "train loss:0.5566512883016714\n",
      "train loss:0.5734318017633889\n",
      "train loss:0.5827072123668271\n",
      "=== epoch:47, train acc:0.8575, test acc:0.76 ===\n",
      "train loss:0.4794639826373358\n",
      "train loss:0.5296248086957644\n",
      "train loss:0.5711904077941838\n",
      "train loss:0.5048428356379818\n",
      "=== epoch:48, train acc:0.86, test acc:0.76 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.5248667092418025\n",
      "train loss:0.5609892142523409\n",
      "train loss:0.5898399063617508\n",
      "train loss:0.5573397868772114\n",
      "=== epoch:49, train acc:0.8725, test acc:0.78 ===\n",
      "train loss:0.511053215842287\n",
      "train loss:0.4875277997033139\n",
      "train loss:0.4897698713659883\n",
      "train loss:0.5141023473757675\n",
      "=== epoch:50, train acc:0.88, test acc:0.76 ===\n",
      "train loss:0.4782834382651046\n",
      "train loss:0.3663278390591615\n",
      "train loss:0.599964414830779\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.77\n",
      "val_acc: 0.7600 | lr: 0.0082, weight_decay: 0.0000\n",
      "train loss:2.4443344904860402\n",
      "=== epoch:1, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4705025053634833\n",
      "train loss:2.4094874824285673\n",
      "train loss:2.4466079821026363\n",
      "train loss:2.4485463895573707\n",
      "=== epoch:2, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4707641981019317\n",
      "train loss:2.476778898821791\n",
      "train loss:2.4417153172955266\n",
      "train loss:2.427193754132077\n",
      "=== epoch:3, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.410314921747781\n",
      "train loss:2.457736379456094\n",
      "train loss:2.4604772841719966\n",
      "train loss:2.4478963890895167\n",
      "=== epoch:4, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4695818662194644\n",
      "train loss:2.52531151214349\n",
      "train loss:2.476503433228506\n",
      "train loss:2.497236971886952\n",
      "=== epoch:5, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4634007639384077\n",
      "train loss:2.4794033728210834\n",
      "train loss:2.4754156945484636\n",
      "train loss:2.5403659838999553\n",
      "=== epoch:6, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.412293687779815\n",
      "train loss:2.482580642576138\n",
      "train loss:2.490094151771476\n",
      "train loss:2.4257098109611226\n",
      "=== epoch:7, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4647684400063756\n",
      "train loss:2.521817695768382\n",
      "train loss:2.505901372064613\n",
      "train loss:2.4740782769102254\n",
      "=== epoch:8, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.420890599200183\n",
      "train loss:2.49000584248262\n",
      "train loss:2.369610996935492\n",
      "train loss:2.4754341002242772\n",
      "=== epoch:9, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.5874729244450623\n",
      "train loss:2.453572048091628\n",
      "train loss:2.4511516987978417\n",
      "train loss:2.5133905147251454\n",
      "=== epoch:10, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.494354318717197\n",
      "train loss:2.5070479352108173\n",
      "train loss:2.4500491314862916\n",
      "train loss:2.464522793655755\n",
      "=== epoch:11, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.342531115354287\n",
      "train loss:2.358018144904155\n",
      "train loss:2.4576123147143116\n",
      "train loss:2.4693907940975977\n",
      "=== epoch:12, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.420177356122843\n",
      "train loss:2.4385391437198374\n",
      "train loss:2.5214516705323886\n",
      "train loss:2.470968876716319\n",
      "=== epoch:13, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.315945048943436\n",
      "train loss:2.4203016398182187\n",
      "train loss:2.5074597836648556\n",
      "train loss:2.4098017749263954\n",
      "=== epoch:14, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.49960991067782\n",
      "train loss:2.3465122473586546\n",
      "train loss:2.438460494797295\n",
      "train loss:2.4644270266588655\n",
      "=== epoch:15, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.5014150877526267\n",
      "train loss:2.494218330994688\n",
      "train loss:2.4971973349473435\n",
      "train loss:2.4893799528505935\n",
      "=== epoch:16, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.3708505381428906\n",
      "train loss:2.5754694489153303\n",
      "train loss:2.6397996561797306\n",
      "train loss:2.473952133007738\n",
      "=== epoch:17, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.5275454209944592\n",
      "train loss:2.451200586028798\n",
      "train loss:2.536713629264745\n",
      "train loss:2.5161176152877944\n",
      "=== epoch:18, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.467247617666906\n",
      "train loss:2.450580601459887\n",
      "train loss:2.4820724782422876\n",
      "train loss:2.4604471287509218\n",
      "=== epoch:19, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4928465541872398\n",
      "train loss:2.430308674373643\n",
      "train loss:2.4393887810373216\n",
      "train loss:2.4650530386643537\n",
      "=== epoch:20, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.352940494579119\n",
      "train loss:2.4683863504246344\n",
      "train loss:2.4277215346680316\n",
      "train loss:2.4859899531827927\n",
      "=== epoch:21, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4395304518387744\n",
      "train loss:2.506942745993778\n",
      "train loss:2.4791023758943624\n",
      "train loss:2.477362323813595\n",
      "=== epoch:22, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4460262732579596\n",
      "train loss:2.4229743240403336\n",
      "train loss:2.433008425718878\n",
      "train loss:2.4467291504156887\n",
      "=== epoch:23, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4545827894592294\n",
      "train loss:2.423426416514812\n",
      "train loss:2.593973517576037\n",
      "train loss:2.402409810847442\n",
      "=== epoch:24, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4804339440558367\n",
      "train loss:2.433100985468644\n",
      "train loss:2.463988199609505\n",
      "train loss:2.5200413452941786\n",
      "=== epoch:25, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.5384765924934487\n",
      "train loss:2.45743729413827\n",
      "train loss:2.3721138113511455\n",
      "train loss:2.4563841699734956\n",
      "=== epoch:26, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4779535175929355\n",
      "train loss:2.503574790086665\n",
      "train loss:2.3697219970780616\n",
      "train loss:2.386618278095918\n",
      "=== epoch:27, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.430470375566604\n",
      "train loss:2.4327831275211222\n",
      "train loss:2.490422632215431\n",
      "train loss:2.476205485932414\n",
      "=== epoch:28, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4390659578163816\n",
      "train loss:2.4336243811206266\n",
      "train loss:2.359716656367252\n",
      "train loss:2.43900477424669\n",
      "=== epoch:29, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.5078148827684106\n",
      "train loss:2.488830453071584\n",
      "train loss:2.3719172026467534\n",
      "train loss:2.4421885896941435\n",
      "=== epoch:30, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.6202041334872677\n",
      "train loss:2.3810197385836784\n",
      "train loss:2.414119954067062\n",
      "train loss:2.4665584729623933\n",
      "=== epoch:31, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.5143840022958988\n",
      "train loss:2.388281397332265\n",
      "train loss:2.429190073871465\n",
      "train loss:2.422513955512951\n",
      "=== epoch:32, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4305860977873683\n",
      "train loss:2.5270288266123595\n",
      "train loss:2.4366206023950028\n",
      "train loss:2.5172843363341264\n",
      "=== epoch:33, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4104451229524346\n",
      "train loss:2.4557415545471657\n",
      "train loss:2.396109018435681\n",
      "train loss:2.389339827584929\n",
      "=== epoch:34, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.440930377833453\n",
      "train loss:2.4064362842699523\n",
      "train loss:2.3647276856711614\n",
      "train loss:2.3235783133640826\n",
      "=== epoch:35, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4537206211608433\n",
      "train loss:2.4341210139518386\n",
      "train loss:2.4753403892354022\n",
      "train loss:2.4069923994108233\n",
      "=== epoch:36, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4756856712035473\n",
      "train loss:2.450599288415739\n",
      "train loss:2.5066953000311054\n",
      "train loss:2.46259197023018\n",
      "=== epoch:37, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.446716997651268\n",
      "train loss:2.4441646429567587\n",
      "train loss:2.400101827643307\n",
      "train loss:2.444308569370826\n",
      "=== epoch:38, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.446242297270279\n",
      "train loss:2.3720327948583337\n",
      "train loss:2.4913251761920137\n",
      "train loss:2.4413259017628532\n",
      "=== epoch:39, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.440896826939067\n",
      "train loss:2.384069266498749\n",
      "train loss:2.5083545203571074\n",
      "train loss:2.4796327457950156\n",
      "=== epoch:40, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4719910101204534\n",
      "train loss:2.573823023740833\n",
      "train loss:2.5364180137324532\n",
      "train loss:2.518893656252534\n",
      "=== epoch:41, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4618011459310902\n",
      "train loss:2.368143547489025\n",
      "train loss:2.4919475673022773\n",
      "train loss:2.4164826678949862\n",
      "=== epoch:42, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.457950567757838\n",
      "train loss:2.5051053406879555\n",
      "train loss:2.418811111015126\n",
      "train loss:2.470677286758635\n",
      "=== epoch:43, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4658085085369406\n",
      "train loss:2.3575426607225327\n",
      "train loss:2.417141059142144\n",
      "train loss:2.4323014356372665\n",
      "=== epoch:44, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.3604441129842493\n",
      "train loss:2.4044755880870414\n",
      "train loss:2.4625474467621125\n",
      "train loss:2.426473248493101\n",
      "=== epoch:45, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.4346833943666364\n",
      "train loss:2.419593713344961\n",
      "train loss:2.4572379792700536\n",
      "train loss:2.4437825905151205\n",
      "=== epoch:46, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.3432559968017683\n",
      "train loss:2.544415925750814\n",
      "train loss:2.462188911737475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.5297636627272975\n",
      "=== epoch:47, train acc:0.085, test acc:0.06 ===\n",
      "train loss:2.428021000993654\n",
      "train loss:2.363658715118703\n",
      "train loss:2.4901496207458553\n",
      "train loss:2.4602887429132165\n",
      "=== epoch:48, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.483018558786915\n",
      "train loss:2.480700739408353\n",
      "train loss:2.4562089163131717\n",
      "train loss:2.4649896914925598\n",
      "=== epoch:49, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.4796140330282483\n",
      "train loss:2.451760474306687\n",
      "train loss:2.487605767147171\n",
      "train loss:2.3188680773733776\n",
      "=== epoch:50, train acc:0.0825, test acc:0.06 ===\n",
      "train loss:2.380961856340764\n",
      "train loss:2.433685969422846\n",
      "train loss:2.4877081533917744\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.06\n",
      "val_acc: 0.0600 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.381011127180629\n",
      "=== epoch:1, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3637399287802046\n",
      "train loss:2.3474628788216516\n",
      "train loss:2.307607947350744\n",
      "train loss:2.31605853959688\n",
      "=== epoch:2, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.368340113597596\n",
      "train loss:2.3373399580581466\n",
      "train loss:2.3272832007273774\n",
      "train loss:2.383791452809834\n",
      "=== epoch:3, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3599759712472577\n",
      "train loss:2.3723615057347827\n",
      "train loss:2.293553163603638\n",
      "train loss:2.3092342415028404\n",
      "=== epoch:4, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3351036722013556\n",
      "train loss:2.3793008721641193\n",
      "train loss:2.4322328918895133\n",
      "train loss:2.328233505148948\n",
      "=== epoch:5, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3356138947104186\n",
      "train loss:2.3135978280329605\n",
      "train loss:2.364059828877026\n",
      "train loss:2.301285717240367\n",
      "=== epoch:6, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3049497449195764\n",
      "train loss:2.4103526594848894\n",
      "train loss:2.3478404923221077\n",
      "train loss:2.3271806170735467\n",
      "=== epoch:7, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3921335557954824\n",
      "train loss:2.410540544808237\n",
      "train loss:2.349230121789002\n",
      "train loss:2.322285947268982\n",
      "=== epoch:8, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.347887163572005\n",
      "train loss:2.4529696634805638\n",
      "train loss:2.3507904132936104\n",
      "train loss:2.3352413634584472\n",
      "=== epoch:9, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.374331393003137\n",
      "train loss:2.377689935030261\n",
      "train loss:2.392018103559299\n",
      "train loss:2.313755686462713\n",
      "=== epoch:10, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3645655760925846\n",
      "train loss:2.30412810401215\n",
      "train loss:2.432306142179944\n",
      "train loss:2.3041878092938464\n",
      "=== epoch:11, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.312814474444738\n",
      "train loss:2.3345801839037406\n",
      "train loss:2.3328149782656467\n",
      "train loss:2.400422030144646\n",
      "=== epoch:12, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.2944721371596324\n",
      "train loss:2.359516954557761\n",
      "train loss:2.348800196034409\n",
      "train loss:2.374698052793984\n",
      "=== epoch:13, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3820071942066594\n",
      "train loss:2.384825336280331\n",
      "train loss:2.3642625374864035\n",
      "train loss:2.3541386595106673\n",
      "=== epoch:14, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3148602057223395\n",
      "train loss:2.3925326431489387\n",
      "train loss:2.3378698424222457\n",
      "train loss:2.3139532443994457\n",
      "=== epoch:15, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3643275320009556\n",
      "train loss:2.3743301714942424\n",
      "train loss:2.3566742415559228\n",
      "train loss:2.3425888892911173\n",
      "=== epoch:16, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3993449478523234\n",
      "train loss:2.305889041517981\n",
      "train loss:2.363415500542534\n",
      "train loss:2.3893919989652495\n",
      "=== epoch:17, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3543071616921027\n",
      "train loss:2.4047424315659875\n",
      "train loss:2.3977148477300774\n",
      "train loss:2.382329469462593\n",
      "=== epoch:18, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3812024452313083\n",
      "train loss:2.2983670646499066\n",
      "train loss:2.360689057067607\n",
      "train loss:2.3191593282535288\n",
      "=== epoch:19, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3982235048269005\n",
      "train loss:2.3037994528371306\n",
      "train loss:2.3643453211260996\n",
      "train loss:2.3491002898672604\n",
      "=== epoch:20, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3896710687895495\n",
      "train loss:2.260188218306191\n",
      "train loss:2.3875070165975507\n",
      "train loss:2.3322036243181663\n",
      "=== epoch:21, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3051241483215237\n",
      "train loss:2.3515478119094326\n",
      "train loss:2.29872962801136\n",
      "train loss:2.330610593285476\n",
      "=== epoch:22, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3699610546511685\n",
      "train loss:2.314592603117857\n",
      "train loss:2.33611108674878\n",
      "train loss:2.362142259182872\n",
      "=== epoch:23, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.4223202585916264\n",
      "train loss:2.3782292395428466\n",
      "train loss:2.3651893618861237\n",
      "train loss:2.3544803824848444\n",
      "=== epoch:24, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.355452626328428\n",
      "train loss:2.382746396159907\n",
      "train loss:2.3621513901446356\n",
      "train loss:2.322236811960078\n",
      "=== epoch:25, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3634417014885454\n",
      "train loss:2.3505828330381062\n",
      "train loss:2.3664252045092313\n",
      "train loss:2.3413746462687954\n",
      "=== epoch:26, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.401650082852763\n",
      "train loss:2.3524188771617696\n",
      "train loss:2.3325256158249648\n",
      "train loss:2.341384954755122\n",
      "=== epoch:27, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.4035045179824737\n",
      "train loss:2.351501774702033\n",
      "train loss:2.3106407778279463\n",
      "train loss:2.4391084138069337\n",
      "=== epoch:28, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.279737094354564\n",
      "train loss:2.2793465748361\n",
      "train loss:2.2811146516972887\n",
      "train loss:2.348837088636953\n",
      "=== epoch:29, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3290016334823127\n",
      "train loss:2.3289649777642976\n",
      "train loss:2.3426439035540145\n",
      "train loss:2.362977533169992\n",
      "=== epoch:30, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.35020389523292\n",
      "train loss:2.319099564756777\n",
      "train loss:2.3939656241235103\n",
      "train loss:2.275129536470752\n",
      "=== epoch:31, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.34964010746596\n",
      "train loss:2.40365995410505\n",
      "train loss:2.314278153338299\n",
      "train loss:2.315281874496705\n",
      "=== epoch:32, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3198513118559374\n",
      "train loss:2.3684754370231875\n",
      "train loss:2.353601949697837\n",
      "train loss:2.3558382873626122\n",
      "=== epoch:33, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.302871936789572\n",
      "train loss:2.35141037134342\n",
      "train loss:2.3660653579579387\n",
      "train loss:2.384733041997805\n",
      "=== epoch:34, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.351944638516002\n",
      "train loss:2.2836833408946395\n",
      "train loss:2.335017242197692\n",
      "train loss:2.293651503063472\n",
      "=== epoch:35, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.368615053755828\n",
      "train loss:2.355954318337103\n",
      "train loss:2.338715830069104\n",
      "train loss:2.37018297113861\n",
      "=== epoch:36, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.2919066987283845\n",
      "train loss:2.3395726933034147\n",
      "train loss:2.36547672626333\n",
      "train loss:2.3559366227855905\n",
      "=== epoch:37, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.2985540594816958\n",
      "train loss:2.3465587141112745\n",
      "train loss:2.291909226554248\n",
      "train loss:2.3879962491463878\n",
      "=== epoch:38, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.320187052123554\n",
      "train loss:2.335799309784471\n",
      "train loss:2.4060139593773298\n",
      "train loss:2.3103484631686655\n",
      "=== epoch:39, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3463485606179377\n",
      "train loss:2.323363957167347\n",
      "train loss:2.3519459342869657\n",
      "train loss:2.393702334138161\n",
      "=== epoch:40, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.411450564939542\n",
      "train loss:2.355588927435775\n",
      "train loss:2.3590841026973743\n",
      "train loss:2.380767103649428\n",
      "=== epoch:41, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.326878073760349\n",
      "train loss:2.3736152826806736\n",
      "train loss:2.394374188552505\n",
      "train loss:2.3739434209609294\n",
      "=== epoch:42, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.319854920143374\n",
      "train loss:2.311444299494403\n",
      "train loss:2.37390900260705\n",
      "train loss:2.3642842461552047\n",
      "=== epoch:43, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.379029891061733\n",
      "train loss:2.411608865502172\n",
      "train loss:2.383932152621209\n",
      "train loss:2.346732139285763\n",
      "=== epoch:44, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3557041421393907\n",
      "train loss:2.290726850892909\n",
      "train loss:2.3112970349939848\n",
      "train loss:2.3828690239449988\n",
      "=== epoch:45, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.346385244524747\n",
      "train loss:2.3173336735268895\n",
      "train loss:2.322242656035092\n",
      "train loss:2.349108726679156\n",
      "=== epoch:46, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.302367413505792\n",
      "train loss:2.3771975942297057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.326163767897407\n",
      "train loss:2.3595590885212756\n",
      "=== epoch:47, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3282136427965945\n",
      "train loss:2.3821419696421295\n",
      "train loss:2.295131873407638\n",
      "train loss:2.3608377474500783\n",
      "=== epoch:48, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.300869869775717\n",
      "train loss:2.367326440813925\n",
      "train loss:2.3684383579972286\n",
      "train loss:2.376475848873179\n",
      "=== epoch:49, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.356994700202952\n",
      "train loss:2.2583688864349303\n",
      "train loss:2.2691596625740114\n",
      "train loss:2.376076603764908\n",
      "=== epoch:50, train acc:0.0725, test acc:0.06 ===\n",
      "train loss:2.3279527659858545\n",
      "train loss:2.397910484193623\n",
      "train loss:2.341993558429704\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.06\n",
      "val_acc: 0.0600 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3656557741499102\n",
      "=== epoch:1, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.311745748902909\n",
      "train loss:2.324875836189269\n",
      "train loss:2.311067017885809\n",
      "train loss:2.3235913914475796\n",
      "=== epoch:2, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3182786676853\n",
      "train loss:2.345113701554789\n",
      "train loss:2.315389857834462\n",
      "train loss:2.335565724187199\n",
      "=== epoch:3, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3016656239730255\n",
      "train loss:2.318724501878795\n",
      "train loss:2.3210638756750077\n",
      "train loss:2.349399202697702\n",
      "=== epoch:4, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3135643449539764\n",
      "train loss:2.3195796901175925\n",
      "train loss:2.318320996657065\n",
      "train loss:2.3475327754814193\n",
      "=== epoch:5, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3151365587244688\n",
      "train loss:2.297219024176765\n",
      "train loss:2.3512396730938057\n",
      "train loss:2.292730204900174\n",
      "=== epoch:6, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3504738112119425\n",
      "train loss:2.3080928233072275\n",
      "train loss:2.3153141219613533\n",
      "train loss:2.307947810095562\n",
      "=== epoch:7, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.300990858545424\n",
      "train loss:2.3065860816288892\n",
      "train loss:2.2851753140870814\n",
      "train loss:2.355878187056107\n",
      "=== epoch:8, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3368950573800733\n",
      "train loss:2.3388519032916233\n",
      "train loss:2.3508024792706976\n",
      "train loss:2.3023244350322725\n",
      "=== epoch:9, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.315461073176099\n",
      "train loss:2.3350533989271143\n",
      "train loss:2.3136322576010664\n",
      "train loss:2.316560472040097\n",
      "=== epoch:10, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.33068074803665\n",
      "train loss:2.316929164929391\n",
      "train loss:2.3312893492127285\n",
      "train loss:2.276688027696471\n",
      "=== epoch:11, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3123937039866953\n",
      "train loss:2.340995998802962\n",
      "train loss:2.3295951982116385\n",
      "train loss:2.3168779681176717\n",
      "=== epoch:12, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3119789069863965\n",
      "train loss:2.3240086284013586\n",
      "train loss:2.300259746828528\n",
      "train loss:2.337080846984105\n",
      "=== epoch:13, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.309339749778582\n",
      "train loss:2.329017198420489\n",
      "train loss:2.3185159273630283\n",
      "train loss:2.3308624363252894\n",
      "=== epoch:14, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.336564373175013\n",
      "train loss:2.3481388694297376\n",
      "train loss:2.3074722353911197\n",
      "train loss:2.3336001302654426\n",
      "=== epoch:15, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3227542112052375\n",
      "train loss:2.3405811735938493\n",
      "train loss:2.3378453407213655\n",
      "train loss:2.321082741192617\n",
      "=== epoch:16, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3430038137867983\n",
      "train loss:2.305588065110426\n",
      "train loss:2.296146951881658\n",
      "train loss:2.336641909853478\n",
      "=== epoch:17, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3429998825450973\n",
      "train loss:2.3240041362468187\n",
      "train loss:2.3059731594365007\n",
      "train loss:2.318821208504991\n",
      "=== epoch:18, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.288867957098512\n",
      "train loss:2.299975512227919\n",
      "train loss:2.31476335898952\n",
      "train loss:2.323598577431134\n",
      "=== epoch:19, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3219410618557816\n",
      "train loss:2.3093094191181005\n",
      "train loss:2.3094431115981267\n",
      "train loss:2.3217478051600904\n",
      "=== epoch:20, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.299452791503871\n",
      "train loss:2.349192933680008\n",
      "train loss:2.2917205359336674\n",
      "train loss:2.3231106288950274\n",
      "=== epoch:21, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.308044770856252\n",
      "train loss:2.3114190463898883\n",
      "train loss:2.3020223065405463\n",
      "train loss:2.316702566662405\n",
      "=== epoch:22, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.310132347882418\n",
      "train loss:2.3542895134056803\n",
      "train loss:2.358863886723983\n",
      "train loss:2.3107397648822277\n",
      "=== epoch:23, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3305360469505647\n",
      "train loss:2.3532954763053073\n",
      "train loss:2.316974007768868\n",
      "train loss:2.3236107015006104\n",
      "=== epoch:24, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3294002833751204\n",
      "train loss:2.314710547083056\n",
      "train loss:2.309763875414121\n",
      "train loss:2.343618452919023\n",
      "=== epoch:25, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.301308676968679\n",
      "train loss:2.312647713953395\n",
      "train loss:2.334668022717798\n",
      "train loss:2.3220644081153954\n",
      "=== epoch:26, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.262039834904815\n",
      "train loss:2.289621410567929\n",
      "train loss:2.3389410681017893\n",
      "train loss:2.338770663793429\n",
      "=== epoch:27, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.341372573601457\n",
      "train loss:2.306209387331677\n",
      "train loss:2.373698066588865\n",
      "train loss:2.345326842044944\n",
      "=== epoch:28, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3193744901951256\n",
      "train loss:2.3323352671584296\n",
      "train loss:2.323246442403005\n",
      "train loss:2.288515359429098\n",
      "=== epoch:29, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3045137869478496\n",
      "train loss:2.3154562101259666\n",
      "train loss:2.3385068366206556\n",
      "train loss:2.3289802398004014\n",
      "=== epoch:30, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3156987676388785\n",
      "train loss:2.3023392944518637\n",
      "train loss:2.3361338682209998\n",
      "train loss:2.319589001082831\n",
      "=== epoch:31, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.328460024194317\n",
      "train loss:2.3493113870106215\n",
      "train loss:2.3333160954007064\n",
      "train loss:2.3451064097952226\n",
      "=== epoch:32, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.322464968386261\n",
      "train loss:2.356984448780434\n",
      "train loss:2.3175464961422847\n",
      "train loss:2.283175761093229\n",
      "=== epoch:33, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3131739774780344\n",
      "train loss:2.34041134525704\n",
      "train loss:2.3148586628355172\n",
      "train loss:2.3529054072762547\n",
      "=== epoch:34, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3291628064017758\n",
      "train loss:2.3192166339823053\n",
      "train loss:2.3344248397041487\n",
      "train loss:2.326372440346554\n",
      "=== epoch:35, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3656774316326943\n",
      "train loss:2.3575678367083475\n",
      "train loss:2.3257187070890812\n",
      "train loss:2.333990924529324\n",
      "=== epoch:36, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3147994987523086\n",
      "train loss:2.3215773631693435\n",
      "train loss:2.329548933563505\n",
      "train loss:2.340933261448278\n",
      "=== epoch:37, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3187089251468547\n",
      "train loss:2.3207909966987152\n",
      "train loss:2.33472982577172\n",
      "train loss:2.306140388501718\n",
      "=== epoch:38, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3192909689741263\n",
      "train loss:2.287387799755499\n",
      "train loss:2.3184237019313394\n",
      "train loss:2.3245961055859627\n",
      "=== epoch:39, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3142006706333644\n",
      "train loss:2.3420703386094885\n",
      "train loss:2.3194800522050505\n",
      "train loss:2.306490597976855\n",
      "=== epoch:40, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.321459862239807\n",
      "train loss:2.341073566148347\n",
      "train loss:2.366466290315777\n",
      "train loss:2.3052272331253487\n",
      "=== epoch:41, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3106004466392362\n",
      "train loss:2.3136768951820623\n",
      "train loss:2.3339041567104797\n",
      "train loss:2.3705692924499484\n",
      "=== epoch:42, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.313339189641068\n",
      "train loss:2.3091799587456707\n",
      "train loss:2.3223670783727712\n",
      "train loss:2.318333971717298\n",
      "=== epoch:43, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3200578789380595\n",
      "train loss:2.3297780595842483\n",
      "train loss:2.3403116712448684\n",
      "train loss:2.3008386840149457\n",
      "=== epoch:44, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3401497146414374\n",
      "train loss:2.3243915678241396\n",
      "train loss:2.314796341864359\n",
      "train loss:2.300356408624853\n",
      "=== epoch:45, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.317184724182415\n",
      "train loss:2.3547943331887127\n",
      "train loss:2.322150181576398\n",
      "train loss:2.3225252746809564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:46, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3065785170206015\n",
      "train loss:2.307813427540954\n",
      "train loss:2.33608359709424\n",
      "train loss:2.3784837706054844\n",
      "=== epoch:47, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.2912139650547574\n",
      "train loss:2.320971795738419\n",
      "train loss:2.2790683086734846\n",
      "train loss:2.344104249584146\n",
      "=== epoch:48, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.3252351159048916\n",
      "train loss:2.308232369648477\n",
      "train loss:2.3154472158714237\n",
      "train loss:2.3106503118985757\n",
      "=== epoch:49, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.329081979266156\n",
      "train loss:2.335812349948073\n",
      "train loss:2.2987223721552295\n",
      "train loss:2.3095065892524254\n",
      "=== epoch:50, train acc:0.045, test acc:0.08 ===\n",
      "train loss:2.2907141368039605\n",
      "train loss:2.3156584850342035\n",
      "train loss:2.2821294858652523\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.08\n",
      "val_acc: 0.0800 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.4013426213253783\n",
      "=== epoch:1, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.371732489021836\n",
      "train loss:2.3791329626277578\n",
      "train loss:2.3762322572141867\n",
      "train loss:2.3777280306050783\n",
      "=== epoch:2, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.418878717178515\n",
      "train loss:2.4064477776598654\n",
      "train loss:2.411285986852241\n",
      "train loss:2.4480590780855507\n",
      "=== epoch:3, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.3691063011345492\n",
      "train loss:2.37927796614068\n",
      "train loss:2.3256645208381914\n",
      "train loss:2.458180598972569\n",
      "=== epoch:4, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.3751836227777967\n",
      "train loss:2.386149302468601\n",
      "train loss:2.3890542124938667\n",
      "train loss:2.399364298470264\n",
      "=== epoch:5, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.3187010428893906\n",
      "train loss:2.414967510315041\n",
      "train loss:2.3957551050613244\n",
      "train loss:2.3600948693952906\n",
      "=== epoch:6, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.4055246281644536\n",
      "train loss:2.3833562147922542\n",
      "train loss:2.369905142964115\n",
      "train loss:2.3693923608002714\n",
      "=== epoch:7, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.4191672827869812\n",
      "train loss:2.3509258332620453\n",
      "train loss:2.394629785189083\n",
      "train loss:2.325729006481873\n",
      "=== epoch:8, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.372093697958308\n",
      "train loss:2.3577618505228313\n",
      "train loss:2.3457187178084644\n",
      "train loss:2.391575073757982\n",
      "=== epoch:9, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.348185304835432\n",
      "train loss:2.4128041117021928\n",
      "train loss:2.3673389473937645\n",
      "train loss:2.3745610131364643\n",
      "=== epoch:10, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.3884925008612337\n",
      "train loss:2.369967975341155\n",
      "train loss:2.3685004969224592\n",
      "train loss:2.379075958191261\n",
      "=== epoch:11, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.335244742433488\n",
      "train loss:2.3492780715658244\n",
      "train loss:2.3406705728164825\n",
      "train loss:2.3592371103948433\n",
      "=== epoch:12, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.3763372167376966\n",
      "train loss:2.3582082747664606\n",
      "train loss:2.41445831541775\n",
      "train loss:2.3769558125282995\n",
      "=== epoch:13, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.3870191317266123\n",
      "train loss:2.3802054531225356\n",
      "train loss:2.3721012177039045\n",
      "train loss:2.420002578087557\n",
      "=== epoch:14, train acc:0.1275, test acc:0.14 ===\n",
      "train loss:2.397095674547324\n",
      "train loss:2.3232018931593577\n",
      "train loss:2.4276655281832626\n",
      "train loss:2.3933920211229665\n",
      "=== epoch:15, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.4028951135218324\n",
      "train loss:2.311300997892842\n",
      "train loss:2.3567994606852904\n",
      "train loss:2.397762229785738\n",
      "=== epoch:16, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.3430146792416005\n",
      "train loss:2.3655155208961767\n",
      "train loss:2.328714492535153\n",
      "train loss:2.3538637811486955\n",
      "=== epoch:17, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.434329243540779\n",
      "train loss:2.3788391135240254\n",
      "train loss:2.377936455154264\n",
      "train loss:2.367060657166054\n",
      "=== epoch:18, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.3700971156788957\n",
      "train loss:2.3878999751544563\n",
      "train loss:2.382792955697685\n",
      "train loss:2.3923952076073203\n",
      "=== epoch:19, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.408685992543083\n",
      "train loss:2.3885779026095313\n",
      "train loss:2.3494611906584066\n",
      "train loss:2.377674780455853\n",
      "=== epoch:20, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.357249636164066\n",
      "train loss:2.3469455045955074\n",
      "train loss:2.3147376290634742\n",
      "train loss:2.3461968818382006\n",
      "=== epoch:21, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.428053615382309\n",
      "train loss:2.3167085987126326\n",
      "train loss:2.4165587699930873\n",
      "train loss:2.315479403631014\n",
      "=== epoch:22, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.3279281441846273\n",
      "train loss:2.345336577369169\n",
      "train loss:2.400125395855666\n",
      "train loss:2.451525063653328\n",
      "=== epoch:23, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.360834369744919\n",
      "train loss:2.3462818233307554\n",
      "train loss:2.3465481919271567\n",
      "train loss:2.3072926980670956\n",
      "=== epoch:24, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.4162663411459833\n",
      "train loss:2.362181825837018\n",
      "train loss:2.376709381972954\n",
      "train loss:2.3801552402751307\n",
      "=== epoch:25, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.3726478108745654\n",
      "train loss:2.394220463144673\n",
      "train loss:2.4008915747152053\n",
      "train loss:2.379333829437343\n",
      "=== epoch:26, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.3342089861059696\n",
      "train loss:2.319277507770158\n",
      "train loss:2.3463352231571553\n",
      "train loss:2.3129597797311607\n",
      "=== epoch:27, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.405131092378444\n",
      "train loss:2.4030202246338987\n",
      "train loss:2.3594893101714174\n",
      "train loss:2.4033285541052947\n",
      "=== epoch:28, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.3164882489637333\n",
      "train loss:2.39633019477651\n",
      "train loss:2.416913541499648\n",
      "train loss:2.3568112411378848\n",
      "=== epoch:29, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.3226299749192183\n",
      "train loss:2.406636463939536\n",
      "train loss:2.368462858719926\n",
      "train loss:2.3311257856886556\n",
      "=== epoch:30, train acc:0.13, test acc:0.14 ===\n",
      "train loss:2.354511853222866\n",
      "train loss:2.3802259195830002\n",
      "train loss:2.4037666131838464\n",
      "train loss:2.379933988646601\n",
      "=== epoch:31, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.3550119962261458\n",
      "train loss:2.3151765191745666\n",
      "train loss:2.3907778529884665\n",
      "train loss:2.400295177681912\n",
      "=== epoch:32, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.4148569324679388\n",
      "train loss:2.3173805068777518\n",
      "train loss:2.3914411278153396\n",
      "train loss:2.4139384955021312\n",
      "=== epoch:33, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.377491032575136\n",
      "train loss:2.353315018792194\n",
      "train loss:2.375793844153582\n",
      "train loss:2.3141951524557403\n",
      "=== epoch:34, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.324925569835564\n",
      "train loss:2.3508734596508116\n",
      "train loss:2.3889525514260765\n",
      "train loss:2.3520725982740505\n",
      "=== epoch:35, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.3807456324394543\n",
      "train loss:2.373596530797304\n",
      "train loss:2.3748941409936735\n",
      "train loss:2.372651295184355\n",
      "=== epoch:36, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.407455570181565\n",
      "train loss:2.390004980511938\n",
      "train loss:2.3480732146348053\n",
      "train loss:2.368473661618446\n",
      "=== epoch:37, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.312903384539728\n",
      "train loss:2.4090672629285574\n",
      "train loss:2.374865573625382\n",
      "train loss:2.3476571683046785\n",
      "=== epoch:38, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.353590035206529\n",
      "train loss:2.364161531508318\n",
      "train loss:2.2959552847007645\n",
      "train loss:2.370798313288592\n",
      "=== epoch:39, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.407541370508261\n",
      "train loss:2.323547139862615\n",
      "train loss:2.371043615147147\n",
      "train loss:2.406413573621782\n",
      "=== epoch:40, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.3318306553201955\n",
      "train loss:2.358293120950126\n",
      "train loss:2.39705603001719\n",
      "train loss:2.3560247695259577\n",
      "=== epoch:41, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.383027312102078\n",
      "train loss:2.413236637866441\n",
      "train loss:2.3509496610354415\n",
      "train loss:2.3638165021857183\n",
      "=== epoch:42, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.3465073256463915\n",
      "train loss:2.3713111047843904\n",
      "train loss:2.3697835904511777\n",
      "train loss:2.4151534155335663\n",
      "=== epoch:43, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.375580796283124\n",
      "train loss:2.3680479302779003\n",
      "train loss:2.3523685289566854\n",
      "train loss:2.363632705376543\n",
      "=== epoch:44, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.3763674786430364\n",
      "train loss:2.336505595088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3484253139874367\n",
      "train loss:2.374936827159371\n",
      "=== epoch:45, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.3936671958978284\n",
      "train loss:2.3779964663674846\n",
      "train loss:2.3828919524540573\n",
      "train loss:2.352202129940674\n",
      "=== epoch:46, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.3694761379414118\n",
      "train loss:2.406052660728746\n",
      "train loss:2.3675648875680624\n",
      "train loss:2.365467775948526\n",
      "=== epoch:47, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.4296904868808453\n",
      "train loss:2.358210756233069\n",
      "train loss:2.3019706492334997\n",
      "train loss:2.347779174932284\n",
      "=== epoch:48, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.318069844220612\n",
      "train loss:2.4194407876278516\n",
      "train loss:2.3584368039752857\n",
      "train loss:2.3437935467801156\n",
      "=== epoch:49, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.389476648889751\n",
      "train loss:2.3646792755501487\n",
      "train loss:2.350603139310801\n",
      "train loss:2.4124694021834006\n",
      "=== epoch:50, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.415555247066129\n",
      "train loss:2.392516636632556\n",
      "train loss:2.4048858363394667\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.15\n",
      "val_acc: 0.1500 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.475412568618301\n",
      "=== epoch:1, train acc:0.11, test acc:0.12 ===\n",
      "train loss:2.418455049294517\n",
      "train loss:2.3351237138058623\n",
      "train loss:2.4845727357289626\n",
      "train loss:2.5260989672083363\n",
      "=== epoch:2, train acc:0.1125, test acc:0.13 ===\n",
      "train loss:2.407330340430491\n",
      "train loss:2.369699468703425\n",
      "train loss:2.287493211404081\n",
      "train loss:2.2863185879651446\n",
      "=== epoch:3, train acc:0.11, test acc:0.13 ===\n",
      "train loss:2.318739935738515\n",
      "train loss:2.354292377849598\n",
      "train loss:2.3960881649281944\n",
      "train loss:2.3198694433209366\n",
      "=== epoch:4, train acc:0.11, test acc:0.13 ===\n",
      "train loss:2.346959153833431\n",
      "train loss:2.3994056696675954\n",
      "train loss:2.417829409865675\n",
      "train loss:2.3527168009675195\n",
      "=== epoch:5, train acc:0.11, test acc:0.13 ===\n",
      "train loss:2.4119215446118396\n",
      "train loss:2.3202877822691086\n",
      "train loss:2.3425948796610805\n",
      "train loss:2.3507681607236828\n",
      "=== epoch:6, train acc:0.1125, test acc:0.14 ===\n",
      "train loss:2.428487624457763\n",
      "train loss:2.2764905132132633\n",
      "train loss:2.365728596789135\n",
      "train loss:2.3651689905748983\n",
      "=== epoch:7, train acc:0.1125, test acc:0.14 ===\n",
      "train loss:2.2486122804140223\n",
      "train loss:2.4130774711152596\n",
      "train loss:2.41166107624966\n",
      "train loss:2.3610922297734716\n",
      "=== epoch:8, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.3174909222514075\n",
      "train loss:2.2950086240337106\n",
      "train loss:2.335823895283696\n",
      "train loss:2.420186101450272\n",
      "=== epoch:9, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.3466164563962963\n",
      "train loss:2.402274948758618\n",
      "train loss:2.402041403123134\n",
      "train loss:2.3170543691118684\n",
      "=== epoch:10, train acc:0.1175, test acc:0.15 ===\n",
      "train loss:2.3376099426873065\n",
      "train loss:2.33789137186604\n",
      "train loss:2.3807505449001085\n",
      "train loss:2.33911621301726\n",
      "=== epoch:11, train acc:0.1175, test acc:0.15 ===\n",
      "train loss:2.257831848029352\n",
      "train loss:2.3002023159174327\n",
      "train loss:2.2373711137640737\n",
      "train loss:2.4108849380263697\n",
      "=== epoch:12, train acc:0.125, test acc:0.15 ===\n",
      "train loss:2.4065971642568886\n",
      "train loss:2.362674815761802\n",
      "train loss:2.221099672172516\n",
      "train loss:2.232189272431029\n",
      "=== epoch:13, train acc:0.1275, test acc:0.15 ===\n",
      "train loss:2.389855078426031\n",
      "train loss:2.301339983010652\n",
      "train loss:2.2915392553181912\n",
      "train loss:2.290455621003076\n",
      "=== epoch:14, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.3654515519658013\n",
      "train loss:2.265894864633916\n",
      "train loss:2.2363137006731635\n",
      "train loss:2.253390861218914\n",
      "=== epoch:15, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.273635553724454\n",
      "train loss:2.3257018159626237\n",
      "train loss:2.3232227108716232\n",
      "train loss:2.254291441859471\n",
      "=== epoch:16, train acc:0.1275, test acc:0.15 ===\n",
      "train loss:2.2886282785777894\n",
      "train loss:2.2309118455153105\n",
      "train loss:2.2275086634033396\n",
      "train loss:2.2123102647860877\n",
      "=== epoch:17, train acc:0.13, test acc:0.15 ===\n",
      "train loss:2.309699487676434\n",
      "train loss:2.2359380227341266\n",
      "train loss:2.308982578489309\n",
      "train loss:2.366147676084048\n",
      "=== epoch:18, train acc:0.1325, test acc:0.15 ===\n",
      "train loss:2.245773819853564\n",
      "train loss:2.291873162864528\n",
      "train loss:2.29693915962648\n",
      "train loss:2.274623983948312\n",
      "=== epoch:19, train acc:0.135, test acc:0.15 ===\n",
      "train loss:2.2159750725081517\n",
      "train loss:2.2940984333931036\n",
      "train loss:2.2524945547223014\n",
      "train loss:2.2803113246148237\n",
      "=== epoch:20, train acc:0.135, test acc:0.15 ===\n",
      "train loss:2.242414238703236\n",
      "train loss:2.2704359348178884\n",
      "train loss:2.304375072008006\n",
      "train loss:2.1660462096122277\n",
      "=== epoch:21, train acc:0.14, test acc:0.16 ===\n",
      "train loss:2.2175236970044745\n",
      "train loss:2.2294681631646704\n",
      "train loss:2.2573228042029827\n",
      "train loss:2.243448094309458\n",
      "=== epoch:22, train acc:0.145, test acc:0.16 ===\n",
      "train loss:2.3529589130439463\n",
      "train loss:2.2976535387957986\n",
      "train loss:2.301121593189277\n",
      "train loss:2.255597032410691\n",
      "=== epoch:23, train acc:0.1525, test acc:0.16 ===\n",
      "train loss:2.25764621431814\n",
      "train loss:2.2402963627104984\n",
      "train loss:2.2316717077386867\n",
      "train loss:2.258310725875122\n",
      "=== epoch:24, train acc:0.155, test acc:0.15 ===\n",
      "train loss:2.2353507793683445\n",
      "train loss:2.248056801993537\n",
      "train loss:2.227399145421632\n",
      "train loss:2.239077039740598\n",
      "=== epoch:25, train acc:0.1575, test acc:0.16 ===\n",
      "train loss:2.3067974637919795\n",
      "train loss:2.1677627159276898\n",
      "train loss:2.2279142320742586\n",
      "train loss:2.2951826946349536\n",
      "=== epoch:26, train acc:0.16, test acc:0.18 ===\n",
      "train loss:2.2583735872334225\n",
      "train loss:2.210635422232065\n",
      "train loss:2.18025365992422\n",
      "train loss:2.218518350966554\n",
      "=== epoch:27, train acc:0.1625, test acc:0.18 ===\n",
      "train loss:2.1893212923431946\n",
      "train loss:2.222530981520667\n",
      "train loss:2.28130051333883\n",
      "train loss:2.144330304148949\n",
      "=== epoch:28, train acc:0.1625, test acc:0.18 ===\n",
      "train loss:2.2615484028931303\n",
      "train loss:2.2293341228214825\n",
      "train loss:2.2093370018955167\n",
      "train loss:2.1761400967232643\n",
      "=== epoch:29, train acc:0.1625, test acc:0.18 ===\n",
      "train loss:2.1651912905082273\n",
      "train loss:2.290762442254581\n",
      "train loss:2.2197294069787867\n",
      "train loss:2.3139567678815207\n",
      "=== epoch:30, train acc:0.1675, test acc:0.18 ===\n",
      "train loss:2.2343592252356177\n",
      "train loss:2.234221797289776\n",
      "train loss:2.1935471343107653\n",
      "train loss:2.2268829979683886\n",
      "=== epoch:31, train acc:0.17, test acc:0.18 ===\n",
      "train loss:2.130388176188689\n",
      "train loss:2.206909223456092\n",
      "train loss:2.2789821804328936\n",
      "train loss:2.1375872060763017\n",
      "=== epoch:32, train acc:0.17, test acc:0.19 ===\n",
      "train loss:2.1690786276571923\n",
      "train loss:2.206136178332916\n",
      "train loss:2.1746827890241045\n",
      "train loss:2.204227342451074\n",
      "=== epoch:33, train acc:0.17, test acc:0.2 ===\n",
      "train loss:2.246183008816527\n",
      "train loss:2.190072503793072\n",
      "train loss:2.1770806400919787\n",
      "train loss:2.167009253136843\n",
      "=== epoch:34, train acc:0.18, test acc:0.21 ===\n",
      "train loss:2.1637781525186717\n",
      "train loss:2.1633518007179613\n",
      "train loss:2.210640769865262\n",
      "train loss:2.200701371604983\n",
      "=== epoch:35, train acc:0.1825, test acc:0.21 ===\n",
      "train loss:2.1060687362353434\n",
      "train loss:2.2124129249426177\n",
      "train loss:2.2269145153951535\n",
      "train loss:2.2138690725482384\n",
      "=== epoch:36, train acc:0.195, test acc:0.22 ===\n",
      "train loss:2.1351999218838302\n",
      "train loss:2.2173816800768966\n",
      "train loss:2.1585233682942575\n",
      "train loss:2.138815761892515\n",
      "=== epoch:37, train acc:0.205, test acc:0.22 ===\n",
      "train loss:2.2194590230116686\n",
      "train loss:2.2085053361664126\n",
      "train loss:2.124154495211634\n",
      "train loss:2.1952889510760474\n",
      "=== epoch:38, train acc:0.2075, test acc:0.23 ===\n",
      "train loss:2.1760833038830687\n",
      "train loss:2.161831677881608\n",
      "train loss:2.255837738277505\n",
      "train loss:2.1389084549810606\n",
      "=== epoch:39, train acc:0.2075, test acc:0.25 ===\n",
      "train loss:2.1060347514785818\n",
      "train loss:2.153312165363233\n",
      "train loss:2.1799644454681517\n",
      "train loss:2.112430846460594\n",
      "=== epoch:40, train acc:0.2075, test acc:0.25 ===\n",
      "train loss:2.130548190483441\n",
      "train loss:2.188989051071781\n",
      "train loss:2.1999601140054073\n",
      "train loss:2.1571658805111653\n",
      "=== epoch:41, train acc:0.2075, test acc:0.26 ===\n",
      "train loss:2.175036402259845\n",
      "train loss:2.185907153848724\n",
      "train loss:2.1960134125918715\n",
      "train loss:2.1870180317100636\n",
      "=== epoch:42, train acc:0.2125, test acc:0.28 ===\n",
      "train loss:2.1617710667203833\n",
      "train loss:2.130586183794165\n",
      "train loss:2.1378694081986716\n",
      "train loss:2.064718800876983\n",
      "=== epoch:43, train acc:0.2125, test acc:0.29 ===\n",
      "train loss:2.196400871434092\n",
      "train loss:2.195443919410842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.0772172150403794\n",
      "train loss:2.1096612688539533\n",
      "=== epoch:44, train acc:0.2125, test acc:0.29 ===\n",
      "train loss:2.1369426003045984\n",
      "train loss:2.197684946811807\n",
      "train loss:2.1279177040139707\n",
      "train loss:2.166246953772255\n",
      "=== epoch:45, train acc:0.2125, test acc:0.29 ===\n",
      "train loss:2.15164584810089\n",
      "train loss:2.1717275120943365\n",
      "train loss:2.152024162628725\n",
      "train loss:2.1727661880807414\n",
      "=== epoch:46, train acc:0.2175, test acc:0.29 ===\n",
      "train loss:2.1734757865950867\n",
      "train loss:2.1264692576009745\n",
      "train loss:2.179117431884421\n",
      "train loss:2.1600845963405386\n",
      "=== epoch:47, train acc:0.2175, test acc:0.29 ===\n",
      "train loss:2.092094358820419\n",
      "train loss:2.1534576254169946\n",
      "train loss:2.1757615439995543\n",
      "train loss:2.1678834782061926\n",
      "=== epoch:48, train acc:0.215, test acc:0.27 ===\n",
      "train loss:2.1554300796788377\n",
      "train loss:2.116056381525511\n",
      "train loss:2.115518004771548\n",
      "train loss:2.1378783751576975\n",
      "=== epoch:49, train acc:0.215, test acc:0.27 ===\n",
      "train loss:2.1040932170718962\n",
      "train loss:2.159340125001883\n",
      "train loss:2.115398491054728\n",
      "train loss:2.1197011364343092\n",
      "=== epoch:50, train acc:0.215, test acc:0.27 ===\n",
      "train loss:2.152889850593821\n",
      "train loss:2.1872741048546778\n",
      "train loss:2.1660282109643387\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.27\n",
      "val_acc: 0.2700 | lr: 0.0009, weight_decay: 0.0000\n",
      "train loss:2.259141955481569\n",
      "=== epoch:1, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.2933846729504612\n",
      "train loss:2.260884767386258\n",
      "train loss:2.338332245626168\n",
      "train loss:2.3128444212253667\n",
      "=== epoch:2, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.345192211949362\n",
      "train loss:2.3612687010777798\n",
      "train loss:2.3206190086603793\n",
      "train loss:2.3759135448164455\n",
      "=== epoch:3, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3042338487656\n",
      "train loss:2.3536693548515433\n",
      "train loss:2.3250006974082806\n",
      "train loss:2.3360032988612245\n",
      "=== epoch:4, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3985785879149883\n",
      "train loss:2.2967125676882114\n",
      "train loss:2.4008618023311095\n",
      "train loss:2.2943399135076685\n",
      "=== epoch:5, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.32111561991477\n",
      "train loss:2.3401516198881973\n",
      "train loss:2.2873742967734887\n",
      "train loss:2.3636158793737545\n",
      "=== epoch:6, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3428711670839144\n",
      "train loss:2.3828525207904967\n",
      "train loss:2.3410425368470373\n",
      "train loss:2.314656184223002\n",
      "=== epoch:7, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3742400479547228\n",
      "train loss:2.3332212704185875\n",
      "train loss:2.3415644424187314\n",
      "train loss:2.3462607428218054\n",
      "=== epoch:8, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.323510732575493\n",
      "train loss:2.377054872693277\n",
      "train loss:2.3606031344131764\n",
      "train loss:2.34574560935638\n",
      "=== epoch:9, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3502698382924345\n",
      "train loss:2.41403825048001\n",
      "train loss:2.3079543584376943\n",
      "train loss:2.3628115169116644\n",
      "=== epoch:10, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.339226112624887\n",
      "train loss:2.3253890889639144\n",
      "train loss:2.3414094934448864\n",
      "train loss:2.3363296859846514\n",
      "=== epoch:11, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.381041447864663\n",
      "train loss:2.3757908902433735\n",
      "train loss:2.331699339901171\n",
      "train loss:2.2528978704152918\n",
      "=== epoch:12, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3590061471425456\n",
      "train loss:2.340565710760171\n",
      "train loss:2.3574816965558387\n",
      "train loss:2.377236754249642\n",
      "=== epoch:13, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.28121005299386\n",
      "train loss:2.305606123214899\n",
      "train loss:2.3360012965603185\n",
      "train loss:2.3342137899267774\n",
      "=== epoch:14, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.331247535519411\n",
      "train loss:2.3753048167935464\n",
      "train loss:2.3672350658638486\n",
      "train loss:2.3596355418355093\n",
      "=== epoch:15, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3575140388555114\n",
      "train loss:2.2981023484151955\n",
      "train loss:2.2878450842069604\n",
      "train loss:2.3344607715629357\n",
      "=== epoch:16, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3270441125720893\n",
      "train loss:2.2857661582139794\n",
      "train loss:2.34353079439549\n",
      "train loss:2.332017217050325\n",
      "=== epoch:17, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3472942785289757\n",
      "train loss:2.291465616019146\n",
      "train loss:2.3200935114847248\n",
      "train loss:2.366697814068574\n",
      "=== epoch:18, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.32589254486021\n",
      "train loss:2.3686696813782127\n",
      "train loss:2.3874378575718147\n",
      "train loss:2.3477312680941704\n",
      "=== epoch:19, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3160699954998143\n",
      "train loss:2.4256744773930343\n",
      "train loss:2.364124983704172\n",
      "train loss:2.4027042147730406\n",
      "=== epoch:20, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3119357795806303\n",
      "train loss:2.2917953962481104\n",
      "train loss:2.3363811470405733\n",
      "train loss:2.349079853808258\n",
      "=== epoch:21, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.329655130308885\n",
      "train loss:2.3428440690541628\n",
      "train loss:2.294056209483903\n",
      "train loss:2.3830756344295123\n",
      "=== epoch:22, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3889652992438863\n",
      "train loss:2.3014132167052814\n",
      "train loss:2.3694269426431536\n",
      "train loss:2.2832128448948503\n",
      "=== epoch:23, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.280886961604936\n",
      "train loss:2.352555237252166\n",
      "train loss:2.3372173277052064\n",
      "train loss:2.401421548798208\n",
      "=== epoch:24, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3709373837856167\n",
      "train loss:2.3380023103469694\n",
      "train loss:2.385060471012364\n",
      "train loss:2.360427582393346\n",
      "=== epoch:25, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3175809952355686\n",
      "train loss:2.4254594316721425\n",
      "train loss:2.336860525324038\n",
      "train loss:2.3520974904465444\n",
      "=== epoch:26, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3164422455736373\n",
      "train loss:2.302162782612015\n",
      "train loss:2.3264145301955255\n",
      "train loss:2.3647194414918786\n",
      "=== epoch:27, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3621713249167398\n",
      "train loss:2.2464382374416525\n",
      "train loss:2.3855140984918397\n",
      "train loss:2.364279869667656\n",
      "=== epoch:28, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3795023720119532\n",
      "train loss:2.3737373650656717\n",
      "train loss:2.330822323531648\n",
      "train loss:2.2930467713135863\n",
      "=== epoch:29, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3632093393157505\n",
      "train loss:2.2909455682176385\n",
      "train loss:2.314709530956881\n",
      "train loss:2.4104911544021377\n",
      "=== epoch:30, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3998568680591865\n",
      "train loss:2.3343649255113146\n",
      "train loss:2.3518858579146946\n",
      "train loss:2.357257270890893\n",
      "=== epoch:31, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.264609418233017\n",
      "train loss:2.3670048237585553\n",
      "train loss:2.3328763714664857\n",
      "train loss:2.3965730357705115\n",
      "=== epoch:32, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.340449855724411\n",
      "train loss:2.3477495880246297\n",
      "train loss:2.3627157433787156\n",
      "train loss:2.371780002160413\n",
      "=== epoch:33, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.37272865111213\n",
      "train loss:2.296058583040459\n",
      "train loss:2.3535895560405806\n",
      "train loss:2.3870523551362397\n",
      "=== epoch:34, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3012791198122673\n",
      "train loss:2.3181413483455637\n",
      "train loss:2.320180138835539\n",
      "train loss:2.3811039545530757\n",
      "=== epoch:35, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.249224571731897\n",
      "train loss:2.338039488117398\n",
      "train loss:2.3877690009241705\n",
      "train loss:2.3096827492224397\n",
      "=== epoch:36, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.2919231440681673\n",
      "train loss:2.2773837027235473\n",
      "train loss:2.359607101696486\n",
      "train loss:2.3436520385148127\n",
      "=== epoch:37, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3110628513703095\n",
      "train loss:2.3389489607335627\n",
      "train loss:2.323751466429479\n",
      "train loss:2.361887159623582\n",
      "=== epoch:38, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.282203890078516\n",
      "train loss:2.274820317304138\n",
      "train loss:2.3146029986852303\n",
      "train loss:2.296207694310122\n",
      "=== epoch:39, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3431807205008033\n",
      "train loss:2.3780758171355414\n",
      "train loss:2.2893546275715484\n",
      "train loss:2.3382993947632835\n",
      "=== epoch:40, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3298731413692986\n",
      "train loss:2.297656996203776\n",
      "train loss:2.3084599408161126\n",
      "train loss:2.384935948914065\n",
      "=== epoch:41, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.332681333693396\n",
      "train loss:2.322736232571476\n",
      "train loss:2.375794361893246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.407802206468693\n",
      "=== epoch:42, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3531605981956827\n",
      "train loss:2.3563203442682683\n",
      "train loss:2.3310362482313\n",
      "train loss:2.322854555085755\n",
      "=== epoch:43, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.341984679316987\n",
      "train loss:2.3584180484585273\n",
      "train loss:2.31364639450423\n",
      "train loss:2.309347639949402\n",
      "=== epoch:44, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.376386792607916\n",
      "train loss:2.265359096144234\n",
      "train loss:2.326665990877417\n",
      "train loss:2.390545136268423\n",
      "=== epoch:45, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3574609970113025\n",
      "train loss:2.313958987580241\n",
      "train loss:2.3524364421814346\n",
      "train loss:2.388326844658633\n",
      "=== epoch:46, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3478823919216487\n",
      "train loss:2.3576873129772715\n",
      "train loss:2.265032883304461\n",
      "train loss:2.2999025773906134\n",
      "=== epoch:47, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3258371652829966\n",
      "train loss:2.3588511660397233\n",
      "train loss:2.362211589950846\n",
      "train loss:2.329292157880652\n",
      "=== epoch:48, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3685900871162686\n",
      "train loss:2.3567243025860174\n",
      "train loss:2.337435534911202\n",
      "train loss:2.335306379960697\n",
      "=== epoch:49, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.3660832200965456\n",
      "train loss:2.279959110220657\n",
      "train loss:2.300981470226417\n",
      "train loss:2.313825054916219\n",
      "=== epoch:50, train acc:0.0925, test acc:0.12 ===\n",
      "train loss:2.2931701334565155\n",
      "train loss:2.303570326345576\n",
      "train loss:2.343313883092269\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.2811254248684385\n",
      "=== epoch:1, train acc:0.205, test acc:0.15 ===\n",
      "train loss:2.3465296173791335\n",
      "train loss:2.347377152528758\n",
      "train loss:2.377154822557995\n",
      "train loss:2.34920883756466\n",
      "=== epoch:2, train acc:0.205, test acc:0.15 ===\n",
      "train loss:2.3484333124436083\n",
      "train loss:2.383255917402802\n",
      "train loss:2.391142495909246\n",
      "train loss:2.3924887668927517\n",
      "=== epoch:3, train acc:0.205, test acc:0.15 ===\n",
      "train loss:2.335082290143562\n",
      "train loss:2.3953991679904223\n",
      "train loss:2.335761980952011\n",
      "train loss:2.3926420896759444\n",
      "=== epoch:4, train acc:0.21, test acc:0.15 ===\n",
      "train loss:2.3158977250409336\n",
      "train loss:2.3222249737703833\n",
      "train loss:2.285550535467874\n",
      "train loss:2.403343802586153\n",
      "=== epoch:5, train acc:0.21, test acc:0.15 ===\n",
      "train loss:2.3960038546513305\n",
      "train loss:2.3561459706550956\n",
      "train loss:2.2972857369211233\n",
      "train loss:2.3680508657029167\n",
      "=== epoch:6, train acc:0.21, test acc:0.16 ===\n",
      "train loss:2.3486503102675145\n",
      "train loss:2.2976294840862166\n",
      "train loss:2.3090055845784163\n",
      "train loss:2.312236603368565\n",
      "=== epoch:7, train acc:0.21, test acc:0.16 ===\n",
      "train loss:2.339564075146225\n",
      "train loss:2.352408525883104\n",
      "train loss:2.3484166210868778\n",
      "train loss:2.3351886510189255\n",
      "=== epoch:8, train acc:0.21, test acc:0.16 ===\n",
      "train loss:2.304600423505919\n",
      "train loss:2.3747529848913316\n",
      "train loss:2.353063135553007\n",
      "train loss:2.3275641424328923\n",
      "=== epoch:9, train acc:0.21, test acc:0.16 ===\n",
      "train loss:2.3765698157464548\n",
      "train loss:2.4220575050871602\n",
      "train loss:2.3442993319746317\n",
      "train loss:2.2827086195138837\n",
      "=== epoch:10, train acc:0.21, test acc:0.16 ===\n",
      "train loss:2.2959151456756848\n",
      "train loss:2.382058896843804\n",
      "train loss:2.343498772796976\n",
      "train loss:2.3156177426989846\n",
      "=== epoch:11, train acc:0.21, test acc:0.16 ===\n",
      "train loss:2.345296397084918\n",
      "train loss:2.3172980328746178\n",
      "train loss:2.3099885907989512\n",
      "train loss:2.333248095977532\n",
      "=== epoch:12, train acc:0.21, test acc:0.16 ===\n",
      "train loss:2.2811684124189027\n",
      "train loss:2.358492296119325\n",
      "train loss:2.3583307701935046\n",
      "train loss:2.3581477839290264\n",
      "=== epoch:13, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.366144469054284\n",
      "train loss:2.34529114313964\n",
      "train loss:2.3392504555678135\n",
      "train loss:2.34246006756626\n",
      "=== epoch:14, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.306567938871605\n",
      "train loss:2.364352034351625\n",
      "train loss:2.3293901776408217\n",
      "train loss:2.3055411260479\n",
      "=== epoch:15, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.3123847712392123\n",
      "train loss:2.248876236090555\n",
      "train loss:2.221017015488279\n",
      "train loss:2.341312850970634\n",
      "=== epoch:16, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.469487627009934\n",
      "train loss:2.3532731394170363\n",
      "train loss:2.3349756445386136\n",
      "train loss:2.3396017285874917\n",
      "=== epoch:17, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.3255825768971587\n",
      "train loss:2.351389712186204\n",
      "train loss:2.253598714263868\n",
      "train loss:2.343745207390764\n",
      "=== epoch:18, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.277997589768072\n",
      "train loss:2.318588590387965\n",
      "train loss:2.36108987325594\n",
      "train loss:2.384376699827686\n",
      "=== epoch:19, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.3278029664185893\n",
      "train loss:2.29068402176342\n",
      "train loss:2.3666951759291175\n",
      "train loss:2.3652473571450514\n",
      "=== epoch:20, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.313488770134157\n",
      "train loss:2.3256358643246777\n",
      "train loss:2.294010736518084\n",
      "train loss:2.3178036060835\n",
      "=== epoch:21, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.3290990767312367\n",
      "train loss:2.3347373739329247\n",
      "train loss:2.3450626421305905\n",
      "train loss:2.3742464503128753\n",
      "=== epoch:22, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.3032667068363155\n",
      "train loss:2.2238327985990347\n",
      "train loss:2.2804408229952435\n",
      "train loss:2.33392916195782\n",
      "=== epoch:23, train acc:0.2075, test acc:0.16 ===\n",
      "train loss:2.298586624311183\n",
      "train loss:2.306842497277978\n",
      "train loss:2.316828623239801\n",
      "train loss:2.3636636552349413\n",
      "=== epoch:24, train acc:0.2075, test acc:0.17 ===\n",
      "train loss:2.327741126887276\n",
      "train loss:2.32082673443612\n",
      "train loss:2.3324710249793\n",
      "train loss:2.3468567555569813\n",
      "=== epoch:25, train acc:0.2075, test acc:0.17 ===\n",
      "train loss:2.34614379248976\n",
      "train loss:2.3228478715381793\n",
      "train loss:2.347566811878576\n",
      "train loss:2.2814639168111115\n",
      "=== epoch:26, train acc:0.21, test acc:0.17 ===\n",
      "train loss:2.4076852378497513\n",
      "train loss:2.3716226824930327\n",
      "train loss:2.296871723865734\n",
      "train loss:2.282463774518281\n",
      "=== epoch:27, train acc:0.21, test acc:0.17 ===\n",
      "train loss:2.3265760236383883\n",
      "train loss:2.355512655392741\n",
      "train loss:2.3628526063448825\n",
      "train loss:2.3161068684792023\n",
      "=== epoch:28, train acc:0.21, test acc:0.17 ===\n",
      "train loss:2.317211021007628\n",
      "train loss:2.3991302091522835\n",
      "train loss:2.312241160955482\n",
      "train loss:2.3108678696626312\n",
      "=== epoch:29, train acc:0.21, test acc:0.17 ===\n",
      "train loss:2.27017295791655\n",
      "train loss:2.308892564138443\n",
      "train loss:2.3133615987493013\n",
      "train loss:2.225193793908435\n",
      "=== epoch:30, train acc:0.21, test acc:0.17 ===\n",
      "train loss:2.349050033541512\n",
      "train loss:2.3652287265533203\n",
      "train loss:2.3427199390709195\n",
      "train loss:2.323699740147728\n",
      "=== epoch:31, train acc:0.21, test acc:0.17 ===\n",
      "train loss:2.3677059600206074\n",
      "train loss:2.344615526502836\n",
      "train loss:2.2903781726141546\n",
      "train loss:2.2772143785278534\n",
      "=== epoch:32, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.298761505654486\n",
      "train loss:2.364500847502701\n",
      "train loss:2.3470839398065713\n",
      "train loss:2.2690176025932347\n",
      "=== epoch:33, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.2841695822837575\n",
      "train loss:2.2536553523112457\n",
      "train loss:2.374856302032853\n",
      "train loss:2.270502267264233\n",
      "=== epoch:34, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.3412032863307406\n",
      "train loss:2.336573827198372\n",
      "train loss:2.281025069953077\n",
      "train loss:2.360273455864102\n",
      "=== epoch:35, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.305420010189197\n",
      "train loss:2.3502803855504886\n",
      "train loss:2.335170356154781\n",
      "train loss:2.3300744324187628\n",
      "=== epoch:36, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.2970482624817055\n",
      "train loss:2.356318476024118\n",
      "train loss:2.321629942190135\n",
      "train loss:2.2861013576174805\n",
      "=== epoch:37, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.3595283525469495\n",
      "train loss:2.318391599655094\n",
      "train loss:2.29214926069276\n",
      "train loss:2.263865583270483\n",
      "=== epoch:38, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.2885268689963345\n",
      "train loss:2.345928521641451\n",
      "train loss:2.3481195049416415\n",
      "train loss:2.362173715782446\n",
      "=== epoch:39, train acc:0.2125, test acc:0.17 ===\n",
      "train loss:2.330130989527937\n",
      "train loss:2.3275458541049407\n",
      "train loss:2.329790610312871\n",
      "train loss:2.305579342248978\n",
      "=== epoch:40, train acc:0.2125, test acc:0.18 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3517530897520915\n",
      "train loss:2.2982975600692885\n",
      "train loss:2.301843178845598\n",
      "train loss:2.3372686065673114\n",
      "=== epoch:41, train acc:0.2125, test acc:0.18 ===\n",
      "train loss:2.2822479937882107\n",
      "train loss:2.374905818551501\n",
      "train loss:2.348478027333336\n",
      "train loss:2.3209616663572237\n",
      "=== epoch:42, train acc:0.2125, test acc:0.18 ===\n",
      "train loss:2.3486020211762946\n",
      "train loss:2.2922514137892605\n",
      "train loss:2.378881432175019\n",
      "train loss:2.3343155012352295\n",
      "=== epoch:43, train acc:0.2125, test acc:0.18 ===\n",
      "train loss:2.3868060041088213\n",
      "train loss:2.2603737105234707\n",
      "train loss:2.3420548057158945\n",
      "train loss:2.4022982935354986\n",
      "=== epoch:44, train acc:0.2125, test acc:0.18 ===\n",
      "train loss:2.4242744527514315\n",
      "train loss:2.3120193767178585\n",
      "train loss:2.346824598603173\n",
      "train loss:2.350323205137219\n",
      "=== epoch:45, train acc:0.215, test acc:0.18 ===\n",
      "train loss:2.377352368149419\n",
      "train loss:2.355665226810546\n",
      "train loss:2.2948934525329836\n",
      "train loss:2.3266494231013053\n",
      "=== epoch:46, train acc:0.2175, test acc:0.18 ===\n",
      "train loss:2.2810196702694463\n",
      "train loss:2.3223359889993156\n",
      "train loss:2.314527371221627\n",
      "train loss:2.2764703942934235\n",
      "=== epoch:47, train acc:0.2175, test acc:0.18 ===\n",
      "train loss:2.3154249158001483\n",
      "train loss:2.33113360192515\n",
      "train loss:2.3268382507373686\n",
      "train loss:2.351768313669094\n",
      "=== epoch:48, train acc:0.2175, test acc:0.18 ===\n",
      "train loss:2.3462141721250425\n",
      "train loss:2.381101880819357\n",
      "train loss:2.3129879026453777\n",
      "train loss:2.363620241734267\n",
      "=== epoch:49, train acc:0.2175, test acc:0.18 ===\n",
      "train loss:2.2471359429440394\n",
      "train loss:2.305251623294141\n",
      "train loss:2.29037502050576\n",
      "train loss:2.320815379824413\n",
      "=== epoch:50, train acc:0.2175, test acc:0.19 ===\n",
      "train loss:2.3090848791259626\n",
      "train loss:2.3034395619472785\n",
      "train loss:2.2939712205615077\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.19\n",
      "val_acc: 0.1900 | lr: 0.0001, weight_decay: 0.0000\n",
      "train loss:2.2968064046358334\n",
      "=== epoch:1, train acc:0.06, test acc:0.13 ===\n",
      "train loss:2.349390588346144\n",
      "train loss:2.455592683345365\n",
      "train loss:2.383166121927636\n",
      "train loss:2.331973020352629\n",
      "=== epoch:2, train acc:0.07, test acc:0.14 ===\n",
      "train loss:2.3584514250357382\n",
      "train loss:2.307833798103807\n",
      "train loss:2.3541313425946555\n",
      "train loss:2.2906634791629665\n",
      "=== epoch:3, train acc:0.08, test acc:0.15 ===\n",
      "train loss:2.3171403638142736\n",
      "train loss:2.245581910241865\n",
      "train loss:2.2662179931154713\n",
      "train loss:2.287557410259239\n",
      "=== epoch:4, train acc:0.0925, test acc:0.16 ===\n",
      "train loss:2.284016452516471\n",
      "train loss:2.2555692681778847\n",
      "train loss:2.1920307044453287\n",
      "train loss:2.288794067322118\n",
      "=== epoch:5, train acc:0.125, test acc:0.15 ===\n",
      "train loss:2.199681098277632\n",
      "train loss:2.23233765815719\n",
      "train loss:2.2554278325824075\n",
      "train loss:2.27449317835992\n",
      "=== epoch:6, train acc:0.15, test acc:0.16 ===\n",
      "train loss:2.213906577294136\n",
      "train loss:2.230269481825402\n",
      "train loss:2.205772962261811\n",
      "train loss:2.25351690385914\n",
      "=== epoch:7, train acc:0.175, test acc:0.2 ===\n",
      "train loss:2.1339763982406303\n",
      "train loss:2.2069972343761766\n",
      "train loss:2.2151581064566352\n",
      "train loss:2.2166278193646844\n",
      "=== epoch:8, train acc:0.2125, test acc:0.22 ===\n",
      "train loss:2.164435991325132\n",
      "train loss:2.1778036144750237\n",
      "train loss:2.162758462874787\n",
      "train loss:2.191147633410257\n",
      "=== epoch:9, train acc:0.2525, test acc:0.21 ===\n",
      "train loss:2.086076124301149\n",
      "train loss:2.1867513623514316\n",
      "train loss:2.1579773653716567\n",
      "train loss:2.124414879759229\n",
      "=== epoch:10, train acc:0.3025, test acc:0.23 ===\n",
      "train loss:2.0943740548142036\n",
      "train loss:2.126228431541152\n",
      "train loss:2.1451340308392606\n",
      "train loss:2.1634510593755794\n",
      "=== epoch:11, train acc:0.32, test acc:0.24 ===\n",
      "train loss:2.119628057110111\n",
      "train loss:2.116287624893425\n",
      "train loss:2.0922762098247176\n",
      "train loss:2.0335884620290705\n",
      "=== epoch:12, train acc:0.3575, test acc:0.27 ===\n",
      "train loss:2.0650625899960877\n",
      "train loss:2.0535045020188964\n",
      "train loss:2.079390159946875\n",
      "train loss:2.106249745378754\n",
      "=== epoch:13, train acc:0.355, test acc:0.29 ===\n",
      "train loss:2.0812059648881895\n",
      "train loss:2.0101870132602526\n",
      "train loss:2.037446111024566\n",
      "train loss:2.065703447766147\n",
      "=== epoch:14, train acc:0.3925, test acc:0.3 ===\n",
      "train loss:2.0182533184175755\n",
      "train loss:1.9315829567654046\n",
      "train loss:2.0068948304693923\n",
      "train loss:2.0618759891210936\n",
      "=== epoch:15, train acc:0.4, test acc:0.32 ===\n",
      "train loss:2.0057196256566066\n",
      "train loss:1.9868615659941395\n",
      "train loss:1.9298878045275676\n",
      "train loss:2.0186654604894256\n",
      "=== epoch:16, train acc:0.4075, test acc:0.32 ===\n",
      "train loss:1.9290513184972358\n",
      "train loss:1.952091232923653\n",
      "train loss:1.9234353433933258\n",
      "train loss:1.9138104563814127\n",
      "=== epoch:17, train acc:0.4275, test acc:0.36 ===\n",
      "train loss:1.999337264465058\n",
      "train loss:1.9809010967747276\n",
      "train loss:1.953497751152388\n",
      "train loss:1.9625163058499726\n",
      "=== epoch:18, train acc:0.4525, test acc:0.39 ===\n",
      "train loss:1.811958146788115\n",
      "train loss:1.9640654852185087\n",
      "train loss:1.9056500468958797\n",
      "train loss:1.8981173630264367\n",
      "=== epoch:19, train acc:0.455, test acc:0.41 ===\n",
      "train loss:1.9284396793923626\n",
      "train loss:1.8557005453809996\n",
      "train loss:1.872144484361778\n",
      "train loss:1.892652711025513\n",
      "=== epoch:20, train acc:0.4575, test acc:0.43 ===\n",
      "train loss:1.8724186867999708\n",
      "train loss:1.7631929211267023\n",
      "train loss:1.8815571735127818\n",
      "train loss:1.8813553119317827\n",
      "=== epoch:21, train acc:0.455, test acc:0.45 ===\n",
      "train loss:1.8188700403415534\n",
      "train loss:1.7883697258223157\n",
      "train loss:1.812144806817279\n",
      "train loss:1.793288755993459\n",
      "=== epoch:22, train acc:0.47, test acc:0.48 ===\n",
      "train loss:1.88978815173768\n",
      "train loss:1.6992233524934823\n",
      "train loss:1.7232172977786828\n",
      "train loss:1.7538567674752514\n",
      "=== epoch:23, train acc:0.47, test acc:0.49 ===\n",
      "train loss:1.7065261961829625\n",
      "train loss:1.6413515690942033\n",
      "train loss:1.7537834914657107\n",
      "train loss:1.7397294065528284\n",
      "=== epoch:24, train acc:0.505, test acc:0.51 ===\n",
      "train loss:1.7426036175624735\n",
      "train loss:1.76915179279403\n",
      "train loss:1.774318791647021\n",
      "train loss:1.730187686043632\n",
      "=== epoch:25, train acc:0.5375, test acc:0.5 ===\n",
      "train loss:1.6426905642849845\n",
      "train loss:1.610330511146757\n",
      "train loss:1.637172434692622\n",
      "train loss:1.5605733271250424\n",
      "=== epoch:26, train acc:0.5525, test acc:0.51 ===\n",
      "train loss:1.613711199119287\n",
      "train loss:1.702558433699323\n",
      "train loss:1.6203126190416877\n",
      "train loss:1.6518919458905277\n",
      "=== epoch:27, train acc:0.5725, test acc:0.51 ===\n",
      "train loss:1.595830600564097\n",
      "train loss:1.5850355063869122\n",
      "train loss:1.6176632773778463\n",
      "train loss:1.60642401697676\n",
      "=== epoch:28, train acc:0.585, test acc:0.52 ===\n",
      "train loss:1.5755361671837909\n",
      "train loss:1.538634810795612\n",
      "train loss:1.4908007151970815\n",
      "train loss:1.5815859732291422\n",
      "=== epoch:29, train acc:0.6, test acc:0.56 ===\n",
      "train loss:1.5535857339526289\n",
      "train loss:1.4097377452957764\n",
      "train loss:1.3999409151858457\n",
      "train loss:1.451072563767786\n",
      "=== epoch:30, train acc:0.6075, test acc:0.56 ===\n",
      "train loss:1.4639336734155928\n",
      "train loss:1.4823428354090125\n",
      "train loss:1.4687356593857246\n",
      "train loss:1.3684824295968778\n",
      "=== epoch:31, train acc:0.625, test acc:0.57 ===\n",
      "train loss:1.3658461740565735\n",
      "train loss:1.4974883277634157\n",
      "train loss:1.4173009803097607\n",
      "train loss:1.3861691136807928\n",
      "=== epoch:32, train acc:0.655, test acc:0.62 ===\n",
      "train loss:1.406883558043658\n",
      "train loss:1.3597819515050251\n",
      "train loss:1.4556193174762193\n",
      "train loss:1.360393203030849\n",
      "=== epoch:33, train acc:0.6675, test acc:0.63 ===\n",
      "train loss:1.3420498169940043\n",
      "train loss:1.3685442071362763\n",
      "train loss:1.2824384948116534\n",
      "train loss:1.3419491413286964\n",
      "=== epoch:34, train acc:0.695, test acc:0.67 ===\n",
      "train loss:1.478060097099133\n",
      "train loss:1.3487537402922074\n",
      "train loss:1.2189826796455743\n",
      "train loss:1.3074953643645577\n",
      "=== epoch:35, train acc:0.7, test acc:0.64 ===\n",
      "train loss:1.3640687987565923\n",
      "train loss:1.0938402392316753\n",
      "train loss:1.2253308706384154\n",
      "train loss:1.1953610909256764\n",
      "=== epoch:36, train acc:0.71, test acc:0.67 ===\n",
      "train loss:1.3472445908611734\n",
      "train loss:1.1589430130235925\n",
      "train loss:1.2553927065972044\n",
      "train loss:1.1097094175963735\n",
      "=== epoch:37, train acc:0.7425, test acc:0.68 ===\n",
      "train loss:1.1823531539407373\n",
      "train loss:1.1548075255616268\n",
      "train loss:1.169238453712359\n",
      "train loss:1.058510558954843\n",
      "=== epoch:38, train acc:0.7375, test acc:0.7 ===\n",
      "train loss:1.154492804067994\n",
      "train loss:1.1682622831289813\n",
      "train loss:1.0195439692969739\n",
      "train loss:1.0287090755319217\n",
      "=== epoch:39, train acc:0.77, test acc:0.7 ===\n",
      "train loss:1.0719098142674586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.086044555467743\n",
      "train loss:1.0497688724343541\n",
      "train loss:1.0197815545499553\n",
      "=== epoch:40, train acc:0.755, test acc:0.71 ===\n",
      "train loss:1.0191402305143413\n",
      "train loss:0.9886731355212725\n",
      "train loss:1.0515254222404926\n",
      "train loss:1.062427943395008\n",
      "=== epoch:41, train acc:0.775, test acc:0.71 ===\n",
      "train loss:0.9467701480316775\n",
      "train loss:0.9172562386839713\n",
      "train loss:1.0432030537975003\n",
      "train loss:0.8997875832889336\n",
      "=== epoch:42, train acc:0.78, test acc:0.72 ===\n",
      "train loss:1.0404386041455416\n",
      "train loss:1.0131617112606994\n",
      "train loss:0.8896020782882447\n",
      "train loss:0.8733523458210634\n",
      "=== epoch:43, train acc:0.78, test acc:0.74 ===\n",
      "train loss:1.1644201972188988\n",
      "train loss:0.793835558845012\n",
      "train loss:0.9076455920031461\n",
      "train loss:0.8483276413300527\n",
      "=== epoch:44, train acc:0.78, test acc:0.73 ===\n",
      "train loss:0.949099153448516\n",
      "train loss:0.9071166529347108\n",
      "train loss:0.8287456682141278\n",
      "train loss:0.8639742662449509\n",
      "=== epoch:45, train acc:0.7825, test acc:0.76 ===\n",
      "train loss:0.9303491353977309\n",
      "train loss:0.8426786428143215\n",
      "train loss:0.8178143541929846\n",
      "train loss:0.8562131557030953\n",
      "=== epoch:46, train acc:0.8125, test acc:0.73 ===\n",
      "train loss:1.0231939417467486\n",
      "train loss:0.9356901326872046\n",
      "train loss:0.8537837656022312\n",
      "train loss:0.8200612485461719\n",
      "=== epoch:47, train acc:0.805, test acc:0.74 ===\n",
      "train loss:0.7588844933577971\n",
      "train loss:0.6453322481279541\n",
      "train loss:0.7678738033244586\n",
      "train loss:0.8454681807193992\n",
      "=== epoch:48, train acc:0.8075, test acc:0.74 ===\n",
      "train loss:0.8548741999713866\n",
      "train loss:0.7091126528559626\n",
      "train loss:0.6331710122565476\n",
      "train loss:0.8210703384007363\n",
      "=== epoch:49, train acc:0.82, test acc:0.74 ===\n",
      "train loss:0.7412145553341624\n",
      "train loss:0.6076352096312335\n",
      "train loss:0.8694328910014875\n",
      "train loss:0.780660260539253\n",
      "=== epoch:50, train acc:0.84, test acc:0.73 ===\n",
      "train loss:0.7006566847683762\n",
      "train loss:0.6931027764780069\n",
      "train loss:0.602623218422973\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.73\n",
      "val_acc: 0.7300 | lr: 0.0070, weight_decay: 0.0000\n",
      "train loss:2.360241403877976\n",
      "=== epoch:1, train acc:0.0725, test acc:0.07 ===\n",
      "train loss:2.362395509843667\n",
      "train loss:2.352050844079149\n",
      "train loss:2.3934187660119064\n",
      "train loss:2.3578500379969523\n",
      "=== epoch:2, train acc:0.075, test acc:0.08 ===\n",
      "train loss:2.348586893290482\n",
      "train loss:2.4048912525385933\n",
      "train loss:2.3630939164955893\n",
      "train loss:2.359841955157545\n",
      "=== epoch:3, train acc:0.075, test acc:0.08 ===\n",
      "train loss:2.338621528431672\n",
      "train loss:2.3141948957032064\n",
      "train loss:2.334320113796551\n",
      "train loss:2.3183497423913506\n",
      "=== epoch:4, train acc:0.0875, test acc:0.09 ===\n",
      "train loss:2.2972075259835454\n",
      "train loss:2.3301243406327714\n",
      "train loss:2.3261433309614543\n",
      "train loss:2.32530344418765\n",
      "=== epoch:5, train acc:0.0925, test acc:0.08 ===\n",
      "train loss:2.279592542509801\n",
      "train loss:2.3186945078292753\n",
      "train loss:2.333384225079674\n",
      "train loss:2.303161377438806\n",
      "=== epoch:6, train acc:0.0975, test acc:0.1 ===\n",
      "train loss:2.2729509929875973\n",
      "train loss:2.2814415595529036\n",
      "train loss:2.278411735481476\n",
      "train loss:2.3285758716428693\n",
      "=== epoch:7, train acc:0.105, test acc:0.09 ===\n",
      "train loss:2.2697777891772195\n",
      "train loss:2.297627264750607\n",
      "train loss:2.3169165246720818\n",
      "train loss:2.2957604067640887\n",
      "=== epoch:8, train acc:0.1225, test acc:0.1 ===\n",
      "train loss:2.2928846641591893\n",
      "train loss:2.2791715127416183\n",
      "train loss:2.2615010940097995\n",
      "train loss:2.230389806576325\n",
      "=== epoch:9, train acc:0.1425, test acc:0.1 ===\n",
      "train loss:2.2528731411643452\n",
      "train loss:2.284778767106979\n",
      "train loss:2.281154269878026\n",
      "train loss:2.254455319602288\n",
      "=== epoch:10, train acc:0.1525, test acc:0.12 ===\n",
      "train loss:2.212162427406026\n",
      "train loss:2.235982937976483\n",
      "train loss:2.1875803985608107\n",
      "train loss:2.2359619422757735\n",
      "=== epoch:11, train acc:0.165, test acc:0.12 ===\n",
      "train loss:2.1967949412467385\n",
      "train loss:2.2076082450451437\n",
      "train loss:2.2083115681177077\n",
      "train loss:2.198415145161067\n",
      "=== epoch:12, train acc:0.2025, test acc:0.14 ===\n",
      "train loss:2.2139278371177906\n",
      "train loss:2.2116928549288666\n",
      "train loss:2.193769857260645\n",
      "train loss:2.201606325428665\n",
      "=== epoch:13, train acc:0.2225, test acc:0.15 ===\n",
      "train loss:2.2026688215102666\n",
      "train loss:2.167429328337306\n",
      "train loss:2.1569443640167125\n",
      "train loss:2.15306996915854\n",
      "=== epoch:14, train acc:0.23, test acc:0.17 ===\n",
      "train loss:2.2061048269315746\n",
      "train loss:2.1664853165911415\n",
      "train loss:2.211647059843013\n",
      "train loss:2.17686120620931\n",
      "=== epoch:15, train acc:0.255, test acc:0.19 ===\n",
      "train loss:2.145344509762078\n",
      "train loss:2.215368565465631\n",
      "train loss:2.139304231304682\n",
      "train loss:2.1914303760546963\n",
      "=== epoch:16, train acc:0.2625, test acc:0.2 ===\n",
      "train loss:2.149759175444039\n",
      "train loss:2.1249435286862117\n",
      "train loss:2.101462667332464\n",
      "train loss:2.1796773683688957\n",
      "=== epoch:17, train acc:0.2675, test acc:0.22 ===\n",
      "train loss:2.1340755345946203\n",
      "train loss:2.1584486741873943\n",
      "train loss:2.154710684861345\n",
      "train loss:2.0983079748257807\n",
      "=== epoch:18, train acc:0.2825, test acc:0.23 ===\n",
      "train loss:2.1556298912475857\n",
      "train loss:2.130226011429021\n",
      "train loss:2.1269391740775854\n",
      "train loss:2.1052772551903383\n",
      "=== epoch:19, train acc:0.3125, test acc:0.25 ===\n",
      "train loss:2.1639250046676\n",
      "train loss:2.15981996940515\n",
      "train loss:2.076594859216539\n",
      "train loss:2.083081114278935\n",
      "=== epoch:20, train acc:0.315, test acc:0.26 ===\n",
      "train loss:2.1055563876346897\n",
      "train loss:2.0902256350091872\n",
      "train loss:2.0687676902271446\n",
      "train loss:2.0814490327678805\n",
      "=== epoch:21, train acc:0.3275, test acc:0.25 ===\n",
      "train loss:2.109634619524436\n",
      "train loss:2.0530691520636926\n",
      "train loss:2.028657720827185\n",
      "train loss:2.0852401585812976\n",
      "=== epoch:22, train acc:0.33, test acc:0.27 ===\n",
      "train loss:2.0076383927560144\n",
      "train loss:2.0570866222180544\n",
      "train loss:2.043084358424061\n",
      "train loss:2.0503156331910835\n",
      "=== epoch:23, train acc:0.345, test acc:0.28 ===\n",
      "train loss:2.0283463080470767\n",
      "train loss:2.031129891710455\n",
      "train loss:1.9775841075573894\n",
      "train loss:2.0096416230560643\n",
      "=== epoch:24, train acc:0.3675, test acc:0.29 ===\n",
      "train loss:1.9284921172059928\n",
      "train loss:2.004666694920116\n",
      "train loss:2.0192624050907204\n",
      "train loss:1.958495118907337\n",
      "=== epoch:25, train acc:0.385, test acc:0.31 ===\n",
      "train loss:1.962894815903873\n",
      "train loss:1.96072585306718\n",
      "train loss:1.9843521609592678\n",
      "train loss:2.0250277704727324\n",
      "=== epoch:26, train acc:0.4, test acc:0.3 ===\n",
      "train loss:2.0643519759029267\n",
      "train loss:2.008814669786852\n",
      "train loss:1.8762775421923095\n",
      "train loss:1.9886209019700503\n",
      "=== epoch:27, train acc:0.4175, test acc:0.3 ===\n",
      "train loss:2.0098508988997685\n",
      "train loss:1.9619192139359907\n",
      "train loss:2.0494996800537524\n",
      "train loss:2.0242387653960314\n",
      "=== epoch:28, train acc:0.4325, test acc:0.31 ===\n",
      "train loss:1.9683941993721428\n",
      "train loss:1.9068336546512568\n",
      "train loss:2.0032528527489166\n",
      "train loss:1.9374477940076142\n",
      "=== epoch:29, train acc:0.4525, test acc:0.33 ===\n",
      "train loss:1.8834923558567411\n",
      "train loss:1.9573782383654756\n",
      "train loss:1.9865845652753507\n",
      "train loss:1.941989323601878\n",
      "=== epoch:30, train acc:0.45, test acc:0.37 ===\n",
      "train loss:1.9346633648435052\n",
      "train loss:1.82100622777981\n",
      "train loss:1.8882738438031297\n",
      "train loss:1.857904849931135\n",
      "=== epoch:31, train acc:0.47, test acc:0.35 ===\n",
      "train loss:1.910008996324794\n",
      "train loss:1.8728001715711677\n",
      "train loss:1.8532689109003668\n",
      "train loss:1.833850150825501\n",
      "=== epoch:32, train acc:0.475, test acc:0.36 ===\n",
      "train loss:1.888423751611558\n",
      "train loss:1.8532542404152408\n",
      "train loss:1.943712572481639\n",
      "train loss:1.8888214341592773\n",
      "=== epoch:33, train acc:0.4825, test acc:0.39 ===\n",
      "train loss:1.804114576489476\n",
      "train loss:1.9662981159131168\n",
      "train loss:1.8323552820098412\n",
      "train loss:1.911935317006121\n",
      "=== epoch:34, train acc:0.495, test acc:0.38 ===\n",
      "train loss:1.8109315691445371\n",
      "train loss:1.9244280801752323\n",
      "train loss:1.8225854933945953\n",
      "train loss:1.7652692474887035\n",
      "=== epoch:35, train acc:0.5, test acc:0.4 ===\n",
      "train loss:1.88867624906707\n",
      "train loss:1.692602309238247\n",
      "train loss:1.8677044932698266\n",
      "train loss:1.8580544240301555\n",
      "=== epoch:36, train acc:0.51, test acc:0.41 ===\n",
      "train loss:1.8204819732757511\n",
      "train loss:1.8246116625764501\n",
      "train loss:1.7863702237785812\n",
      "train loss:1.7513963991587538\n",
      "=== epoch:37, train acc:0.5225, test acc:0.39 ===\n",
      "train loss:1.7844029192626103\n",
      "train loss:1.7155054609703542\n",
      "train loss:1.8112219130198948\n",
      "train loss:1.749020896425376\n",
      "=== epoch:38, train acc:0.5375, test acc:0.41 ===\n",
      "train loss:1.836870008665343\n",
      "train loss:1.8017928741171771\n",
      "train loss:1.7972206907801567\n",
      "train loss:1.7758080474356293\n",
      "=== epoch:39, train acc:0.54, test acc:0.45 ===\n",
      "train loss:1.7225998211162954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.8058991559701625\n",
      "train loss:1.6502335117116342\n",
      "train loss:1.7225254965100514\n",
      "=== epoch:40, train acc:0.5475, test acc:0.43 ===\n",
      "train loss:1.776843926480675\n",
      "train loss:1.673014225673522\n",
      "train loss:1.795106678620351\n",
      "train loss:1.7067205912395298\n",
      "=== epoch:41, train acc:0.555, test acc:0.46 ===\n",
      "train loss:1.606643691800413\n",
      "train loss:1.763330195299341\n",
      "train loss:1.7360398450444503\n",
      "train loss:1.6423688374427912\n",
      "=== epoch:42, train acc:0.58, test acc:0.47 ===\n",
      "train loss:1.7576788362524067\n",
      "train loss:1.6336328591475424\n",
      "train loss:1.7357118505584512\n",
      "train loss:1.6950733890321876\n",
      "=== epoch:43, train acc:0.59, test acc:0.48 ===\n",
      "train loss:1.6057956155700661\n",
      "train loss:1.638646803790855\n",
      "train loss:1.6200912770193476\n",
      "train loss:1.6142470109174487\n",
      "=== epoch:44, train acc:0.5925, test acc:0.49 ===\n",
      "train loss:1.747951823336285\n",
      "train loss:1.655725419689435\n",
      "train loss:1.6255889537704302\n",
      "train loss:1.6010494561549942\n",
      "=== epoch:45, train acc:0.595, test acc:0.48 ===\n",
      "train loss:1.6142901584995244\n",
      "train loss:1.4995922003798257\n",
      "train loss:1.5511640142146264\n",
      "train loss:1.6080548835624957\n",
      "=== epoch:46, train acc:0.6075, test acc:0.49 ===\n",
      "train loss:1.5659707816594133\n",
      "train loss:1.5410108158120792\n",
      "train loss:1.5019811879834306\n",
      "train loss:1.4774503918427886\n",
      "=== epoch:47, train acc:0.6275, test acc:0.49 ===\n",
      "train loss:1.591481027480894\n",
      "train loss:1.5408535047167982\n",
      "train loss:1.6173935579692396\n",
      "train loss:1.5109010608654327\n",
      "=== epoch:48, train acc:0.6375, test acc:0.5 ===\n",
      "train loss:1.5083748312153604\n",
      "train loss:1.609488010555492\n",
      "train loss:1.5050747693536746\n",
      "train loss:1.5246260588920642\n",
      "=== epoch:49, train acc:0.6425, test acc:0.53 ===\n",
      "train loss:1.4877862511733577\n",
      "train loss:1.5213648626722027\n",
      "train loss:1.4270614326419142\n",
      "train loss:1.532565946639578\n",
      "=== epoch:50, train acc:0.6575, test acc:0.54 ===\n",
      "train loss:1.459700353896654\n",
      "train loss:1.3839588173958943\n",
      "train loss:1.3267959262458044\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.53\n",
      "val_acc: 0.5400 | lr: 0.0037, weight_decay: 0.0000\n",
      "train loss:2.5095388348546432\n",
      "=== epoch:1, train acc:0.1025, test acc:0.12 ===\n",
      "train loss:2.4897765234009253\n",
      "train loss:2.420597428244873\n",
      "train loss:2.485171719749979\n",
      "train loss:2.4272724183385233\n",
      "=== epoch:2, train acc:0.1275, test acc:0.13 ===\n",
      "train loss:2.3871130576558683\n",
      "train loss:2.481962070694398\n",
      "train loss:2.4479095086560414\n",
      "train loss:2.313277009021027\n",
      "=== epoch:3, train acc:0.125, test acc:0.13 ===\n",
      "train loss:2.479271832879951\n",
      "train loss:2.437696339388154\n",
      "train loss:2.4206219165967164\n",
      "train loss:2.3723164186939654\n",
      "=== epoch:4, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.300530768242226\n",
      "train loss:2.345993287540118\n",
      "train loss:2.272489334479075\n",
      "train loss:2.359381158498546\n",
      "=== epoch:5, train acc:0.14, test acc:0.06 ===\n",
      "train loss:2.293730613396833\n",
      "train loss:2.337729299246209\n",
      "train loss:2.3817359812907455\n",
      "train loss:2.38915315233634\n",
      "=== epoch:6, train acc:0.14, test acc:0.06 ===\n",
      "train loss:2.3226939760664878\n",
      "train loss:2.3594204459895094\n",
      "train loss:2.2607512756897656\n",
      "train loss:2.2588771953761686\n",
      "=== epoch:7, train acc:0.14, test acc:0.06 ===\n",
      "train loss:2.3254644234127433\n",
      "train loss:2.348863808866157\n",
      "train loss:2.3199453615673\n",
      "train loss:2.2393771390485515\n",
      "=== epoch:8, train acc:0.1425, test acc:0.08 ===\n",
      "train loss:2.323682957468379\n",
      "train loss:2.2764739014379476\n",
      "train loss:2.272292321641806\n",
      "train loss:2.350295962194346\n",
      "=== epoch:9, train acc:0.145, test acc:0.09 ===\n",
      "train loss:2.2897878831864715\n",
      "train loss:2.2488829031017694\n",
      "train loss:2.2743173009219366\n",
      "train loss:2.198534500803838\n",
      "=== epoch:10, train acc:0.1475, test acc:0.1 ===\n",
      "train loss:2.1929306406909843\n",
      "train loss:2.3003251420981985\n",
      "train loss:2.2622415188919547\n",
      "train loss:2.3260593712038955\n",
      "=== epoch:11, train acc:0.1475, test acc:0.1 ===\n",
      "train loss:2.1668945763480525\n",
      "train loss:2.2652541308010523\n",
      "train loss:2.2381828639576025\n",
      "train loss:2.2572125418367266\n",
      "=== epoch:12, train acc:0.15, test acc:0.09 ===\n",
      "train loss:2.2354146488957514\n",
      "train loss:2.2497266963575546\n",
      "train loss:2.203660615182562\n",
      "train loss:2.229788671814743\n",
      "=== epoch:13, train acc:0.1575, test acc:0.09 ===\n",
      "train loss:2.2537076416090427\n",
      "train loss:2.305288338228586\n",
      "train loss:2.1976432102038115\n",
      "train loss:2.1931132745505506\n",
      "=== epoch:14, train acc:0.16, test acc:0.09 ===\n",
      "train loss:2.23503230193277\n",
      "train loss:2.2236362687818727\n",
      "train loss:2.2027182887335255\n",
      "train loss:2.2883352904369576\n",
      "=== epoch:15, train acc:0.1625, test acc:0.09 ===\n",
      "train loss:2.2053477646345567\n",
      "train loss:2.2009963292231527\n",
      "train loss:2.243596356832939\n",
      "train loss:2.2478644765787372\n",
      "=== epoch:16, train acc:0.1675, test acc:0.09 ===\n",
      "train loss:2.1907824700446707\n",
      "train loss:2.193557242248459\n",
      "train loss:2.181661204635752\n",
      "train loss:2.1595064444772105\n",
      "=== epoch:17, train acc:0.1675, test acc:0.1 ===\n",
      "train loss:2.2000414354259124\n",
      "train loss:2.175954180555163\n",
      "train loss:2.110187866852565\n",
      "train loss:2.1598992691690206\n",
      "=== epoch:18, train acc:0.175, test acc:0.11 ===\n",
      "train loss:2.202144078245563\n",
      "train loss:2.137189753271721\n",
      "train loss:2.164189596957198\n",
      "train loss:2.159813136509747\n",
      "=== epoch:19, train acc:0.1775, test acc:0.11 ===\n",
      "train loss:2.1507277319589106\n",
      "train loss:2.2226306105306675\n",
      "train loss:2.1847229908291297\n",
      "train loss:2.1572392110466545\n",
      "=== epoch:20, train acc:0.19, test acc:0.14 ===\n",
      "train loss:2.1624730634617193\n",
      "train loss:2.2001438278446783\n",
      "train loss:2.1069609674177263\n",
      "train loss:2.2100940235995803\n",
      "=== epoch:21, train acc:0.195, test acc:0.15 ===\n",
      "train loss:2.2075999081201734\n",
      "train loss:2.1135323626533995\n",
      "train loss:2.151522342399869\n",
      "train loss:2.1111115816404222\n",
      "=== epoch:22, train acc:0.21, test acc:0.17 ===\n",
      "train loss:2.148000522266565\n",
      "train loss:2.1518481936186875\n",
      "train loss:2.1759927378973045\n",
      "train loss:2.1336267723611293\n",
      "=== epoch:23, train acc:0.225, test acc:0.19 ===\n",
      "train loss:2.1853783416873247\n",
      "train loss:2.092466124505083\n",
      "train loss:2.1674457919833334\n",
      "train loss:2.081941375074952\n",
      "=== epoch:24, train acc:0.2375, test acc:0.19 ===\n",
      "train loss:2.1309169418626714\n",
      "train loss:2.1186783398081426\n",
      "train loss:2.058097461775583\n",
      "train loss:2.124726264531661\n",
      "=== epoch:25, train acc:0.245, test acc:0.19 ===\n",
      "train loss:2.0879513143169808\n",
      "train loss:2.127465003482176\n",
      "train loss:2.0863502580552438\n",
      "train loss:2.1747264185405024\n",
      "=== epoch:26, train acc:0.2675, test acc:0.2 ===\n",
      "train loss:2.109985237948651\n",
      "train loss:2.084283029855402\n",
      "train loss:2.094273018344085\n",
      "train loss:2.076787654301531\n",
      "=== epoch:27, train acc:0.2825, test acc:0.21 ===\n",
      "train loss:2.1175496080465797\n",
      "train loss:2.1107183814950203\n",
      "train loss:2.1110682322422543\n",
      "train loss:2.134666699141432\n",
      "=== epoch:28, train acc:0.3, test acc:0.21 ===\n",
      "train loss:2.1231675860120927\n",
      "train loss:2.1386834678072892\n",
      "train loss:2.0834450290627746\n",
      "train loss:2.108389938286308\n",
      "=== epoch:29, train acc:0.3075, test acc:0.21 ===\n",
      "train loss:2.047035042777026\n",
      "train loss:2.10136355357246\n",
      "train loss:2.045331369104743\n",
      "train loss:2.0554596849434246\n",
      "=== epoch:30, train acc:0.3225, test acc:0.21 ===\n",
      "train loss:2.093021188980208\n",
      "train loss:2.083082990419463\n",
      "train loss:2.0122690660388267\n",
      "train loss:2.080901271929717\n",
      "=== epoch:31, train acc:0.3275, test acc:0.22 ===\n",
      "train loss:2.058305637943097\n",
      "train loss:2.0686360030998734\n",
      "train loss:2.0799304040326088\n",
      "train loss:2.0389466406572336\n",
      "=== epoch:32, train acc:0.3575, test acc:0.24 ===\n",
      "train loss:2.0364437060337637\n",
      "train loss:2.012441278134389\n",
      "train loss:2.0436890150427134\n",
      "train loss:2.0262703551595034\n",
      "=== epoch:33, train acc:0.36, test acc:0.24 ===\n",
      "train loss:2.039196543386041\n",
      "train loss:2.018593573666387\n",
      "train loss:2.0894441825952326\n",
      "train loss:2.0150845918033364\n",
      "=== epoch:34, train acc:0.3625, test acc:0.24 ===\n",
      "train loss:2.064990781091516\n",
      "train loss:2.055112500349491\n",
      "train loss:2.0182221958642583\n",
      "train loss:1.9998271294890533\n",
      "=== epoch:35, train acc:0.3625, test acc:0.24 ===\n",
      "train loss:2.1040763821991146\n",
      "train loss:1.9910555360975244\n",
      "train loss:1.9479624251080827\n",
      "train loss:2.047537944100503\n",
      "=== epoch:36, train acc:0.365, test acc:0.26 ===\n",
      "train loss:2.027224568595633\n",
      "train loss:1.9726702605618909\n",
      "train loss:1.9403916424932126\n",
      "train loss:2.021035990538258\n",
      "=== epoch:37, train acc:0.3675, test acc:0.27 ===\n",
      "train loss:1.9660748840584656\n",
      "train loss:2.040923743321231\n",
      "train loss:1.9394772684450146\n",
      "train loss:1.9669237267964805\n",
      "=== epoch:38, train acc:0.3875, test acc:0.28 ===\n",
      "train loss:1.9446778669576803\n",
      "train loss:2.0503238816807703\n",
      "train loss:1.9826047750300455\n",
      "train loss:1.9706010825092461\n",
      "=== epoch:39, train acc:0.39, test acc:0.28 ===\n",
      "train loss:1.929482541841441\n",
      "train loss:2.0179922747177788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.9400231663879284\n",
      "train loss:1.9469112499034464\n",
      "=== epoch:40, train acc:0.4075, test acc:0.29 ===\n",
      "train loss:2.0497535752740554\n",
      "train loss:1.9760444191634163\n",
      "train loss:2.0026535797758456\n",
      "train loss:2.0627504345834797\n",
      "=== epoch:41, train acc:0.425, test acc:0.31 ===\n",
      "train loss:1.9519675141946329\n",
      "train loss:1.9952384504618308\n",
      "train loss:1.9872599361829135\n",
      "train loss:1.9973075401418272\n",
      "=== epoch:42, train acc:0.4325, test acc:0.31 ===\n",
      "train loss:1.905220627848603\n",
      "train loss:1.9254574373602786\n",
      "train loss:1.9347359739376837\n",
      "train loss:1.9350902287445544\n",
      "=== epoch:43, train acc:0.4325, test acc:0.35 ===\n",
      "train loss:1.9887108613608677\n",
      "train loss:1.963580440540962\n",
      "train loss:1.94848655667465\n",
      "train loss:1.9479494343507566\n",
      "=== epoch:44, train acc:0.4525, test acc:0.36 ===\n",
      "train loss:2.0084263791248174\n",
      "train loss:1.9949272092605799\n",
      "train loss:1.8904255624404933\n",
      "train loss:1.9708441655112465\n",
      "=== epoch:45, train acc:0.455, test acc:0.37 ===\n",
      "train loss:1.9728324622813465\n",
      "train loss:1.8893461470563604\n",
      "train loss:1.863464100218563\n",
      "train loss:1.9312550686052514\n",
      "=== epoch:46, train acc:0.46, test acc:0.38 ===\n",
      "train loss:1.9333910449350995\n",
      "train loss:1.7642622444389824\n",
      "train loss:1.904612228482233\n",
      "train loss:1.8875992112699067\n",
      "=== epoch:47, train acc:0.4525, test acc:0.38 ===\n",
      "train loss:1.8690274775557814\n",
      "train loss:1.9254071230011378\n",
      "train loss:1.872576956725263\n",
      "train loss:1.8700575532471586\n",
      "=== epoch:48, train acc:0.455, test acc:0.38 ===\n",
      "train loss:1.8321509257311148\n",
      "train loss:1.8373276222344552\n",
      "train loss:1.8878202194230764\n",
      "train loss:1.946197977047977\n",
      "=== epoch:49, train acc:0.4575, test acc:0.39 ===\n",
      "train loss:1.836085724123698\n",
      "train loss:1.8140201572109087\n",
      "train loss:1.9205154834286366\n",
      "train loss:1.898053305295359\n",
      "=== epoch:50, train acc:0.485, test acc:0.41 ===\n",
      "train loss:1.8994885752285986\n",
      "train loss:1.938263418172617\n",
      "train loss:1.7705311291192227\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.41\n",
      "val_acc: 0.4100 | lr: 0.0023, weight_decay: 0.0000\n",
      "train loss:2.417514366091079\n",
      "=== epoch:1, train acc:0.0625, test acc:0.13 ===\n",
      "train loss:2.410632402159187\n",
      "train loss:2.422448360779682\n",
      "train loss:2.4154834307654998\n",
      "train loss:2.3707050948659876\n",
      "=== epoch:2, train acc:0.0725, test acc:0.13 ===\n",
      "train loss:2.397370814668304\n",
      "train loss:2.382057951111177\n",
      "train loss:2.4192689855165526\n",
      "train loss:2.383876270190537\n",
      "=== epoch:3, train acc:0.0725, test acc:0.13 ===\n",
      "train loss:2.4241240118256693\n",
      "train loss:2.4203729354702266\n",
      "train loss:2.390917512041007\n",
      "train loss:2.339461675151422\n",
      "=== epoch:4, train acc:0.0675, test acc:0.13 ===\n",
      "train loss:2.4162774621679635\n",
      "train loss:2.376141084183208\n",
      "train loss:2.359738013973164\n",
      "train loss:2.4125138012656526\n",
      "=== epoch:5, train acc:0.0725, test acc:0.13 ===\n",
      "train loss:2.380906596781863\n",
      "train loss:2.409636675675648\n",
      "train loss:2.358323533797034\n",
      "train loss:2.3495446096005197\n",
      "=== epoch:6, train acc:0.0775, test acc:0.13 ===\n",
      "train loss:2.3539059426627467\n",
      "train loss:2.334064064982195\n",
      "train loss:2.360837015813636\n",
      "train loss:2.3054035614421364\n",
      "=== epoch:7, train acc:0.075, test acc:0.13 ===\n",
      "train loss:2.379445245590538\n",
      "train loss:2.3204978710276234\n",
      "train loss:2.303887129632259\n",
      "train loss:2.375178888137347\n",
      "=== epoch:8, train acc:0.0775, test acc:0.13 ===\n",
      "train loss:2.389683211854722\n",
      "train loss:2.4009295074809307\n",
      "train loss:2.390599952322981\n",
      "train loss:2.372062856156569\n",
      "=== epoch:9, train acc:0.0875, test acc:0.13 ===\n",
      "train loss:2.334973640612002\n",
      "train loss:2.2960224905160893\n",
      "train loss:2.3282374302712774\n",
      "train loss:2.3691527499868417\n",
      "=== epoch:10, train acc:0.0925, test acc:0.13 ===\n",
      "train loss:2.3453043873849495\n",
      "train loss:2.323371930218206\n",
      "train loss:2.2834248096248952\n",
      "train loss:2.369221601544415\n",
      "=== epoch:11, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.341076905047843\n",
      "train loss:2.3090051425505074\n",
      "train loss:2.3557189201105175\n",
      "train loss:2.34021901732559\n",
      "=== epoch:12, train acc:0.095, test acc:0.13 ===\n",
      "train loss:2.3318923110433403\n",
      "train loss:2.335848134788328\n",
      "train loss:2.3687483539279826\n",
      "train loss:2.2958076673871797\n",
      "=== epoch:13, train acc:0.0975, test acc:0.13 ===\n",
      "train loss:2.3754671957127593\n",
      "train loss:2.3190560335285166\n",
      "train loss:2.295457293183706\n",
      "train loss:2.332967640718017\n",
      "=== epoch:14, train acc:0.1, test acc:0.13 ===\n",
      "train loss:2.3150285639158676\n",
      "train loss:2.292087884536271\n",
      "train loss:2.2904408747579605\n",
      "train loss:2.33733241783651\n",
      "=== epoch:15, train acc:0.1025, test acc:0.13 ===\n",
      "train loss:2.286077586548793\n",
      "train loss:2.334087212175984\n",
      "train loss:2.3045131336315947\n",
      "train loss:2.244040623843067\n",
      "=== epoch:16, train acc:0.11, test acc:0.13 ===\n",
      "train loss:2.288285479267274\n",
      "train loss:2.278915260154488\n",
      "train loss:2.252275380106034\n",
      "train loss:2.3376382259577837\n",
      "=== epoch:17, train acc:0.11, test acc:0.13 ===\n",
      "train loss:2.2942960847952\n",
      "train loss:2.2915677051884593\n",
      "train loss:2.283988691156954\n",
      "train loss:2.282023013742995\n",
      "=== epoch:18, train acc:0.11, test acc:0.13 ===\n",
      "train loss:2.254937162798378\n",
      "train loss:2.320190134815442\n",
      "train loss:2.2310888491068437\n",
      "train loss:2.2678406827317983\n",
      "=== epoch:19, train acc:0.115, test acc:0.14 ===\n",
      "train loss:2.3390438548165435\n",
      "train loss:2.264241630144225\n",
      "train loss:2.2792606721400777\n",
      "train loss:2.2652853300638025\n",
      "=== epoch:20, train acc:0.1225, test acc:0.13 ===\n",
      "train loss:2.249333076773272\n",
      "train loss:2.3024060884813404\n",
      "train loss:2.242380985319526\n",
      "train loss:2.265112567797692\n",
      "=== epoch:21, train acc:0.1175, test acc:0.14 ===\n",
      "train loss:2.267496789136531\n",
      "train loss:2.2437530700848876\n",
      "train loss:2.2631818182736736\n",
      "train loss:2.2640301718582574\n",
      "=== epoch:22, train acc:0.1175, test acc:0.16 ===\n",
      "train loss:2.2536653813665217\n",
      "train loss:2.3251462709432142\n",
      "train loss:2.258194125051345\n",
      "train loss:2.219312260082419\n",
      "=== epoch:23, train acc:0.1175, test acc:0.17 ===\n",
      "train loss:2.254375727459626\n",
      "train loss:2.294040187332947\n",
      "train loss:2.278937838272192\n",
      "train loss:2.2440437081429043\n",
      "=== epoch:24, train acc:0.1225, test acc:0.17 ===\n",
      "train loss:2.2200780674379095\n",
      "train loss:2.254652735812855\n",
      "train loss:2.266639965057703\n",
      "train loss:2.238008596684437\n",
      "=== epoch:25, train acc:0.1225, test acc:0.17 ===\n",
      "train loss:2.2650060593718138\n",
      "train loss:2.2329068435483195\n",
      "train loss:2.2613866796518223\n",
      "train loss:2.2704571519647274\n",
      "=== epoch:26, train acc:0.1275, test acc:0.17 ===\n",
      "train loss:2.2937778829420723\n",
      "train loss:2.2498045242266156\n",
      "train loss:2.246823342803082\n",
      "train loss:2.236040711414825\n",
      "=== epoch:27, train acc:0.13, test acc:0.18 ===\n",
      "train loss:2.255385567034727\n",
      "train loss:2.3043813844360397\n",
      "train loss:2.234258046795103\n",
      "train loss:2.267154340742541\n",
      "=== epoch:28, train acc:0.1325, test acc:0.19 ===\n",
      "train loss:2.3269029867695092\n",
      "train loss:2.2023853134172526\n",
      "train loss:2.241665874486768\n",
      "train loss:2.2083720793147634\n",
      "=== epoch:29, train acc:0.1325, test acc:0.19 ===\n",
      "train loss:2.2343089941434697\n",
      "train loss:2.254042070959816\n",
      "train loss:2.2417164091859894\n",
      "train loss:2.2139854103682963\n",
      "=== epoch:30, train acc:0.1325, test acc:0.19 ===\n",
      "train loss:2.2033385218006774\n",
      "train loss:2.216150222848838\n",
      "train loss:2.2377054165714116\n",
      "train loss:2.25397238480334\n",
      "=== epoch:31, train acc:0.135, test acc:0.19 ===\n",
      "train loss:2.2200710307137195\n",
      "train loss:2.2262397568128405\n",
      "train loss:2.259068399616031\n",
      "train loss:2.191976048529443\n",
      "=== epoch:32, train acc:0.1375, test acc:0.19 ===\n",
      "train loss:2.223743221495506\n",
      "train loss:2.2031329141340175\n",
      "train loss:2.2184191361548318\n",
      "train loss:2.235015741748691\n",
      "=== epoch:33, train acc:0.14, test acc:0.19 ===\n",
      "train loss:2.2170335407440094\n",
      "train loss:2.221380326428949\n",
      "train loss:2.236129671129924\n",
      "train loss:2.199239878387313\n",
      "=== epoch:34, train acc:0.1425, test acc:0.19 ===\n",
      "train loss:2.197117613160271\n",
      "train loss:2.215362886298557\n",
      "train loss:2.2346152966958117\n",
      "train loss:2.191907233838942\n",
      "=== epoch:35, train acc:0.15, test acc:0.2 ===\n",
      "train loss:2.217647911797769\n",
      "train loss:2.209630817388885\n",
      "train loss:2.192506407497644\n",
      "train loss:2.226446969144367\n",
      "=== epoch:36, train acc:0.1525, test acc:0.2 ===\n",
      "train loss:2.1939962150630197\n",
      "train loss:2.191019858175257\n",
      "train loss:2.2422309624555674\n",
      "train loss:2.1862538158365026\n",
      "=== epoch:37, train acc:0.1675, test acc:0.2 ===\n",
      "train loss:2.261149175507562\n",
      "train loss:2.1827680656705932\n",
      "train loss:2.2125975431034646\n",
      "train loss:2.222567020097797\n",
      "=== epoch:38, train acc:0.1725, test acc:0.2 ===\n",
      "train loss:2.2190432552148063\n",
      "train loss:2.195756640186021\n",
      "train loss:2.194094537276007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2013385699002836\n",
      "=== epoch:39, train acc:0.1725, test acc:0.2 ===\n",
      "train loss:2.1950855705454\n",
      "train loss:2.1780104304784227\n",
      "train loss:2.2276663388649585\n",
      "train loss:2.2167644749224706\n",
      "=== epoch:40, train acc:0.1775, test acc:0.2 ===\n",
      "train loss:2.1945805720067004\n",
      "train loss:2.214332175747066\n",
      "train loss:2.185360700269666\n",
      "train loss:2.2196835602001768\n",
      "=== epoch:41, train acc:0.1775, test acc:0.2 ===\n",
      "train loss:2.1794116327407718\n",
      "train loss:2.1627371770131574\n",
      "train loss:2.224095651988907\n",
      "train loss:2.133929371003751\n",
      "=== epoch:42, train acc:0.185, test acc:0.21 ===\n",
      "train loss:2.150517144219647\n",
      "train loss:2.2296221487189634\n",
      "train loss:2.1997318501236025\n",
      "train loss:2.176111438529611\n",
      "=== epoch:43, train acc:0.1925, test acc:0.21 ===\n",
      "train loss:2.1621844055255934\n",
      "train loss:2.1770194719239533\n",
      "train loss:2.130141456469733\n",
      "train loss:2.1448506594114725\n",
      "=== epoch:44, train acc:0.2, test acc:0.21 ===\n",
      "train loss:2.165762421784873\n",
      "train loss:2.2254751650627425\n",
      "train loss:2.1267388217565157\n",
      "train loss:2.1599412854953237\n",
      "=== epoch:45, train acc:0.21, test acc:0.21 ===\n",
      "train loss:2.195509035271013\n",
      "train loss:2.1814132897270224\n",
      "train loss:2.2382839018377045\n",
      "train loss:2.1869348370827475\n",
      "=== epoch:46, train acc:0.225, test acc:0.21 ===\n",
      "train loss:2.158482180579608\n",
      "train loss:2.1292512603139144\n",
      "train loss:2.188525638157506\n",
      "train loss:2.1478589586165002\n",
      "=== epoch:47, train acc:0.2275, test acc:0.21 ===\n",
      "train loss:2.1715226948171\n",
      "train loss:2.241820164729248\n",
      "train loss:2.1378295459473704\n",
      "train loss:2.137552167231683\n",
      "=== epoch:48, train acc:0.2325, test acc:0.21 ===\n",
      "train loss:2.154869065802283\n",
      "train loss:2.1961261527257356\n",
      "train loss:2.1389196449279138\n",
      "train loss:2.1687135209974926\n",
      "=== epoch:49, train acc:0.2375, test acc:0.21 ===\n",
      "train loss:2.178312862253664\n",
      "train loss:2.1506349928594153\n",
      "train loss:2.198150030008588\n",
      "train loss:2.1455844191612004\n",
      "=== epoch:50, train acc:0.245, test acc:0.23 ===\n",
      "train loss:2.156770619986848\n",
      "train loss:2.1618114507375634\n",
      "train loss:2.117954056594542\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.22\n",
      "val_acc: 0.2300 | lr: 0.0009, weight_decay: 0.0000\n",
      "train loss:2.5804030948894057\n",
      "=== epoch:1, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.426610400204874\n",
      "train loss:2.4449256682629716\n",
      "train loss:2.5867742519724732\n",
      "train loss:2.6192919348941457\n",
      "=== epoch:2, train acc:0.115, test acc:0.09 ===\n",
      "train loss:2.4991284476608384\n",
      "train loss:2.5375745608713434\n",
      "train loss:2.4667625955927024\n",
      "train loss:2.4606106225814512\n",
      "=== epoch:3, train acc:0.12, test acc:0.09 ===\n",
      "train loss:2.5383249701150463\n",
      "train loss:2.4835656124052705\n",
      "train loss:2.3776439859535112\n",
      "train loss:2.4218691991322507\n",
      "=== epoch:4, train acc:0.12, test acc:0.09 ===\n",
      "train loss:2.494393246262895\n",
      "train loss:2.4366716686339536\n",
      "train loss:2.4389468328384054\n",
      "train loss:2.3849043835040096\n",
      "=== epoch:5, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3864551022211877\n",
      "train loss:2.387388152540343\n",
      "train loss:2.4261542084052232\n",
      "train loss:2.4251066667556658\n",
      "=== epoch:6, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.3901602327359126\n",
      "train loss:2.455451996362298\n",
      "train loss:2.483814959854255\n",
      "train loss:2.4044569921107284\n",
      "=== epoch:7, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.4240290200579193\n",
      "train loss:2.4245288133543896\n",
      "train loss:2.3764114273025867\n",
      "train loss:2.4513513845333104\n",
      "=== epoch:8, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.4482751172205566\n",
      "train loss:2.3922722165313175\n",
      "train loss:2.4430429385234613\n",
      "train loss:2.4353999288941877\n",
      "=== epoch:9, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.3613618127380582\n",
      "train loss:2.394623995824382\n",
      "train loss:2.3798573683773028\n",
      "train loss:2.369634066838206\n",
      "=== epoch:10, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.3657917287820025\n",
      "train loss:2.402163610123963\n",
      "train loss:2.311175580161562\n",
      "train loss:2.2872912739179996\n",
      "=== epoch:11, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.36742056340135\n",
      "train loss:2.344846351768919\n",
      "train loss:2.441516944838911\n",
      "train loss:2.3032719034321336\n",
      "=== epoch:12, train acc:0.1225, test acc:0.09 ===\n",
      "train loss:2.366337722612811\n",
      "train loss:2.391439148187563\n",
      "train loss:2.3172828827101424\n",
      "train loss:2.3627237448882696\n",
      "=== epoch:13, train acc:0.125, test acc:0.09 ===\n",
      "train loss:2.400122479016925\n",
      "train loss:2.2962696601188575\n",
      "train loss:2.382566653377874\n",
      "train loss:2.336616246064749\n",
      "=== epoch:14, train acc:0.1275, test acc:0.1 ===\n",
      "train loss:2.383727653604452\n",
      "train loss:2.3212994879573676\n",
      "train loss:2.3724138010866445\n",
      "train loss:2.3399922766910155\n",
      "=== epoch:15, train acc:0.135, test acc:0.1 ===\n",
      "train loss:2.371846654283517\n",
      "train loss:2.324503779185105\n",
      "train loss:2.336948421494107\n",
      "train loss:2.3506212836452693\n",
      "=== epoch:16, train acc:0.1375, test acc:0.1 ===\n",
      "train loss:2.35000466402712\n",
      "train loss:2.3334012339209593\n",
      "train loss:2.4398233968703287\n",
      "train loss:2.307580221376559\n",
      "=== epoch:17, train acc:0.135, test acc:0.1 ===\n",
      "train loss:2.3938229737039753\n",
      "train loss:2.37477189762347\n",
      "train loss:2.350669543496829\n",
      "train loss:2.3297085382086515\n",
      "=== epoch:18, train acc:0.135, test acc:0.1 ===\n",
      "train loss:2.3723602481667125\n",
      "train loss:2.3839169136504235\n",
      "train loss:2.3522860479518317\n",
      "train loss:2.3437593140922894\n",
      "=== epoch:19, train acc:0.135, test acc:0.11 ===\n",
      "train loss:2.313864370439067\n",
      "train loss:2.36210549408111\n",
      "train loss:2.3342947475018576\n",
      "train loss:2.3508813884251603\n",
      "=== epoch:20, train acc:0.135, test acc:0.12 ===\n",
      "train loss:2.3439899614992084\n",
      "train loss:2.286859152675928\n",
      "train loss:2.350845945533662\n",
      "train loss:2.382803822422038\n",
      "=== epoch:21, train acc:0.14, test acc:0.12 ===\n",
      "train loss:2.2840643522057578\n",
      "train loss:2.327874562042637\n",
      "train loss:2.3269540651264617\n",
      "train loss:2.3109572189631282\n",
      "=== epoch:22, train acc:0.14, test acc:0.12 ===\n",
      "train loss:2.3107958771811767\n",
      "train loss:2.297385851603292\n",
      "train loss:2.343569836078121\n",
      "train loss:2.32891415454329\n",
      "=== epoch:23, train acc:0.1425, test acc:0.12 ===\n",
      "train loss:2.3687719258875646\n",
      "train loss:2.3127235002364115\n",
      "train loss:2.3099649599455065\n",
      "train loss:2.287482794921402\n",
      "=== epoch:24, train acc:0.145, test acc:0.12 ===\n",
      "train loss:2.341326203878957\n",
      "train loss:2.317640067996719\n",
      "train loss:2.3670652094495046\n",
      "train loss:2.2856025315937463\n",
      "=== epoch:25, train acc:0.1475, test acc:0.13 ===\n",
      "train loss:2.314313120216719\n",
      "train loss:2.278784073665057\n",
      "train loss:2.2510601838067856\n",
      "train loss:2.275224487332337\n",
      "=== epoch:26, train acc:0.1525, test acc:0.13 ===\n",
      "train loss:2.304904333956404\n",
      "train loss:2.281858978665166\n",
      "train loss:2.223511959829231\n",
      "train loss:2.3443856843001125\n",
      "=== epoch:27, train acc:0.1575, test acc:0.14 ===\n",
      "train loss:2.264684379383656\n",
      "train loss:2.3243190085056806\n",
      "train loss:2.2742819697298473\n",
      "train loss:2.3050568956087516\n",
      "=== epoch:28, train acc:0.16, test acc:0.14 ===\n",
      "train loss:2.271724585650789\n",
      "train loss:2.213294464480942\n",
      "train loss:2.299702975702751\n",
      "train loss:2.2857719224014357\n",
      "=== epoch:29, train acc:0.1625, test acc:0.15 ===\n",
      "train loss:2.2590758701385383\n",
      "train loss:2.2417633831202854\n",
      "train loss:2.3150717887901977\n",
      "train loss:2.301238496662388\n",
      "=== epoch:30, train acc:0.1625, test acc:0.15 ===\n",
      "train loss:2.3276191062308746\n",
      "train loss:2.2723459517484748\n",
      "train loss:2.203815880652924\n",
      "train loss:2.270739005642414\n",
      "=== epoch:31, train acc:0.16, test acc:0.16 ===\n",
      "train loss:2.2587114617428945\n",
      "train loss:2.272123249351338\n",
      "train loss:2.2500036199252738\n",
      "train loss:2.255869772671573\n",
      "=== epoch:32, train acc:0.1625, test acc:0.16 ===\n",
      "train loss:2.2822083444994377\n",
      "train loss:2.2444593880312356\n",
      "train loss:2.3168634972706768\n",
      "train loss:2.2785772212042334\n",
      "=== epoch:33, train acc:0.1625, test acc:0.16 ===\n",
      "train loss:2.317563782235949\n",
      "train loss:2.281185858216497\n",
      "train loss:2.337055224216503\n",
      "train loss:2.288485023034162\n",
      "=== epoch:34, train acc:0.165, test acc:0.16 ===\n",
      "train loss:2.2973536182543017\n",
      "train loss:2.301730374292736\n",
      "train loss:2.234899162252089\n",
      "train loss:2.3006089074655454\n",
      "=== epoch:35, train acc:0.165, test acc:0.16 ===\n",
      "train loss:2.2635161441110245\n",
      "train loss:2.2771057617287966\n",
      "train loss:2.2637829965754617\n",
      "train loss:2.298402094678959\n",
      "=== epoch:36, train acc:0.165, test acc:0.16 ===\n",
      "train loss:2.276337457406622\n",
      "train loss:2.250870537268724\n",
      "train loss:2.347896309195257\n",
      "train loss:2.268148835511473\n",
      "=== epoch:37, train acc:0.165, test acc:0.16 ===\n",
      "train loss:2.2597098265232662\n",
      "train loss:2.229113835804874\n",
      "train loss:2.2010751850575456\n",
      "train loss:2.308806396548426\n",
      "=== epoch:38, train acc:0.165, test acc:0.16 ===\n",
      "train loss:2.2857675299801805\n",
      "train loss:2.2547525437905334\n",
      "train loss:2.3009479387542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.245825550361671\n",
      "=== epoch:39, train acc:0.1675, test acc:0.16 ===\n",
      "train loss:2.304786968068981\n",
      "train loss:2.28520115717586\n",
      "train loss:2.284074536453743\n",
      "train loss:2.2791374511986784\n",
      "=== epoch:40, train acc:0.1675, test acc:0.16 ===\n",
      "train loss:2.240677173915396\n",
      "train loss:2.211933462057096\n",
      "train loss:2.2300425425469075\n",
      "train loss:2.2682783728348803\n",
      "=== epoch:41, train acc:0.1675, test acc:0.16 ===\n",
      "train loss:2.236882793984013\n",
      "train loss:2.279965451299425\n",
      "train loss:2.2472944985742935\n",
      "train loss:2.2565712423616473\n",
      "=== epoch:42, train acc:0.17, test acc:0.16 ===\n",
      "train loss:2.231302726236446\n",
      "train loss:2.2651736506623488\n",
      "train loss:2.2535940447705016\n",
      "train loss:2.2069102793464457\n",
      "=== epoch:43, train acc:0.175, test acc:0.16 ===\n",
      "train loss:2.2587649486502785\n",
      "train loss:2.2376397548315112\n",
      "train loss:2.2673214495196783\n",
      "train loss:2.230653950674122\n",
      "=== epoch:44, train acc:0.1775, test acc:0.16 ===\n",
      "train loss:2.209647386624359\n",
      "train loss:2.2140685965096902\n",
      "train loss:2.2485987998940264\n",
      "train loss:2.246654069813293\n",
      "=== epoch:45, train acc:0.18, test acc:0.16 ===\n",
      "train loss:2.206566267987522\n",
      "train loss:2.2005913789508504\n",
      "train loss:2.251979816864815\n",
      "train loss:2.194303170488119\n",
      "=== epoch:46, train acc:0.18, test acc:0.16 ===\n",
      "train loss:2.2316760691267263\n",
      "train loss:2.191063692363171\n",
      "train loss:2.2494999700583636\n",
      "train loss:2.213151311351517\n",
      "=== epoch:47, train acc:0.18, test acc:0.16 ===\n",
      "train loss:2.2885463523958336\n",
      "train loss:2.242348103239929\n",
      "train loss:2.2347619588233596\n",
      "train loss:2.2347031067918075\n",
      "=== epoch:48, train acc:0.18, test acc:0.16 ===\n",
      "train loss:2.255541109954029\n",
      "train loss:2.229545252609908\n",
      "train loss:2.276060336147616\n",
      "train loss:2.217679121814402\n",
      "=== epoch:49, train acc:0.18, test acc:0.16 ===\n",
      "train loss:2.2227986250731133\n",
      "train loss:2.245514786169106\n",
      "train loss:2.257037170654461\n",
      "train loss:2.2844129175857697\n",
      "=== epoch:50, train acc:0.18, test acc:0.16 ===\n",
      "train loss:2.2251786084783545\n",
      "train loss:2.2174008462055914\n",
      "train loss:2.1938797246157167\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.16\n",
      "val_acc: 0.1600 | lr: 0.0007, weight_decay: 0.0000\n",
      "train loss:2.410863480126755\n",
      "=== epoch:1, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.400299808822082\n",
      "train loss:2.3851609679121295\n",
      "train loss:2.4154435343652603\n",
      "train loss:2.3682042468060605\n",
      "=== epoch:2, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3836167240277923\n",
      "train loss:2.332578827542805\n",
      "train loss:2.359889568064907\n",
      "train loss:2.4207364252930086\n",
      "=== epoch:3, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.410514528122221\n",
      "train loss:2.4226137498480735\n",
      "train loss:2.341474663264554\n",
      "train loss:2.284074736128908\n",
      "=== epoch:4, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3809610742231433\n",
      "train loss:2.35114650280655\n",
      "train loss:2.3374920605976137\n",
      "train loss:2.3449387775168513\n",
      "=== epoch:5, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3728857959055083\n",
      "train loss:2.3855613747602433\n",
      "train loss:2.3906418736283612\n",
      "train loss:2.340765508067052\n",
      "=== epoch:6, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3727704997329035\n",
      "train loss:2.3272784506581465\n",
      "train loss:2.3662282929298213\n",
      "train loss:2.3201898505273437\n",
      "=== epoch:7, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3900100183927724\n",
      "train loss:2.3794720852891786\n",
      "train loss:2.337197320250373\n",
      "train loss:2.39231434839113\n",
      "=== epoch:8, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.380704439451851\n",
      "train loss:2.3818644217240266\n",
      "train loss:2.370223081946792\n",
      "train loss:2.341152061220553\n",
      "=== epoch:9, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.330946708171875\n",
      "train loss:2.3297168945790494\n",
      "train loss:2.4193506053097513\n",
      "train loss:2.379696982655543\n",
      "=== epoch:10, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3517466633283353\n",
      "train loss:2.350299578927808\n",
      "train loss:2.3799049924664746\n",
      "train loss:2.355428521570355\n",
      "=== epoch:11, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.355872467361642\n",
      "train loss:2.329771748886981\n",
      "train loss:2.4090959272892754\n",
      "train loss:2.32338027482876\n",
      "=== epoch:12, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.4170955771596185\n",
      "train loss:2.3694882870297698\n",
      "train loss:2.334501853337731\n",
      "train loss:2.385877857614119\n",
      "=== epoch:13, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.365056995553037\n",
      "train loss:2.3426242935440724\n",
      "train loss:2.32421214632822\n",
      "train loss:2.3486512422414583\n",
      "=== epoch:14, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.362510352588672\n",
      "train loss:2.372274068912009\n",
      "train loss:2.333055592449681\n",
      "train loss:2.3504294039049314\n",
      "=== epoch:15, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.392330229636415\n",
      "train loss:2.38273525207657\n",
      "train loss:2.3576999197002935\n",
      "train loss:2.365262619935614\n",
      "=== epoch:16, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.357152432243774\n",
      "train loss:2.2817666727480828\n",
      "train loss:2.383584400610667\n",
      "train loss:2.3320067132044686\n",
      "=== epoch:17, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.401308978567801\n",
      "train loss:2.3716641808125325\n",
      "train loss:2.3708213591842036\n",
      "train loss:2.4030028294833126\n",
      "=== epoch:18, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3394958039806473\n",
      "train loss:2.38595518761715\n",
      "train loss:2.3841403217693355\n",
      "train loss:2.3368956360412616\n",
      "=== epoch:19, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3184470800122154\n",
      "train loss:2.3419541036374154\n",
      "train loss:2.392466413518895\n",
      "train loss:2.3731426034294514\n",
      "=== epoch:20, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3116297737512075\n",
      "train loss:2.378817908648335\n",
      "train loss:2.3795749078294155\n",
      "train loss:2.3447399090840126\n",
      "=== epoch:21, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.348808451351957\n",
      "train loss:2.339333352776132\n",
      "train loss:2.3800223708724983\n",
      "train loss:2.365173606537397\n",
      "=== epoch:22, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3732325099329943\n",
      "train loss:2.344642655983326\n",
      "train loss:2.3071500637959734\n",
      "train loss:2.366664771799628\n",
      "=== epoch:23, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3942811747524115\n",
      "train loss:2.3013771512626886\n",
      "train loss:2.325319215559926\n",
      "train loss:2.4897450186041756\n",
      "=== epoch:24, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3357428690831834\n",
      "train loss:2.3358011124000617\n",
      "train loss:2.384903006082074\n",
      "train loss:2.360895820749793\n",
      "=== epoch:25, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.397389970885752\n",
      "train loss:2.3690346192833416\n",
      "train loss:2.376991074605023\n",
      "train loss:2.357362063780459\n",
      "=== epoch:26, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.2896364721879348\n",
      "train loss:2.333894218742825\n",
      "train loss:2.3869479421671365\n",
      "train loss:2.391390136059218\n",
      "=== epoch:27, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.366123852953629\n",
      "train loss:2.3487189849336914\n",
      "train loss:2.3926571972201245\n",
      "train loss:2.370656434203883\n",
      "=== epoch:28, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.351310264345254\n",
      "train loss:2.43301387027225\n",
      "train loss:2.321121788613096\n",
      "train loss:2.3773739878548397\n",
      "=== epoch:29, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3557694452136344\n",
      "train loss:2.376398478260782\n",
      "train loss:2.3594221171942116\n",
      "train loss:2.3552936488640808\n",
      "=== epoch:30, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.387225708469452\n",
      "train loss:2.3434185004346357\n",
      "train loss:2.3830271008581163\n",
      "train loss:2.340393940070521\n",
      "=== epoch:31, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.37855991247065\n",
      "train loss:2.3593262112839466\n",
      "train loss:2.3774343245723837\n",
      "train loss:2.3377224212468644\n",
      "=== epoch:32, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.353700482285053\n",
      "train loss:2.3742630244044687\n",
      "train loss:2.3719904997281733\n",
      "train loss:2.3987739934081027\n",
      "=== epoch:33, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3750586278449792\n",
      "train loss:2.35648388248703\n",
      "train loss:2.326120221260044\n",
      "train loss:2.353924662216508\n",
      "=== epoch:34, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3515890518940608\n",
      "train loss:2.3467269052627198\n",
      "train loss:2.3500545396458543\n",
      "train loss:2.3794294422120275\n",
      "=== epoch:35, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3805608757128023\n",
      "train loss:2.3406821874714585\n",
      "train loss:2.383048078235432\n",
      "train loss:2.364677143596875\n",
      "=== epoch:36, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.393149496280701\n",
      "train loss:2.35164898808921\n",
      "train loss:2.2916327825642404\n",
      "train loss:2.3843031214803614\n",
      "=== epoch:37, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3489333917000037\n",
      "train loss:2.3647308425822873\n",
      "train loss:2.35827589670996\n",
      "train loss:2.378710798489462\n",
      "=== epoch:38, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.338359439375417\n",
      "train loss:2.4231077141424247\n",
      "train loss:2.383476083155347\n",
      "train loss:2.314723875626188\n",
      "=== epoch:39, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3698342095041434\n",
      "train loss:2.358411355990863\n",
      "train loss:2.366109371361747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3405380419412407\n",
      "=== epoch:40, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.384074713149115\n",
      "train loss:2.3498706525601603\n",
      "train loss:2.354069785820663\n",
      "train loss:2.4011419405551075\n",
      "=== epoch:41, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3681330987105498\n",
      "train loss:2.4031906957498546\n",
      "train loss:2.328964961022255\n",
      "train loss:2.332840892456905\n",
      "=== epoch:42, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3119851104504545\n",
      "train loss:2.3464665439686954\n",
      "train loss:2.3583655715089713\n",
      "train loss:2.293659411753403\n",
      "=== epoch:43, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.303276779447583\n",
      "train loss:2.384607791055729\n",
      "train loss:2.340734234043668\n",
      "train loss:2.4023071086637935\n",
      "=== epoch:44, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.4067991459067093\n",
      "train loss:2.3966871986097487\n",
      "train loss:2.3683448414605746\n",
      "train loss:2.393423586916384\n",
      "=== epoch:45, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.320550989888034\n",
      "train loss:2.373916851290463\n",
      "train loss:2.3391673861845312\n",
      "train loss:2.4042380636494434\n",
      "=== epoch:46, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.3663734115500477\n",
      "train loss:2.393634027461517\n",
      "train loss:2.373348761372513\n",
      "train loss:2.365813796808724\n",
      "=== epoch:47, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.383725230160912\n",
      "train loss:2.4083292108216283\n",
      "train loss:2.41416848757538\n",
      "train loss:2.336129182989962\n",
      "=== epoch:48, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.427834012170849\n",
      "train loss:2.4058812354955084\n",
      "train loss:2.3940361723827346\n",
      "train loss:2.3664447157476816\n",
      "=== epoch:49, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.385673793624541\n",
      "train loss:2.35492563171788\n",
      "train loss:2.3613825458897084\n",
      "train loss:2.3608113130510464\n",
      "=== epoch:50, train acc:0.0525, test acc:0.12 ===\n",
      "train loss:2.349146540454996\n",
      "train loss:2.4279470101240315\n",
      "train loss:2.4030339436698545\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.12\n",
      "val_acc: 0.1200 | lr: 0.0000, weight_decay: 0.0000\n",
      "train loss:2.3698151989113643\n",
      "=== epoch:1, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.4002146227999965\n",
      "train loss:2.3527077293307825\n",
      "train loss:2.376097412394267\n",
      "train loss:2.387420302236752\n",
      "=== epoch:2, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3464170550418486\n",
      "train loss:2.3299752469376864\n",
      "train loss:2.374459513351251\n",
      "train loss:2.369244979455322\n",
      "=== epoch:3, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.3665306176821677\n",
      "train loss:2.303475640169427\n",
      "train loss:2.3985241017064047\n",
      "train loss:2.364098795083513\n",
      "=== epoch:4, train acc:0.0925, test acc:0.1 ===\n",
      "train loss:2.390232634921893\n",
      "train loss:2.3645440740527732\n",
      "train loss:2.3636603650760164\n",
      "train loss:2.3294042518000153\n",
      "=== epoch:5, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.38988319234218\n",
      "train loss:2.3507527028790447\n",
      "train loss:2.368888972796181\n",
      "train loss:2.3594443761320574\n",
      "=== epoch:6, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.391395891397965\n",
      "train loss:2.3589126207324385\n",
      "train loss:2.3356350489531756\n",
      "train loss:2.3557444275785553\n",
      "=== epoch:7, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.34393586513151\n",
      "train loss:2.360922813038905\n",
      "train loss:2.383665940114984\n",
      "train loss:2.3830567991988065\n",
      "=== epoch:8, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.3310528614688364\n",
      "train loss:2.389862325885296\n",
      "train loss:2.347767461470505\n",
      "train loss:2.3458276061307997\n",
      "=== epoch:9, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3359777499104815\n",
      "train loss:2.337081621885238\n",
      "train loss:2.387760287690806\n",
      "train loss:2.3959696112158513\n",
      "=== epoch:10, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.3779091893617115\n",
      "train loss:2.314579977202466\n",
      "train loss:2.3516128020859894\n",
      "train loss:2.3251141760943086\n",
      "=== epoch:11, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.320642826431462\n",
      "train loss:2.3564470575853793\n",
      "train loss:2.3832899243293366\n",
      "train loss:2.371849966567571\n",
      "=== epoch:12, train acc:0.095, test acc:0.09 ===\n",
      "train loss:2.3570544975696994\n",
      "train loss:2.318723260457282\n",
      "train loss:2.3435103853028734\n",
      "train loss:2.3304632597301045\n",
      "=== epoch:13, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.3500582401301258\n",
      "train loss:2.3594619743392866\n",
      "train loss:2.3182333446989642\n",
      "train loss:2.3713185041042886\n",
      "=== epoch:14, train acc:0.0925, test acc:0.09 ===\n",
      "train loss:2.314208992483834\n",
      "train loss:2.38410025516881\n",
      "train loss:2.33762111211641\n",
      "train loss:2.34876976829478\n",
      "=== epoch:15, train acc:0.0925, test acc:0.08 ===\n",
      "train loss:2.353265893363459\n",
      "train loss:2.3593201404850253\n",
      "train loss:2.368175125511568\n",
      "train loss:2.3264396294164023\n",
      "=== epoch:16, train acc:0.0925, test acc:0.08 ===\n",
      "train loss:2.3468111801190967\n",
      "train loss:2.327077991032929\n",
      "train loss:2.349352210519306\n",
      "train loss:2.362742979071076\n",
      "=== epoch:17, train acc:0.095, test acc:0.08 ===\n",
      "train loss:2.367562398607976\n",
      "train loss:2.308377229816855\n",
      "train loss:2.318734508037686\n",
      "train loss:2.3827862568425315\n",
      "=== epoch:18, train acc:0.0975, test acc:0.08 ===\n",
      "train loss:2.3514154991889313\n",
      "train loss:2.359792156147865\n",
      "train loss:2.3791040646749084\n",
      "train loss:2.357287326487618\n",
      "=== epoch:19, train acc:0.0975, test acc:0.07 ===\n",
      "train loss:2.3637532538934733\n",
      "train loss:2.373675074028587\n",
      "train loss:2.3506772441674095\n",
      "train loss:2.3523324817555777\n",
      "=== epoch:20, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.329698928907272\n",
      "train loss:2.3595148052055985\n",
      "train loss:2.3700460184844045\n",
      "train loss:2.328383259855563\n",
      "=== epoch:21, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.367245293841682\n",
      "train loss:2.3154074288819513\n",
      "train loss:2.3430016130472686\n",
      "train loss:2.360191992913252\n",
      "=== epoch:22, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3365623366858106\n",
      "train loss:2.3404887894528756\n",
      "train loss:2.340632602932606\n",
      "train loss:2.286410125474718\n",
      "=== epoch:23, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.2936092095774248\n",
      "train loss:2.315126632303858\n",
      "train loss:2.3176334269508767\n",
      "train loss:2.3107582731152556\n",
      "=== epoch:24, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.338938360139744\n",
      "train loss:2.385240097838995\n",
      "train loss:2.3839439796281545\n",
      "train loss:2.3360855953111397\n",
      "=== epoch:25, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3438217940152675\n",
      "train loss:2.3274637109858456\n",
      "train loss:2.32912511940151\n",
      "train loss:2.3325594542301795\n",
      "=== epoch:26, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3548667354398516\n",
      "train loss:2.386144264388663\n",
      "train loss:2.3336298951578662\n",
      "train loss:2.329186839925989\n",
      "=== epoch:27, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.353608628368487\n",
      "train loss:2.3615452433915873\n",
      "train loss:2.3508505417936925\n",
      "train loss:2.3424628407041497\n",
      "=== epoch:28, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.330118547538365\n",
      "train loss:2.3710896685169867\n",
      "train loss:2.3197525024973613\n",
      "train loss:2.2923651713129543\n",
      "=== epoch:29, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3590837384828722\n",
      "train loss:2.323894697644572\n",
      "train loss:2.3226909492220638\n",
      "train loss:2.3476733693798435\n",
      "=== epoch:30, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3172309352719145\n",
      "train loss:2.3381248071526297\n",
      "train loss:2.3240032300293185\n",
      "train loss:2.303702553409323\n",
      "=== epoch:31, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3372451693681486\n",
      "train loss:2.319805024547118\n",
      "train loss:2.3197286482225175\n",
      "train loss:2.347120344055705\n",
      "=== epoch:32, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.345817970989591\n",
      "train loss:2.3497822102636334\n",
      "train loss:2.352912389960268\n",
      "train loss:2.3241218122467973\n",
      "=== epoch:33, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3570878215233524\n",
      "train loss:2.337254855009495\n",
      "train loss:2.3489702420095804\n",
      "train loss:2.328022244594531\n",
      "=== epoch:34, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.304820483294522\n",
      "train loss:2.3040438284995046\n",
      "train loss:2.3336806489890702\n",
      "train loss:2.3125007887524625\n",
      "=== epoch:35, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3318478248838344\n",
      "train loss:2.381252741333189\n",
      "train loss:2.3212440105672485\n",
      "train loss:2.333632225184295\n",
      "=== epoch:36, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3172494587525523\n",
      "train loss:2.320521309036518\n",
      "train loss:2.2878751867238063\n",
      "train loss:2.3263940509624303\n",
      "=== epoch:37, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.338043979593683\n",
      "train loss:2.3504564949232702\n",
      "train loss:2.3447350202273176\n",
      "train loss:2.30323698357339\n",
      "=== epoch:38, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.323641020133101\n",
      "train loss:2.301277070106715\n",
      "train loss:2.34626444700892\n",
      "train loss:2.3114041715335714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:39, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.31021698753966\n",
      "train loss:2.317164141098281\n",
      "train loss:2.3530523498268465\n",
      "train loss:2.3235849126780037\n",
      "=== epoch:40, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.364732842566374\n",
      "train loss:2.335399405906203\n",
      "train loss:2.336567076430168\n",
      "train loss:2.3596072997700253\n",
      "=== epoch:41, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3629799039610164\n",
      "train loss:2.303508384034972\n",
      "train loss:2.3394309165473532\n",
      "train loss:2.308020839947803\n",
      "=== epoch:42, train acc:0.1, test acc:0.07 ===\n",
      "train loss:2.3217694347832665\n",
      "train loss:2.358656438346185\n",
      "train loss:2.342676305111854\n",
      "train loss:2.328986259712175\n",
      "=== epoch:43, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.343098646724504\n",
      "train loss:2.3123338887525575\n",
      "train loss:2.353704212599297\n",
      "train loss:2.3345089172764344\n",
      "=== epoch:44, train acc:0.1025, test acc:0.07 ===\n",
      "train loss:2.3248393351177303\n",
      "train loss:2.3586762853187726\n",
      "train loss:2.304390689855494\n",
      "train loss:2.3490813390886105\n",
      "=== epoch:45, train acc:0.1075, test acc:0.07 ===\n",
      "train loss:2.318033186842735\n",
      "train loss:2.336567614555578\n",
      "train loss:2.295547252548167\n",
      "train loss:2.3690841618102128\n",
      "=== epoch:46, train acc:0.11, test acc:0.07 ===\n",
      "train loss:2.3305162265669637\n",
      "train loss:2.327479133482965\n",
      "train loss:2.336308243026791\n",
      "train loss:2.297669942256322\n",
      "=== epoch:47, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.313514026348244\n",
      "train loss:2.2804138337483444\n",
      "train loss:2.2969221387562953\n",
      "train loss:2.2908117163816644\n",
      "=== epoch:48, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.313239928636979\n",
      "train loss:2.317270537400221\n",
      "train loss:2.3311271133288454\n",
      "train loss:2.299284372746712\n",
      "=== epoch:49, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.323366359564787\n",
      "train loss:2.3534778545508113\n",
      "train loss:2.3334076353618576\n",
      "train loss:2.306230553494154\n",
      "=== epoch:50, train acc:0.1125, test acc:0.07 ===\n",
      "train loss:2.377657155620211\n",
      "train loss:2.337609263269442\n",
      "train loss:2.3149850574407123\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.07\n",
      "val_acc: 0.0700 | lr: 0.0003, weight_decay: 0.0000\n",
      "train loss:2.4248184346135284\n",
      "=== epoch:1, train acc:0.08, test acc:0.11 ===\n",
      "train loss:2.3827063746768604\n",
      "train loss:2.4498734140735654\n",
      "train loss:2.410736839688415\n",
      "train loss:2.536698071172024\n",
      "=== epoch:2, train acc:0.08, test acc:0.11 ===\n",
      "train loss:2.418072884360677\n",
      "train loss:2.3929286042998843\n",
      "train loss:2.418040217897345\n",
      "train loss:2.335917998915403\n",
      "=== epoch:3, train acc:0.08, test acc:0.11 ===\n",
      "train loss:2.3755771178599323\n",
      "train loss:2.431407676431966\n",
      "train loss:2.417049472338327\n",
      "train loss:2.399264604056477\n",
      "=== epoch:4, train acc:0.08, test acc:0.11 ===\n",
      "train loss:2.4280287673578407\n",
      "train loss:2.429948220660233\n",
      "train loss:2.3648494997494764\n",
      "train loss:2.4228706365501997\n",
      "=== epoch:5, train acc:0.0825, test acc:0.11 ===\n",
      "train loss:2.4699205772459005\n",
      "train loss:2.41020979570505\n",
      "train loss:2.413205364238212\n",
      "train loss:2.4458138557547238\n",
      "=== epoch:6, train acc:0.0825, test acc:0.11 ===\n",
      "train loss:2.424172772065242\n",
      "train loss:2.3468166871976766\n",
      "train loss:2.441608779201541\n",
      "train loss:2.3795235841604305\n",
      "=== epoch:7, train acc:0.0825, test acc:0.11 ===\n",
      "train loss:2.3960435345616626\n",
      "train loss:2.4363186981865868\n",
      "train loss:2.5088385160444835\n",
      "train loss:2.456168979930496\n",
      "=== epoch:8, train acc:0.0825, test acc:0.11 ===\n",
      "train loss:2.384388855992707\n",
      "train loss:2.4041733437201414\n",
      "train loss:2.4092113674932447\n",
      "train loss:2.3486687540350637\n",
      "=== epoch:9, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.444171113443025\n",
      "train loss:2.379424119034981\n",
      "train loss:2.421753076792082\n",
      "train loss:2.3503710080706433\n",
      "=== epoch:10, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.4952312583279626\n",
      "train loss:2.467469964728146\n",
      "train loss:2.3593104090928834\n",
      "train loss:2.394142408706917\n",
      "=== epoch:11, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.417582428366451\n",
      "train loss:2.459523611020857\n",
      "train loss:2.4033523788677114\n",
      "train loss:2.4102314752290708\n",
      "=== epoch:12, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.445428035669745\n",
      "train loss:2.4012584268796346\n",
      "train loss:2.4164091470772573\n",
      "train loss:2.4132716304554944\n",
      "=== epoch:13, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.358396653736209\n",
      "train loss:2.418247173952251\n",
      "train loss:2.3556664450246347\n",
      "train loss:2.362019037245751\n",
      "=== epoch:14, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.4287609383906714\n",
      "train loss:2.3947992668637994\n",
      "train loss:2.3308288049189008\n",
      "train loss:2.348001605473411\n",
      "=== epoch:15, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.4200654064386233\n",
      "train loss:2.3363206012027464\n",
      "train loss:2.400841167313375\n",
      "train loss:2.372115578903684\n",
      "=== epoch:16, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.457277663652924\n",
      "train loss:2.395484340281509\n",
      "train loss:2.386997970265704\n",
      "train loss:2.340661295760821\n",
      "=== epoch:17, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.4460688664221872\n",
      "train loss:2.366255061840592\n",
      "train loss:2.36896918327732\n",
      "train loss:2.4074775382958937\n",
      "=== epoch:18, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.4416374981958744\n",
      "train loss:2.399366955535379\n",
      "train loss:2.380999216883636\n",
      "train loss:2.389231838956064\n",
      "=== epoch:19, train acc:0.085, test acc:0.11 ===\n",
      "train loss:2.4045048326140184\n",
      "train loss:2.428576676058103\n",
      "train loss:2.4446881905893325\n",
      "train loss:2.364403196289833\n"
     ]
    }
   ],
   "source": [
    "optimization_trial = 100\n",
    "results_val = {}\n",
    "results_train = {}\n",
    "for _ in range(optimization_trial): # 탐색한 하이퍼파라미터의 범위 지정===============\n",
    "    weight_decay = 10 ** np.random.uniform(-8, -4)\n",
    "    lr = 10 ** np.random.uniform(-6, -2)\n",
    "    \n",
    "    val_acc_list, train_acc_list = __train(lr, weight_decay)\n",
    "    print('val_acc: %.4f | lr: %.4f, weight_decay: %.4f' %\n",
    "              (val_acc_list[-1], lr, weight_decay)\n",
    "    )\n",
    "    \n",
    "    key = 'lr: %.4f, weight_decay: %.4f' % (lr, weight_decay)\n",
    "    results_val[key] = val_acc_list\n",
    "    results_train[key] = train_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('========== Hyper-Parameter Optimization Result ==========')\n",
    "graph_draw_num = 20\n",
    "col_num = 5\n",
    "row_num = int(np.ceil(graph_draw_num / col_num))\n",
    "i = 0\n",
    "\n",
    "for key, val_acc_list in sorted(results_val.items(), key=lambda x: x[1][-1], reverse=True):\n",
    "    print('Best-' + str(i+1) + '(val acc:' + str(val_acc_list[-1]) + ') | ' + key)\n",
    "    \n",
    "    plt.subplot(row_num, col_num, i+1)\n",
    "    plt.title('Best-' + str(i+1))\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    if i % 5:\n",
    "        plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    x = np.arange(len(val_acc_list))\n",
    "    plt.plot(x, val_acc_list)\n",
    "    plt.plot(x, results_train[key], '--')\n",
    "    i += 1\n",
    "    \n",
    "    if i >= graph_draw_num:\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
